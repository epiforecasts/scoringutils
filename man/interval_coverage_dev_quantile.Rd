% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metrics-quantile.R
\name{interval_coverage_dev_quantile}
\alias{interval_coverage_dev_quantile}
\title{Interval Coverage Deviation (For Quantile-Based Forecasts)}
\usage{
interval_coverage_dev_quantile(observed, predicted, quantile)
}
\arguments{
\item{observed}{numeric vector of size n with the observed values}

\item{predicted}{numeric nxN matrix of predictive
quantiles, n (number of rows) being the number of forecasts (corresponding
to the number of observed values) and N
(number of columns) the number of quantiles per forecast.
If \code{observed} is just a single number, then predicted can just be a
vector of size N.}

\item{quantile}{vector with quantile levels of size N}
}
\value{
A numeric vector of length n with the interval coverage deviation
for each forecast (comprising one or multiple prediction intervals).
}
\description{
Check the agreement between desired and actual interval coverage
of a forecast.

The function is similar to \code{\link[=interval_coverage_quantile]{interval_coverage_quantile()}},
but takes all provided prediction intervals into account and
compares nominal interval coverage (i.e. the desired interval coverage) with
the actual observed interval coverage.

A central symmetric prediction interval is defined by a lower and an
upper bound formed by a pair of predictive quantiles. For example, a 50\%
prediction interval is formed by the 0.25 and 0.75 quantiles of the
predictive distribution. Ideally, a forecaster should aim to cover about
50\% of all observed values with their 50\% prediction intervals, 90\% of all
observed values with their 90\% prediction intervals, and so on.

For every prediction interval, the deviation is computed as the difference
between the observed interval coverage and the nominal interval coverage
For a single observed value and a single prediction interval, coverage is
always either 0 or 1 (\code{FALSE} or \code{TRUE}). This is not the case for a single
observed value and multiple prediction intervals,
but it still doesn't make that much
sense to compare nominal (desired) coverage and actual coverage for a single
observation. In that sense coverage deviation only really starts to make
sense as a metric when averaged across multiple observations).

Positive values of interval coverage deviation are an indication for
underconfidence, i.e. the forecaster could likely have issued a narrower
forecast. Negative values are an indication for overconfidence, i.e. the
forecasts were too narrow.

\deqn{
\textrm{interval coverage deviation} =
\mathbf{1}(\textrm{observed value falls within interval}) -
\textrm{nominal interval coverage}
}{
interval coverage deviation =
1(observed value falls within interval) - nominal interval coverage
}
The interval coverage deviation is then averaged across all prediction
intervals. The median is ignored when computing coverage deviation.
}
\keyword{metric}

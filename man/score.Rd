% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/score.R
\name{score}
\alias{score}
\title{Evaluate forecasts}
\usage{
score(data, metrics = NULL, ...)
}
\arguments{
\item{data}{A data.frame or data.table with the predictions and observations.
The following columns need to be present:
\itemize{
\item \code{true_value} - the true observed values
\item \code{prediction} - predictions or predictive samples for one
true value. (You only don't need to provide a prediction column if
you want to score quantile forecasts in a wide range format.)}
For integer and continuous forecasts a \code{sample} column is needed:
\itemize{
\item \code{sample} - an index to identify the predictive samples in the
prediction column generated by one model for one true value. Only
necessary for continuous and integer forecasts, not for
binary predictions.}
For a quantile-format forecast you should provide a column called \code{quantile}:
\itemize{
\item \code{quantile}: quantile to which the prediction corresponds
}}

\item{metrics}{the metrics you want to have in the output. If \code{NULL} (the
default), all available metrics will be computed. For a list of available
metrics see \code{\link[=available_metrics]{available_metrics()}}}

\item{...}{additional parameters passed down to lower-level functions.
For example, the following arguments can change how weighted interval
scores are computed:
\itemize{
\item \code{count_median_twice} that controls how the interval scores for different
intervals are summed up. This should be a logical (default is \code{FALSE}) that
indicates whether or not to count the median twice when summarising.
This would conceptually treat the
median as a 0\% prediction interval, where the median is the lower as well as
the upper bound. The alternative is to treat the median as a single quantile
forecast instead of an interval. The interval score would then
be better understood as an average of quantile scores.)
}}
}
\value{
A data.table with unsummarised scores. There will be one score per
quantile or sample, which is usually not desired, so you should always run
\code{\link[=summarise_scores]{summarise_scores()}} on the unsummarised scores.
}
\description{
The function \code{score} allows automatic scoring of forecasts and
wraps the lower level functions in the \pkg{scoringutils} package.

It can be used to score forecasts in a quantile-based, sample-based, or
binary format. To obtain an overview of what input is expected, have a look
at the \link{example_quantile}, \link{example_continuous}, \link{example_integer}, and
\link{example_binary} data sets.

You can (and should) check your input using the function \code{\link[=check_forecasts]{check_forecasts()}}
before scoring.

To obtain a quick overview of the evaluation metrics used, have a look at the
\link{metrics_summary} data included in the package.
}
\examples{
library("scoringutils")
library(magrittr) # pipe operator

# usual workflow:
check_forecasts(example_quantile)
score(example_quantile) \%>\%
  add_coverage(by = c("model", "target_type")) \%>\%
  summarise_scores(by = c("model", "target_type"))

# Other forecast formats with different metrics
score(example_binary)
score(example_quantile)
score(example_integer)
score(example_continuous)
}
\references{
Funk S, Camacho A, Kucharski AJ, Lowe R, Eggo RM, Edmunds WJ
(2019) Assessing the performance of real-time epidemic forecasts: A
case study of Ebola in the Western Area region of Sierra Leone, 2014-15.
PLoS Comput Biol 15(2): e1006785. \url{doi:10.1371/journal.pcbi.1006785}
}
\author{
Nikos Bosse \email{nikosbosse@gmail.com}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-confidence-set.R
\name{get_model_confidence_set}
\alias{get_model_confidence_set}
\title{Compute model confidence set from pairwise comparisons}
\usage{
get_model_confidence_set(pairwise, compare = "model", alpha = 0.1)
}
\arguments{
\item{pairwise}{A data.table of pairwise comparisons as produced by
\code{\link[=get_pairwise_comparisons]{get_pairwise_comparisons()}}.}

\item{compare}{Character vector with a single column name that defines the
elements being compared. By default this is \code{"model"}.}

\item{alpha}{Numeric, the significance level for determining MCS membership.
By default this is 0.1, meaning the MCS contains the best models with
90 percent confidence.}
}
\value{
A data.table with the results of the model confidence set
computation, containing the relative skill (\code{relative_skill}), the p-value
from comparison against the best model (\code{pval_vs_best}), the adjusted
p-value using the Holm method (\code{adj_pval_vs_best}), and whether the model
is included in the MCS (\code{in_mcs}). Any grouping columns present in the
pairwise input are preserved.
}
\description{
Identify the set of models that cannot be statistically distinguished from
the best model at a given confidence level. This implements the Model
Confidence Set concept from Hansen, Lunde & Nason (2011) using the
pairwise comparison results from \code{\link[=get_pairwise_comparisons]{get_pairwise_comparisons()}}.

The procedure identifies the best model (lowest relative skill) and tests
whether each other model is significantly worse. Models where the null
hypothesis of equal performance cannot be rejected are included in the MCS.

\emph{Interpretation}

Models in the MCS are those that cannot be ruled out as being the best at
the specified confidence level. A larger MCS indicates more uncertainty
about which model is truly best, often due to limited data, similar
performance, or high score variability.

\emph{Conditional MCS}

To compute separate confidence sets for different subgroups (e.g., locations,
target types, epidemic phases), use the \code{by} argument in
\code{\link[=get_pairwise_comparisons]{get_pairwise_comparisons()}}.

\emph{Sequential MCS}

To track how the MCS evolves over time, filter scores cumulatively before
computing pairwise comparisons.
}
\examples{
\dontshow{
  data.table::setDTthreads(2) # restricts number of cores used on CRAN
}

scores <- example_quantile |>
  as_forecast_quantile() |>
  score()

# Basic MCS
scores |>
  get_pairwise_comparisons() |>
  get_model_confidence_set()

# Conditional MCS by target type
scores |>
  get_pairwise_comparisons(by = "target_type") |>
  get_model_confidence_set()

# More stringent confidence level
scores |>
  get_pairwise_comparisons() |>
  get_model_confidence_set(alpha = 0.05)
}
\references{
Hansen, P. R., Lunde, A., & Nason, J. M. (2011). The model confidence set.
Econometrica, 79(2), 453-497. \doi{10.3982/ECTA5771}

Arnold, S., Henzi, A., & Ziegel, J. F. (2024). Sequential model confidence
sets. \url{https://arxiv.org/abs/2404.18678}

Borusyak, K., & Jaravel, X. (2025). Conditional method confidence set.
\url{https://arxiv.org/abs/2505.21278}
}
\seealso{
\code{\link[=get_pairwise_comparisons]{get_pairwise_comparisons()}} for generating the input.
}
\keyword{scoring}

{"type":"system","subtype":"init","cwd":"/Users/nikos/github-synced/scoringutils-pipeline","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","TaskStop","AskUserQuestion","Skill","EnterPlanMode","ToolSearch"],"mcp_servers":[],"model":"claude-opus-4-6","permissionMode":"bypassPermissions","slash_commands":["keybindings-help","debug","compact","context","cost","init","pr-comments","release-notes","review","security-review","insights"],"apiKeySource":"none","claude_code_version":"2.1.39","output_style":"default","agents":["Bash","general-purpose","statusline-setup","Explore","Plan","claude-code-guide"],"skills":["keybindings-help","debug"],"plugins":[],"uuid":"bdb43d51-951d-4617-8da2-713b62525ce5","fast_mode_state":"off"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QTx8SVkQc8o2469Do7Tzso","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll start by verifying the worktree and then proceeding with the task."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2611,"cache_read_input_tokens":18004,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2611},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"0bda1cae-4f1a-4b7c-bc07-1ce3099598c6"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QTx8SVkQc8o2469Do7Tzso","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EiZ6Ubj3XLjv5XwEswXgg8","name":"Bash","input":{"command":"git rev-parse --show-toplevel","description":"Verify git worktree root"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2611,"cache_read_input_tokens":18004,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2611},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"ea56d026-96b7-4821-92a0-e105f761ff1e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QTx8SVkQc8o2469Do7Tzso","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DbkSLYS7Hx5ubPKjT8THSe","name":"Bash","input":{"command":"git branch --show-current","description":"Verify current branch"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":2611,"cache_read_input_tokens":18004,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2611},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f17e015d-9d17-45b1-8e97-0e32db4e55b9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DbkSLYS7Hx5ubPKjT8THSe","type":"tool_result","content":"ralph","is_error":false}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"79c2af76-3119-4873-9981-a4a7410f33c0","tool_use_result":{"stdout":"ralph","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EiZ6Ubj3XLjv5XwEswXgg8","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline","is_error":false}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"8c7d2bf1-5ce9-4c1f-9fcc-5da7dabbc687","tool_use_result":{"stdout":"/Users/nikos/github-synced/scoringutils-pipeline","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01HaFvfknhszNMtsxexF7rW7","type":"message","role":"assistant","content":[{"type":"text","text":"Good — correct worktree and branch. Now let me fetch and merge main."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":32,"cache_creation_input_tokens":212,"cache_read_input_tokens":20615,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":212},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"49ef7af6-c202-44c0-b267-6706e0b43b45"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01HaFvfknhszNMtsxexF7rW7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NJxje96aeKJUCteMbSmNX1","name":"Bash","input":{"command":"git fetch origin main && git merge origin/main --ff-only","description":"Update ralph branch with latest main"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":32,"cache_creation_input_tokens":212,"cache_read_input_tokens":20615,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":212},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"15cca6e7-935b-49cb-a35b-85e4924248a7"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NJxje96aeKJUCteMbSmNX1","type":"tool_result","content":"Already up to date.\nFrom https://github.com/epiforecasts/scoringutils\n * branch              main       -> FETCH_HEAD","is_error":false}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d91dccbd-b92b-497e-80de-d70db2bb13af","tool_use_result":{"stdout":"Already up to date.\nFrom https://github.com/epiforecasts/scoringutils\n * branch              main       -> FETCH_HEAD","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016AsqNxuiXiQW7oP4e78d3A","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the triage table to find the next automatable issue without tests."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":182,"cache_read_input_tokens":20827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":182},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7e6c0bcb-949b-473f-bac9-c4ac5920de6d"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016AsqNxuiXiQW7oP4e78d3A","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XSx58wg6t3zUxWDExtZxwX","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":182,"cache_read_input_tokens":20827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":182},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d0853742-f32a-43cb-bcfd-6b3644d6af2c"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XSx58wg6t3zUxWDExtZxwX","type":"tool_result","content":"     1→# scoringutils Issue Triage\n     2→\n     3→> Auto-generated by Ralph triage loop. Do not edit manually during the loop.\n     4→\n     5→## Summary\n     6→\n     7→| Metric | Count |\n     8→|--------|-------|\n     9→| Total open issues | 106 |\n    10→| Triaged | 106 |\n    11→| Remaining | 0 |\n    12→\n    13→## Pipeline\n    14→\n    15→- [ ] **Test design** — Test specs written for automatable issues\n    16→- [ ] **Implement** — Fixes implemented, PRs created\n    17→- [ ] **Review** — All PRs independently reviewed\n    18→- [ ] **Summary** — Human summary generated\n    19→\n    20→## Issues\n    21→\n    22→| # | Title | Labels | Opened | Category | Priority | Complexity | Automatable | Status Note | Dependencies | Action Summary | Has Tests | Implemented | PR | Reviewed |\n    23→|---|-------|--------|--------|----------|----------|------------|-------------|-------------|--------------|----------------|-----------|-------------|-----|----------|\n    24→| 1065 | Release reminder - February 2026 | | 2026-02-02 | meta | medium | medium | partially | Automated reminder. Dev version (2.1.2.9000) has multivariate feature + bug fix accumulated over 161 days. No blocking bugs. Two open PRs (#1060, #1062) are infrastructure changes. | Maintainers should decide whether to merge #1060/#1062 before releasing. | Decide whether to cut a new release (likely v2.2.0 given multivariate feature). If yes, run `usethis::use_release_issue()` and proceed with CRAN submission. If not, close the issue. | N/A | N/A | — | N/A |\n    25→| 1064 | Pre-ranking for multivariate calibration assessment | | 2026-01-30 | feature | medium | large | no | No pre-ranking or multivariate calibration diagnostics exist in the codebase. The `forecast_sample_multivariate` class and energy score are implemented and stable. Design decision needed: integrate into `score()` (Option A) or standalone `get_multivariate_ranks()` function (Option B). MST method may need `igraph` dependency. | None blocking. Builds on existing `forecast_sample_multivariate` infrastructure. | Implement pre-ranking methods (multivariate rank, optionally MST rank) from Gneiting et al. (2008) as calibration diagnostics for multivariate forecasts, after resolving the API design choice with maintainers. | N/A | N/A | — | N/A |\n    26→| 1057 | Revise README to remove news about the package rewrite | documentation | 2026-01-29 | documentation | low | medium | partially | Open, no assignee. The rewrite messaging and Google Drive paper links appear in 4 locations in README.Rmd. Mechanical edits are straightforward but replacement text requires editorial decisions about where to point users for documentation. | Loosely related to #810 (pkgdown for dev docs) and #759 (future of scoringutils.Rmd vignette). | Edit `README.Rmd` to remove/soften the \"major re-write\" paragraph and replace Google Drive paper links with pointers to package vignettes/docs, then re-render README.md. Confirm preferred documentation hierarchy with maintainers first. | N/A | N/A | — | N/A |\n    27→| 1055 | Model confidence sets | feature request | 2026-01-19 | feature | medium | large | no | Design phase — methodology not yet agreed upon. 6 comments with active debate. Naive pairwise p-value approach acknowledged as incomplete. Three alternatives discussed: Hansen et al. MCS, novel extension for incomplete sets, Bayesian approach. No consensus reached. | Relates to #750 (p-value computation refactor), #769 (pairwise comparison arguments), #37 (Diebold-Mariano test), #1022 (two-model pairwise). | Resolve design consensus on which MCS methodology to implement (Hansen et al. on complete sets, novel incomplete-set extension, or Bayesian), then implement `get_model_confidence_set()` building on existing pairwise comparison infrastructure. | N/A | N/A | — | N/A |\n    28→| 1046 | multivariate scoring in scoring rules vignette | documentation | 2025-11-04 | documentation | low | small | partially | Open, agreed upon by maintainers. The scoring-rules vignette has zero mentions of multivariate scoring. A dedicated multivariate vignette already exists. Only a cross-reference and brief section are missing. | None. All underlying code and the dedicated multivariate vignette already exist. | Add a short section to `vignettes/scoring-rules.Rmd` describing the energy score for multivariate forecasts and cross-linking to the existing `scoring-multivariate-forecasts` vignette. No code changes needed. | N/A | N/A | — | N/A |\n    29→| 1044 | Remove the commented out vignette code. | | 2025-09-23 | cleanup | low | small | yes | Still relevant. Two HTML comment blocks remain: a WIP \"Details on the grouping\" section in `scoring-multivariate-forecasts.Rmd` (lines 88-102) and a ~50-line PIT/Calibration section in `scoring-rules.Rmd` (lines 444-493). Originated from PR #998 review comment. | None. | Delete the two HTML-commented-out code blocks from `vignettes/scoring-multivariate-forecasts.Rmd` and `vignettes/scoring-rules.Rmd`. Optionally confirm with maintainers whether the PIT/Calibration text should be preserved elsewhere. | N/A | [ ] | — | [ ] |\n    30→| 1043 | Update print method for multivariate forecasts to show `joint_across` | | 2025-09-21 | enhancement | low | small | yes | Still relevant. No `print.forecast_sample_multivariate` method exists; the generic `print.forecast` handles all types. `joint_across` is not stored as an attribute — `set_grouping()` computes `.mv_group_id` but discards the original `joint_across` value. | Builds on multivariate infrastructure from merged PR #998. | Add a `print.forecast_sample_multivariate()` method that displays `joint_across` columns. Requires either storing `joint_across` as an attribute during object construction or computing it as the set difference between forecast unit and `get_grouping()` output. Update test snapshots. | [x] | [ ] | — | [ ] |\n    31→| 1026 | as_forecast_sample.forecast_quantile | enhancement | 2025-07-13 | enhancement | medium | medium | partially | Still relevant. The reverse conversion (`as_forecast_quantile.forecast_sample`) exists, but `as_forecast_sample.forecast_quantile` does not. No distribution-fitting dependencies in DESCRIPTION. Author plans to borrow from hubverse approach. | Related to #557 (sample_to_quantile.numeric). May introduce new dependency (e.g., `distfromq`). | Implement `as_forecast_sample.forecast_quantile()` S3 method that fits a distribution or uses interpolation to approximate the predictive CDF from quantiles and draws samples. Requires design decision on approximation method and potential new package dependency. | N/A | N/A | — | N/A |\n    32→| 1022 | Let `get_pairwise_comparison()` run with two models? | | 2025-07-03 | enhancement | low | small | yes | Still relevant. The check at line 162 of `R/pairwise-comparisons.R` calls `cli_abort()` when `length(setdiff(comparators, baseline)) < 2`, blocking the 2-models-with-baseline case. Maintainer has expressed agreement to change to a warning. Also has typo \"compairisons\". | None. Self-contained change. | Change the `cli_abort()` to `cli_warn()` at line 162 of `R/pairwise-comparisons.R` so that 2 models with one as baseline emits a warning instead of an error. Update test expectations and fix the \"compairisons\" typo. | [x] | [ ] | — | [ ] |\n    33→| 1002 | LaTeX not rendering in function reference | | 2025-05-20 | documentation | medium | small | yes | Still relevant. pkgdown defaults to `mathml` which doesn't handle the 63 `\\eqn{}`/`\\deqn{}` occurrences in 4 metrics files. Upstream r-lib/pkgdown#2704 is closed (won't fix mathml); recommended fix is to use `mathjax` or `katex`. No `math-rendering` setting exists in `_pkgdown.yml`. | None internally. CRAN release needed for release site fix. | Add `math-rendering: katex` (or `mathjax`) under the `template:` key in `_pkgdown.yml` and rebuild the pkgdown site. One-line config change fixes all 63 LaTeX expressions across 4 documentation files. | [x] | [ ] | — | [ ] |\n    34→| 986 | Test scores are correct | | 2025-02-21 | enhancement | medium | medium | partially | Still relevant. WIS has reference tests (CovidHubUtils), `logs_binary` validates against `Metrics::ll`, `rps_ordinal` against `scoringRules::rps_probs`. But CRPS/DSS/log_score for sample-based forecasts, dispersion, overprediction, underprediction lack absolute-value tests. No snapshot tests pin numerical outputs on example datasets. | None | Add (1) snapshot tests pinning `score()` output on each built-in example dataset, and (2) targeted correctness tests validating key sample-based scoring functions against known analytical solutions or external reference implementations. | N/A | N/A | — | N/A |\n    35→| 983 | Create `.data.frame` methods for `as_forecast<type>` | | 2025-01-14 | refactor | low | small | yes | Still relevant. Prerequisite #981 (making `as_forecast_*` S3 generics) is done. Currently all 7 types only have `.default` methods; no `.data.frame` methods exist. The `.default` methods silently accept any type and rely on `as.data.table()` coercion deep inside. | #981 (done). No blockers. | Rename the 7 existing `.default` methods to `.data.frame` (since they assume data.frame-like input), then create new `.default` methods that error with a helpful message about unsupported types. Update NAMESPACE, docs, and tests. | [x] | [ ] | — | [ ] |\n    36→| 975 | Add link to score definitions in `summarise_score()` | | 2024-11-05 | enhancement | low | small | yes | Still relevant. No `print.scores` method exists anywhere in the codebase. Scores objects fall through to data.table's default print. The scoring rules vignette exists at the expected URL. Maintainers favor option 1 (link to docs) over printing definitions. | Closely related to #667 (create `print.scores` method). Should be aware of #935 (print side-effects on column mutation). | Create a `print.scores()` S3 method in `R/class-scores.R` that calls `NextMethod()` then appends a `cli_text()` link to the scoring rules vignette. Ideally coordinate with #667 to also show the metrics used. | [x] | [ ] | — | [ ] |\n    37→| 944 | Make `get_metrics()` more customisable | enhancement, feature request | 2024-10-08 | enhancement | low | medium | partially | Still relevant. `get_metrics()` is an S3 generic with `select`/`exclude` args (via #832/#903), but the proposed `replace` argument for inline metric customization has not been implemented. The `add_args` idea from the issue body is less well-defined. | #832 (done). Related to #789 (documenting customization workflow). | Add a `replace` argument to `select_metrics()` and propagate through all 7 `get_metrics.forecast_*` methods, accepting a named list of functions to substitute by name. Evaluate whether `add_args` is worth implementing or should be dropped. | N/A | N/A | — | N/A |\n    38→| 942 | Discrimination plots for binary forecasts | enhancement, feature request | 2024-10-07 | feature | low | small | yes | Still relevant. No binary-specific plot functions exist in the codebase. No discrimination plot, reliability diagram, or any binary visualization exists. The `forecast_binary` class and `example_binary` dataset provide exactly the data structures needed. | None. Thematically adjacent to #49 (calibration plotting) and #286 (diagnostics) but no hard dependency. | Implement a new `plot_discrimination()` function that accepts a `forecast_binary` object, groups predicted probabilities by the two levels of observed, and renders overlapping density plots via ggplot2, with optional faceting by model. Add tests and docs. | [x] | [ ] | — | [ ] |\n    39→| 941 | Rethink `score()` and maybe make it not S3 anymore | refactor | 2024-10-06 | refactor | medium | medium | no | Still relevant. All 7 `score.forecast_*` S3 methods share near-identical boilerplate (clean, validate, reshape, apply_metrics, as_scores). Only the reshape step differs per type. No refactoring has been done since the issue was opened. Both opener and reviewer agree on the direction. | Related to #338 (cross-type metrics). Benefits from #982 (done). | Refactor `score()` from 7 S3 methods into a single function by extracting the type-specific data reshaping into a new internal S3 generic (e.g., `prepare_for_scoring()`). Requires design decision on the preparation step's interface. | N/A | N/A | — | N/A |\n    40→| 939 | remove `check_input_<forecast_type>` functions | refactor | 2024-10-03 | refactor | low | small | partially | Still relevant. All 5 `check_input_*` functions exist. 3 (sample, quantile, interval) are unused in production code — only tested. 2 (binary, point) are used in `assert_forecast` methods. Other types (sample, quantile) already skip the check pattern, showing inconsistency. | Supersedes #684 (subset of this issue). | Delete all 5 `check_input_*` functions and their man pages. For the 2 in use (binary, point), refactor call sites to call `assert_input_*` directly or inline `check_try()`, matching the pattern already used by sample/quantile. Close #684 as duplicate. | N/A | N/A | — | N/A |\n    41→| 938 | Rename/refactor? `assert_dims_ok_point` | refactor, low-priority | 2024-10-03 | refactor | low | small | partially | Still relevant. `assert_dims_ok_point` is used by both `assert_input_point` and `assert_input_binary`, making the `_point` suffix misleading. The function is a general-purpose dimension check. Companion `check_dims_ok_point` also exists. ~5 files to update. | None. | Rename `assert_dims_ok_point` (and `check_dims_ok_point`) to a type-agnostic name (e.g., `assert_dims_ok_scalar` or `assert_dims_match`). Update definition, 2 call sites, tests, and docs. Optionally move out of `metrics-point.R` into a shared file. | N/A | N/A | — | N/A |\n    42→| 935 | `forecast` and `scores` objects print output every time a column is changed | high-priority | 2024-09-29 | bug | medium | large | no | Still relevant. Core bug unfixed: `print.forecast` dispatches to `print.data.table` via `NextMethod()`, which breaks data.table's internal `:=` print-suppression (call stack too deep for `shouldPrint()`). PR #956 only worked around nominal forecast validation errors with a `nrow > 30` hack. The `scores` side may no longer be affected (no `print.scores` exists). | Related to #667 (print.scores — would reintroduce problem), #685 (suppress printing in tests), #1043 (multivariate print). | Design decision needed: (a) accept cosmetic annoyance, (b) reimplement `print.forecast` without dispatching to `print.data.table` (e.g., use `format.data.table` + manipulate `.global$print`), or (c) pursue upstream data.table fix per @MichaelChirico's suggestion. | N/A | N/A | — | N/A |\n    43→| 934 | Use illustration of local and global scores | documentation | 2024-09-28 | documentation | low | small | partially | Still relevant. `score-locality.png` already exists in `vignettes/` but is orphaned — not referenced by any vignette. The scoring-rules vignette mentions local/global in text only, with no visual. Code to regenerate is in the issue body. | Sibling issues: #929, #930, #933 (all repurpose manuscript illustrations). Consider batching. | Add the existing `score-locality.png` to `scoring-rules.Rmd` (or a new comparative vignette) with an explanatory paragraph on local vs. global scoring rules. Coordinate with #929/#930/#933 for a unified approach. | N/A | N/A | — | N/A |\n    44→| 933 | Use nice illustration of CRPS/DSS/Log score + the number of samples needed for scores to converge | documentation | 2024-09-28 | documentation | low | medium | partially | Still relevant. `score-convergence-outliers.png` already exists in `vignettes/` but is orphaned (not referenced by any vignette). Issue #758 contains a detailed draft vignette stub (\"Choosing a scoring rule\") that already references this PNG with prose. Should be batched with siblings #929, #930, #934. | Sibling issues #929, #930, #934. Parent issue #758 (scoring rules explanation vignette). Related to #759 (vignette future). | Create a new \"Choosing a scoring rule\" vignette (per #758's stub) or integrate `score-convergence-outliers.png` into `scoring-rules.Rmd` with explanatory text on sample convergence and score properties. Best addressed as a batch with #929/#930/#934 under #758. | N/A | N/A | — | N/A |\n    45→| 930 | Use nice illustration of the effect of increasing the mean on increasing average scores | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. `illustration-effect-scale.png` already exists in `vignettes/` but is orphaned. A deleted stub vignette (`Choosing-a-score.Rmd`) once referenced it. Author expressed uncertainty (\"maybe we don't want it anymore\"). Should be batched with siblings #929, #933, #934. | Sibling issues #929, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future). | Decide whether to integrate `illustration-effect-scale.png` into `scoring-rules.Rmd` or a new \"Choosing a score\" vignette, with text explaining how average scores scale with forecast target magnitude. If unwanted, close and delete orphaned PNG. Address with #929/#933/#934 as batch. | N/A | N/A | — | N/A |\n    46→| 929 | Use nice illustration of Sharpness and calibration | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. Unlike siblings (#930, #933, #934), the calibration/sharpness PNG does **not** exist in the repo — it was never generated. Code to create it is in the issue body. The `scoring-rules.Rmd` has a commented-out calibration section (lines ~449-492) where this illustration would naturally fit. | Sibling issues #930, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future), #785 (vignette updates). | Generate `calibration-sharpness-illustration.png` from the code in the issue body, place in `vignettes/`, and integrate into `scoring-rules.Rmd` (or a new \"Choosing a score\" vignette). Coordinate with #930/#933/#934 batch. | N/A | N/A | — | N/A |\n    47→| 927 | Make all internal columns, in particular `forecast_id`, more robust by prefixing it with \"scoringutils_\" | good first issue, high-priority | 2024-09-26 | refactor | high | medium | partially | Still relevant. Unprefixed internal columns (`forecast_id`, `weight`, `boundary`) risk collision with user data columns. Codebase already mixes two conventions: `.scoringutils_*` (e.g., `.scoringutils_N`) and `scoringutils_Internal*`. ~3 source files, 1 globalVariables file, 1 snapshot to update for `forecast_id` alone. Not a breaking change — all affected columns are internal. | None blocking. Self-contained refactor. | Rename unprefixed internal temp columns (`forecast_id`, `weight`, `boundary`) to `.scoringutils_` prefix, matching existing convention. Update `R/helper-quantile-interval-range.R`, `R/metrics-quantile.R`, `R/z-globalVariables.R`, and test snapshots. Also unify the two naming conventions (`.scoringutils_*` vs `scoringutils_Internal*`). | N/A | N/A | — | N/A |\n    48→| 922 | remove `check_columns_present` | | 2024-09-25 | cleanup | low | small | yes | Still relevant. `check_columns_present` (and `test_columns_present`) are internal functions with 10 call sites across 9 files. All can be replaced by `checkmate::assert_subset`/`check_subset`/`test_subset` (already a dependency). One call site in `pairwise-comparisons.R:143` uses a custom error message and needs slightly different handling. No user-facing API impact. | Related to #839 (remove `test_columns_not_present`) — both modify `R/check-input-helpers.R`, should be batched. | Replace all 10 call sites of `check_columns_present` (and 1 of `test_columns_present`) with equivalent `checkmate` functions, then delete both functions and their tests. Consider batching with #839. | [x] | [ ] | — | [ ] |\n    49→| 909 | Compact version of `get_duplicate_forecasts()` | enhancement, good first issue, help wanted | 2024-09-13 | enhancement | low | small | yes | Already implemented. The `counts` parameter on `get_duplicate_forecasts()` provides exactly the compact output requested. Tests exist. Issue can be closed. | None | Close this issue — the `counts` argument already provides compact/aggregated duplicate output. No further code changes needed. | N/A | N/A | — | N/A |\n    50→| 907 | coverage of function factory | enhancement | 2024-09-12 | enhancement | low | small | partially | Still relevant. No factory helper exists. Users must manually use `purrr::partial()` (documented in `score()` docs). Only `interval_coverage` benefits currently. Hard-coded 50% and 90% variants in `get_metrics.forecast_quantile()`. Discussion stalled after 5 comments with no consensus on approach. | Related to #451 (quantile/interval metric organization), #668 (coverage flexibility). | Add either a generic `expand_metric()` utility or a `coverage_ranges` argument to `get_metrics.forecast_quantile()` to programmatically generate multiple parameterized coverage metric variants. Needs design decision on approach given only one metric currently benefits. | N/A | N/A | — | N/A |\n    51→| 898 | Support for \"Mixture of Parameters\" scoring | feature request | 2024-09-06 | feature | low | large | partially | Still relevant but low urgency. No `forecast_distribution` class exists. Prerequisites #832 (metrics S3 rework) and #846 (ordinal class) are done. Original requester has deprioritized. Would require new class, input format design, dispatch to `scoringRules` parametric functions, and mixture handling. | #888 (S3 rework of `get_duplicate_forecasts()` — minor blocker for clean extensibility). Builds on completed #832, #846. | Implement a new `forecast_distribution` class for scoring forecasts expressed as parametric distributions or mixtures, dispatching to `scoringRules`' closed-form scoring functions. Deferred until active demand — keep on `scoringutils-2.x` milestone. | N/A | N/A | — | N/A |\n    52→| 895 | Check quantile prediction order helper function | enhancement | 2024-08-19 | enhancement | medium | small | yes | Still relevant. Monotonicity check only exists deep in `bias_quantile_single_vector()` (metrics-quantile.R:495) as a hard error. No early warning in `assert_forecast.forecast_quantile()`. No user-facing diagnostic function. Issue #412 is the maintainer-created parent with an agreed plan (steps 1 and 3 not done). | Duplicate of / should be resolved together with #412. | Create a user-facing helper (e.g., `get_non_monotonic_forecasts()`) to identify rows where predictions decrease with increasing quantile level, and add a warning in `assert_forecast.forecast_quantile()`. Resolves both #895 and #412. | [x] | [ ] | — | [ ] |\n    53→| 889 | Make `get_protected_columns()` S3 to avoid hard-coding things | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. `get_protected_columns()` is a plain function with a hard-coded superset of all column names for all forecast types. Not S3. Only 2 call sites (both in `forecast-unit.R`). The `intersect()` filter masks the problem but prevents extensibility for new forecast classes. No progress made. | Coordinate with #888 (same S3 pattern for `get_duplicate_forecasts()`). Unblocks #852 (new forecast class workflow). Largely resolves #740 (`get_forecast_unit` customization). | Convert `get_protected_columns()` into an S3 generic with per-class methods so each forecast type declares its own protected columns. Coordinate with #888 for consistent pattern. | N/A | N/A | — | N/A |\n    54→| 888 | Rework `get_duplicate_forecasts()` to S3 to avoid hard-coding columns and types | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. Function hard-codes `c(\"sample_id\", \"quantile_level\", \"predicted_label\")` in two places instead of dispatching on S3 class. No work done. Codebase has many S3 precedents now. | Coordinate with #889 (same pattern for `get_protected_columns()`). Partially blocks #898, #852. Related to #740. | Convert `get_duplicate_forecasts()` into an S3 generic with per-class methods where each method knows its own type-specific columns. Retain a `.data.frame`/`.default` method with current column-sniffing logic for backward compatibility. | N/A | N/A | — | N/A |\n    55→| 885 | Functions to export or make internal | refactor, high-priority | 2024-08-10 | refactor | medium | medium | no | Partially done. `validate_forecast()` already deleted (PR #921). Remaining: `as_forecast_generic()`, `as_scores()`, `apply_metrics()` still internal; `new_forecast()` ambiguously exported with `@keywords internal`. Design decision needed on which functions to export for custom forecast class authors. | Depends on #746 (closed). Blocks custom forecast class creation. Related to #852 (design workflow for new classes). | Decide final export list for custom forecast class API: export `as_forecast_generic()`, `as_scores()`, `apply_metrics()`, resolve ambiguous `new_forecast()` status, and update NAMESPACE. Needs maintainer decision on naming/prefixing. | N/A | N/A | — | N/A |\n    56→| 880 | Allow users to specify the quantile in `as_forecast_point.forecast_quantile()? | | 2024-07-30 | enhancement | low | small | yes | Still relevant. Function hard-codes `0.5` on two lines (107, 115) in `R/class-forecast-quantile.R`. Design decisions already resolved in PR #876 discussion: parameter name `quantile_level`, default `0.5`, passed via `...`. No work done since issue opened. | None. Self-contained enhancement. | Add a `quantile_level` parameter (default `0.5`) to `as_forecast_point.forecast_quantile()`, replacing the two hard-coded `0.5` references, then add tests and documentation. | [x] | [ ] | — | [ ] |\n    57→| 872 | Add a reference for CRPS decomposition approach. | | 2024-07-25 | documentation | low | small | partially | Still relevant. `crps_sample()` in `R/metrics-sample.R` has only a `scoringRules` package reference, not one for the decomposition approach. `wis()` already properly cites Bracher et al. 2021. Minor decision needed on which paper(s) to cite: Bracher et al. 2021 and/or Arnold et al. 2023. | Related to #870 (CRPS/WIS decomposition refactor). Could be addressed in same PR. | Add `@references` entries to `crps_sample()` roxygen block citing paper(s) formalizing the overprediction/underprediction/dispersion decomposition (likely Bracher et al. 2021 and/or Arnold et al. 2023). | N/A | N/A | — | N/A |\n    58→| 870 | Refactor CRPS and WIS decomposition | refactor | 2024-07-22 | refactor | low | medium | partially | Partially addressed. PR #985 (Feb 2025) simplified `crps_sample()` decomposition internally, but the structural duplication remains: `crps_sample()`, `wis()`, and `interval_score()` each independently implement `separate_results` branching, and 6 wrapper functions (3 sample + 3 quantile) repeat identical extraction patterns. | Related to #872 (CRPS decomposition reference). Filed during PR #854 review. On `scoringutils-2.x` milestone. | Extract the decomposition logic (`separate_results` branching and wrapper function boilerplate) into a shared internal helper or factory pattern so `crps_sample()`, `wis()`, and `interval_score()` delegate to the same mechanism instead of each implementing it independently. | N/A | N/A | — | N/A |\n    59→| 852 | Design workflow for creating new forecast classes | enhancement | 2024-07-10 | enhancement | high | large | no | Still relevant. The building blocks exist (`new_forecast()` exported, `as_forecast_generic()` internal, pattern visible in 7 class files) but no documentation, vignette, or guide for third-party class creation exists. Three prerequisite S3 refactors (#889, #888, #740) remain open and block clean extensibility because `get_protected_columns()` and `get_duplicate_forecasts()` hard-code column names, preventing new classes from working seamlessly. `as_forecast_generic()`, `apply_metrics()`, and `as_scores()` are still unexported (#885). | #889 (S3 `get_protected_columns`), #888 (S3 `get_duplicate_forecasts`), #740 (`get_forecast_unit` customization), #885 (export decision for helper functions). | Complete prerequisite S3 refactors (#889, #888), decide export list for class-creation helpers (#885), then write a vignette or article documenting the step-by-step workflow for creating a custom `forecast_*` class (define `as_forecast_<type>`, `assert_forecast.<type>`, `score.<type>`, `get_metrics.<type>`, `get_protected_columns.<type>`, `get_duplicate_forecasts.<type>`). | N/A | N/A | — | N/A |\n    60→| 840 | Clean up input checks | | 2024-06-07 | refactor | low | medium | partially | Still relevant. Input checks are applied inconsistently: `assert_forecast.forecast_binary` and `assert_forecast.forecast_point` call `check_input_*` wrappers (double-validating with scoring functions), while sample/quantile/ordinal/nominal types skip this. `check-input-helpers.R` has a comment marking `check_try()` and wrappers for future deletion. Author leans toward pushing all checks to the scoring-function level. No work done. | Related to #939 (remove `check_input_*` functions), #839, #922. On `scoringutils-2.x` milestone. | Decide where input validation should live (scoring-function level vs. `assert_forecast` level vs. both-consistently). Then either remove `check_input_binary`/`check_input_point` calls from `assert_forecast` methods and delete wrappers + `check_try()`, or add missing checks to sample/quantile `assert_forecast` methods for consistency. | N/A | N/A | — | N/A |\n    61→| 839 | Remove `test_columns_not_present` | | 2024-06-07 | cleanup | low | small | yes | Still relevant. `test_columns_not_present()` is a trivial 1-line wrapper around `checkmate::test_names(..., disjunct.from = ...)` with exactly 1 production call site (`R/class-forecast-binary.R:68`) and 1 test block. `checkmate::test_names` is already imported. Straightforward removal. | Related to #922 (remove `check_columns_present`) and #840 (clean up input checks). Can be batched but has no blocking dependency. | Replace the single call in `R/class-forecast-binary.R:68` with `test_names(colnames(forecast), disjunct.from = ...)`, delete the function definition in `R/check-input-helpers.R`, delete the test block, and remove the generated man page. Optionally bundle with #922. | [x] | [ ] | — | [ ] |\n    62→| 826 | Update `plot_heatmap()` to be a table instead of a plot | | 2024-05-19 | enhancement | low | medium | partially | Still relevant. Accessibility concern from @Bisaloo is valid: current ggplot2 heatmap renders values as image text, inaccessible to screen readers. Conversation stalled — Bisaloo never replied to follow-up about output format (HTML/LaTeX). `kableExtra` is already in `Suggests`. This is a breaking change: function returns `ggplot` object, used with `+ facet_wrap()` in `inst/manuscript/`. Not used in any current vignette. Design decision needed on migration strategy. | None blocking. Thematically adjacent to #713 (visualization vignette). | Resolve stalled design conversation on output format and migration strategy (deprecate + new function vs. breaking change). Implement colored-table version using `kableExtra` (already in Suggests) or `gt` (new dep), update manuscript, replace test/snapshot, and deprecate or replace `plot_heatmap()`. | N/A | N/A | — | N/A |\n    63→| 825 | Package scaffolding | | 2024-05-19 | refactor | low | small | yes | Still relevant. Neither recommendation acted upon: (1) `Metrics` package still imported for 3 trivial functions (`ae`, `se`, `ape`) used only in `R/class-forecast-point.R` — these are one-line base-R replacements. `Metrics` did receive a 2025 CRAN update, reducing urgency. (2) `matrixStats` not adopted; 3 `apply()` calls in `R/metrics-sample.R` could benefit. Suggest splitting into two sub-tasks, prioritizing `Metrics` removal as a quick win. | None blocking. Removing `Metrics` requires updating vignettes (`scoring-rules.Rmd`) and tests (`test-metrics-binary.R`) that reference `Metrics::` functions. | (1) Replace `Metrics::ae/se/ape` with internal one-liners in `R/class-forecast-point.R`, remove from DESCRIPTION/NAMESPACE, update vignettes and tests. (2) Optionally evaluate adding `matrixStats` for 3 `apply()` calls — lower value, separate decision. | [x] | [ ] | — | [ ] |\n    64→| 823 | Reduce number of `try()`, `suppressMessages()`, `suppressWarnings()` used in the package | | 2024-05-19 | refactor | medium | medium | no | Still relevant. 8 direct `try()` calls + 6 indirect via `check_try()` + 1 `suppressWarnings(suppressMessages(...))` in R/ code. Usage has slightly increased since filing due to new `[.forecast` subsetting operators (PR #884). Each `try()` exists for a reason; removal requires architectural rethinking of validation flow, not simple find-and-replace. | Deeply linked to #935 (print on column change), #840 (input check cleanup), #939 (remove `check_input_*`), #885 (export decisions), #811 (batch warnings). | Address incrementally: (1) Replace blanket `try()` in subsetting operators with targeted `tryCatch()`, (2) add `verbose` params to internal validation paths to eliminate `suppress*()`, (3) replace `check_try()` with proper `check_*()` functions as part of #840. | N/A | N/A | — | N/A |\n    65→| 811 | Should `score()`/`apply_metrics()` return warning about failed metrics in a batch? | enhancement | 2024-05-07 | enhancement | low | small | yes | Still relevant. `run_safely()` in `R/score.R:210` uses `try()` + immediate `cli_warn()` per failed metric. No batching/deferring mechanism exists. Failed metrics silently dropped from `scores` object via `as_scores()` filtering. Blog post on deferred errors referenced in issue. Only 1 comment from maintainer (\"I like this idea\"). | None blocking. Tangentially related to #823 (reduce `try()`) and #382 (metric/column name clash warnings). | Modify `apply_metrics()`/`run_safely()` to collect error messages in a list during the `lapply` loop, then emit a single batched `cli_warn()` summarizing all failed metrics at the end. Update test expectations in `test-score.R`. | [x] | [ ] | — | [ ] |\n    66→| 810 | Clean up readme by using `pkgdown` to render dev version docs | | 2024-05-05 | documentation | low | small | yes | CLOSED (completed 2026-02-09). PR #1060 merged today, replacing R-based `packageVersion()` detection with pkgdown selective HTML (`.pkgdown-devel`/`.pkgdown-release` fenced divs). `_pkgdown.yml` already had `development: mode: auto`. Dev docs deployed at `/dev/` on gh-pages. | None. Fully resolved. | No action needed — issue closed via merged PR #1060. | N/A | N/A | — | N/A |\n    67→| 808 | Run lintr everywhere | | 2024-05-05 | cleanup | low | medium | partially | Active work in progress. PR #1062 (\"enable lintr for tests, inst, and vignettes\") is open but not yet merged. `.lintr` excludes all `tests/`, `inst/`, and `vignettes/*.R` files. CI only lints changed files on PRs. Main scope is `tests/` (~5,400 lines across 35 files). `inst/` has only 2 R files. `vignettes/*.R` not tracked in git (auto-generated tangles). ~90 `nolint` annotations already exist in `R/` source. | #807 (cli nolint cleanup) should be done first to establish pattern. #513 (vignette .R scripts) related to vignette exclusion. PR #1062 is in flight. | Merge or rebase PR #1062 once reviews pass. May need to fix remaining lint violations or add targeted `# nolint` annotations. Address `tests/` directory-wide lint cleanup separately from `inst/` and `vignettes/`. | N/A | N/A | — | N/A |\n    68→| 807 | Clean up linter statements around `cli` conditions | good first issue, implementation-ready | 2024-05-05 | cleanup | low | medium | yes | Still relevant. ~43 `#nolint start: keyword_quote_linter` blocks across R/ wrap `cli_abort()`/`cli_warn()` calls that use `\"!\" =`, `\"i\" =` named vector syntax. Only 12 instances use Hugo's backtick fix (`\\`!\\` =`). The fix is mechanical: replace `\"!\" =` with `` `!` = `` inside cli condition calls, then remove the `nolint` annotations. Additional `object_usage_linter` suppressions (14 blocks) exist for `.data[...]` patterns in data.table code — these need separate handling. No work done on this issue since filing. | Prerequisite for #808 (run lintr everywhere). Related to PR #583 (which introduced the cli pattern). | Replace all `\"!\" =`, `\"i\" =`, `\"x\" =`, `\"v\" =` with backtick-quoted equivalents (`` `!` = ``, etc.) in `cli_abort()`/`cli_warn()` calls across ~20 R/ files, then delete the corresponding `#nolint start`/`#nolint end` blocks. Handle `object_usage_linter` suppressions separately. | [x] | [ ] | — | [ ] |\n    69→| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |\n    70→| 789 | Add documentation about how to customise scores | documentation | 2024-04-13 | documentation | medium | medium | partially | Partially addressed. The `score()` roxygen docs now have a \"Customising metrics\" section with `purrr::partial()` examples (PR #874). But the core ask — a vignette walkthrough — remains undone. No vignette covers `get_metrics()` → `select_metrics()` → `purrr::partial()` → `score()` workflow. On `scoringutils-2.x` milestone. | Related to #546 (vignette restructuring — decides where customization docs go), #666 (manuscript update). | Create a vignette section (or standalone vignette) walking users through the full metric customization workflow: `get_metrics()`, `select_metrics()`, `purrr::partial()`, custom metric functions, and passing to `score()`. Coordinate with vignette restructuring in #546. | N/A | N/A | — | N/A |\n    71→| 785 | Small updates to the scoring rules Vignette | documentation | 2024-04-10 | documentation | low | small | yes | Still relevant. None of the 7 suggestions from @seabbs's review of PR #762 have been implemented: author field still present, Google Drive link still used, no citations for proper scoring rules or transformed scores paper, `get_metrics` wording not improved for website readers, no introductory paragraph on different probabilistic forecast types. Nearly 2 years open with no progress on these items. | Loosely related to #666 (manuscript update re: Google Drive link), #758 (scoring rules vignette parent issue), #1046 (multivariate scoring in same vignette). | Implement the 7 small documentation edits in `vignettes/scoring-rules.Rmd`: remove author field, replace Google Drive link with proper reference, add citations for proper scoring rules and transformed scores, improve `get_metrics` wording, clean whitespace, and add intro paragraph on probabilistic forecast types. | [ ] | [ ] | — | [ ] |\n    72→| 780 | Add a `verbose` argument to `as_forecast()` | | 2024-04-05 | enhancement | low | small | yes | Still relevant. `verbose` already exists on `assert_forecast()` and `assert_forecast_generic()` (PR #778) but has not been threaded through to any `as_forecast_<type>()` constructor. ~11 test lines and 1 internal R source line use `suppressMessages`/`suppressWarnings` wrappers around `as_forecast_*` calls, confirming ongoing need. Author acknowledged low urgency but wants it for test cleanup. | None. PR #778 (verbose on `assert_forecast`) already merged; plumbing is in place. | Add `verbose = TRUE` parameter to each `as_forecast_<type>.default()` method, pass it to their `assert_forecast()` calls, guard direct `cli_warn()`/`cli_inform()` calls behind the flag, and replace `suppressMessages`/`suppressWarnings` wrappers in tests and internal code with `verbose = FALSE`. | [ ] | [ ] | — | [ ] |\n    73→| 769 | Rethink the way arguments are passed in `get_pairwise_comparisons()` | package improvement | 2024-04-03 | refactor | low | small | yes | Still relevant. `test_type`, `one_sided`, and `n_permutations` are still passed via `...` through 3 levels (`get_pairwise_comparisons` → `pairwise_comparison_one_group` → `compare_forecasts`). Users must read internal `compare_forecasts` docs to discover options. PR #994 added `test_type = NULL` but didn't address the `...` pattern. #750 (split out p-values) was deferred. | Loosely related to #750 (if p-values split out, this becomes moot — but #750 deferred indefinitely). No hard blockers. | Promote `test_type`, `one_sided`, and `n_permutations` from `...` to explicit named arguments in `get_pairwise_comparisons()` and `add_relative_skill()`, improving API discoverability. Update roxygen `@param` tags accordingly. | [ ] | [ ] | — | [ ] |\n    74→| 763 | We should check for consistency when scoring binary forecasts | feature request, high-priority | 2024-03-30 | enhancement | medium | small | yes | Still relevant. No code warns when 0/1 factor levels are in counterintuitive order (e.g., `levels = c(1, 0)` making `0` the reference level). `assert_input_binary()` only validates factor with 2 levels and predicted in [0,1]. No helper for safe factor conversion exists. @seabbs questioned whether this is must-have for 2.0 or nice-to-have. | Loosely related to #840 (input check cleanup) and #939 (remove `check_input_*` functions). | Add a check in `assert_input_binary()` that warns when observed values are \"0\"/\"1\" and level order is `c(1, 0)`. Optionally create `as_binary_observed()` helper with a `reference_level` argument for safe factor conversion. | [ ] | [ ] | — | [ ] |\n    75→| 759 | Future of the current `scoringutils.Rmd` vignette | documentation, question | 2024-03-27 | documentation | medium | medium | partially | Partially addressed. The outdated `scoringutils.Rmd` was removed in PR #836 (May 2024). However, the promised replacement \"Get started\" vignette was never written — @seabbs volunteered June 2024 but no PR materialized. Package has no introductory vignette. README also has dead links to deleted vignettes (`metric-details`, `scoring-forecasts-directly`). | Related to #546 (simplify getting started). Completing this would likely close #546. Dead README links should be fixed regardless. | Write a new \"Get started\" / quick-start vignette to replace the deleted `scoringutils.Rmd`. Fix dead vignette links in README.Rmd. Consider merging #546 into this issue. | N/A | N/A | — | N/A |\n    76→| 758 | Create a vignette that explains scoring rules | documentation | 2024-03-27 | documentation | medium | large | partially | Partially addressed. Part 1 (explain each scoring rule) is covered by the existing `scoring-rules.Rmd` vignette. Part 2 (practical guidance on choosing a scoring rule — convergence, overconfidence, locality, scale sensitivity) remains unaddressed. The issue body contains a detailed vignette stub. Three illustration PNGs exist in `vignettes/` but are orphaned (not referenced by any vignette). | Parent issue for #929, #930, #933, #934 (illustration issues). Related to #785 (scoring rules vignette updates), #1046 (multivariate content). | Narrow scope to creating a \"Choosing a scoring rule\" vignette covering comparative guidance (convergence, overconfidence, locality, scale sensitivity). Coordinate with #929/#930/#933/#934 to incorporate the orphaned illustrations. | N/A | N/A | — | N/A |\n    77→| 752 | Split up `plot_pit()` into a method for vectors and one for data.frames | | 2024-03-27 | refactor | low | small | yes | Fully resolved. `plot_pit()` was removed entirely in PRs #940 and #949. Replaced by `get_pit_histogram()` (S3 generic with methods for `forecast_sample` and `forecast_quantile`) and `pit_histogram_sample()` for low-level computation. Plotting is now via standard ggplot2 calls. The dual-purpose if/else concern no longer exists. | None. | Close as completed. The issue's concern was superseded by a complete removal of `plot_pit()` in favor of `get_pit_histogram()` with proper S3 dispatch. | N/A | N/A | — | N/A |\n    78→| 750 | Move computation of p-values out of `get_pairwise_comparisons()`? | question | 2024-03-26 | discussion | low | medium | no | Partially addressed. PR #994 added `test_type = NULL` to skip p-value computation, resolving the main pain point (spurious warnings from `add_relative_skill()`). The broader architectural question of separating p-value from score ratio computation remains open but contributor consensus was option 1 (do nothing). | #769 (explicit test_type argument) should be considered together. #1022 (two-model case) tangentially related. | Consider closing as won't-fix or converting to long-term design discussion. The practical problem was solved by PR #994. If kept open, the most impactful remaining change would be defaulting `add_relative_skill()` to `test_type = NULL` since it discards p-values anyway. | N/A | N/A | — | N/A |\n    79→| 740 | Make `get_forecast_unit()` and friends customisable such that they can work with new forecast classes | enhancement | 2024-03-24 | refactor | medium | medium | partially | Still relevant. No implementation work done. `get_protected_columns()` remains a plain function with hard-coded column lists (not S3). `get_duplicate_forecasts()` still hard-codes type-specific columns. Related S3 conversions (e.g., `get_forecast_type`, `get_pit`, `as_forecast`) establish the pattern. On `scoringutils-2.x` milestone. | Near-duplicate of #889 (S3 `get_protected_columns`) and #888 (S3 `get_duplicate_forecasts`). Blocks #852 (custom forecast class workflow). | Convert `get_protected_columns()` into an S3 generic with per-class methods (addressing #889), similarly make `get_duplicate_forecasts()` S3 (#888), so each forecast class declares its own columns. Follow established pattern from completed S3 conversions. | N/A | N/A | — | N/A |\n    80→| 731 | Should `wis()` warn about missing values? | question | 2024-03-23 | discussion | low | small | no | Still relevant. Current behavior is correct — `as_forecast()` emits a vague NA message, `clean_forecast()` strips NA rows before `wis()` sees them. Discussion converged on improving the `as_forecast()` message (#537) as the primary fix, with `wis()`-specific warning being secondary. No consensus reached on implementation. | Related to #537 (high-priority: improve NA-removal message). Related to #542 (debug `score()`). Resolving #537 first would clarify what remains here. | Resolve #537 first (improve NA-removal message in `as_forecast()` to report affected row count). Then decide whether `wis()` needs its own warning for direct (non-`score()` pipeline) usage. May be closeable once #537 is done. | N/A | N/A | — | N/A |\n    81→| 718 | Testing fails locally when done repeatedly | enhancement | 2024-03-20 | bug | low | small | yes | Still relevant and unfixed. Root cause: `cli_warn()` with `.frequency = \"once\"` and `.frequency_id = \"small_interval_range\"` suppresses warnings after first test run in same R session. 4 instances of `.frequency = \"once\"` in codebase. Tests pass on CI (fresh process) and on first local run. | No blocking dependencies. Tangentially related to #935 (surprising output behavior). | Add `rlang::reset_message_verbosity(\"small_interval_range\")` before the `expect_warning()` call in `test-metrics-interval-range.R`. Audit the other 3 `.frequency = \"once\"` sites to ensure their tests are similarly resilient. | [ ] | [ ] | — | [ ] |\n    82→| 713 | Create vignette that showcases different ways to visualise forecasts and scores | documentation | 2024-03-11 | documentation | medium | medium | no | Still relevant. Package has 7 exported plot functions (`plot_wis`, `plot_heatmap`, `plot_interval_coverage`, `plot_quantile_coverage`, `plot_pairwise_comparisons`, `plot_forecast_counts`, `plot_correlations`) plus `theme_scoringutils()` but no dedicated visualization vignette. Only a deprecated-visualisations vignette exists. Issue requests updated `plot_score_table()` and mention of `hubVis`. | Related to #826 (plot_heatmap accessibility), #49 (calibration plotting), #942 (discrimination plots), #356 (interactions vignette). Does not block other issues. | Create a new `vignettes/visualising-scores.Rmd` with worked examples for all exported plot functions using example data. Include mention of `hubVis` as alternative for forecast visualization (per closed #812), and an updated `plot_score_table()` equivalent. | N/A | N/A | — | N/A |\n    83→| 702 | Update docs to conform to tidyverse styleguide | good first issue | 2024-03-08 | documentation | low | small | partially | Still relevant. ~85% of `@param` tags already conform to sentence case. ~21 clearly non-conforming (lowercase start) and ~21 special-character-starting descriptions across ~15 R files. Blocker PR #705 (file reorg) was merged March 2024. Assigned to @jamesmbaazam but no PR submitted. | No blocking dependencies. Standalone cleanup task. PR #705 dependency resolved. | Fix ~21 `@param` descriptions across ~15 R files to start with capital letter and end with full stop per tidyverse style guide. Also audit ~21 special-character-starting descriptions and all `@return`/`@returns` tags for same conformance. | N/A | N/A | — | N/A |\n    84→| 686 | Improve code coverage | | 2024-03-06 | meta | low | small | partially | Largely resolved. Coverage is at 98%. The specific sub-issue (#703, misnamed test file) was fixed in PR #704. Only `theme_scoringutils()` (18 lines) lacks any test coverage. The remaining 2% is edge-case branches. Could be closed as-is. | Sub-issue #703 resolved. No blockers. | Optionally add a test for `theme_scoringutils()` and a `.codecov.yml` with a coverage target to prevent regressions, then close this issue given the excellent 98% coverage level. | N/A | N/A | — | N/A |\n    85→| 685 | Suppress printing in tests | enhancement, implementation-ready | 2024-03-06 | cleanup | medium | medium | partially | Still relevant. 29 `suppressMessages()` and 16 `suppressWarnings()` remain across 13 test files, silently swallowing conditions instead of asserting them. Partially addressed: 80+ `expect_no_condition()` calls already exist. Root causes include `as_forecast_*()` verbose messaging and the #935 print bug. | Partially depends on #935 (unwanted printing on `:=`). Overlaps significantly with #823 (reduce `suppress*()` in package). | Audit all 29 `suppressMessages()` and 16 `suppressWarnings()` in tests: replace with `expect_message()`/`expect_warning()` for intentional conditions, pass `verbose = FALSE` where available, or use `expect_no_condition()` after fixing the source. Also review `setup.R` score calls. | N/A | N/A | — | N/A |\n    86→| 684 | Delete functions `check_input_sample()`, `check_input_quantile()`, `check_input_interval()` | | 2024-03-06 | cleanup | low | small | yes | Still relevant but fully superseded by #939, which covers all 5 `check_input_*` functions. These 3 functions are dead code: never called in production, not exported, only tested. A comment in `check-input-helpers.R` explicitly marks them for future deletion. Should be closed as duplicate of #939. | Superseded by #939. Related to #840 (input check cleanup) and #823 (reduce `try()`). | Close as duplicate of #939. If handled independently, delete the 3 function definitions, their man pages, roxygen cross-references, and corresponding test blocks. | [ ] | [ ] | — | [ ] |\n    87→| 668 | Add argument to control what kind of coverage is computed by `get_coverage()` | feature request | 2024-02-29 | enhancement | low | small | yes | Still relevant and unimplemented. `get_coverage()` always computes all 4 coverage metrics with no user control. The issue body contains a near-complete code proposal (with a minor bug to fix). The function structure already cleanly separates interval and quantile computation paths. On `scoringutils-2.x` milestone. | No blocking dependencies. Standalone enhancement. | Add a `type = c(\"quantile\", \"interval\")` argument to `get_coverage()` that conditionally computes interval coverage, quantile coverage, or both. Update downstream column handling, summarisation, and tests. | [ ] | [ ] | — | [ ] |\n    88→| 667 | Create print method for `scores()` objects | feature request | 2024-02-29 | feature | low | small | partially | Still relevant but effectively blocked by #935. No `print.scores` method exists; scores objects fall through to `print.data.table`. Adding a custom print method would exacerbate the unwanted-printing-on-`:=` bug documented in #935. Both maintainers expressed lukewarm interest, deferring to post-release. | Blocked by #935 (print on column change bug). Related to #975 (link to score definitions in print). | Implement `print.scores()` S3 method displaying computed metric names (from `metrics` attribute) before delegating to `NextMethod()`, following the `print.forecast` pattern. Wait until #935 is resolved first to avoid spurious printing on `:=` operations. | N/A | N/A | — | N/A |\n    89→| 666 | Update the scoringutils paper that accompanies the package | question | 2024-02-29 | documentation | medium | large | no | Still relevant but partially stale. Only 2 of ~15 checklist items done. Manuscript in `inst/manuscript/` still references `magrittr`, CITATION still points to 2022 arXiv preprint. README links to Google Drive PDF. Some checklist items reference functions no longer exported. Should be broken into smaller actionable issues. | Related to #759, #789, #546, #758, #1057. | Audit the to-do list against current API to remove stale items, break remaining unchecked items into individual issues, and decide whether to prioritize the \"make a vignette out of the paper\" item before the next CRAN release. Requires human authorship decisions. | N/A | N/A | — | N/A |\n    90→| 646 | Stop converting errors to warnings in `score()`? | help wanted, question, Breaking change | 2024-02-23 | refactor | medium | medium | partially | Still relevant. `run_safely()` in `R/score.R` still converts all metric errors to warnings via `try()` + `cli_warn()` and returns `NULL`, silently dropping failed metrics. Deferred to `scoringutils-2.x` milestone. No consensus on approach: let errors propagate (breaking), add `on_error` parameter (compatible), or batch warnings (#811). | Related to #811 (batch warnings), #941 (`score()` redesign), #823 (reduce `try()`). | Design decision needed: (a) let errors propagate as errors, (b) add `on_error = c(\"warn\", \"error\")` param to `score()`, or (c) combine with #811's batch-warning approach. Implementation touches `run_safely()` in `R/score.R` and test expectations. | N/A | N/A | — | N/A |\n    91→| 625 | Implement a `get_unique_values()` function | implementation-ready | 2024-02-10 | enhancement | low | small | yes | Still relevant. No implementation work done. Function does not exist. Would compute `length(unique(values))` per forecast-unit column (via `get_forecast_unit()`), optionally grouped by model. Similar diagnostic purpose to `get_forecast_counts()` but different output. | Loosely related to #581 (NA in print), #935 (print bug), #621 (closed, prettier print). No hard blockers for standalone function. | Implement a new exported `get_unique_values()` function that takes a forecast object, calls `get_forecast_unit()` to identify relevant columns, and returns a summary table of unique value counts per column. Optionally integrate into `print.forecast()`. | [ ] | [ ] | — | [ ] |\n    92→| 608 | Define input format for categorical forecasts | implementation-ready | 2024-01-17 | discussion | low | small | no | Largely resolved. Input format fully defined and implemented in `forecast_nominal` (PR #837) and `forecast_ordinal` (PR #977). Column named `predicted_label`. Strict completeness enforced. Only unimplemented item is a helper function to auto-expand incomplete forecasts with zero-probability rows, which has no dedicated tracking issue. Can be closed. | #604 (parent, closed), #607 (naming, closed). No blockers. | Close this issue as completed. Optionally open a new targeted issue for the helper function that auto-expands incomplete forecasts with zero-probability rows if still desired. | N/A | N/A | — | N/A |\n    93→| 581 | Add the number of `NA` values to the planned print method for `forecast_*` objects, rather than throw a message? | feature request | 2024-01-05 | enhancement | medium | medium | partially | Still relevant. None of the three requested features implemented: `print.forecast()` shows no NA info, NA message in `assert_forecast_generic()` is still vague (no row count), no `get_NA()` helper exists. Issue #537 is a near-duplicate and both should be addressed together. | Near-duplicate of #537 (should be resolved together). Tangentially related to #731, #542, #935 (print bug). | Enhance `print.forecast()` to display NA row count, improve the message in `assert_forecast_generic()` to report exact number of NA rows, and consider adding a `get_na_summary()` helper. Consolidate with #537. | N/A | N/A | — | N/A |\n    94→| 557 | sample_to_quantile.numeric method | low-priority | 2024-01-05 | enhancement | low | small | yes | Effectively resolved. `sample_to_quantile()` was replaced by `as_forecast_quantile.forecast_sample()` in PR #876. The motivating code (`interval_coverage_sample()`) was deleted entirely. No current code needs a `.numeric` method. Can be closed. | Tangentially related to #1026 (reverse conversion). No blockers. | Close this issue as resolved. The refactoring in PR #876 and deletion of `interval_coverage_sample()` eliminated the code pattern that motivated this request. | N/A | N/A | — | N/A |\n    95→| 546 | Simplify \"Getting Started\" \\| Split into smaller chunks | documentation | 2024-01-05 | documentation | medium | medium | no | Still relevant. The old `scoringutils.Rmd` was deleted (PR #836) but the promised replacement \"Get started\" vignette was never written. Package currently has no introductory vignette at all. README has a \"Quick start\" section but no pkgdown \"Get started\" page. @seabbs volunteered in #759 but no PR materialized. | Tightly coupled with #759 (future of scoringutils.Rmd) — should be resolved together. Related to #789 (metric customization docs). | Write a new introductory \"Getting Started\" vignette (as `vignettes/scoringutils.Rmd` for pkgdown) providing a concise end-to-end walkthrough. Can close both #546 and #759 simultaneously. Requires editorial decisions on scope and content. | N/A | N/A | — | N/A |\n    96→| 542 | Improve ways to debug `score()` | question | 2024-01-04 | enhancement | medium | medium | partially | Still relevant. Neither action item is done: (1) no vignette documents `debugonce()` for scoring rule debugging, (2) `run_safely()` still only reports the metric name in warnings, not which forecast unit/row caused the failure. The `{cli}` migration (PR #583) improved formatting but not informativeness. | Closely related to #646 (stop converting errors to warnings — open, breaking change). Related to closed #391, #418, #543, #583. | Two tasks remain: (1) add documentation showing `debugonce()` usage for debugging scoring failures, and (2) enhance `run_safely()`/`apply_metrics()` to include forecast-unit context in warning messages. Coordinate error-vs-warning design with #646. | N/A | N/A | — | N/A |\n    97→| 537 | Inform users about the number of rows that have NA values | good first issue, question, implementation-ready, high-priority | 2024-01-03 | enhancement | medium | medium | partially | Still relevant. The message in `assert_forecast_generic()` (line 150 of `R/class-forecast.R`) still says the generic \"Some rows containing NA values may be removed\" without a row count. No NA info in `print.forecast`, no `get_na()` helper. The `anyNA()` check and `na.omit()` call are already in place, so computing the count is trivial. | Near-duplicate of #581 (NA count in print method) — should be resolved together. Related to #731 (wis NA warnings). | Minimal fix: add NA row count to the existing `cli_inform` message in `assert_forecast_generic()`. For a more complete resolution, combine with #581 to also add NA summary to `print.forecast` and potentially create a `get_na()` diagnostic helper. | N/A | N/A | — | N/A |\n    98→| 522 | Create a way to test user-provided scoring functions | feature request | 2023-12-06 | feature | medium | medium | partially | Still relevant. No progress made. `validate_metrics()` only checks that items are functions (via `checkmate::check_function`), not signature compatibility, output shape, or runtime behavior. Custom metric errors are silently converted to warnings by `run_safely()`, making debugging hard. Each of the 6+ forecast types passes different arguments to metrics. | Loosely related to #362 (non-standard metric I/O), #823 (reduce `try()`). | Implement an exported `test_metrics()` function that runs each metric on a small representative subset of a forecast object and reports informative diagnostics: signature compatibility, runtime errors, and output shape validation. Needs design decision on API. | N/A | N/A | — | N/A |\n    99→| 520 | Create documentation/vignette for the naming scheme of our functions | help wanted, question | 2023-11-30 | documentation | low | medium | partially | Still relevant. The issue body already describes the naming scheme in detail but no vignette or formal documentation exists. CONTRIBUTING.md only references tidyverse style guide. Issue #948 (closed) debated `get_` prefix but decided to keep it. 65 exported functions follow conventions consistently. ~2 years old with no implementation. | Related to closed #948, #610, #476, #357. No blockers. | Create a developer-facing vignette or CONTRIBUTING.md section formalizing the naming conventions (scoring rules: `<name>_<type>`, `get_*`, `as_forecast_*`, `is_forecast_*`, `plot_*`, `add_*`, `assert_`/`check_`/`test_`). Update to reflect current classes including `forecast_nominal`, `forecast_ordinal`, `forecast_sample_multivariate`. | N/A | N/A | — | N/A |\n   100→| 513 | Investigate R scripts that get generated based on our vignettes | | 2023-11-28 | cleanup | low | small | yes | Already resolved. The `.R` and `.html` vignette artifacts (generated by `knitr` tangle) are gitignored via `vignettes/.gitignore`, excluded from linting via `.lintr`, and not tracked in git. All three mitigations from the discussion are in place. Issue can be closed. | None. | Close this issue — all requested investigation and mitigations (gitignore, buildignore, lint-ignore for vignette-generated `.R` files) are already implemented. No code changes needed. | N/A | N/A | — | N/A |\n   101→| 492 | Expose `get_range_from_quantile()` to the user | question | 2023-11-22 | enhancement | low | small | yes | Still relevant. Function exists at `R/helper-quantile-interval-range.R:185` as `@keywords internal`, not exported. Maintainer consensus reached: rename to `get_interval_range()` and create `add_interval_range()` wrapper. Neither implemented. Original motivating function `plot_ranges()` was deleted, reducing urgency. 3 internal call sites. | Parent meta-issue #484. Tangentially related to #885 (export decisions). | Rename `get_range_from_quantile()` to `get_interval_range()`, export it, and create a new exported `add_interval_range()` that adds an `interval_range` column to a quantile-format data.table. Update 3 internal call sites, NAMESPACE, docs, and tests. | [ ] | [ ] | — | [ ] |\n   102→| 484 | Discussion: Functions to expose to users | | 2023-11-19 | meta | low | small | partially | Partially done. 1 of 3 tracked items complete (`get_metrics()` is already exported). Remaining: `get_protected_columns()` still internal (`@keywords internal` in `R/get-protected-columns.R`), `get_range_from_quantile()` still internal (blocked on naming decision in #492). ~2 years old. | #492 (naming decision blocks `get_range_from_quantile` export). No blockers for `get_protected_columns`. | Update checkboxes: tick `get_metrics()` as done. Export `get_protected_columns()` (add `@export`, remove `@keywords internal`). Resolve #492 naming decision before exporting `get_range_from_quantile`. Consider closing in favor of tracking remaining items individually. | N/A | N/A | — | N/A |\n   103→| 459 | Meta-issue: Code refactoring | refactor | 2023-11-17 | meta | low | medium | partially | 2 of 5 tracked sub-issues done (#446, #469). Of remaining 3: #411 is stale (function `interval_coverage_sample` removed), #454 needs updating (named function gone but duplication between `get_coverage()` and `interval_coverage()` persists), #445 still actionable (64 `::` occurrences across 18 R files). Untracked dimension-checking item partially addressed by existing `assert_input_*` pattern. 2+ years old. | #938 (rename `assert_dims_ok_point`) related to untracked item. #870 (CRPS/WIS refactor) is related open refactoring work not tracked here. | Update the issue body: close #411 as stale, update #454's description to reference current duplication, and decide whether to close this meta-issue in favor of tracking remaining refactoring (#445, #870, #938) as standalone issues. | N/A | N/A | — | N/A |\n   104→| 455 | Discussion: Should scoring rules always return a vector? | Breaking change | 2023-11-15 | discussion | low | large | no | Stale discussion from Nov 2023 with only 2 comments and no concrete proposal. The current design (separate functions per metric component, e.g., `overprediction_quantile()`) already addresses the motivating example. All metrics consistently return numeric vectors; `apply_metrics()` requires this. API is settled. | None | Close as \"won't fix\". The vector-return contract is consistent across all metrics and well-integrated with `apply_metrics()`. The separate-function-per-component pattern already solves the motivating WIS use case. | N/A | N/A | — | N/A |\n   105→| 454 | Code refactoring: Deduplicate code in `get_coverage()` and `interval_coverage_deviation_quantile()` | refactor, implementation-ready | 2023-11-15 | refactor | low | small | yes | Original function `interval_coverage_deviation_quantile()` was removed. Issue title is outdated. Remaining duplication is between `get_coverage()` (data.table-level) and `interval_coverage()` (numeric scoring metric) — both call `quantile_to_interval()` + bounds check independently. Duplication is small (~5 lines of core logic). | Tracked in meta-issue #459. Related to #668 (coverage type argument). | Update issue title to reference `interval_coverage()`. Refactor `get_coverage()` to delegate interval coverage computation to `interval_coverage()` or a shared internal helper, eliminating duplicated `quantile_to_interval()` + bounds-check pattern. | [ ] | [ ] | — | [ ] |\n   106→| 453 | Create function `quantile_coverage_deviation()` | feature request, implementation-ready | 2023-11-15 | feature | low | small | no | Superseded. The requested functionality is already provided by `get_coverage()` (line 88 of `R/get-coverage.R` computes `quantile_coverage_deviation`). The analogous standalone function (`interval_coverage_dev_quantile()`) was removed rather than duplicated. Can be closed. | Related to #454 (also likely closeable) and meta-issue #459. | Close as superseded. Quantile coverage deviation is already computed in `get_coverage()`. The design decision was to consolidate coverage metrics there rather than create standalone functions. | N/A | N/A | — | N/A |\n   107→| 451 | Deal with one-to-one functions related to quantile and interval metrics | question | 2023-11-15 | discussion | low | medium | no | Still relevant. The issue concerns the one-to-one correspondence between quantile-format and interval-format metric functions. Currently: `interval_score()` is internal (not exported), called by `wis()` after `quantile_to_interval()` conversion. Exported quantile metrics: `wis()`, `quantile_score()`, `interval_coverage()`, `ae_median_quantile()`, `bias_quantile()`, `dispersion_quantile()`, `overprediction_quantile()`, `underprediction_quantile()`. No `forecast_interval` class exists — interval format is internal only. The comment from the maintainer (\"not expose functions to users for now and rethink later\") is the current policy. Coverage code in `get_coverage()` still has its own inline computation rather than reusing `interval_coverage()`. | Related to #668 (coverage type argument), #492 (expose `get_range_from_quantile`), #870 (CRPS/WIS decomposition refactor), #907 (coverage function factory), #454 (deduplicate coverage code), #484 (functions to expose). | Keep open as a design discussion for future releases. The immediate question (whether to expose interval-format functions) was deferred. The broader question of code reuse between `get_coverage()` and `interval_coverage()` overlaps with #454 and #668. Revisit when planning the next API refactor cycle. | N/A | N/A | — | N/A |\n   108→| 445 | Cleanup: delete calls that use `::` or `:::` and add to imports instead | refactor, implementation-ready | 2023-11-15 | cleanup | low | small | yes | Still relevant. 25 redundant `pkg::fn()` calls across 9 R files where functions are already imported in NAMESPACE (13 data.table, 5 scoringRules, 3 Metrics, 2 cli, 1 purrr, 1 utils). The oft-cited \"64 occurrences\" overstates scope — 37 are roxygen/comment references that should stay. Purely cosmetic cleanup. | None. Standalone cleanup. Tracked in meta-issue #459. | Remove the `pkg::` prefix from 25 redundant function calls across 9 R files. Leave roxygen documentation cross-references and cli-formatting self-references unchanged. | [ ] | [ ] | — | [ ] |\n   109→| 434 | Discussion: composing score data.frames | help wanted, question | 2023-11-14 | discussion | low | medium | partially | Still relevant. No `c.scores()` or score composition method exists. Scores objects are data.tables with a `metrics` attribute. A `c.scores()` method would need `rbindlist(..., fill = TRUE)` and union of `metrics` attributes. No comments on the issue; design not discussed beyond the example in the issue body. ~2.5 years old with no progress. | Sub-issue of #433. Depends on #432 (as_point) being resolved first to enable the full workflow. | Design and implement a `c.scores()` (or `merge_scores()`) method that combines multiple scores objects via `rbindlist(fill = TRUE)`, merges `metrics` attributes, and validates that forecast unit columns are compatible. Needs maintainer input on API design. | N/A | N/A | — | N/A |\n   110→| 433 | Meta-issue - Feature: scoring probabilistic and point forecasts together / composing scores | help wanted | 2023-11-14 | meta | low | medium | no | Neither sub-issue resolved. PR #790 (implementing `as_point`/`as_quantile`) was closed without merging in May 2024. Only `as_forecast_point.forecast_quantile()` exists (hard-coded to median). No `as_forecast_point.forecast_sample()` method. No score composition mechanism. ~2.5 years old with stalled progress. | Tracks #432 (as_point) and #434 (composing scores). Related to #880 (customizable quantile in as_forecast_point). | Complete both sub-issues: (1) implement `as_forecast_point.forecast_sample()` and optionally a user-friendly `as_point()` wrapper, (2) implement score composition via `c.scores()` or similar. Needs fresh design decision given closed PR #790. | N/A | N/A | — | N/A |\n   111→| 432 | Create function `as_point()` that converts sample- or quantile-based forecasts into point forecasts | help wanted | 2023-11-14 | feature | medium | medium | partially | Partially addressed. `as_forecast_point.forecast_quantile()` exists (hard-coded to median, lines 105-120 of `R/class-forecast-quantile.R`). `as_forecast_point.forecast_sample()` does NOT exist. PR #790 attempted full `as_point()`/`as_quantile()` implementation but was closed without merging (May 2024). @seabbs deprioritized as \"nice to have\". | Sub-issue of #433. Related to #880 (customizable quantile_level in as_forecast_point). | Implement `as_forecast_point.forecast_sample()` (summarize samples via median/mean/custom function). Optionally create a convenience `as_point()` generic wrapping `as_forecast_point()`. Revisit closed PR #790 for design reference. | N/A | N/A | — | N/A |\n   112→| 412 | Add check to `validate_forecast()` that predictions must not decrease with quantile | implementation-ready | 2023-11-10 | enhancement | medium | small | yes | Still relevant. Monotonicity check exists only as a hard error deep in `bias_quantile_single_vector()` (R/metrics-quantile.R:495). `assert_forecast.forecast_quantile()` does NOT check monotonicity — it only validates column presence, quantile range [0,1], and type. `validate_forecast()` was deleted and replaced by `assert_forecast()`. Agreed plan: helper function + warning in `assert_forecast`. No user-facing diagnostic function exists. | Near-duplicate of #895 (user-facing `get_non_monotonic_forecasts()` helper). Related to #840 (input check cleanup). | Add monotonicity warning to `assert_forecast.forecast_quantile()` checking that predictions don't decrease with increasing quantile_level. Create a user-facing `get_non_monotonic_forecasts()` helper to identify affected rows (resolving both #412 and #895). | [ ] | [ ] | — | [ ] |\n   113→| 411 | Rework `interval_coverage_sample()` | refactor | 2023-11-10 | refactor | low | small | yes | Fully resolved. `interval_coverage_sample()` was deleted in commit cc41a0e5 (Jan 5, 2024) as part of the v2.0.0 redesign. NEWS.md documents: \"Removed `interval_coverage_sample()` as users are now expected to convert to a quantile format first before scoring.\" Coverage is now handled by `interval_coverage()` (quantile-based) and `get_coverage()`. Issue can be closed. | None. | Close this issue — `interval_coverage_sample()` was intentionally removed in v2.0.0. The underlying concerns (code simplification, reuse of `interval_coverage_quantile`) were resolved by deleting the function and unifying the API around quantile-format coverage computation. | N/A | N/A | — | N/A |\n   114→| 406 | Maybe expose `get_type()`. | | 2023-11-10 | enhancement | low | small | yes | Still relevant. `get_type()` (vector type detection: classification/integer/continuous) and `get_forecast_type()` (forecast class type) both exist in `R/get-forecast-type.R` but are internal (`@keywords internal`), not exported. The proposed renames (`get_vector_type`, `get_observed_type`, `get_predicted_type`) were never implemented. No comments, no progress. | Related to #484 (functions to expose) and #885 (export decisions). No blockers. | Rename `get_type()` to `get_vector_type()`, export it, and create `get_observed_type()` / `get_predicted_type()` wrappers that extract the relevant column from a forecast and call `get_vector_type()`. Decide whether to also export `get_forecast_type()` (tracked in #484/#885). | [ ] | [ ] | — | [ ] |\n   115→| 385 | Feature: Add data transformation functions to work with other packages | help wanted | 2023-11-03 | feature | low | large | no | Still relevant but aspirational. No conversion functions for external packages (Stan, Odin, yardstick, hubverse) exist. The `as_forecast_*` S3 generic system provides extension points for external packages to write their own methods. Hubverse integration was explicitly moved to external `hubEvals` package (#605 closed). Maintainer consensus: package-specific conversions are too varied and dependency-heavy for scoringutils. Yardstick conversion code in comments never formalized. 2+ years old with no progress. | Related to #356 (interoperability vignette), #363 (external function interface), #852 (custom forecast class workflow), #983 (`.data.frame` methods), #1026 (`as_forecast_sample.forecast_quantile`). | Consider narrowing scope or closing in favor of more specific issues. The broad goal is better served by: (1) completing S3 extensibility infrastructure (#852, #983, #889, #888), (2) writing an interoperability vignette (#356), and (3) possibly adding 1-2 zero-dependency convenience converters if demand warrants. Too broad to be directly actionable as stated. | N/A | N/A | — | N/A |\n   116→| 382 | Feature: Input check to notify about clashes with metrics and column names | good first issue, package improvement, implementation-ready | 2023-11-02 | enhancement | medium | small | yes | Still relevant and unresolved. A pre-v2.0 implementation existed in `check_clean_data()` but was removed during the v2.0 rewrite. A commented-out test skeleton exists in `test-score.R` (lines 51-62). `apply_metrics()` silently overwrites any existing column whose name matches a metric name via `forecast[, (metric_name) := result]`. No pre-scoring clash detection exists. | Tangentially related to #927 (prefix internal columns). Could coordinate with #811 (batch warnings). No blockers. | Add a check after `validate_metrics(metrics)` in each `score.forecast_*` method comparing `names(metrics)` against `colnames(forecast)` and emitting `cli_warn()` on overlap. Uncomment and update the existing test skeleton in `test-score.R`. | [ ] | [ ] | — | [ ] |\n   117→| 363 | Discussion: design interface for external functions with different input/output formats | help wanted, question | 2023-10-26 | enhancement | low | small | yes | Still relevant. No wrapper/adapter functions exist. Users must manually wrap external metrics with non-standard signatures (e.g., reversed arg order, numeric 0/1 instead of factor observed). Two small wrapper proposals in the issue body (`wrap_binary_numeric`, `wrap_switch_order`) were never implemented. The `purrr::partial()` mechanism alone cannot solve argument reordering or type conversion. Zero comments, no design consensus. 2+ years old. | Related to #362 (non-standard I/O formats), #522 (test user-provided scoring functions), #385 (data transformation), #789 (customization docs). No blockers. | Implement 2-3 small exported adapter functions (e.g., `metric_adapt_binary_numeric()` to convert factor to 0/1, `metric_adapt_swap_args()` to reverse observed/predicted order). Document usage in `score()`'s \"Customising metrics\" section. Resolve naming convention with maintainers first. | [ ] | [ ] | — | [ ] |\n   118→| 362 | Discussion: How to handle scores with input / output formats not currently covered | question | 2023-10-26 | discussion | low | large | no | Still relevant. `apply_metrics()` requires each metric to return a numeric vector of length n (one per forecast unit). Metrics with non-standard I/O (many-to-one like AUC, many-to-many like PIT) cannot fit into `score()`. The PIT case is solved outside `score()` via `get_pit_histogram()`. Zero comments, no design consensus. The multivariate sample class introduced a partial precedent (multiple rows collapse into groups) but by restructuring data before `apply_metrics()`, not by changing it. 2+ years old. | Related to #455 (data frame returns — recommended for closure), #363 (wrapper functions), #338 (cross-type metrics), #941 (rethink `score()` S3), #852 (custom class workflow). | Long-term design question with no clear path forward. The pragmatic pattern (non-standard metrics live outside `score()` as standalone functions) is established. Consider closing as won't-fix or consolidating with #455, #363, #338 into a single milestone-level tracking issue. Any solution requires fundamental changes to `apply_metrics()`. | N/A | N/A | — | N/A |\n   119→| 360 | Create a wrapper around log score to warn about its use for integer-valued forecasts | implementation-ready | 2023-10-26 | enhancement | medium | small | yes | Still relevant and unaddressed. `logs_sample()` is a thin wrapper with no integer detection or warning. `get_type()` already exists and is used by `bias_sample()` and `pit_histogram_sample()` for the same purpose. Consensus reached on MVP: add a warning when `get_type(predicted) == \"integer\"`. Discussion also suggested possibly removing `log_score` from default metrics for sample forecasts. | None. All building blocks exist (`get_type()`, `cli_warn()`, pattern established in `bias_sample()`). | Add `get_type(predicted)` check to `logs_sample()` that emits `cli_warn()` when predictions are integer-valued. Optionally move `log_score` out of the default metric list in `get_metrics.forecast_sample()`. Add targeted tests. | [ ] | [ ] | — | [ ] |\n   120→| 356 | Documentation: Create a vignette for interactions with other packages | documentation | 2023-10-26 | documentation | low | medium | partially | Still relevant. No interoperability vignette exists. Deprecated-visualisations vignette mentions hubVis. Hubverse integration moved to external `hubEvals` package (#605, closed). No conversion functions for external packages exist in scoringutils. `as_forecast_*` S3 generics provide extension points for external packages. ~2.5 years old with no progress. | Related to #385 (data transformation for other packages), #852 (custom forecast class workflow), #983 (`.data.frame` methods). | Create a vignette documenting how to use scoringutils with common external packages (hubverse via hubEvals, Stan output, yardstick). Focus on showing the `as_forecast_*()` S3 extension mechanism and practical conversion patterns. Requires editorial decisions on scope and which packages to feature. | N/A | N/A | — | N/A |\n   121→| 353 | Documentation: Create a vignette that details the different inputs and internal workings of scoringutils | documentation | 2023-10-26 | documentation | medium | large | partially | Still relevant but heavily overlapping with #546, #759, #852. The deleted `scoringutils.Rmd` vignette (PR #836) covered 3 of 4 bullet points; replacement was never written. README \"Quick start\" section partially addresses input formats and workflow. The \"create your own class\" bullet is blocked by prerequisite S3 refactors (#889, #888, #885). Package currently has no introductory or architecture vignette. | Tightly coupled with #546 (simplify getting started) and #759 (replace deleted vignette). \"Create your own class\" aspect depends on #852, blocked by #889, #888, #885. | Consider consolidating with #546 and #759 into a single effort to write a new introductory vignette covering input formats, the `as_forecast_*()` / `score()` workflow, and forecast object anatomy. Defer \"create your own class\" section until S3 extensibility refactors are complete. | N/A | N/A | — | N/A |\n   122→| 338 | Discussion: Define implementation for metrics which work for different forecast types | help wanted, question, Breaking change | 2023-10-22 | discussion | low | medium | no | Partially addressed by #832 (`get_metrics()` now S3). The remaining question is whether individual metric functions (e.g., `bias_sample`/`bias_quantile`) should also become S3 generics for standalone use. Practical need is low since `score()` already dispatches correctly via `get_metrics.<class>`. 6 conceptual metrics span 2+ forecast types with type-suffixed names. | #832 (done). Related to #455 (vector returns), #941 (rethink `score()` S3). No blockers. | Consider downgrading from \"Breaking change\" since S3 wrappers could be additive. If pursued, create `bias()`, `overprediction()`, `underprediction()`, `dispersion()`, `ae_median()`, `logs()` as S3 generics dispatching on forecast class, keeping suffixed functions as implementations. Defer to future major release. | N/A | N/A | — | N/A |\n   123→| 329 | Add additional documentation for `crps_sample()`, `logs_sample()` and `dss_sample()` | package improvement | 2023-09-15 | documentation | low | small | partially | Still relevant. Formulas exist in the vignette (`scoring-rules.Rmd`) but have not been ported to the roxygen docs for these three functions. Other functions in the same file (e.g., `bias_sample`, `pit_histogram_sample`) already have formula-rich roxygen documentation via `\\deqn{}`, providing a clear template. `dss_sample()` is worst — almost no description beyond \"wrapper.\" | None. Standalone documentation task. | Add `\\deqn{}` mathematical formulas and expanded descriptions to roxygen docs of `crps_sample()`, `logs_sample()`, and `dss_sample()` in `R/metrics-sample.R`. Adapt formulas from the existing vignette content. `dss_sample()` needs the most work. | N/A | N/A | — | N/A |\n   124→| 289 | Add support for comparing two distributions | | 2023-07-12 | feature | low | large | no | Still relevant. Zero implementation exists. The entire package architecture assumes scoring against scalar observations. No distribution comparison functions in codebase or in `scoringRules` dependency. Requires fundamental design decisions: new forecast class, new metric functions, and integration approach. 2.5+ years old with zero comments. Filed as an aspirational idea. | Related to #852 (custom forecast class workflow), #889/#888 (S3 extensibility). No issues depend on this. | Design and implement a new forecast class for distribution-to-distribution comparison with associated metrics (energy distance, KL divergence, Wasserstein distance). Should be deferred until S3 extensibility infrastructure (#852, #889, #888) is complete. | N/A | N/A | — | N/A |\n   125→| 286 | Extension covering idees in \"Model Diagnostics and Forecast Evaluation for Quantiles\" | enhancement, feature request | 2023-05-03 | feature | medium | large | no | Still relevant. None of the three proposed features (consistency-banded coverage plots, Murphy diagrams, CORP reliability diagrams) are implemented. Basic coverage plots and PIT histograms exist but lack the statistical rigor proposed. Paper's code could serve as starting point. ~3 years old with no progress. Design decisions needed on scope, API, and potential new dependencies (e.g., `reliabilitydiag` R package). | Thematically related to #49 (calibration plotting improvement). No hard blockers. @jbracher is already a scoringutils contributor. | Implement three new diagnostic tools from Bracher et al.: (1) add consistency bands and confidence intervals to existing coverage plots, (2) create `murphy_diagram()` function and plot, (3) create CORP reliability diagram function. Consider addressing #49 simultaneously. | N/A | N/A | — | N/A |\n   126→| 267 | How to score literature/other resources | documentation, help wanted | 2023-02-13 | documentation | low | small | no | Still relevant. Function-level `@references` tags exist across 8 R files, and the scoring-rules vignette has a .bib with 7 papers. However, the agreed-upon deliverable — a standalone, discoverable vignette summarizing scoring methodology and linking to key literature — has not been created. Two vignettes referenced in the README (\"metric-details\", \"scoring-forecasts-directly\") do not exist on disk. ~3 years old. | None blocking. Related to #758 (scoring rules vignette), #789 (customization docs), #666 (update paper). | Create a short standalone vignette summarizing scoring methodology and consolidating all referenced literature into one discoverable place. Link to the full paper and relevant external resources. Also fix the broken vignette links in the README. Requires editorial decisions on content. | N/A | N/A | — | N/A |\n   127→| 193 | Add more metrics to assess sharpness of forecasts in a sample format | feature request, implementation-ready | 2022-02-16 | feature | low | small | yes | Still relevant. `mad_sample()` is the only dedicated sharpness metric. SD and IQR (specifically requested) are not implemented. Both are trivial to add following the `mad_sample()` pattern (data-independent, apply function row-wise over predicted matrix). `dispersion_sample()` (CRPS component) also measures spread but is observation-dependent. `scoringRules` provides no additional sharpness measures. | None. Self-contained addition following existing `mad_sample()` pattern. | Implement `sd_sample()` and `iqr_sample()` in `R/metrics-sample.R` following the `mad_sample()` pattern. Add both to the default metric list in `get_metrics.forecast_sample()`. Add tests, documentation, and NAMESPACE exports. | [ ] | [ ] | — | [ ] |\n   128→| 49 | Improve calibration plotting | enhancement, feature request | 2020-07-25 | feature | low | medium | no | Partially addressed. PIT histograms exist via `get_pit_histogram()` (covering item 1 approximately). Items 2 (ACF of PIT values) and 3 (marginal calibration plot) are completely unimplemented. True Talagrand/verification rank histogram also not implemented as a distinct tool. Maintainer said \"no active plan, but nice to have.\" 5+ years old. | Thematically overlaps with #286 (advanced calibration diagnostics). No hard blockers. | Three remaining items: (1) implement verification rank histogram for ensemble/sample forecasts, (2) implement ACF computation/plot for PIT values, (3) implement marginal calibration plot. Consider consolidating with #286 into a single calibration diagnostics tracking issue. | N/A | N/A | — | N/A |\n   129→| 37 | Add Diebold Mariano test | enhancement, good first issue, help wanted, feature request | 2020-06-20 | feature | low | small | partially | Still relevant. No DM test implementation exists. `compare_forecasts()` in `R/pairwise-comparisons.R` already has a clean `test_type` dispatch pattern (Wilcoxon and permutation). The DM test's main value-add is proper handling of autocorrelated score differences common in time-series forecasting. Open since 2020 with maintainer agreement but explicitly deferred. | Dependency of #1055 (model confidence sets). Related to #750 (p-value refactor), #769 (pairwise comparison arguments), #1022 (two-model case). | Add `\"dm\"` as a new `test_type` option in `compare_forecasts()`. Self-implement the DM test statistic (preferred over adding `forecast` dependency) with Newey-West HAC variance estimator. Add tests and documentation. Coordinate naming and autocorrelation lag handling with maintainers. | N/A | N/A | — | N/A |\n   130→\n   131→TRIAGE_COMPLETE"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"fc23ccba-a552-46b9-b1a1-7dba2a84d9f4","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md","content":"# scoringutils Issue Triage\n\n> Auto-generated by Ralph triage loop. Do not edit manually during the loop.\n\n## Summary\n\n| Metric | Count |\n|--------|-------|\n| Total open issues | 106 |\n| Triaged | 106 |\n| Remaining | 0 |\n\n## Pipeline\n\n- [ ] **Test design** — Test specs written for automatable issues\n- [ ] **Implement** — Fixes implemented, PRs created\n- [ ] **Review** — All PRs independently reviewed\n- [ ] **Summary** — Human summary generated\n\n## Issues\n\n| # | Title | Labels | Opened | Category | Priority | Complexity | Automatable | Status Note | Dependencies | Action Summary | Has Tests | Implemented | PR | Reviewed |\n|---|-------|--------|--------|----------|----------|------------|-------------|-------------|--------------|----------------|-----------|-------------|-----|----------|\n| 1065 | Release reminder - February 2026 | | 2026-02-02 | meta | medium | medium | partially | Automated reminder. Dev version (2.1.2.9000) has multivariate feature + bug fix accumulated over 161 days. No blocking bugs. Two open PRs (#1060, #1062) are infrastructure changes. | Maintainers should decide whether to merge #1060/#1062 before releasing. | Decide whether to cut a new release (likely v2.2.0 given multivariate feature). If yes, run `usethis::use_release_issue()` and proceed with CRAN submission. If not, close the issue. | N/A | N/A | — | N/A |\n| 1064 | Pre-ranking for multivariate calibration assessment | | 2026-01-30 | feature | medium | large | no | No pre-ranking or multivariate calibration diagnostics exist in the codebase. The `forecast_sample_multivariate` class and energy score are implemented and stable. Design decision needed: integrate into `score()` (Option A) or standalone `get_multivariate_ranks()` function (Option B). MST method may need `igraph` dependency. | None blocking. Builds on existing `forecast_sample_multivariate` infrastructure. | Implement pre-ranking methods (multivariate rank, optionally MST rank) from Gneiting et al. (2008) as calibration diagnostics for multivariate forecasts, after resolving the API design choice with maintainers. | N/A | N/A | — | N/A |\n| 1057 | Revise README to remove news about the package rewrite | documentation | 2026-01-29 | documentation | low | medium | partially | Open, no assignee. The rewrite messaging and Google Drive paper links appear in 4 locations in README.Rmd. Mechanical edits are straightforward but replacement text requires editorial decisions about where to point users for documentation. | Loosely related to #810 (pkgdown for dev docs) and #759 (future of scoringutils.Rmd vignette). | Edit `README.Rmd` to remove/soften the \"major re-write\" paragraph and replace Google Drive paper links with pointers to package vignettes/docs, then re-render README.md. Confirm preferred documentation hierarchy with maintainers first. | N/A | N/A | — | N/A |\n| 1055 | Model confidence sets | feature request | 2026-01-19 | feature | medium | large | no | Design phase — methodology not yet agreed upon. 6 comments with active debate. Naive pairwise p-value approach acknowledged as incomplete. Three alternatives discussed: Hansen et al. MCS, novel extension for incomplete sets, Bayesian approach. No consensus reached. | Relates to #750 (p-value computation refactor), #769 (pairwise comparison arguments), #37 (Diebold-Mariano test), #1022 (two-model pairwise). | Resolve design consensus on which MCS methodology to implement (Hansen et al. on complete sets, novel incomplete-set extension, or Bayesian), then implement `get_model_confidence_set()` building on existing pairwise comparison infrastructure. | N/A | N/A | — | N/A |\n| 1046 | multivariate scoring in scoring rules vignette | documentation | 2025-11-04 | documentation | low | small | partially | Open, agreed upon by maintainers. The scoring-rules vignette has zero mentions of multivariate scoring. A dedicated multivariate vignette already exists. Only a cross-reference and brief section are missing. | None. All underlying code and the dedicated multivariate vignette already exist. | Add a short section to `vignettes/scoring-rules.Rmd` describing the energy score for multivariate forecasts and cross-linking to the existing `scoring-multivariate-forecasts` vignette. No code changes needed. | N/A | N/A | — | N/A |\n| 1044 | Remove the commented out vignette code. | | 2025-09-23 | cleanup | low | small | yes | Still relevant. Two HTML comment blocks remain: a WIP \"Details on the grouping\" section in `scoring-multivariate-forecasts.Rmd` (lines 88-102) and a ~50-line PIT/Calibration section in `scoring-rules.Rmd` (lines 444-493). Originated from PR #998 review comment. | None. | Delete the two HTML-commented-out code blocks from `vignettes/scoring-multivariate-forecasts.Rmd` and `vignettes/scoring-rules.Rmd`. Optionally confirm with maintainers whether the PIT/Calibration text should be preserved elsewhere. | N/A | [ ] | — | [ ] |\n| 1043 | Update print method for multivariate forecasts to show `joint_across` | | 2025-09-21 | enhancement | low | small | yes | Still relevant. No `print.forecast_sample_multivariate` method exists; the generic `print.forecast` handles all types. `joint_across` is not stored as an attribute — `set_grouping()` computes `.mv_group_id` but discards the original `joint_across` value. | Builds on multivariate infrastructure from merged PR #998. | Add a `print.forecast_sample_multivariate()` method that displays `joint_across` columns. Requires either storing `joint_across` as an attribute during object construction or computing it as the set difference between forecast unit and `get_grouping()` output. Update test snapshots. | [x] | [ ] | — | [ ] |\n| 1026 | as_forecast_sample.forecast_quantile | enhancement | 2025-07-13 | enhancement | medium | medium | partially | Still relevant. The reverse conversion (`as_forecast_quantile.forecast_sample`) exists, but `as_forecast_sample.forecast_quantile` does not. No distribution-fitting dependencies in DESCRIPTION. Author plans to borrow from hubverse approach. | Related to #557 (sample_to_quantile.numeric). May introduce new dependency (e.g., `distfromq`). | Implement `as_forecast_sample.forecast_quantile()` S3 method that fits a distribution or uses interpolation to approximate the predictive CDF from quantiles and draws samples. Requires design decision on approximation method and potential new package dependency. | N/A | N/A | — | N/A |\n| 1022 | Let `get_pairwise_comparison()` run with two models? | | 2025-07-03 | enhancement | low | small | yes | Still relevant. The check at line 162 of `R/pairwise-comparisons.R` calls `cli_abort()` when `length(setdiff(comparators, baseline)) < 2`, blocking the 2-models-with-baseline case. Maintainer has expressed agreement to change to a warning. Also has typo \"compairisons\". | None. Self-contained change. | Change the `cli_abort()` to `cli_warn()` at line 162 of `R/pairwise-comparisons.R` so that 2 models with one as baseline emits a warning instead of an error. Update test expectations and fix the \"compairisons\" typo. | [x] | [ ] | — | [ ] |\n| 1002 | LaTeX not rendering in function reference | | 2025-05-20 | documentation | medium | small | yes | Still relevant. pkgdown defaults to `mathml` which doesn't handle the 63 `\\eqn{}`/`\\deqn{}` occurrences in 4 metrics files. Upstream r-lib/pkgdown#2704 is closed (won't fix mathml); recommended fix is to use `mathjax` or `katex`. No `math-rendering` setting exists in `_pkgdown.yml`. | None internally. CRAN release needed for release site fix. | Add `math-rendering: katex` (or `mathjax`) under the `template:` key in `_pkgdown.yml` and rebuild the pkgdown site. One-line config change fixes all 63 LaTeX expressions across 4 documentation files. | [x] | [ ] | — | [ ] |\n| 986 | Test scores are correct | | 2025-02-21 | enhancement | medium | medium | partially | Still relevant. WIS has reference tests (CovidHubUtils), `logs_binary` validates against `Metrics::ll`, `rps_ordinal` against `scoringRules::rps_probs`. But CRPS/DSS/log_score for sample-based forecasts, dispersion, overprediction, underprediction lack absolute-value tests. No snapshot tests pin numerical outputs on example datasets. | None | Add (1) snapshot tests pinning `score()` output on each built-in example dataset, and (2) targeted correctness tests validating key sample-based scoring functions against known analytical solutions or external reference implementations. | N/A | N/A | — | N/A |\n| 983 | Create `.data.frame` methods for `as_forecast<type>` | | 2025-01-14 | refactor | low | small | yes | Still relevant. Prerequisite #981 (making `as_forecast_*` S3 generics) is done. Currently all 7 types only have `.default` methods; no `.data.frame` methods exist. The `.default` methods silently accept any type and rely on `as.data.table()` coercion deep inside. | #981 (done). No blockers. | Rename the 7 existing `.default` methods to `.data.frame` (since they assume data.frame-like input), then create new `.default` methods that error with a helpful message about unsupported types. Update NAMESPACE, docs, and tests. | [x] | [ ] | — | [ ] |\n| 975 | Add link to score definitions in `summarise_score()` | | 2024-11-05 | enhancement | low | small | yes | Still relevant. No `print.scores` method exists anywhere in the codebase. Scores objects fall through to data.table's default print. The scoring rules vignette exists at the expected URL. Maintainers favor option 1 (link to docs) over printing definitions. | Closely related to #667 (create `print.scores` method). Should be aware of #935 (print side-effects on column mutation). | Create a `print.scores()` S3 method in `R/class-scores.R` that calls `NextMethod()` then appends a `cli_text()` link to the scoring rules vignette. Ideally coordinate with #667 to also show the metrics used. | [x] | [ ] | — | [ ] |\n| 944 | Make `get_metrics()` more customisable | enhancement, feature request | 2024-10-08 | enhancement | low | medium | partially | Still relevant. `get_metrics()` is an S3 generic with `select`/`exclude` args (via #832/#903), but the proposed `replace` argument for inline metric customization has not been implemented. The `add_args` idea from the issue body is less well-defined. | #832 (done). Related to #789 (documenting customization workflow). | Add a `replace` argument to `select_metrics()` and propagate through all 7 `get_metrics.forecast_*` methods, accepting a named list of functions to substitute by name. Evaluate whether `add_args` is worth implementing or should be dropped. | N/A | N/A | — | N/A |\n| 942 | Discrimination plots for binary forecasts | enhancement, feature request | 2024-10-07 | feature | low | small | yes | Still relevant. No binary-specific plot functions exist in the codebase. No discrimination plot, reliability diagram, or any binary visualization exists. The `forecast_binary` class and `example_binary` dataset provide exactly the data structures needed. | None. Thematically adjacent to #49 (calibration plotting) and #286 (diagnostics) but no hard dependency. | Implement a new `plot_discrimination()` function that accepts a `forecast_binary` object, groups predicted probabilities by the two levels of observed, and renders overlapping density plots via ggplot2, with optional faceting by model. Add tests and docs. | [x] | [ ] | — | [ ] |\n| 941 | Rethink `score()` and maybe make it not S3 anymore | refactor | 2024-10-06 | refactor | medium | medium | no | Still relevant. All 7 `score.forecast_*` S3 methods share near-identical boilerplate (clean, validate, reshape, apply_metrics, as_scores). Only the reshape step differs per type. No refactoring has been done since the issue was opened. Both opener and reviewer agree on the direction. | Related to #338 (cross-type metrics). Benefits from #982 (done). | Refactor `score()` from 7 S3 methods into a single function by extracting the type-specific data reshaping into a new internal S3 generic (e.g., `prepare_for_scoring()`). Requires design decision on the preparation step's interface. | N/A | N/A | — | N/A |\n| 939 | remove `check_input_<forecast_type>` functions | refactor | 2024-10-03 | refactor | low | small | partially | Still relevant. All 5 `check_input_*` functions exist. 3 (sample, quantile, interval) are unused in production code — only tested. 2 (binary, point) are used in `assert_forecast` methods. Other types (sample, quantile) already skip the check pattern, showing inconsistency. | Supersedes #684 (subset of this issue). | Delete all 5 `check_input_*` functions and their man pages. For the 2 in use (binary, point), refactor call sites to call `assert_input_*` directly or inline `check_try()`, matching the pattern already used by sample/quantile. Close #684 as duplicate. | N/A | N/A | — | N/A |\n| 938 | Rename/refactor? `assert_dims_ok_point` | refactor, low-priority | 2024-10-03 | refactor | low | small | partially | Still relevant. `assert_dims_ok_point` is used by both `assert_input_point` and `assert_input_binary`, making the `_point` suffix misleading. The function is a general-purpose dimension check. Companion `check_dims_ok_point` also exists. ~5 files to update. | None. | Rename `assert_dims_ok_point` (and `check_dims_ok_point`) to a type-agnostic name (e.g., `assert_dims_ok_scalar` or `assert_dims_match`). Update definition, 2 call sites, tests, and docs. Optionally move out of `metrics-point.R` into a shared file. | N/A | N/A | — | N/A |\n| 935 | `forecast` and `scores` objects print output every time a column is changed | high-priority | 2024-09-29 | bug | medium | large | no | Still relevant. Core bug unfixed: `print.forecast` dispatches to `print.data.table` via `NextMethod()`, which breaks data.table's internal `:=` print-suppression (call stack too deep for `shouldPrint()`). PR #956 only worked around nominal forecast validation errors with a `nrow > 30` hack. The `scores` side may no longer be affected (no `print.scores` exists). | Related to #667 (print.scores — would reintroduce problem), #685 (suppress printing in tests), #1043 (multivariate print). | Design decision needed: (a) accept cosmetic annoyance, (b) reimplement `print.forecast` without dispatching to `print.data.table` (e.g., use `format.data.table` + manipulate `.global$print`), or (c) pursue upstream data.table fix per @MichaelChirico's suggestion. | N/A | N/A | — | N/A |\n| 934 | Use illustration of local and global scores | documentation | 2024-09-28 | documentation | low | small | partially | Still relevant. `score-locality.png` already exists in `vignettes/` but is orphaned — not referenced by any vignette. The scoring-rules vignette mentions local/global in text only, with no visual. Code to regenerate is in the issue body. | Sibling issues: #929, #930, #933 (all repurpose manuscript illustrations). Consider batching. | Add the existing `score-locality.png` to `scoring-rules.Rmd` (or a new comparative vignette) with an explanatory paragraph on local vs. global scoring rules. Coordinate with #929/#930/#933 for a unified approach. | N/A | N/A | — | N/A |\n| 933 | Use nice illustration of CRPS/DSS/Log score + the number of samples needed for scores to converge | documentation | 2024-09-28 | documentation | low | medium | partially | Still relevant. `score-convergence-outliers.png` already exists in `vignettes/` but is orphaned (not referenced by any vignette). Issue #758 contains a detailed draft vignette stub (\"Choosing a scoring rule\") that already references this PNG with prose. Should be batched with siblings #929, #930, #934. | Sibling issues #929, #930, #934. Parent issue #758 (scoring rules explanation vignette). Related to #759 (vignette future). | Create a new \"Choosing a scoring rule\" vignette (per #758's stub) or integrate `score-convergence-outliers.png` into `scoring-rules.Rmd` with explanatory text on sample convergence and score properties. Best addressed as a batch with #929/#930/#934 under #758. | N/A | N/A | — | N/A |\n| 930 | Use nice illustration of the effect of increasing the mean on increasing average scores | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. `illustration-effect-scale.png` already exists in `vignettes/` but is orphaned. A deleted stub vignette (`Choosing-a-score.Rmd`) once referenced it. Author expressed uncertainty (\"maybe we don't want it anymore\"). Should be batched with siblings #929, #933, #934. | Sibling issues #929, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future). | Decide whether to integrate `illustration-effect-scale.png` into `scoring-rules.Rmd` or a new \"Choosing a score\" vignette, with text explaining how average scores scale with forecast target magnitude. If unwanted, close and delete orphaned PNG. Address with #929/#933/#934 as batch. | N/A | N/A | — | N/A |\n| 929 | Use nice illustration of Sharpness and calibration | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. Unlike siblings (#930, #933, #934), the calibration/sharpness PNG does **not** exist in the repo — it was never generated. Code to create it is in the issue body. The `scoring-rules.Rmd` has a commented-out calibration section (lines ~449-492) where this illustration would naturally fit. | Sibling issues #930, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future), #785 (vignette updates). | Generate `calibration-sharpness-illustration.png` from the code in the issue body, place in `vignettes/`, and integrate into `scoring-rules.Rmd` (or a new \"Choosing a score\" vignette). Coordinate with #930/#933/#934 batch. | N/A | N/A | — | N/A |\n| 927 | Make all internal columns, in particular `forecast_id`, more robust by prefixing it with \"scoringutils_\" | good first issue, high-priority | 2024-09-26 | refactor | high | medium | partially | Still relevant. Unprefixed internal columns (`forecast_id`, `weight`, `boundary`) risk collision with user data columns. Codebase already mixes two conventions: `.scoringutils_*` (e.g., `.scoringutils_N`) and `scoringutils_Internal*`. ~3 source files, 1 globalVariables file, 1 snapshot to update for `forecast_id` alone. Not a breaking change — all affected columns are internal. | None blocking. Self-contained refactor. | Rename unprefixed internal temp columns (`forecast_id`, `weight`, `boundary`) to `.scoringutils_` prefix, matching existing convention. Update `R/helper-quantile-interval-range.R`, `R/metrics-quantile.R`, `R/z-globalVariables.R`, and test snapshots. Also unify the two naming conventions (`.scoringutils_*` vs `scoringutils_Internal*`). | N/A | N/A | — | N/A |\n| 922 | remove `check_columns_present` | | 2024-09-25 | cleanup | low | small | yes | Still relevant. `check_columns_present` (and `test_columns_present`) are internal functions with 10 call sites across 9 files. All can be replaced by `checkmate::assert_subset`/`check_subset`/`test_subset` (already a dependency). One call site in `pairwise-comparisons.R:143` uses a custom error message and needs slightly different handling. No user-facing API impact. | Related to #839 (remove `test_columns_not_present`) — both modify `R/check-input-helpers.R`, should be batched. | Replace all 10 call sites of `check_columns_present` (and 1 of `test_columns_present`) with equivalent `checkmate` functions, then delete both functions and their tests. Consider batching with #839. | [x] | [ ] | — | [ ] |\n| 909 | Compact version of `get_duplicate_forecasts()` | enhancement, good first issue, help wanted | 2024-09-13 | enhancement | low | small | yes | Already implemented. The `counts` parameter on `get_duplicate_forecasts()` provides exactly the compact output requested. Tests exist. Issue can be closed. | None | Close this issue — the `counts` argument already provides compact/aggregated duplicate output. No further code changes needed. | N/A | N/A | — | N/A |\n| 907 | coverage of function factory | enhancement | 2024-09-12 | enhancement | low | small | partially | Still relevant. No factory helper exists. Users must manually use `purrr::partial()` (documented in `score()` docs). Only `interval_coverage` benefits currently. Hard-coded 50% and 90% variants in `get_metrics.forecast_quantile()`. Discussion stalled after 5 comments with no consensus on approach. | Related to #451 (quantile/interval metric organization), #668 (coverage flexibility). | Add either a generic `expand_metric()` utility or a `coverage_ranges` argument to `get_metrics.forecast_quantile()` to programmatically generate multiple parameterized coverage metric variants. Needs design decision on approach given only one metric currently benefits. | N/A | N/A | — | N/A |\n| 898 | Support for \"Mixture of Parameters\" scoring | feature request | 2024-09-06 | feature | low | large | partially | Still relevant but low urgency. No `forecast_distribution` class exists. Prerequisites #832 (metrics S3 rework) and #846 (ordinal class) are done. Original requester has deprioritized. Would require new class, input format design, dispatch to `scoringRules` parametric functions, and mixture handling. | #888 (S3 rework of `get_duplicate_forecasts()` — minor blocker for clean extensibility). Builds on completed #832, #846. | Implement a new `forecast_distribution` class for scoring forecasts expressed as parametric distributions or mixtures, dispatching to `scoringRules`' closed-form scoring functions. Deferred until active demand — keep on `scoringutils-2.x` milestone. | N/A | N/A | — | N/A |\n| 895 | Check quantile prediction order helper function | enhancement | 2024-08-19 | enhancement | medium | small | yes | Still relevant. Monotonicity check only exists deep in `bias_quantile_single_vector()` (metrics-quantile.R:495) as a hard error. No early warning in `assert_forecast.forecast_quantile()`. No user-facing diagnostic function. Issue #412 is the maintainer-created parent with an agreed plan (steps 1 and 3 not done). | Duplicate of / should be resolved together with #412. | Create a user-facing helper (e.g., `get_non_monotonic_forecasts()`) to identify rows where predictions decrease with increasing quantile level, and add a warning in `assert_forecast.forecast_quantile()`. Resolves both #895 and #412. | [x] | [ ] | — | [ ] |\n| 889 | Make `get_protected_columns()` S3 to avoid hard-coding things | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. `get_protected_columns()` is a plain function with a hard-coded superset of all column names for all forecast types. Not S3. Only 2 call sites (both in `forecast-unit.R`). The `intersect()` filter masks the problem but prevents extensibility for new forecast classes. No progress made. | Coordinate with #888 (same S3 pattern for `get_duplicate_forecasts()`). Unblocks #852 (new forecast class workflow). Largely resolves #740 (`get_forecast_unit` customization). | Convert `get_protected_columns()` into an S3 generic with per-class methods so each forecast type declares its own protected columns. Coordinate with #888 for consistent pattern. | N/A | N/A | — | N/A |\n| 888 | Rework `get_duplicate_forecasts()` to S3 to avoid hard-coding columns and types | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. Function hard-codes `c(\"sample_id\", \"quantile_level\", \"predicted_label\")` in two places instead of dispatching on S3 class. No work done. Codebase has many S3 precedents now. | Coordinate with #889 (same pattern for `get_protected_columns()`). Partially blocks #898, #852. Related to #740. | Convert `get_duplicate_forecasts()` into an S3 generic with per-class methods where each method knows its own type-specific columns. Retain a `.data.frame`/`.default` method with current column-sniffing logic for backward compatibility. | N/A | N/A | — | N/A |\n| 885 | Functions to export or make internal | refactor, high-priority | 2024-08-10 | refactor | medium | medium | no | Partially done. `validate_forecast()` already deleted (PR #921). Remaining: `as_forecast_generic()`, `as_scores()`, `apply_metrics()` still internal; `new_forecast()` ambiguously exported with `@keywords internal`. Design decision needed on which functions to export for custom forecast class authors. | Depends on #746 (closed). Blocks custom forecast class creation. Related to #852 (design workflow for new classes). | Decide final export list for custom forecast class API: export `as_forecast_generic()`, `as_scores()`, `apply_metrics()`, resolve ambiguous `new_forecast()` status, and update NAMESPACE. Needs maintainer decision on naming/prefixing. | N/A | N/A | — | N/A |\n| 880 | Allow users to specify the quantile in `as_forecast_point.forecast_quantile()? | | 2024-07-30 | enhancement | low | small | yes | Still relevant. Function hard-codes `0.5` on two lines (107, 115) in `R/class-forecast-quantile.R`. Design decisions already resolved in PR #876 discussion: parameter name `quantile_level`, default `0.5`, passed via `...`. No work done since issue opened. | None. Self-contained enhancement. | Add a `quantile_level` parameter (default `0.5`) to `as_forecast_point.forecast_quantile()`, replacing the two hard-coded `0.5` references, then add tests and documentation. | [x] | [ ] | — | [ ] |\n| 872 | Add a reference for CRPS decomposition approach. | | 2024-07-25 | documentation | low | small | partially | Still relevant. `crps_sample()` in `R/metrics-sample.R` has only a `scoringRules` package reference, not one for the decomposition approach. `wis()` already properly cites Bracher et al. 2021. Minor decision needed on which paper(s) to cite: Bracher et al. 2021 and/or Arnold et al. 2023. | Related to #870 (CRPS/WIS decomposition refactor). Could be addressed in same PR. | Add `@references` entries to `crps_sample()` roxygen block citing paper(s) formalizing the overprediction/underprediction/dispersion decomposition (likely Bracher et al. 2021 and/or Arnold et al. 2023). | N/A | N/A | — | N/A |\n| 870 | Refactor CRPS and WIS decomposition | refactor | 2024-07-22 | refactor | low | medium | partially | Partially addressed. PR #985 (Feb 2025) simplified `crps_sample()` decomposition internally, but the structural duplication remains: `crps_sample()`, `wis()`, and `interval_score()` each independently implement `separate_results` branching, and 6 wrapper functions (3 sample + 3 quantile) repeat identical extraction patterns. | Related to #872 (CRPS decomposition reference). Filed during PR #854 review. On `scoringutils-2.x` milestone. | Extract the decomposition logic (`separate_results` branching and wrapper function boilerplate) into a shared internal helper or factory pattern so `crps_sample()`, `wis()`, and `interval_score()` delegate to the same mechanism instead of each implementing it independently. | N/A | N/A | — | N/A |\n| 852 | Design workflow for creating new forecast classes | enhancement | 2024-07-10 | enhancement | high | large | no | Still relevant. The building blocks exist (`new_forecast()` exported, `as_forecast_generic()` internal, pattern visible in 7 class files) but no documentation, vignette, or guide for third-party class creation exists. Three prerequisite S3 refactors (#889, #888, #740) remain open and block clean extensibility because `get_protected_columns()` and `get_duplicate_forecasts()` hard-code column names, preventing new classes from working seamlessly. `as_forecast_generic()`, `apply_metrics()`, and `as_scores()` are still unexported (#885). | #889 (S3 `get_protected_columns`), #888 (S3 `get_duplicate_forecasts`), #740 (`get_forecast_unit` customization), #885 (export decision for helper functions). | Complete prerequisite S3 refactors (#889, #888), decide export list for class-creation helpers (#885), then write a vignette or article documenting the step-by-step workflow for creating a custom `forecast_*` class (define `as_forecast_<type>`, `assert_forecast.<type>`, `score.<type>`, `get_metrics.<type>`, `get_protected_columns.<type>`, `get_duplicate_forecasts.<type>`). | N/A | N/A | — | N/A |\n| 840 | Clean up input checks | | 2024-06-07 | refactor | low | medium | partially | Still relevant. Input checks are applied inconsistently: `assert_forecast.forecast_binary` and `assert_forecast.forecast_point` call `check_input_*` wrappers (double-validating with scoring functions), while sample/quantile/ordinal/nominal types skip this. `check-input-helpers.R` has a comment marking `check_try()` and wrappers for future deletion. Author leans toward pushing all checks to the scoring-function level. No work done. | Related to #939 (remove `check_input_*` functions), #839, #922. On `scoringutils-2.x` milestone. | Decide where input validation should live (scoring-function level vs. `assert_forecast` level vs. both-consistently). Then either remove `check_input_binary`/`check_input_point` calls from `assert_forecast` methods and delete wrappers + `check_try()`, or add missing checks to sample/quantile `assert_forecast` methods for consistency. | N/A | N/A | — | N/A |\n| 839 | Remove `test_columns_not_present` | | 2024-06-07 | cleanup | low | small | yes | Still relevant. `test_columns_not_present()` is a trivial 1-line wrapper around `checkmate::test_names(..., disjunct.from = ...)` with exactly 1 production call site (`R/class-forecast-binary.R:68`) and 1 test block. `checkmate::test_names` is already imported. Straightforward removal. | Related to #922 (remove `check_columns_present`) and #840 (clean up input checks). Can be batched but has no blocking dependency. | Replace the single call in `R/class-forecast-binary.R:68` with `test_names(colnames(forecast), disjunct.from = ...)`, delete the function definition in `R/check-input-helpers.R`, delete the test block, and remove the generated man page. Optionally bundle with #922. | [x] | [ ] | — | [ ] |\n| 826 | Update `plot_heatmap()` to be a table instead of a plot | | 2024-05-19 | enhancement | low | medium | partially | Still relevant. Accessibility concern from @Bisaloo is valid: current ggplot2 heatmap renders values as image text, inaccessible to screen readers. Conversation stalled — Bisaloo never replied to follow-up about output format (HTML/LaTeX). `kableExtra` is already in `Suggests`. This is a breaking change: function returns `ggplot` object, used with `+ facet_wrap()` in `inst/manuscript/`. Not used in any current vignette. Design decision needed on migration strategy. | None blocking. Thematically adjacent to #713 (visualization vignette). | Resolve stalled design conversation on output format and migration strategy (deprecate + new function vs. breaking change). Implement colored-table version using `kableExtra` (already in Suggests) or `gt` (new dep), update manuscript, replace test/snapshot, and deprecate or replace `plot_heatmap()`. | N/A | N/A | — | N/A |\n| 825 | Package scaffolding | | 2024-05-19 | refactor | low | small | yes | Still relevant. Neither recommendation acted upon: (1) `Metrics` package still imported for 3 trivial functions (`ae`, `se`, `ape`) used only in `R/class-forecast-point.R` — these are one-line base-R replacements. `Metrics` did receive a 2025 CRAN update, reducing urgency. (2) `matrixStats` not adopted; 3 `apply()` calls in `R/metrics-sample.R` could benefit. Suggest splitting into two sub-tasks, prioritizing `Metrics` removal as a quick win. | None blocking. Removing `Metrics` requires updating vignettes (`scoring-rules.Rmd`) and tests (`test-metrics-binary.R`) that reference `Metrics::` functions. | (1) Replace `Metrics::ae/se/ape` with internal one-liners in `R/class-forecast-point.R`, remove from DESCRIPTION/NAMESPACE, update vignettes and tests. (2) Optionally evaluate adding `matrixStats` for 3 `apply()` calls — lower value, separate decision. | [x] | [ ] | — | [ ] |\n| 823 | Reduce number of `try()`, `suppressMessages()`, `suppressWarnings()` used in the package | | 2024-05-19 | refactor | medium | medium | no | Still relevant. 8 direct `try()` calls + 6 indirect via `check_try()` + 1 `suppressWarnings(suppressMessages(...))` in R/ code. Usage has slightly increased since filing due to new `[.forecast` subsetting operators (PR #884). Each `try()` exists for a reason; removal requires architectural rethinking of validation flow, not simple find-and-replace. | Deeply linked to #935 (print on column change), #840 (input check cleanup), #939 (remove `check_input_*`), #885 (export decisions), #811 (batch warnings). | Address incrementally: (1) Replace blanket `try()` in subsetting operators with targeted `tryCatch()`, (2) add `verbose` params to internal validation paths to eliminate `suppress*()`, (3) replace `check_try()` with proper `check_*()` functions as part of #840. | N/A | N/A | — | N/A |\n| 811 | Should `score()`/`apply_metrics()` return warning about failed metrics in a batch? | enhancement | 2024-05-07 | enhancement | low | small | yes | Still relevant. `run_safely()` in `R/score.R:210` uses `try()` + immediate `cli_warn()` per failed metric. No batching/deferring mechanism exists. Failed metrics silently dropped from `scores` object via `as_scores()` filtering. Blog post on deferred errors referenced in issue. Only 1 comment from maintainer (\"I like this idea\"). | None blocking. Tangentially related to #823 (reduce `try()`) and #382 (metric/column name clash warnings). | Modify `apply_metrics()`/`run_safely()` to collect error messages in a list during the `lapply` loop, then emit a single batched `cli_warn()` summarizing all failed metrics at the end. Update test expectations in `test-score.R`. | [x] | [ ] | — | [ ] |\n| 810 | Clean up readme by using `pkgdown` to render dev version docs | | 2024-05-05 | documentation | low | small | yes | CLOSED (completed 2026-02-09). PR #1060 merged today, replacing R-based `packageVersion()` detection with pkgdown selective HTML (`.pkgdown-devel`/`.pkgdown-release` fenced divs). `_pkgdown.yml` already had `development: mode: auto`. Dev docs deployed at `/dev/` on gh-pages. | None. Fully resolved. | No action needed — issue closed via merged PR #1060. | N/A | N/A | — | N/A |\n| 808 | Run lintr everywhere | | 2024-05-05 | cleanup | low | medium | partially | Active work in progress. PR #1062 (\"enable lintr for tests, inst, and vignettes\") is open but not yet merged. `.lintr` excludes all `tests/`, `inst/`, and `vignettes/*.R` files. CI only lints changed files on PRs. Main scope is `tests/` (~5,400 lines across 35 files). `inst/` has only 2 R files. `vignettes/*.R` not tracked in git (auto-generated tangles). ~90 `nolint` annotations already exist in `R/` source. | #807 (cli nolint cleanup) should be done first to establish pattern. #513 (vignette .R scripts) related to vignette exclusion. PR #1062 is in flight. | Merge or rebase PR #1062 once reviews pass. May need to fix remaining lint violations or add targeted `# nolint` annotations. Address `tests/` directory-wide lint cleanup separately from `inst/` and `vignettes/`. | N/A | N/A | — | N/A |\n| 807 | Clean up linter statements around `cli` conditions | good first issue, implementation-ready | 2024-05-05 | cleanup | low | medium | yes | Still relevant. ~43 `#nolint start: keyword_quote_linter` blocks across R/ wrap `cli_abort()`/`cli_warn()` calls that use `\"!\" =`, `\"i\" =` named vector syntax. Only 12 instances use Hugo's backtick fix (`\\`!\\` =`). The fix is mechanical: replace `\"!\" =` with `` `!` = `` inside cli condition calls, then remove the `nolint` annotations. Additional `object_usage_linter` suppressions (14 blocks) exist for `.data[...]` patterns in data.table code — these need separate handling. No work done on this issue since filing. | Prerequisite for #808 (run lintr everywhere). Related to PR #583 (which introduced the cli pattern). | Replace all `\"!\" =`, `\"i\" =`, `\"x\" =`, `\"v\" =` with backtick-quoted equivalents (`` `!` = ``, etc.) in `cli_abort()`/`cli_warn()` calls across ~20 R/ files, then delete the corresponding `#nolint start`/`#nolint end` blocks. Handle `object_usage_linter` suppressions separately. | [x] | [ ] | — | [ ] |\n| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |\n| 789 | Add documentation about how to customise scores | documentation | 2024-04-13 | documentation | medium | medium | partially | Partially addressed. The `score()` roxygen docs now have a \"Customising metrics\" section with `purrr::partial()` examples (PR #874). But the core ask — a vignette walkthrough — remains undone. No vignette covers `get_metrics()` → `select_metrics()` → `purrr::partial()` → `score()` workflow. On `scoringutils-2.x` milestone. | Related to #546 (vignette restructuring — decides where customization docs go), #666 (manuscript update). | Create a vignette section (or standalone vignette) walking users through the full metric customization workflow: `get_metrics()`, `select_metrics()`, `purrr::partial()`, custom metric functions, and passing to `score()`. Coordinate with vignette restructuring in #546. | N/A | N/A | — | N/A |\n| 785 | Small updates to the scoring rules Vignette | documentation | 2024-04-10 | documentation | low | small | yes | Still relevant. None of the 7 suggestions from @seabbs's review of PR #762 have been implemented: author field still present, Google Drive link still used, no citations for proper scoring rules or transformed scores paper, `get_metrics` wording not improved for website readers, no introductory paragraph on different probabilistic forecast types. Nearly 2 years open with no progress on these items. | Loosely related to #666 (manuscript update re: Google Drive link), #758 (scoring rules vignette parent issue), #1046 (multivariate scoring in same vignette). | Implement the 7 small documentation edits in `vignettes/scoring-rules.Rmd`: remove author field, replace Google Drive link with proper reference, add citations for proper scoring rules and transformed scores, improve `get_metrics` wording, clean whitespace, and add intro paragraph on probabilistic forecast types. | [ ] | [ ] | — | [ ] |\n| 780 | Add a `verbose` argument to `as_forecast()` | | 2024-04-05 | enhancement | low | small | yes | Still relevant. `verbose` already exists on `assert_forecast()` and `assert_forecast_generic()` (PR #778) but has not been threaded through to any `as_forecast_<type>()` constructor. ~11 test lines and 1 internal R source line use `suppressMessages`/`suppressWarnings` wrappers around `as_forecast_*` calls, confirming ongoing need. Author acknowledged low urgency but wants it for test cleanup. | None. PR #778 (verbose on `assert_forecast`) already merged; plumbing is in place. | Add `verbose = TRUE` parameter to each `as_forecast_<type>.default()` method, pass it to their `assert_forecast()` calls, guard direct `cli_warn()`/`cli_inform()` calls behind the flag, and replace `suppressMessages`/`suppressWarnings` wrappers in tests and internal code with `verbose = FALSE`. | [ ] | [ ] | — | [ ] |\n| 769 | Rethink the way arguments are passed in `get_pairwise_comparisons()` | package improvement | 2024-04-03 | refactor | low | small | yes | Still relevant. `test_type`, `one_sided`, and `n_permutations` are still passed via `...` through 3 levels (`get_pairwise_comparisons` → `pairwise_comparison_one_group` → `compare_forecasts`). Users must read internal `compare_forecasts` docs to discover options. PR #994 added `test_type = NULL` but didn't address the `...` pattern. #750 (split out p-values) was deferred. | Loosely related to #750 (if p-values split out, this becomes moot — but #750 deferred indefinitely). No hard blockers. | Promote `test_type`, `one_sided`, and `n_permutations` from `...` to explicit named arguments in `get_pairwise_comparisons()` and `add_relative_skill()`, improving API discoverability. Update roxygen `@param` tags accordingly. | [ ] | [ ] | — | [ ] |\n| 763 | We should check for consistency when scoring binary forecasts | feature request, high-priority | 2024-03-30 | enhancement | medium | small | yes | Still relevant. No code warns when 0/1 factor levels are in counterintuitive order (e.g., `levels = c(1, 0)` making `0` the reference level). `assert_input_binary()` only validates factor with 2 levels and predicted in [0,1]. No helper for safe factor conversion exists. @seabbs questioned whether this is must-have for 2.0 or nice-to-have. | Loosely related to #840 (input check cleanup) and #939 (remove `check_input_*` functions). | Add a check in `assert_input_binary()` that warns when observed values are \"0\"/\"1\" and level order is `c(1, 0)`. Optionally create `as_binary_observed()` helper with a `reference_level` argument for safe factor conversion. | [ ] | [ ] | — | [ ] |\n| 759 | Future of the current `scoringutils.Rmd` vignette | documentation, question | 2024-03-27 | documentation | medium | medium | partially | Partially addressed. The outdated `scoringutils.Rmd` was removed in PR #836 (May 2024). However, the promised replacement \"Get started\" vignette was never written — @seabbs volunteered June 2024 but no PR materialized. Package has no introductory vignette. README also has dead links to deleted vignettes (`metric-details`, `scoring-forecasts-directly`). | Related to #546 (simplify getting started). Completing this would likely close #546. Dead README links should be fixed regardless. | Write a new \"Get started\" / quick-start vignette to replace the deleted `scoringutils.Rmd`. Fix dead vignette links in README.Rmd. Consider merging #546 into this issue. | N/A | N/A | — | N/A |\n| 758 | Create a vignette that explains scoring rules | documentation | 2024-03-27 | documentation | medium | large | partially | Partially addressed. Part 1 (explain each scoring rule) is covered by the existing `scoring-rules.Rmd` vignette. Part 2 (practical guidance on choosing a scoring rule — convergence, overconfidence, locality, scale sensitivity) remains unaddressed. The issue body contains a detailed vignette stub. Three illustration PNGs exist in `vignettes/` but are orphaned (not referenced by any vignette). | Parent issue for #929, #930, #933, #934 (illustration issues). Related to #785 (scoring rules vignette updates), #1046 (multivariate content). | Narrow scope to creating a \"Choosing a scoring rule\" vignette covering comparative guidance (convergence, overconfidence, locality, scale sensitivity). Coordinate with #929/#930/#933/#934 to incorporate the orphaned illustrations. | N/A | N/A | — | N/A |\n| 752 | Split up `plot_pit()` into a method for vectors and one for data.frames | | 2024-03-27 | refactor | low | small | yes | Fully resolved. `plot_pit()` was removed entirely in PRs #940 and #949. Replaced by `get_pit_histogram()` (S3 generic with methods for `forecast_sample` and `forecast_quantile`) and `pit_histogram_sample()` for low-level computation. Plotting is now via standard ggplot2 calls. The dual-purpose if/else concern no longer exists. | None. | Close as completed. The issue's concern was superseded by a complete removal of `plot_pit()` in favor of `get_pit_histogram()` with proper S3 dispatch. | N/A | N/A | — | N/A |\n| 750 | Move computation of p-values out of `get_pairwise_comparisons()`? | question | 2024-03-26 | discussion | low | medium | no | Partially addressed. PR #994 added `test_type = NULL` to skip p-value computation, resolving the main pain point (spurious warnings from `add_relative_skill()`). The broader architectural question of separating p-value from score ratio computation remains open but contributor consensus was option 1 (do nothing). | #769 (explicit test_type argument) should be considered together. #1022 (two-model case) tangentially related. | Consider closing as won't-fix or converting to long-term design discussion. The practical problem was solved by PR #994. If kept open, the most impactful remaining change would be defaulting `add_relative_skill()` to `test_type = NULL` since it discards p-values anyway. | N/A | N/A | — | N/A |\n| 740 | Make `get_forecast_unit()` and friends customisable such that they can work with new forecast classes | enhancement | 2024-03-24 | refactor | medium | medium | partially | Still relevant. No implementation work done. `get_protected_columns()` remains a plain function with hard-coded column lists (not S3). `get_duplicate_forecasts()` still hard-codes type-specific columns. Related S3 conversions (e.g., `get_forecast_type`, `get_pit`, `as_forecast`) establish the pattern. On `scoringutils-2.x` milestone. | Near-duplicate of #889 (S3 `get_protected_columns`) and #888 (S3 `get_duplicate_forecasts`). Blocks #852 (custom forecast class workflow). | Convert `get_protected_columns()` into an S3 generic with per-class methods (addressing #889), similarly make `get_duplicate_forecasts()` S3 (#888), so each forecast class declares its own columns. Follow established pattern from completed S3 conversions. | N/A | N/A | — | N/A |\n| 731 | Should `wis()` warn about missing values? | question | 2024-03-23 | discussion | low | small | no | Still relevant. Current behavior is correct — `as_forecast()` emits a vague NA message, `clean_forecast()` strips NA rows before `wis()` sees them. Discussion converged on improving the `as_forecast()` message (#537) as the primary fix, with `wis()`-specific warning being secondary. No consensus reached on implementation. | Related to #537 (high-priority: improve NA-removal message). Related to #542 (debug `score()`). Resolving #537 first would clarify what remains here. | Resolve #537 first (improve NA-removal message in `as_forecast()` to report affected row count). Then decide whether `wis()` needs its own warning for direct (non-`score()` pipeline) usage. May be closeable once #537 is done. | N/A | N/A | — | N/A |\n| 718 | Testing fails locally when done repeatedly | enhancement | 2024-03-20 | bug | low | small | yes | Still relevant and unfixed. Root cause: `cli_warn()` with `.frequency = \"once\"` and `.frequency_id = \"small_interval_range\"` suppresses warnings after first test run in same R session. 4 instances of `.frequency = \"once\"` in codebase. Tests pass on CI (fresh process) and on first local run. | No blocking dependencies. Tangentially related to #935 (surprising output behavior). | Add `rlang::reset_message_verbosity(\"small_interval_range\")` before the `expect_warning()` call in `test-metrics-interval-range.R`. Audit the other 3 `.frequency = \"once\"` sites to ensure their tests are similarly resilient. | [ ] | [ ] | — | [ ] |\n| 713 | Create vignette that showcases different ways to visualise forecasts and scores | documentation | 2024-03-11 | documentation | medium | medium | no | Still relevant. Package has 7 exported plot functions (`plot_wis`, `plot_heatmap`, `plot_interval_coverage`, `plot_quantile_coverage`, `plot_pairwise_comparisons`, `plot_forecast_counts`, `plot_correlations`) plus `theme_scoringutils()` but no dedicated visualization vignette. Only a deprecated-visualisations vignette exists. Issue requests updated `plot_score_table()` and mention of `hubVis`. | Related to #826 (plot_heatmap accessibility), #49 (calibration plotting), #942 (discrimination plots), #356 (interactions vignette). Does not block other issues. | Create a new `vignettes/visualising-scores.Rmd` with worked examples for all exported plot functions using example data. Include mention of `hubVis` as alternative for forecast visualization (per closed #812), and an updated `plot_score_table()` equivalent. | N/A | N/A | — | N/A |\n| 702 | Update docs to conform to tidyverse styleguide | good first issue | 2024-03-08 | documentation | low | small | partially | Still relevant. ~85% of `@param` tags already conform to sentence case. ~21 clearly non-conforming (lowercase start) and ~21 special-character-starting descriptions across ~15 R files. Blocker PR #705 (file reorg) was merged March 2024. Assigned to @jamesmbaazam but no PR submitted. | No blocking dependencies. Standalone cleanup task. PR #705 dependency resolved. | Fix ~21 `@param` descriptions across ~15 R files to start with capital letter and end with full stop per tidyverse style guide. Also audit ~21 special-character-starting descriptions and all `@return`/`@returns` tags for same conformance. | N/A | N/A | — | N/A |\n| 686 | Improve code coverage | | 2024-03-06 | meta | low | small | partially | Largely resolved. Coverage is at 98%. The specific sub-issue (#703, misnamed test file) was fixed in PR #704. Only `theme_scoringutils()` (18 lines) lacks any test coverage. The remaining 2% is edge-case branches. Could be closed as-is. | Sub-issue #703 resolved. No blockers. | Optionally add a test for `theme_scoringutils()` and a `.codecov.yml` with a coverage target to prevent regressions, then close this issue given the excellent 98% coverage level. | N/A | N/A | — | N/A |\n| 685 | Suppress printing in tests | enhancement, implementation-ready | 2024-03-06 | cleanup | medium | medium | partially | Still relevant. 29 `suppressMessages()` and 16 `suppressWarnings()` remain across 13 test files, silently swallowing conditions instead of asserting them. Partially addressed: 80+ `expect_no_condition()` calls already exist. Root causes include `as_forecast_*()` verbose messaging and the #935 print bug. | Partially depends on #935 (unwanted printing on `:=`). Overlaps significantly with #823 (reduce `suppress*()` in package). | Audit all 29 `suppressMessages()` and 16 `suppressWarnings()` in tests: replace with `expect_message()`/`expect_warning()` for intentional conditions, pass `verbose = FALSE` where available, or use `expect_no_condition()` after fixing the source. Also review `setup.R` score calls. | N/A | N/A | — | N/A |\n| 684 | Delete functions `check_input_sample()`, `check_input_quantile()`, `check_input_interval()` | | 2024-03-06 | cleanup | low | small | yes | Still relevant but fully superseded by #939, which covers all 5 `check_input_*` functions. These 3 functions are dead code: never called in production, not exported, only tested. A comment in `check-input-helpers.R` explicitly marks them for future deletion. Should be closed as duplicate of #939. | Superseded by #939. Related to #840 (input check cleanup) and #823 (reduce `try()`). | Close as duplicate of #939. If handled independently, delete the 3 function definitions, their man pages, roxygen cross-references, and corresponding test blocks. | [ ] | [ ] | — | [ ] |\n| 668 | Add argument to control what kind of coverage is computed by `get_coverage()` | feature request | 2024-02-29 | enhancement | low | small | yes | Still relevant and unimplemented. `get_coverage()` always computes all 4 coverage metrics with no user control. The issue body contains a near-complete code proposal (with a minor bug to fix). The function structure already cleanly separates interval and quantile computation paths. On `scoringutils-2.x` milestone. | No blocking dependencies. Standalone enhancement. | Add a `type = c(\"quantile\", \"interval\")` argument to `get_coverage()` that conditionally computes interval coverage, quantile coverage, or both. Update downstream column handling, summarisation, and tests. | [ ] | [ ] | — | [ ] |\n| 667 | Create print method for `scores()` objects | feature request | 2024-02-29 | feature | low | small | partially | Still relevant but effectively blocked by #935. No `print.scores` method exists; scores objects fall through to `print.data.table`. Adding a custom print method would exacerbate the unwanted-printing-on-`:=` bug documented in #935. Both maintainers expressed lukewarm interest, deferring to post-release. | Blocked by #935 (print on column change bug). Related to #975 (link to score definitions in print). | Implement `print.scores()` S3 method displaying computed metric names (from `metrics` attribute) before delegating to `NextMethod()`, following the `print.forecast` pattern. Wait until #935 is resolved first to avoid spurious printing on `:=` operations. | N/A | N/A | — | N/A |\n| 666 | Update the scoringutils paper that accompanies the package | question | 2024-02-29 | documentation | medium | large | no | Still relevant but partially stale. Only 2 of ~15 checklist items done. Manuscript in `inst/manuscript/` still references `magrittr`, CITATION still points to 2022 arXiv preprint. README links to Google Drive PDF. Some checklist items reference functions no longer exported. Should be broken into smaller actionable issues. | Related to #759, #789, #546, #758, #1057. | Audit the to-do list against current API to remove stale items, break remaining unchecked items into individual issues, and decide whether to prioritize the \"make a vignette out of the paper\" item before the next CRAN release. Requires human authorship decisions. | N/A | N/A | — | N/A |\n| 646 | Stop converting errors to warnings in `score()`? | help wanted, question, Breaking change | 2024-02-23 | refactor | medium | medium | partially | Still relevant. `run_safely()` in `R/score.R` still converts all metric errors to warnings via `try()` + `cli_warn()` and returns `NULL`, silently dropping failed metrics. Deferred to `scoringutils-2.x` milestone. No consensus on approach: let errors propagate (breaking), add `on_error` parameter (compatible), or batch warnings (#811). | Related to #811 (batch warnings), #941 (`score()` redesign), #823 (reduce `try()`). | Design decision needed: (a) let errors propagate as errors, (b) add `on_error = c(\"warn\", \"error\")` param to `score()`, or (c) combine with #811's batch-warning approach. Implementation touches `run_safely()` in `R/score.R` and test expectations. | N/A | N/A | — | N/A |\n| 625 | Implement a `get_unique_values()` function | implementation-ready | 2024-02-10 | enhancement | low | small | yes | Still relevant. No implementation work done. Function does not exist. Would compute `length(unique(values))` per forecast-unit column (via `get_forecast_unit()`), optionally grouped by model. Similar diagnostic purpose to `get_forecast_counts()` but different output. | Loosely related to #581 (NA in print), #935 (print bug), #621 (closed, prettier print). No hard blockers for standalone function. | Implement a new exported `get_unique_values()` function that takes a forecast object, calls `get_forecast_unit()` to identify relevant columns, and returns a summary table of unique value counts per column. Optionally integrate into `print.forecast()`. | [ ] | [ ] | — | [ ] |\n| 608 | Define input format for categorical forecasts | implementation-ready | 2024-01-17 | discussion | low | small | no | Largely resolved. Input format fully defined and implemented in `forecast_nominal` (PR #837) and `forecast_ordinal` (PR #977). Column named `predicted_label`. Strict completeness enforced. Only unimplemented item is a helper function to auto-expand incomplete forecasts with zero-probability rows, which has no dedicated tracking issue. Can be closed. | #604 (parent, closed), #607 (naming, closed). No blockers. | Close this issue as completed. Optionally open a new targeted issue for the helper function that auto-expands incomplete forecasts with zero-probability rows if still desired. | N/A | N/A | — | N/A |\n| 581 | Add the number of `NA` values to the planned print method for `forecast_*` objects, rather than throw a message? | feature request | 2024-01-05 | enhancement | medium | medium | partially | Still relevant. None of the three requested features implemented: `print.forecast()` shows no NA info, NA message in `assert_forecast_generic()` is still vague (no row count), no `get_NA()` helper exists. Issue #537 is a near-duplicate and both should be addressed together. | Near-duplicate of #537 (should be resolved together). Tangentially related to #731, #542, #935 (print bug). | Enhance `print.forecast()` to display NA row count, improve the message in `assert_forecast_generic()` to report exact number of NA rows, and consider adding a `get_na_summary()` helper. Consolidate with #537. | N/A | N/A | — | N/A |\n| 557 | sample_to_quantile.numeric method | low-priority | 2024-01-05 | enhancement | low | small | yes | Effectively resolved. `sample_to_quantile()` was replaced by `as_forecast_quantile.forecast_sample()` in PR #876. The motivating code (`interval_coverage_sample()`) was deleted entirely. No current code needs a `.numeric` method. Can be closed. | Tangentially related to #1026 (reverse conversion). No blockers. | Close this issue as resolved. The refactoring in PR #876 and deletion of `interval_coverage_sample()` eliminated the code pattern that motivated this request. | N/A | N/A | — | N/A |\n| 546 | Simplify \"Getting Started\" \\| Split into smaller chunks | documentation | 2024-01-05 | documentation | medium | medium | no | Still relevant. The old `scoringutils.Rmd` was deleted (PR #836) but the promised replacement \"Get started\" vignette was never written. Package currently has no introductory vignette at all. README has a \"Quick start\" section but no pkgdown \"Get started\" page. @seabbs volunteered in #759 but no PR materialized. | Tightly coupled with #759 (future of scoringutils.Rmd) — should be resolved together. Related to #789 (metric customization docs). | Write a new introductory \"Getting Started\" vignette (as `vignettes/scoringutils.Rmd` for pkgdown) providing a concise end-to-end walkthrough. Can close both #546 and #759 simultaneously. Requires editorial decisions on scope and content. | N/A | N/A | — | N/A |\n| 542 | Improve ways to debug `score()` | question | 2024-01-04 | enhancement | medium | medium | partially | Still relevant. Neither action item is done: (1) no vignette documents `debugonce()` for scoring rule debugging, (2) `run_safely()` still only reports the metric name in warnings, not which forecast unit/row caused the failure. The `{cli}` migration (PR #583) improved formatting but not informativeness. | Closely related to #646 (stop converting errors to warnings — open, breaking change). Related to closed #391, #418, #543, #583. | Two tasks remain: (1) add documentation showing `debugonce()` usage for debugging scoring failures, and (2) enhance `run_safely()`/`apply_metrics()` to include forecast-unit context in warning messages. Coordinate error-vs-warning design with #646. | N/A | N/A | — | N/A |\n| 537 | Inform users about the number of rows that have NA values | good first issue, question, implementation-ready, high-priority | 2024-01-03 | enhancement | medium | medium | partially | Still relevant. The message in `assert_forecast_generic()` (line 150 of `R/class-forecast.R`) still says the generic \"Some rows containing NA values may be removed\" without a row count. No NA info in `print.forecast`, no `get_na()` helper. The `anyNA()` check and `na.omit()` call are already in place, so computing the count is trivial. | Near-duplicate of #581 (NA count in print method) — should be resolved together. Related to #731 (wis NA warnings). | Minimal fix: add NA row count to the existing `cli_inform` message in `assert_forecast_generic()`. For a more complete resolution, combine with #581 to also add NA summary to `print.forecast` and potentially create a `get_na()` diagnostic helper. | N/A | N/A | — | N/A |\n| 522 | Create a way to test user-provided scoring functions | feature request | 2023-12-06 | feature | medium | medium | partially | Still relevant. No progress made. `validate_metrics()` only checks that items are functions (via `checkmate::check_function`), not signature compatibility, output shape, or runtime behavior. Custom metric errors are silently converted to warnings by `run_safely()`, making debugging hard. Each of the 6+ forecast types passes different arguments to metrics. | Loosely related to #362 (non-standard metric I/O), #823 (reduce `try()`). | Implement an exported `test_metrics()` function that runs each metric on a small representative subset of a forecast object and reports informative diagnostics: signature compatibility, runtime errors, and output shape validation. Needs design decision on API. | N/A | N/A | — | N/A |\n| 520 | Create documentation/vignette for the naming scheme of our functions | help wanted, question | 2023-11-30 | documentation | low | medium | partially | Still relevant. The issue body already describes the naming scheme in detail but no vignette or formal documentation exists. CONTRIBUTING.md only references tidyverse style guide. Issue #948 (closed) debated `get_` prefix but decided to keep it. 65 exported functions follow conventions consistently. ~2 years old with no implementation. | Related to closed #948, #610, #476, #357. No blockers. | Create a developer-facing vignette or CONTRIBUTING.md section formalizing the naming conventions (scoring rules: `<name>_<type>`, `get_*`, `as_forecast_*`, `is_forecast_*`, `plot_*`, `add_*`, `assert_`/`check_`/`test_`). Update to reflect current classes including `forecast_nominal`, `forecast_ordinal`, `forecast_sample_multivariate`. | N/A | N/A | — | N/A |\n| 513 | Investigate R scripts that get generated based on our vignettes | | 2023-11-28 | cleanup | low | small | yes | Already resolved. The `.R` and `.html` vignette artifacts (generated by `knitr` tangle) are gitignored via `vignettes/.gitignore`, excluded from linting via `.lintr`, and not tracked in git. All three mitigations from the discussion are in place. Issue can be closed. | None. | Close this issue — all requested investigation and mitigations (gitignore, buildignore, lint-ignore for vignette-generated `.R` files) are already implemented. No code changes needed. | N/A | N/A | — | N/A |\n| 492 | Expose `get_range_from_quantile()` to the user | question | 2023-11-22 | enhancement | low | small | yes | Still relevant. Function exists at `R/helper-quantile-interval-range.R:185` as `@keywords internal`, not exported. Maintainer consensus reached: rename to `get_interval_range()` and create `add_interval_range()` wrapper. Neither implemented. Original motivating function `plot_ranges()` was deleted, reducing urgency. 3 internal call sites. | Parent meta-issue #484. Tangentially related to #885 (export decisions). | Rename `get_range_from_quantile()` to `get_interval_range()`, export it, and create a new exported `add_interval_range()` that adds an `interval_range` column to a quantile-format data.table. Update 3 internal call sites, NAMESPACE, docs, and tests. | [ ] | [ ] | — | [ ] |\n| 484 | Discussion: Functions to expose to users | | 2023-11-19 | meta | low | small | partially | Partially done. 1 of 3 tracked items complete (`get_metrics()` is already exported). Remaining: `get_protected_columns()` still internal (`@keywords internal` in `R/get-protected-columns.R`), `get_range_from_quantile()` still internal (blocked on naming decision in #492). ~2 years old. | #492 (naming decision blocks `get_range_from_quantile` export). No blockers for `get_protected_columns`. | Update checkboxes: tick `get_metrics()` as done. Export `get_protected_columns()` (add `@export`, remove `@keywords internal`). Resolve #492 naming decision before exporting `get_range_from_quantile`. Consider closing in favor of tracking remaining items individually. | N/A | N/A | — | N/A |\n| 459 | Meta-issue: Code refactoring | refactor | 2023-11-17 | meta | low | medium | partially | 2 of 5 tracked sub-issues done (#446, #469). Of remaining 3: #411 is stale (function `interval_coverage_sample` removed), #454 needs updating (named function gone but duplication between `get_coverage()` and `interval_coverage()` persists), #445 still actionable (64 `::` occurrences across 18 R files). Untracked dimension-checking item partially addressed by existing `assert_input_*` pattern. 2+ years old. | #938 (rename `assert_dims_ok_point`) related to untracked item. #870 (CRPS/WIS refactor) is related open refactoring work not tracked here. | Update the issue body: close #411 as stale, update #454's description to reference current duplication, and decide whether to close this meta-issue in favor of tracking remaining refactoring (#445, #870, #938) as standalone issues. | N/A | N/A | — | N/A |\n| 455 | Discussion: Should scoring rules always return a vector? | Breaking change | 2023-11-15 | discussion | low | large | no | Stale discussion from Nov 2023 with only 2 comments and no concrete proposal. The current design (separate functions per metric component, e.g., `overprediction_quantile()`) already addresses the motivating example. All metrics consistently return numeric vectors; `apply_metrics()` requires this. API is settled. | None | Close as \"won't fix\". The vector-return contract is consistent across all metrics and well-integrated with `apply_metrics()`. The separate-function-per-component pattern already solves the motivating WIS use case. | N/A | N/A | — | N/A |\n| 454 | Code refactoring: Deduplicate code in `get_coverage()` and `interval_coverage_deviation_quantile()` | refactor, implementation-ready | 2023-11-15 | refactor | low | small | yes | Original function `interval_coverage_deviation_quantile()` was removed. Issue title is outdated. Remaining duplication is between `get_coverage()` (data.table-level) and `interval_coverage()` (numeric scoring metric) — both call `quantile_to_interval()` + bounds check independently. Duplication is small (~5 lines of core logic). | Tracked in meta-issue #459. Related to #668 (coverage type argument). | Update issue title to reference `interval_coverage()`. Refactor `get_coverage()` to delegate interval coverage computation to `interval_coverage()` or a shared internal helper, eliminating duplicated `quantile_to_interval()` + bounds-check pattern. | [ ] | [ ] | — | [ ] |\n| 453 | Create function `quantile_coverage_deviation()` | feature request, implementation-ready | 2023-11-15 | feature | low | small | no | Superseded. The requested functionality is already provided by `get_coverage()` (line 88 of `R/get-coverage.R` computes `quantile_coverage_deviation`). The analogous standalone function (`interval_coverage_dev_quantile()`) was removed rather than duplicated. Can be closed. | Related to #454 (also likely closeable) and meta-issue #459. | Close as superseded. Quantile coverage deviation is already computed in `get_coverage()`. The design decision was to consolidate coverage metrics there rather than create standalone functions. | N/A | N/A | — | N/A |\n| 451 | Deal with one-to-one functions related to quantile and interval metrics | question | 2023-11-15 | discussion | low | medium | no | Still relevant. The issue concerns the one-to-one correspondence between quantile-format and interval-format metric functions. Currently: `interval_score()` is internal (not exported), called by `wis()` after `quantile_to_interval()` conversion. Exported quantile metrics: `wis()`, `quantile_score()`, `interval_coverage()`, `ae_median_quantile()`, `bias_quantile()`, `dispersion_quantile()`, `overprediction_quantile()`, `underprediction_quantile()`. No `forecast_interval` class exists — interval format is internal only. The comment from the maintainer (\"not expose functions to users for now and rethink later\") is the current policy. Coverage code in `get_coverage()` still has its own inline computation rather than reusing `interval_coverage()`. | Related to #668 (coverage type argument), #492 (expose `get_range_from_quantile`), #870 (CRPS/WIS decomposition refactor), #907 (coverage function factory), #454 (deduplicate coverage code), #484 (functions to expose). | Keep open as a design discussion for future releases. The immediate question (whether to expose interval-format functions) was deferred. The broader question of code reuse between `get_coverage()` and `interval_coverage()` overlaps with #454 and #668. Revisit when planning the next API refactor cycle. | N/A | N/A | — | N/A |\n| 445 | Cleanup: delete calls that use `::` or `:::` and add to imports instead | refactor, implementation-ready | 2023-11-15 | cleanup | low | small | yes | Still relevant. 25 redundant `pkg::fn()` calls across 9 R files where functions are already imported in NAMESPACE (13 data.table, 5 scoringRules, 3 Metrics, 2 cli, 1 purrr, 1 utils). The oft-cited \"64 occurrences\" overstates scope — 37 are roxygen/comment references that should stay. Purely cosmetic cleanup. | None. Standalone cleanup. Tracked in meta-issue #459. | Remove the `pkg::` prefix from 25 redundant function calls across 9 R files. Leave roxygen documentation cross-references and cli-formatting self-references unchanged. | [ ] | [ ] | — | [ ] |\n| 434 | Discussion: composing score data.frames | help wanted, question | 2023-11-14 | discussion | low | medium | partially | Still relevant. No `c.scores()` or score composition method exists. Scores objects are data.tables with a `metrics` attribute. A `c.scores()` method would need `rbindlist(..., fill = TRUE)` and union of `metrics` attributes. No comments on the issue; design not discussed beyond the example in the issue body. ~2.5 years old with no progress. | Sub-issue of #433. Depends on #432 (as_point) being resolved first to enable the full workflow. | Design and implement a `c.scores()` (or `merge_scores()`) method that combines multiple scores objects via `rbindlist(fill = TRUE)`, merges `metrics` attributes, and validates that forecast unit columns are compatible. Needs maintainer input on API design. | N/A | N/A | — | N/A |\n| 433 | Meta-issue - Feature: scoring probabilistic and point forecasts together / composing scores | help wanted | 2023-11-14 | meta | low | medium | no | Neither sub-issue resolved. PR #790 (implementing `as_point`/`as_quantile`) was closed without merging in May 2024. Only `as_forecast_point.forecast_quantile()` exists (hard-coded to median). No `as_forecast_point.forecast_sample()` method. No score composition mechanism. ~2.5 years old with stalled progress. | Tracks #432 (as_point) and #434 (composing scores). Related to #880 (customizable quantile in as_forecast_point). | Complete both sub-issues: (1) implement `as_forecast_point.forecast_sample()` and optionally a user-friendly `as_point()` wrapper, (2) implement score composition via `c.scores()` or similar. Needs fresh design decision given closed PR #790. | N/A | N/A | — | N/A |\n| 432 | Create function `as_point()` that converts sample- or quantile-based forecasts into point forecasts | help wanted | 2023-11-14 | feature | medium | medium | partially | Partially addressed. `as_forecast_point.forecast_quantile()` exists (hard-coded to median, lines 105-120 of `R/class-forecast-quantile.R`). `as_forecast_point.forecast_sample()` does NOT exist. PR #790 attempted full `as_point()`/`as_quantile()` implementation but was closed without merging (May 2024). @seabbs deprioritized as \"nice to have\". | Sub-issue of #433. Related to #880 (customizable quantile_level in as_forecast_point). | Implement `as_forecast_point.forecast_sample()` (summarize samples via median/mean/custom function). Optionally create a convenience `as_point()` generic wrapping `as_forecast_point()`. Revisit closed PR #790 for design reference. | N/A | N/A | — | N/A |\n| 412 | Add check to `validate_forecast()` that predictions must not decrease with quantile | implementation-ready | 2023-11-10 | enhancement | medium | small | yes | Still relevant. Monotonicity check exists only as a hard error deep in `bias_quantile_single_vector()` (R/metrics-quantile.R:495). `assert_forecast.forecast_quantile()` does NOT check monotonicity — it only validates column presence, quantile range [0,1], and type. `validate_forecast()` was deleted and replaced by `assert_forecast()`. Agreed plan: helper function + warning in `assert_forecast`. No user-facing diagnostic function exists. | Near-duplicate of #895 (user-facing `get_non_monotonic_forecasts()` helper). Related to #840 (input check cleanup). | Add monotonicity warning to `assert_forecast.forecast_quantile()` checking that predictions don't decrease with increasing quantile_level. Create a user-facing `get_non_monotonic_forecasts()` helper to identify affected rows (resolving both #412 and #895). | [ ] | [ ] | — | [ ] |\n| 411 | Rework `interval_coverage_sample()` | refactor | 2023-11-10 | refactor | low | small | yes | Fully resolved. `interval_coverage_sample()` was deleted in commit cc41a0e5 (Jan 5, 2024) as part of the v2.0.0 redesign. NEWS.md documents: \"Removed `interval_coverage_sample()` as users are now expected to convert to a quantile format first before scoring.\" Coverage is now handled by `interval_coverage()` (quantile-based) and `get_coverage()`. Issue can be closed. | None. | Close this issue — `interval_coverage_sample()` was intentionally removed in v2.0.0. The underlying concerns (code simplification, reuse of `interval_coverage_quantile`) were resolved by deleting the function and unifying the API around quantile-format coverage computation. | N/A | N/A | — | N/A |\n| 406 | Maybe expose `get_type()`. | | 2023-11-10 | enhancement | low | small | yes | Still relevant. `get_type()` (vector type detection: classification/integer/continuous) and `get_forecast_type()` (forecast class type) both exist in `R/get-forecast-type.R` but are internal (`@keywords internal`), not exported. The proposed renames (`get_vector_type`, `get_observed_type`, `get_predicted_type`) were never implemented. No comments, no progress. | Related to #484 (functions to expose) and #885 (export decisions). No blockers. | Rename `get_type()` to `get_vector_type()`, export it, and create `get_observed_type()` / `get_predicted_type()` wrappers that extract the relevant column from a forecast and call `get_vector_type()`. Decide whether to also export `get_forecast_type()` (tracked in #484/#885). | [ ] | [ ] | — | [ ] |\n| 385 | Feature: Add data transformation functions to work with other packages | help wanted | 2023-11-03 | feature | low | large | no | Still relevant but aspirational. No conversion functions for external packages (Stan, Odin, yardstick, hubverse) exist. The `as_forecast_*` S3 generic system provides extension points for external packages to write their own methods. Hubverse integration was explicitly moved to external `hubEvals` package (#605 closed). Maintainer consensus: package-specific conversions are too varied and dependency-heavy for scoringutils. Yardstick conversion code in comments never formalized. 2+ years old with no progress. | Related to #356 (interoperability vignette), #363 (external function interface), #852 (custom forecast class workflow), #983 (`.data.frame` methods), #1026 (`as_forecast_sample.forecast_quantile`). | Consider narrowing scope or closing in favor of more specific issues. The broad goal is better served by: (1) completing S3 extensibility infrastructure (#852, #983, #889, #888), (2) writing an interoperability vignette (#356), and (3) possibly adding 1-2 zero-dependency convenience converters if demand warrants. Too broad to be directly actionable as stated. | N/A | N/A | — | N/A |\n| 382 | Feature: Input check to notify about clashes with metrics and column names | good first issue, package improvement, implementation-ready | 2023-11-02 | enhancement | medium | small | yes | Still relevant and unresolved. A pre-v2.0 implementation existed in `check_clean_data()` but was removed during the v2.0 rewrite. A commented-out test skeleton exists in `test-score.R` (lines 51-62). `apply_metrics()` silently overwrites any existing column whose name matches a metric name via `forecast[, (metric_name) := result]`. No pre-scoring clash detection exists. | Tangentially related to #927 (prefix internal columns). Could coordinate with #811 (batch warnings). No blockers. | Add a check after `validate_metrics(metrics)` in each `score.forecast_*` method comparing `names(metrics)` against `colnames(forecast)` and emitting `cli_warn()` on overlap. Uncomment and update the existing test skeleton in `test-score.R`. | [ ] | [ ] | — | [ ] |\n| 363 | Discussion: design interface for external functions with different input/output formats | help wanted, question | 2023-10-26 | enhancement | low | small | yes | Still relevant. No wrapper/adapter functions exist. Users must manually wrap external metrics with non-standard signatures (e.g., reversed arg order, numeric 0/1 instead of factor observed). Two small wrapper proposals in the issue body (`wrap_binary_numeric`, `wrap_switch_order`) were never implemented. The `purrr::partial()` mechanism alone cannot solve argument reordering or type conversion. Zero comments, no design consensus. 2+ years old. | Related to #362 (non-standard I/O formats), #522 (test user-provided scoring functions), #385 (data transformation), #789 (customization docs). No blockers. | Implement 2-3 small exported adapter functions (e.g., `metric_adapt_binary_numeric()` to convert factor to 0/1, `metric_adapt_swap_args()` to reverse observed/predicted order). Document usage in `score()`'s \"Customising metrics\" section. Resolve naming convention with maintainers first. | [ ] | [ ] | — | [ ] |\n| 362 | Discussion: How to handle scores with input / output formats not currently covered | question | 2023-10-26 | discussion | low | large | no | Still relevant. `apply_metrics()` requires each metric to return a numeric vector of length n (one per forecast unit). Metrics with non-standard I/O (many-to-one like AUC, many-to-many like PIT) cannot fit into `score()`. The PIT case is solved outside `score()` via `get_pit_histogram()`. Zero comments, no design consensus. The multivariate sample class introduced a partial precedent (multiple rows collapse into groups) but by restructuring data before `apply_metrics()`, not by changing it. 2+ years old. | Related to #455 (data frame returns — recommended for closure), #363 (wrapper functions), #338 (cross-type metrics), #941 (rethink `score()` S3), #852 (custom class workflow). | Long-term design question with no clear path forward. The pragmatic pattern (non-standard metrics live outside `score()` as standalone functions) is established. Consider closing as won't-fix or consolidating with #455, #363, #338 into a single milestone-level tracking issue. Any solution requires fundamental changes to `apply_metrics()`. | N/A | N/A | — | N/A |\n| 360 | Create a wrapper around log score to warn about its use for integer-valued forecasts | implementation-ready | 2023-10-26 | enhancement | medium | small | yes | Still relevant and unaddressed. `logs_sample()` is a thin wrapper with no integer detection or warning. `get_type()` already exists and is used by `bias_sample()` and `pit_histogram_sample()` for the same purpose. Consensus reached on MVP: add a warning when `get_type(predicted) == \"integer\"`. Discussion also suggested possibly removing `log_score` from default metrics for sample forecasts. | None. All building blocks exist (`get_type()`, `cli_warn()`, pattern established in `bias_sample()`). | Add `get_type(predicted)` check to `logs_sample()` that emits `cli_warn()` when predictions are integer-valued. Optionally move `log_score` out of the default metric list in `get_metrics.forecast_sample()`. Add targeted tests. | [ ] | [ ] | — | [ ] |\n| 356 | Documentation: Create a vignette for interactions with other packages | documentation | 2023-10-26 | documentation | low | medium | partially | Still relevant. No interoperability vignette exists. Deprecated-visualisations vignette mentions hubVis. Hubverse integration moved to external `hubEvals` package (#605, closed). No conversion functions for external packages exist in scoringutils. `as_forecast_*` S3 generics provide extension points for external packages. ~2.5 years old with no progress. | Related to #385 (data transformation for other packages), #852 (custom forecast class workflow), #983 (`.data.frame` methods). | Create a vignette documenting how to use scoringutils with common external packages (hubverse via hubEvals, Stan output, yardstick). Focus on showing the `as_forecast_*()` S3 extension mechanism and practical conversion patterns. Requires editorial decisions on scope and which packages to feature. | N/A | N/A | — | N/A |\n| 353 | Documentation: Create a vignette that details the different inputs and internal workings of scoringutils | documentation | 2023-10-26 | documentation | medium | large | partially | Still relevant but heavily overlapping with #546, #759, #852. The deleted `scoringutils.Rmd` vignette (PR #836) covered 3 of 4 bullet points; replacement was never written. README \"Quick start\" section partially addresses input formats and workflow. The \"create your own class\" bullet is blocked by prerequisite S3 refactors (#889, #888, #885). Package currently has no introductory or architecture vignette. | Tightly coupled with #546 (simplify getting started) and #759 (replace deleted vignette). \"Create your own class\" aspect depends on #852, blocked by #889, #888, #885. | Consider consolidating with #546 and #759 into a single effort to write a new introductory vignette covering input formats, the `as_forecast_*()` / `score()` workflow, and forecast object anatomy. Defer \"create your own class\" section until S3 extensibility refactors are complete. | N/A | N/A | — | N/A |\n| 338 | Discussion: Define implementation for metrics which work for different forecast types | help wanted, question, Breaking change | 2023-10-22 | discussion | low | medium | no | Partially addressed by #832 (`get_metrics()` now S3). The remaining question is whether individual metric functions (e.g., `bias_sample`/`bias_quantile`) should also become S3 generics for standalone use. Practical need is low since `score()` already dispatches correctly via `get_metrics.<class>`. 6 conceptual metrics span 2+ forecast types with type-suffixed names. | #832 (done). Related to #455 (vector returns), #941 (rethink `score()` S3). No blockers. | Consider downgrading from \"Breaking change\" since S3 wrappers could be additive. If pursued, create `bias()`, `overprediction()`, `underprediction()`, `dispersion()`, `ae_median()`, `logs()` as S3 generics dispatching on forecast class, keeping suffixed functions as implementations. Defer to future major release. | N/A | N/A | — | N/A |\n| 329 | Add additional documentation for `crps_sample()`, `logs_sample()` and `dss_sample()` | package improvement | 2023-09-15 | documentation | low | small | partially | Still relevant. Formulas exist in the vignette (`scoring-rules.Rmd`) but have not been ported to the roxygen docs for these three functions. Other functions in the same file (e.g., `bias_sample`, `pit_histogram_sample`) already have formula-rich roxygen documentation via `\\deqn{}`, providing a clear template. `dss_sample()` is worst — almost no description beyond \"wrapper.\" | None. Standalone documentation task. | Add `\\deqn{}` mathematical formulas and expanded descriptions to roxygen docs of `crps_sample()`, `logs_sample()`, and `dss_sample()` in `R/metrics-sample.R`. Adapt formulas from the existing vignette content. `dss_sample()` needs the most work. | N/A | N/A | — | N/A |\n| 289 | Add support for comparing two distributions | | 2023-07-12 | feature | low | large | no | Still relevant. Zero implementation exists. The entire package architecture assumes scoring against scalar observations. No distribution comparison functions in codebase or in `scoringRules` dependency. Requires fundamental design decisions: new forecast class, new metric functions, and integration approach. 2.5+ years old with zero comments. Filed as an aspirational idea. | Related to #852 (custom forecast class workflow), #889/#888 (S3 extensibility). No issues depend on this. | Design and implement a new forecast class for distribution-to-distribution comparison with associated metrics (energy distance, KL divergence, Wasserstein distance). Should be deferred until S3 extensibility infrastructure (#852, #889, #888) is complete. | N/A | N/A | — | N/A |\n| 286 | Extension covering idees in \"Model Diagnostics and Forecast Evaluation for Quantiles\" | enhancement, feature request | 2023-05-03 | feature | medium | large | no | Still relevant. None of the three proposed features (consistency-banded coverage plots, Murphy diagrams, CORP reliability diagrams) are implemented. Basic coverage plots and PIT histograms exist but lack the statistical rigor proposed. Paper's code could serve as starting point. ~3 years old with no progress. Design decisions needed on scope, API, and potential new dependencies (e.g., `reliabilitydiag` R package). | Thematically related to #49 (calibration plotting improvement). No hard blockers. @jbracher is already a scoringutils contributor. | Implement three new diagnostic tools from Bracher et al.: (1) add consistency bands and confidence intervals to existing coverage plots, (2) create `murphy_diagram()` function and plot, (3) create CORP reliability diagram function. Consider addressing #49 simultaneously. | N/A | N/A | — | N/A |\n| 267 | How to score literature/other resources | documentation, help wanted | 2023-02-13 | documentation | low | small | no | Still relevant. Function-level `@references` tags exist across 8 R files, and the scoring-rules vignette has a .bib with 7 papers. However, the agreed-upon deliverable — a standalone, discoverable vignette summarizing scoring methodology and linking to key literature — has not been created. Two vignettes referenced in the README (\"metric-details\", \"scoring-forecasts-directly\") do not exist on disk. ~3 years old. | None blocking. Related to #758 (scoring rules vignette), #789 (customization docs), #666 (update paper). | Create a short standalone vignette summarizing scoring methodology and consolidating all referenced literature into one discoverable place. Link to the full paper and relevant external resources. Also fix the broken vignette links in the README. Requires editorial decisions on content. | N/A | N/A | — | N/A |\n| 193 | Add more metrics to assess sharpness of forecasts in a sample format | feature request, implementation-ready | 2022-02-16 | feature | low | small | yes | Still relevant. `mad_sample()` is the only dedicated sharpness metric. SD and IQR (specifically requested) are not implemented. Both are trivial to add following the `mad_sample()` pattern (data-independent, apply function row-wise over predicted matrix). `dispersion_sample()` (CRPS component) also measures spread but is observation-dependent. `scoringRules` provides no additional sharpness measures. | None. Self-contained addition following existing `mad_sample()` pattern. | Implement `sd_sample()` and `iqr_sample()` in `R/metrics-sample.R` following the `mad_sample()` pattern. Add both to the default metric list in `get_metrics.forecast_sample()`. Add tests, documentation, and NAMESPACE exports. | [ ] | [ ] | — | [ ] |\n| 49 | Improve calibration plotting | enhancement, feature request | 2020-07-25 | feature | low | medium | no | Partially addressed. PIT histograms exist via `get_pit_histogram()` (covering item 1 approximately). Items 2 (ACF of PIT values) and 3 (marginal calibration plot) are completely unimplemented. True Talagrand/verification rank histogram also not implemented as a distinct tool. Maintainer said \"no active plan, but nice to have.\" 5+ years old. | Thematically overlaps with #286 (advanced calibration diagnostics). No hard blockers. | Three remaining items: (1) implement verification rank histogram for ensemble/sample forecasts, (2) implement ACF computation/plot for PIT values, (3) implement marginal calibration plot. Consider consolidating with #286 into a single calibration diagnostics tracking issue. | N/A | N/A | — | N/A |\n| 37 | Add Diebold Mariano test | enhancement, good first issue, help wanted, feature request | 2020-06-20 | feature | low | small | partially | Still relevant. No DM test implementation exists. `compare_forecasts()` in `R/pairwise-comparisons.R` already has a clean `test_type` dispatch pattern (Wilcoxon and permutation). The DM test's main value-add is proper handling of autocorrelated score differences common in time-series forecasting. Open since 2020 with maintainer agreement but explicitly deferred. | Dependency of #1055 (model confidence sets). Related to #750 (p-value refactor), #769 (pairwise comparison arguments), #1022 (two-model case). | Add `\"dm\"` as a new `test_type` option in `compare_forecasts()`. Self-implement the DM test statistic (preferred over adding `forecast` dependency) with Newey-West HAC variance estimator. Add tests and documentation. Coordinate naming and autocorrelation lag handling with maintainers. | N/A | N/A | — | N/A |\n\nTRIAGE_COMPLETE","numLines":131,"startLine":1,"totalLines":131}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WLyc162oTE1FfAWzTARrou","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me find the first row where **Automatable** is `yes` and **Has Tests** is `[ ]` (unchecked). Let me scan through the table:\n\n1. #1044 - Automatable: yes, Has Tests: N/A - skip\n2. #1043 - Automatable: yes, Has Tests: [x] - already done\n3. #1022 - Automatable: yes, Has Tests: [x] - already done\n4. #1002 - Automatable: yes, Has Tests: [x] - already done\n5. #983 - Automatable: yes, Has Tests: [x] - already done\n6. #975 - Automatable: yes, Has Tests: [x] - already done\n7. #942 - Automatable: yes, Has Tests: [x] - already done\n8. #922 - Automatable: yes, Has Tests: [x] - already done\n9. #909 - Automatable: yes, Has Tests: N/A - skip\n10. #895 - Automatable: yes, Has Tests: [x] - already done\n11. #880 - Automatable: yes, Has Tests: [x] - already done\n12. #839 - Automatable: yes, Has Tests: [x] - already done\n13. #825 - Automatable: yes, Has Tests: [x] - already done\n14. #811 - Automatable: yes, Has Tests: [x] - already done\n15. #807 - Automatable: yes, Has Tests: [x] - already done\n16. #793 - Automatable: yes, Has Tests: [ ] - **THIS ONE**\n\nIssue #793 is the next automatable issue without tests. Let me proceed."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":25383,"cache_read_input_tokens":21009,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":25383},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"3b10aa7c-c46c-4da8-841e-dff1f4926a8f"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WLyc162oTE1FfAWzTARrou","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0111HE2iH5k8KCEAkfdqsXtM","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"in_progress","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"pending","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":25383,"cache_read_input_tokens":21009,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":25383},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"411c5e66-cd36-498d-a080-4e6a701886ce"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0111HE2iH5k8KCEAkfdqsXtM","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d860478a-d779-4843-b175-b03171fa27de","tool_use_result":{"oldTodos":[],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"in_progress","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"pending","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013bVBAj4zDohn6Xp1rkU4o8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011gecNLdjfe5RLYGveCmSgV","name":"Bash","input":{"command":"gh issue view 793 --comments","description":"View GitHub issue #793 with all comments"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":666,"cache_read_input_tokens":46392,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":666},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"77d901f3-c79b-48ba-a55f-f6f316674646"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011gecNLdjfe5RLYGveCmSgV","type":"tool_result","content":"author:\tseabbs\nassociation:\tcontributor\nedited:\tfalse\nstatus:\tnone\n--\nIMO they should appear in different ones. In your first example all the args for all the methods get lumped together in a very confusing way\n--","is_error":false}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a93ccbd8-6140-4d0f-a03b-3a007f42022e","tool_use_result":{"stdout":"author:\tseabbs\nassociation:\tcontributor\nedited:\tfalse\nstatus:\tnone\n--\nIMO they should appear in different ones. In your first example all the args for all the methods get lumped together in a very confusing way\n--","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016RJQB9kVnCEZp43VdWdVp9","type":"message","role":"assistant","content":[{"type":"text","text":"That's very brief. Let me get the full issue view."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":152,"cache_read_input_tokens":47058,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":152},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e25e0ea9-d0f1-4185-8619-17d6a0d6aae3"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016RJQB9kVnCEZp43VdWdVp9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019tvTdhNX72To42s7YLYmSs","name":"Bash","input":{"command":"gh issue view 793 --json title,body,comments,labels,state,createdAt","description":"View issue #793 full details as JSON"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":152,"cache_read_input_tokens":47058,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":152},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"b76e248e-8265-4eaa-ac89-aeadc947b475"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019tvTdhNX72To42s7YLYmSs","type":"tool_result","content":"{\"body\":\"In #790 @seabbs introduced the functions `as_point()` and `as_quantile()` which transform a forecast object into an object of class `forecast_point()` and `forecast_quantile()`, respectively. \\r\\n\\r\\nFor other methods (e.g. `score()` or `is_forecast()`) we always lumped all methods into one doc by using `@rdname generic_function`. This was fine, as all methods had the same arguments. \\r\\n\\r\\nIn this case, the methods have different arguments, depending on the class of the input. \\r\\n\\r\\nShould all methods appear in one manual page, or should they appear in different ones? \\r\\n\\r\\nI.e. should we have something like this\\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/9dc6b3e8-0fea-49fe-82d5-a7896b3c9f34\\\" width=400>\\r\\n\\r\\nOr something like this \\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/09a8fb70-ca91-4da5-bfc1-3be040694a34\\\" width=400>\\r\\n\\r\\nand a separate\\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/48363ec4-8dea-4c21-895b-6033af052bd0\\\" width=400>\\r\\n\",\"comments\":[{\"id\":\"IC_kwDODlXCNM5-6M25\",\"author\":{\"login\":\"seabbs\"},\"authorAssociation\":\"CONTRIBUTOR\",\"body\":\"IMO they should appear in different ones. In your first example all the args for all the methods get lumped together in a very confusing way\",\"createdAt\":\"2024-05-24T10:23:39Z\",\"includesCreatedEdit\":false,\"isMinimized\":false,\"minimizedReason\":\"\",\"reactionGroups\":[],\"url\":\"https://github.com/epiforecasts/scoringutils/issues/793#issuecomment-2129186233\",\"viewerDidAuthor\":false}],\"createdAt\":\"2024-04-19T07:45:11Z\",\"labels\":[],\"state\":\"OPEN\",\"title\":\"How should we document methods that have different arguments than the default method? \"}","is_error":false}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"13accf99-9d5c-405d-912d-55cda46337e1","tool_use_result":{"stdout":"{\"body\":\"In #790 @seabbs introduced the functions `as_point()` and `as_quantile()` which transform a forecast object into an object of class `forecast_point()` and `forecast_quantile()`, respectively. \\r\\n\\r\\nFor other methods (e.g. `score()` or `is_forecast()`) we always lumped all methods into one doc by using `@rdname generic_function`. This was fine, as all methods had the same arguments. \\r\\n\\r\\nIn this case, the methods have different arguments, depending on the class of the input. \\r\\n\\r\\nShould all methods appear in one manual page, or should they appear in different ones? \\r\\n\\r\\nI.e. should we have something like this\\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/9dc6b3e8-0fea-49fe-82d5-a7896b3c9f34\\\" width=400>\\r\\n\\r\\nOr something like this \\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/09a8fb70-ca91-4da5-bfc1-3be040694a34\\\" width=400>\\r\\n\\r\\nand a separate\\r\\n<img alt=\\\"image\\\" src=\\\"https://github.com/epiforecasts/scoringutils/assets/37978797/48363ec4-8dea-4c21-895b-6033af052bd0\\\" width=400>\\r\\n\",\"comments\":[{\"id\":\"IC_kwDODlXCNM5-6M25\",\"author\":{\"login\":\"seabbs\"},\"authorAssociation\":\"CONTRIBUTOR\",\"body\":\"IMO they should appear in different ones. In your first example all the args for all the methods get lumped together in a very confusing way\",\"createdAt\":\"2024-05-24T10:23:39Z\",\"includesCreatedEdit\":false,\"isMinimized\":false,\"minimizedReason\":\"\",\"reactionGroups\":[],\"url\":\"https://github.com/epiforecasts/scoringutils/issues/793#issuecomment-2129186233\",\"viewerDidAuthor\":false}],\"createdAt\":\"2024-04-19T07:45:11Z\",\"labels\":[],\"state\":\"OPEN\",\"title\":\"How should we document methods that have different arguments than the default method? \"}","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EeQZ8bz2T97Bok33qxqrd7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EZ2tt7Z1WD4fbn7hasp3q5","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"in_progress","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":727,"cache_read_input_tokens":47210,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":727},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"c629bd2a-fff1-409d-8f01-0f44fdd27330"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EZ2tt7Z1WD4fbn7hasp3q5","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"269e84b1-d0e2-4092-b997-2359df541a9d","tool_use_result":{"oldTodos":[{"content":"Read full GitHub issue #793 with comments","status":"in_progress","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"pending","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"in_progress","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017oK2v8xmbFRtcMAD4WM5Go","type":"message","role":"assistant","content":[{"type":"text","text":"This issue is about **documentation only** — specifically about roxygen `@rdname` tags and how S3 methods with different arguments should be documented. The action summary says:\n\n> Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description.\n\nThis is a purely documentation/roxygen change — no functional code is altered. Let me examine what kind of tests could apply here. The \"tests\" would need to verify that the documentation structure is correct. Let me look at the current state of these functions and existing tests."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":253,"cache_read_input_tokens":47937,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":253},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"afc920f0-3739-423e-9338-7e502cf39122"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017oK2v8xmbFRtcMAD4WM5Go","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01V83xNxowBp3PsosNrx1ASF","name":"Task","input":{"description":"Explore roxygen docs for #793","subagent_type":"Explore","prompt":"I need to understand issue #793 in the scoringutils package. The issue is about removing shared `@rdname` tags for S3 methods whose arguments differ from the generic. The three affected methods are:\n\n1. `as_forecast_quantile.forecast_sample` \n2. `as_forecast_point.forecast_quantile`\n3. `get_pit_histogram.forecast_sample`\n\nPlease find and show me:\n\n1. The roxygen documentation blocks for each of these three methods AND their corresponding generic/default methods. Look in `R/class-forecast-quantile.R`, `R/class-forecast-point.R` (or wherever they're defined), and wherever `get_pit_histogram` is defined.\n\n2. Specifically, look at the `@rdname` tags and `@param` tags to understand how arguments differ between the generic/default and the specific methods.\n\n3. Any existing tests in `tests/testthat/` related to these three functions (search for test files mentioning `as_forecast_quantile`, `as_forecast_point`, `get_pit_histogram`).\n\n4. Show me `tests/testthat/helper-*.R` and `tests/testthat/setup.R` to understand test helpers and conventions.\n\nBe thorough - read the actual roxygen blocks in full."}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":253,"cache_read_input_tokens":47937,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":253},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"12df7c4c-2610-4f41-b7e7-d2c07330d587"}
{"type":"user","message":{"role":"user","content":[{"type":"text","text":"I need to understand issue #793 in the scoringutils package. The issue is about removing shared `@rdname` tags for S3 methods whose arguments differ from the generic. The three affected methods are:\n\n1. `as_forecast_quantile.forecast_sample` \n2. `as_forecast_point.forecast_quantile`\n3. `get_pit_histogram.forecast_sample`\n\nPlease find and show me:\n\n1. The roxygen documentation blocks for each of these three methods AND their corresponding generic/default methods. Look in `R/class-forecast-quantile.R`, `R/class-forecast-point.R` (or wherever they're defined), and wherever `get_pit_histogram` is defined.\n\n2. Specifically, look at the `@rdname` tags and `@param` tags to understand how arguments differ between the generic/default and the specific methods.\n\n3. Any existing tests in `tests/testthat/` related to these three functions (search for test files mentioning `as_forecast_quantile`, `as_forecast_point`, `get_pit_histogram`).\n\n4. Show me `tests/testthat/helper-*.R` and `tests/testthat/setup.R` to understand test helpers and conventions.\n\nBe thorough - read the actual roxygen blocks in full."}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d9ab8452-91ee-45e6-9fce-188197482f19"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01LZ1hwRbs4xZ6ZVmzsyQrzJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Mtqs2DMKALDEtbtFQezea3","name":"Bash","input":{"command":"find /Users/nikos/github-synced/scoringutils-pipeline -type f -name \"*.R\" | head -20"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1893,"cache_read_input_tokens":9234,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1893},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"bf36e163-c7cd-4bb2-8fa3-64484437a031"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Mtqs2DMKALDEtbtFQezea3","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-duplicate-forecasts.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-forecast-type.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-coverage.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-forecast-unit.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-protected-columns.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-inputs-scoring-functions.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-binary.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-check-input-helpers.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-nominal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-forecast-counts.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-scores.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-nominal.R","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"fa4989cc-78b1-4c3a-a8c6-0a9fbf03c9de"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01SoS3SPVyEKjUwQX9RECTPD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01V7vNfWHwFqRe8gi6XP9mD7","name":"Bash","input":{"command":"find /Users/nikos/github-synced/scoringutils-pipeline/R -type f -name \"*.R\" | sort"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":788,"cache_read_input_tokens":11127,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":788},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a9a1e7e7-ef0b-49dc-8e61-c4e30ef0efc9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01V7vNfWHwFqRe8gi6XP9mD7","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/R/check-input-helpers.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-binary.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-multivariate-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-nominal.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-scores.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/documentation-templates.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/forecast-unit.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-correlations.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-coverage.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-duplicate-forecasts.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-forecast-counts.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-forecast-type.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-pit-histogram.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-protected-columns.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/helper-quantile-interval-range.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-binary.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-interval-range.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-multivariate-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-nominal.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-quantile.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/metrics.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/pairwise-comparisons.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/plot-heatmap.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/plot-wis.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/score.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/scoringutils.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/summarise_scores.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/theme-scoringutils.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/transform-forecasts.R\n/Users/nikos/github-synced/scoringutils-pipeline/R/z-globalVariables.R","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"c290addf-571a-410c-8688-1271d27bf113"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019zJv34fKejGGPoRTHf4X7W","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NYS5scYLVhF2sAvY4XhdCe","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1148,"cache_read_input_tokens":11915,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1148},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"751a2de4-2e0d-4a61-91a9-112c5d0e0eab"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NYS5scYLVhF2sAvY4XhdCe","type":"tool_result","content":"     1→#' @title Create a `forecast` object for quantile-based forecasts\n     2→#' @inherit as_forecast_doc_template params description\n     3→#' @details\n     4→#' # Target format\n     5→#'\n     6→#' The input for all further scoring needs to be a data.frame or similar with\n     7→#' the following columns:\n     8→#' - `observed`: Column of type `numeric` with observed values.\n     9→#' - `predicted`: Column of type `numeric` with predicted values. Predicted\n    10→#'    values represent quantiles of the predictive distribution.\n    11→#' - `quantile_level`: Column of type `numeric`, denoting the quantile level of\n    12→#'    the corresponding predicted value.\n    13→#'    Quantile levels must be between 0 and 1.\n    14→#'\n    15→#' For convenience, we recommend an additional column `model` holding the name\n    16→#' of the forecaster or model that produced a prediction, but this is not\n    17→#' strictly necessary.\n    18→#'\n    19→#' See the [example_quantile] data set for an example.\n    20→#' @inheritSection forecast_types Forecast unit\n    21→#' @param ... Unused\n    22→#' @family functions to create forecast objects\n    23→#' @returns A `forecast` object of class `forecast_quantile`\n    24→#' @export\n    25→#' @keywords as_forecast transform\n    26→#' @examples\n    27→#' as_forecast_quantile(\n    28→#'   example_quantile,\n    29→#'   predicted = \"predicted\",\n    30→#'   forecast_unit = c(\"model\", \"target_type\", \"target_end_date\",\n    31→#'                     \"horizon\", \"location\")\n    32→#' )\n    33→as_forecast_quantile <- function(data, ...) {\n    34→  UseMethod(\"as_forecast_quantile\")\n    35→}\n    36→\n    37→\n    38→#' @rdname as_forecast_quantile\n    39→#' @param quantile_level (optional) Name of the column in `data` that contains\n    40→#'   the quantile level of the predicted values. This column will be renamed to\n    41→#'   \"quantile_level\". Only applicable to quantile-based forecasts.\n    42→#' @export\n    43→#' @method as_forecast_quantile default\n    44→#' @importFrom cli cli_warn\n    45→as_forecast_quantile.default <- function(data,\n    46→                                         forecast_unit = NULL,\n    47→                                         observed = NULL,\n    48→                                         predicted = NULL,\n    49→                                         quantile_level = NULL,\n    50→                                         ...) {\n    51→  data <- as_forecast_generic(\n    52→    data,\n    53→    forecast_unit,\n    54→    observed = observed,\n    55→    predicted = predicted,\n    56→    quantile_level = quantile_level\n    57→  )\n    58→  unique_q_levels <- sort(unique(data$quantile_level))\n    59→  level_diffs <- diff(unique_q_levels)\n    60→  if (any(level_diffs <= 1e-10)) {\n    61→    cli_warn(\n    62→      \"The {.code quantile_level} column in your data\n    63→      seems to have a rounding issue\n    64→      (run {.code diff(sort(unique(data$quantile_level)))} to see this.\n    65→      As {.code scoringutils} does not support arbitrarily fine quantile level\n    66→      increments, we're going to run {.code round(x, digits = 10)} on\n    67→      the {.code quantile_level} column.\"\n    68→    )\n    69→    data$quantile_level <- round(data$quantile_level, digits = 9)\n    70→  }\n    71→\n    72→  data <- new_forecast(data, \"forecast_quantile\")\n    73→  assert_forecast(data)\n    74→  return(data)\n    75→}\n    76→\n    77→\n    78→#' @export\n    79→#' @rdname assert_forecast\n    80→#' @keywords validate-forecast-object\n    81→assert_forecast.forecast_quantile <- function(\n    82→  forecast, forecast_type = NULL, verbose = TRUE, ...\n    83→) {\n    84→  assert(check_columns_present(forecast, \"quantile_level\"))\n    85→  forecast <- assert_forecast_generic(forecast, verbose)\n    86→  assert_forecast_type(forecast, actual = \"quantile\", desired = forecast_type)\n    87→  assert_numeric(forecast$quantile_level, lower = 0, upper = 1)\n    88→  return(invisible(NULL))\n    89→}\n    90→\n    91→\n    92→#' @export\n    93→#' @rdname is_forecast\n    94→is_forecast_quantile <- function(x) {\n    95→  inherits(x, \"forecast_quantile\") && inherits(x, \"forecast\")\n    96→}\n    97→\n    98→\n    99→#' @rdname as_forecast_point\n   100→#' @description\n   101→#' When converting a `forecast_quantile` object into a `forecast_point` object,\n   102→#' the 0.5 quantile is extracted and returned as the point forecast.\n   103→#' @export\n   104→#' @keywords as_forecast\n   105→as_forecast_point.forecast_quantile <- function(data, ...) {\n   106→  assert_forecast(data, verbose = FALSE)\n   107→  assert_subset(0.5, unique(data$quantile_level))\n   108→\n   109→  # At end of this function, the object will have be turned from a\n   110→  # forecast_quantile to a forecast_point and we don't want to validate it as a\n   111→  # forecast_point during the conversion process. The correct class is restored\n   112→  # at the end.\n   113→  data <- as.data.table(data)\n   114→\n   115→  forecast <- data[quantile_level == 0.5]\n   116→  forecast[, \"quantile_level\" := NULL]\n   117→\n   118→  point_forecast <- new_forecast(forecast, \"forecast_point\")\n   119→  return(point_forecast)\n   120→}\n   121→\n   122→\n   123→#' @importFrom stats na.omit\n   124→#' @importFrom data.table `:=` as.data.table rbindlist %like% setattr copy\n   125→#' @rdname score\n   126→#' @export\n   127→score.forecast_quantile <- function(forecast, metrics = get_metrics(forecast), ...) {\n   128→  forecast <- clean_forecast(forecast, copy = TRUE, na.omit = TRUE)\n   129→  forecast_unit <- get_forecast_unit(forecast)\n   130→  metrics <- validate_metrics(metrics)\n   131→  forecast <- as.data.table(forecast)\n   132→\n   133→  # transpose the forecasts that belong to the same forecast unit\n   134→  # make sure the quantiles and predictions are ordered in the same way\n   135→  f_transposed <- forecast[, .(\n   136→    predicted = list(predicted[order(quantile_level)]),\n   137→    observed = unique(observed),\n   138→    quantile_level = list(sort(quantile_level, na.last = TRUE)),\n   139→    scoringutils_quantile_level = toString(sort(quantile_level, na.last = TRUE))\n   140→  ), by = forecast_unit]\n   141→\n   142→  # split according to quantile_level lengths and do calculations for different\n   143→  # quantile_level lengths separately. The function `wis()` assumes that all\n   144→  # forecasts have the same quantile_levels\n   145→  f_split <- split(f_transposed, f_transposed$scoringutils_quantile_level)\n   146→\n   147→  split_result <- lapply(f_split, function(df) {\n   148→    # create a matrix out of the list of predicted values and quantile_levels\n   149→    observed <- df$observed\n   150→    predicted <- do.call(rbind, df$predicted)\n   151→    quantile_level <- unlist(unique(df$quantile_level))\n   152→    df[, c(\n   153→      \"observed\", \"predicted\", \"quantile_level\", \"scoringutils_quantile_level\"\n   154→    ) := NULL]\n   155→\n   156→    result <- apply_metrics(\n   157→      df, metrics,\n   158→      observed, predicted, quantile_level\n   159→    )\n   160→    return(result)\n   161→  })\n   162→  scores <- rbindlist(split_result, fill = TRUE)\n   163→\n   164→  scores <- as_scores(scores, metrics = names(metrics))\n   165→\n   166→  return(scores[])\n   167→}\n   168→\n   169→\n   170→#' Get default metrics for quantile-based forecasts\n   171→#'\n   172→#' @description\n   173→#' For quantile-based forecasts, the default scoring rules are:\n   174→#' - \"wis\" = [wis()]\n   175→#' - \"overprediction\" = [overprediction_quantile()]\n   176→#' - \"underprediction\" = [underprediction_quantile()]\n   177→#' - \"dispersion\" = [dispersion_quantile()]\n   178→#' - \"bias\" = [bias_quantile()]\n   179→#' - \"interval_coverage_50\" = [interval_coverage()]\n   180→#' - \"interval_coverage_90\" = purrr::partial(\n   181→#'      interval_coverage, interval_range = 90\n   182→#'    )\n   183→#' - \"ae_median\" = [ae_median_quantile()]\n   184→#'\n   185→#' Note: The `interval_coverage_90` scoring rule is created by modifying\n   186→#' [interval_coverage()], making use of the function [purrr::partial()].\n   187→#' This construct allows the function to deal with arbitrary arguments in `...`,\n   188→#' while making sure that only those that [interval_coverage()] can\n   189→#' accept get passed on to it. `interval_range = 90` is set in the function\n   190→#' definition, as passing an argument `interval_range = 90` to [score()] would\n   191→#' mean it would also get passed to `interval_coverage_50`.\n   192→#' @inheritSection illustration-input-metric-quantile Input format\n   193→#' @inheritParams get_metrics.forecast_binary\n   194→#' @export\n   195→#' @family get_metrics functions\n   196→#' @keywords handle-metrics\n   197→#' @importFrom purrr partial\n   198→#' @examples\n   199→#' get_metrics(example_quantile, select = \"wis\")\n   200→get_metrics.forecast_quantile <- function(x, select = NULL, exclude = NULL, ...) {\n   201→  all <- list(\n   202→    wis = wis,\n   203→    overprediction = overprediction_quantile,\n   204→    underprediction = underprediction_quantile,\n   205→    dispersion = dispersion_quantile,\n   206→    bias = bias_quantile,\n   207→    interval_coverage_50 = interval_coverage,\n   208→    interval_coverage_90 = purrr::partial(\n   209→      interval_coverage, interval_range = 90\n   210→    ),\n   211→    ae_median = ae_median_quantile\n   212→  )\n   213→  select_metrics(all, select, exclude)\n   214→}\n   215→\n   216→\n   217→#' @rdname get_pit_histogram\n   218→#' @importFrom stats na.omit\n   219→#' @importFrom data.table `:=` as.data.table\n   220→#' @export\n   221→get_pit_histogram.forecast_quantile <- function(forecast, num_bins = NULL,\n   222→                                                breaks = NULL, by, ...) {\n   223→  assert_number(num_bins, lower = 1, null.ok = TRUE)\n   224→  assert_numeric(breaks, lower = 0, upper = 1, null.ok = TRUE)\n   225→  forecast <- clean_forecast(forecast, copy = TRUE, na.omit = TRUE)\n   226→  forecast <- as.data.table(forecast)\n   227→  present_quantiles <- unique(c(0, forecast$quantile_level, 1))\n   228→  present_quantiles <- round(present_quantiles, 10)\n   229→\n   230→  if (!is.null(breaks)) {\n   231→    quantiles <- unique(c(0, breaks, 1))\n   232→  } else if (is.null(num_bins) || num_bins == \"auto\") {\n   233→    quantiles <- present_quantiles\n   234→  } else {\n   235→    quantiles <- seq(0, 1, 1 / num_bins)\n   236→  }\n   237→  ## avoid rounding errors\n   238→  quantiles <- round(quantiles, 10)\n   239→  diffs <- round(diff(quantiles), 10)\n   240→\n   241→  if (length(setdiff(quantiles, present_quantiles)) > 0) {\n   242→    cli::cli_warn(\n   243→      \"Some requested quantiles are missing in the forecast. \",\n   244→      \"The PIT histogram will be based on the quantiles present in the forecast.\"\n   245→    )\n   246→  }\n   247→\n   248→  forecast <- forecast[quantile_level %in% quantiles]\n   249→  forecast[, quantile_coverage := (observed <= predicted)]\n   250→\n   251→  quantile_coverage <-\n   252→    forecast[, .(quantile_coverage = mean(quantile_coverage)),\n   253→             by = c(unique(c(by, \"quantile_level\")))]\n   254→\n   255→  bins <- sprintf(\"[%s,%s)\", quantiles[-length(quantiles)], quantiles[-1])\n   256→  mids <- (quantiles[-length(quantiles)] + quantiles[-1]) / 2\n   257→\n   258→  pit_histogram <- quantile_coverage[\n   259→    order(quantile_level),\n   260→    .(\n   261→      density = diff(c(0, quantile_coverage, 1)) / diffs,\n   262→      bin = bins,\n   263→      mid = mids\n   264→    ),\n   265→    by = c(get_forecast_unit(quantile_coverage))\n   266→  ]\n   267→  return(pit_histogram[])\n   268→}\n   269→\n   270→\n   271→#' Quantile example data\n   272→#'\n   273→#' A data set with predictions for COVID-19 cases and deaths submitted to the\n   274→#' European Forecast Hub.\n   275→#'\n   276→#' The data was created using the script create-example-data.R in the inst/\n   277→#' folder (or the top level folder in a compiled package).\n   278→#'\n   279→#' @format An object of class `forecast_quantile`\n   280→#' (see [as_forecast_quantile()]) with the following columns:\n   281→#' \\describe{\n   282→#'   \\item{location}{the country for which a prediction was made}\n   283→#'   \\item{target_end_date}{the date for which a prediction was made}\n   284→#'   \\item{target_type}{the target to be predicted (cases or deaths)}\n   285→#'   \\item{observed}{Numeric: observed values}\n   286→#'   \\item{location_name}{name of the country for which a prediction was made}\n   287→#'   \\item{forecast_date}{the date on which a prediction was made}\n   288→#'   \\item{quantile_level}{quantile level of the corresponding prediction}\n   289→#'   \\item{predicted}{predicted value}\n   290→#'   \\item{model}{name of the model that generated the forecasts}\n   291→#'   \\item{horizon}{forecast horizon in weeks}\n   292→#' }\n   293→# nolint start\n   294→#' @source \\url{https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/}\n   295→# nolint end\n   296→\"example_quantile\"\n   297→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a97c9332-8d3c-4776-bc33-da11d7259a2f"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019zJv34fKejGGPoRTHf4X7W","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01ES6xDhHvT6PB5FNQsxPjka","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1148,"cache_read_input_tokens":11915,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1148},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"c8f8ed9e-9e1e-4a18-82c4-16090e9c71e6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01ES6xDhHvT6PB5FNQsxPjka","type":"tool_result","content":"     1→#' @title Create a `forecast` object for point forecasts\n     2→#' @inherit as_forecast_doc_template params description\n     3→#' @details\n     4→#' # Target format\n     5→#'\n     6→#' The input for all further scoring needs to be a data.frame or similar with\n     7→#' the following columns:\n     8→#' - `observed`: Column of type `numeric` with observed values.\n     9→#' - `predicted`: Column of type `numeric` with predicted values.\n    10→#'\n    11→#' For convenience, we recommend an additional column `model` holding the name\n    12→#' of the forecaster or model that produced a prediction, but this is not\n    13→#' strictly necessary.\n    14→#'\n    15→#' See the [example_point] data set for an example.\n    16→#' @param ... Unused\n    17→#' @returns A `forecast` object of class `forecast_point`\n    18→#' @family functions to create forecast objects\n    19→#' @export\n    20→#' @keywords as_forecast transform\n    21→as_forecast_point <- function(data, ...) {\n    22→  UseMethod(\"as_forecast_point\")\n    23→}\n    24→\n    25→\n    26→#' @rdname as_forecast_point\n    27→#' @export\n    28→#' @method as_forecast_point default\n    29→#' @importFrom cli cli_warn\n    30→as_forecast_point.default <- function(data,\n    31→                                      forecast_unit = NULL,\n    32→                                      observed = NULL,\n    33→                                      predicted = NULL,\n    34→                                      ...) {\n    35→  data <- as_forecast_generic(\n    36→    data,\n    37→    forecast_unit,\n    38→    observed = observed,\n    39→    predicted = predicted\n    40→  )\n    41→  data <- new_forecast(data, \"forecast_point\")\n    42→  assert_forecast(data)\n    43→  return(data)\n    44→}\n    45→\n    46→\n    47→#' @export\n    48→#' @rdname assert_forecast\n    49→#' @importFrom cli cli_abort\n    50→#' @keywords validate-forecast-object\n    51→assert_forecast.forecast_point <- function(\n    52→  forecast, forecast_type = NULL, verbose = TRUE, ...\n    53→) {\n    54→  forecast <- assert_forecast_generic(forecast, verbose)\n    55→  assert_forecast_type(forecast, actual = \"point\", desired = forecast_type)\n    56→  #nolint start: keyword_quote_linter object_usage_linter\n    57→  input_check <- check_input_point(forecast$observed, forecast$predicted)\n    58→  if (!isTRUE(input_check)) {\n    59→    cli_abort(\n    60→      c(\n    61→        \"!\" = \"Checking `forecast`: Input looks like a point forecast, but found\n    62→        the following issue: {input_check}\"\n    63→      )\n    64→    )\n    65→    #nolint end\n    66→  }\n    67→  return(invisible(NULL))\n    68→}\n    69→\n    70→\n    71→#' @export\n    72→#' @rdname is_forecast\n    73→is_forecast_point <- function(x) {\n    74→  inherits(x, \"forecast_point\") && inherits(x, \"forecast\")\n    75→}\n    76→\n    77→\n    78→#' @importFrom Metrics se ae ape\n    79→#' @importFrom stats na.omit\n    80→#' @importFrom data.table setattr copy\n    81→#' @rdname score\n    82→#' @export\n    83→score.forecast_point <- function(forecast, metrics = get_metrics(forecast), ...) {\n    84→  forecast <- clean_forecast(forecast, copy = TRUE, na.omit = TRUE)\n    85→  metrics <- validate_metrics(metrics)\n    86→  forecast <- as.data.table(forecast)\n    87→\n    88→  scores <- apply_metrics(\n    89→    forecast, metrics,\n    90→    forecast$observed, forecast$predicted\n    91→  )\n    92→  scores[, `:=`(predicted = NULL, observed = NULL)]\n    93→\n    94→  scores <- as_scores(scores, metrics = names(metrics))\n    95→  return(scores[])\n    96→}\n    97→\n    98→\n    99→#' Get default metrics for point forecasts\n   100→#'\n   101→#' @description\n   102→#' For point forecasts, the default scoring rules are:\n   103→#' - \"ae_point\" = [ae()][Metrics::ae()]\n   104→#' - \"se_point\" = [se()][Metrics::se()]\n   105→#' - \"ape\" = [ape()][Metrics::ape()]\n   106→#'\n   107→#' A note of caution: Every scoring rule for a point forecast\n   108→#' is implicitly minimised by a specific aspect of the predictive distribution\n   109→#' (see Gneiting, 2011).\n   110→#'\n   111→#' The mean squared error, for example, is only a meaningful scoring rule if\n   112→#' the forecaster actually reported the mean of their predictive distribution\n   113→#' as a point forecast. If the forecaster reported the median, then the mean\n   114→#' absolute error would be the appropriate scoring rule. If the scoring rule\n   115→#' and the predictive task do not align, the results will be misleading.\n   116→#'\n   117→#' Failure to respect this correspondence can lead to grossly misleading\n   118→#' results! Consider the example in the section below.\n   119→#' @inheritSection illustration-input-metric-binary-point Input format\n   120→#' @inheritParams get_metrics.forecast_binary\n   121→#' @export\n   122→#' @family get_metrics functions\n   123→#' @keywords handle-metrics\n   124→#' @examples\n   125→#' get_metrics(example_point, select = \"ape\")\n   126→#'\n   127→#' set.seed(123)\n   128→#' n <- 500\n   129→#' observed <- rnorm(n, 5, 4)^2\n   130→#'\n   131→#' predicted_mu <- mean(observed)\n   132→#' predicted_not_mu <- predicted_mu - rnorm(n, 10, 2)\n   133→#'\n   134→#' df <- data.frame(\n   135→#'   model = rep(c(\"perfect\", \"bad\"), each = n),\n   136→#'   predicted = c(rep(predicted_mu, n), predicted_not_mu),\n   137→#'   observed = rep(observed, 2),\n   138→#'   id = rep(1:n, 2)\n   139→#' ) |>\n   140→#'   as_forecast_point()\n   141→#' score(df) |>\n   142→#'   summarise_scores()\n   143→#' @references\n   144→#' Making and Evaluating Point Forecasts, Gneiting, Tilmann, 2011,\n   145→#' Journal of the American Statistical Association.\n   146→get_metrics.forecast_point <- function(x, select = NULL, exclude = NULL, ...) {\n   147→  all <- list(\n   148→    ae_point = Metrics::ae,\n   149→    se_point = Metrics::se,\n   150→    ape = Metrics::ape\n   151→  )\n   152→  select_metrics(all, select, exclude)\n   153→}\n   154→\n   155→\n   156→#' Point forecast example data\n   157→#'\n   158→#' A data set with predictions for COVID-19 cases and deaths submitted to the\n   159→#' European Forecast Hub. This data set is like the quantile example data, only\n   160→#' that the median has been replaced by a point forecast.\n   161→#'\n   162→#' The data was created using the script create-example-data.R in the inst/\n   163→#' folder (or the top level folder in a compiled package).\n   164→#'\n   165→#' @format An object of class `forecast_point` (see [as_forecast_point()])\n   166→#' with the following columns:\n   167→#' \\describe{\n   168→#'   \\item{location}{the country for which a prediction was made}\n   169→#'   \\item{target_end_date}{the date for which a prediction was made}\n   170→#'   \\item{target_type}{the target to be predicted (cases or deaths)}\n   171→#'   \\item{observed}{observed values}\n   172→#'   \\item{location_name}{name of the country for which a prediction was made}\n   173→#'   \\item{forecast_date}{the date on which a prediction was made}\n   174→#'   \\item{predicted}{predicted value}\n   175→#'   \\item{model}{name of the model that generated the forecasts}\n   176→#'   \\item{horizon}{forecast horizon in weeks}\n   177→#' }\n   178→# nolint start\n   179→#' @source \\url{https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/}\n   180→# nolint end\n   181→\"example_point\"\n   182→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"88ce4f84-4379-42be-b59e-6add6bb5c99a"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019zJv34fKejGGPoRTHf4X7W","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0184FHBRPofi7mSpVdY9zfZF","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/R/get-pit-histogram.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":1148,"cache_read_input_tokens":11915,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1148},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"c7086148-cad5-444e-881b-235b750d295e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0184FHBRPofi7mSpVdY9zfZF","type":"tool_result","content":"     1→#' @title Probability integral transformation histogram\n     2→#'\n     3→#' @description\n     4→#' Generate a Probability Integral Transformation (PIT) histogram for\n     5→#' validated forecast objects.\n     6→#'\n     7→#' See the examples for how to plot the result of this function.\n     8→#'\n     9→#' @inherit score params\n    10→#' @param num_bins The number of bins in the PIT histogram. For sample-based\n    11→#'   forecasts, the default is 10 bins. For quantile-based forecasts, the\n    12→#'   default is one bin for each available quantile.\n    13→#'   You can control the number of bins by supplying a number. This is fine for\n    14→#'   sample-based pit histograms, but may fail for quantile-based formats. In\n    15→#'   this case it is preferred to supply explicit breaks points using the\n    16→#'   `breaks` argument.\n    17→#' @param breaks Numeric vector with the break points for the bins in the\n    18→#'   PIT histogram. This is preferred when creating a PIT histogram based on\n    19→#'   quantile-based data. Default is `NULL` and breaks will be determined by\n    20→#'   `num_bins`. If `breaks` is used, `num_bins` will be ignored.\n    21→#'   0 and 1 will always be added as left and right bounds, respectively.\n    22→#' @param by Character vector with the columns according to which the\n    23→#'   PIT values shall be grouped. If you e.g. have the columns 'model' and\n    24→#'   'location' in the input data and want to have a PIT histogram for\n    25→#' every model and location, specify `by = c(\"model\", \"location\")`.\n    26→#' @inheritParams pit_histogram_sample\n    27→#' @returns A data.table with density values for each bin in the PIT histogram.\n    28→#' @examples\n    29→#' library(\"ggplot2\")\n    30→#'\n    31→#' result <- get_pit_histogram(example_sample_continuous, by = \"model\")\n    32→#' ggplot(result,  aes(x = mid, y = density)) +\n    33→#'   geom_col() +\n    34→#'   facet_wrap(. ~ model) +\n    35→#'   labs(x = \"Quantile\", y = \"Density\")\n    36→#'\n    37→#' # example with quantile data\n    38→#' result <- get_pit_histogram(example_quantile, by = \"model\")\n    39→#' ggplot(result,  aes(x = mid, y = density)) +\n    40→#'   geom_col() +\n    41→#'   facet_wrap(. ~ model) +\n    42→#'   labs(x = \"Quantile\", y = \"Density\")\n    43→#' @export\n    44→#' @keywords scoring\n    45→#' @references\n    46→#' Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe,\n    47→#' Rosalind M. Eggo, W. John Edmunds (2019) Assessing the performance of\n    48→#' real-time epidemic forecasts: A case study of Ebola in the Western Area\n    49→#' region of Sierra Leone, 2014-15, \\doi{10.1371/journal.pcbi.1006785}\n    50→get_pit_histogram <- function(forecast, num_bins, breaks, by,\n    51→                              ...) {\n    52→  UseMethod(\"get_pit_histogram\")\n    53→}\n    54→\n    55→\n    56→#' @rdname get_pit_histogram\n    57→#' @importFrom cli cli_abort\n    58→#' @export\n    59→get_pit_histogram.default <- function(forecast, num_bins, breaks, by, ...) {\n    60→  cli_abort(c(\n    61→    \"!\" = \"The input needs to be a valid forecast object represented as quantiles or samples.\" # nolint\n    62→  ))\n    63→}\n    64→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"0a8541bf-88a8-4b6e-a9ec-4bf6d7f813e1"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01XTdnjASD2wFjAHcHEHBzHj","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WDW7NCoeYrqZzi8dC7s2DJ","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":8128,"cache_read_input_tokens":13063,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8128},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6a0bd055-01b3-490a-9311-be9f1a788cad"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WDW7NCoeYrqZzi8dC7s2DJ","type":"tool_result","content":"     1→#' @title Create a `forecast` object for sample-based forecasts\n     2→#' @inherit as_forecast_doc_template params description\n     3→#' @details\n     4→#' # Target format\n     5→#'\n     6→#' The input for all further scoring needs to be a data.frame or similar with\n     7→#' the following columns:\n     8→#' - `observed`: Column of type `numeric` with observed values.\n     9→#' - `predicted`: Column of type `numeric` with predicted values. Predicted\n    10→#'    values represent random samples from the predictive distribution.\n    11→#' - `sample_id`: Column of any type with unique identifiers\n    12→#'    (unique within a single forecast) for each sample.\n    13→#'\n    14→#' For convenience, we recommend an additional column `model` holding the name\n    15→#' of the forecaster or model that produced a prediction, but this is not\n    16→#' strictly necessary.\n    17→#'\n    18→#' See the [example_sample_continuous] and [example_sample_discrete] data set\n    19→#' for an example\n    20→#' @inheritSection forecast_types Forecast unit\n    21→#' @param ... Unused\n    22→#' @family functions to create forecast objects\n    23→#' @returns A `forecast` object of class `forecast_sample`\n    24→#' @export\n    25→#' @keywords as_forecast transform\n    26→as_forecast_sample <- function(data, ...) {\n    27→  UseMethod(\"as_forecast_sample\")\n    28→}\n    29→\n    30→\n    31→#' @rdname as_forecast_sample\n    32→#' @param sample_id (optional) Name of the column in `data` that contains the\n    33→#'   sample id. This column will be renamed to \"sample_id\".\n    34→#' @export\n    35→#' @importFrom cli cli_warn\n    36→as_forecast_sample.default <- function(data,\n    37→                                       forecast_unit = NULL,\n    38→                                       observed = NULL,\n    39→                                       predicted = NULL,\n    40→                                       sample_id = NULL,\n    41→                                       ...) {\n    42→  data <- as_forecast_generic(\n    43→    data,\n    44→    forecast_unit,\n    45→    observed = observed,\n    46→    predicted = predicted,\n    47→    sample_id = sample_id\n    48→  )\n    49→  data <- new_forecast(data, \"forecast_sample\")\n    50→  assert_forecast(data)\n    51→  return(data)\n    52→}\n    53→\n    54→\n    55→#' @export\n    56→#' @rdname assert_forecast\n    57→#' @keywords validate-forecast-object\n    58→assert_forecast.forecast_sample <- function(\n    59→  forecast, forecast_type = NULL, verbose = TRUE, ...\n    60→) {\n    61→  forecast <- assert_forecast_generic(forecast, verbose)\n    62→  assert(check_columns_present(forecast, \"sample_id\"))\n    63→  assert_forecast_type(forecast, actual = \"sample\", desired = forecast_type)\n    64→  return(invisible(NULL))\n    65→}\n    66→\n    67→\n    68→#' @export\n    69→#' @rdname is_forecast\n    70→is_forecast_sample <- function(x) {\n    71→  inherits(x, \"forecast_sample\") && inherits(x, \"forecast\")\n    72→}\n    73→\n    74→\n    75→#' @rdname as_forecast_quantile\n    76→#' @details # Converting from `forecast_sample` to `forecast_quantile`\n    77→#' When creating a `forecast_quantile` object from a `forecast_sample` object,\n    78→#' the quantiles are estimated by computing empircal quantiles from the samples\n    79→#' via [quantile()]. Note that empirical quantiles are a biased estimator for\n    80→#' the true quantiles in particular in the tails of the distribution and\n    81→#' when the number of available samples is low.\n    82→#' @param probs A numeric vector of quantile levels for which\n    83→#'   quantiles will be computed. Corresponds to the `probs` argument in\n    84→#'   [quantile()].\n    85→#' @param type Type argument passed down to the quantile function. For more\n    86→#'   information, see [quantile()].\n    87→#' @importFrom stats quantile\n    88→#' @importFrom methods hasArg\n    89→#' @importFrom checkmate assert_numeric\n    90→#' @export\n    91→as_forecast_quantile.forecast_sample <- function(\n    92→  data,\n    93→  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),\n    94→  type = 7,\n    95→  ...\n    96→) {\n    97→  forecast <- as.data.table(data)\n    98→  assert_numeric(probs, min.len = 1)\n    99→  reserved_columns <- c(\"predicted\", \"sample_id\")\n   100→  by <- setdiff(colnames(forecast), reserved_columns)\n   101→\n   102→  quantile_level <- unique(\n   103→    round(c(probs, 1 - probs), digits = 10)\n   104→  )\n   105→\n   106→  forecast <-\n   107→    forecast[, .(quantile_level = quantile_level,\n   108→                 predicted = quantile(x = predicted, probs = ..probs,\n   109→                                      type = ..type, na.rm = TRUE)),\n   110→             by = by]\n   111→\n   112→  quantile_forecast <- new_forecast(forecast, \"forecast_quantile\")\n   113→  assert_forecast(quantile_forecast)\n   114→\n   115→  return(quantile_forecast)\n   116→}\n   117→\n   118→\n   119→#' @importFrom stats na.omit\n   120→#' @importFrom data.table setattr copy\n   121→#' @rdname score\n   122→#' @export\n   123→score.forecast_sample <- function(forecast, metrics = get_metrics(forecast), ...) {\n   124→  forecast <- clean_forecast(forecast, copy = TRUE, na.omit = TRUE)\n   125→  forecast_unit <- get_forecast_unit(forecast)\n   126→  metrics <- validate_metrics(metrics)\n   127→  forecast <- as.data.table(forecast)\n   128→\n   129→  # transpose the forecasts that belong to the same forecast unit\n   130→  f_transposed <- forecast[, .(predicted = list(predicted),\n   131→                               observed = unique(observed),\n   132→                               .scoringutils_N = length(sample_id)),\n   133→                           by = forecast_unit]\n   134→\n   135→  # split according to number of samples and do calculations for different\n   136→  # sample lengths separately\n   137→  f_split <- split(f_transposed, f_transposed$.scoringutils_N)\n   138→\n   139→  split_result <- lapply(f_split, function(forecast) {\n   140→    # create a matrix\n   141→    observed <- forecast$observed\n   142→    predicted <- do.call(rbind, forecast$predicted)\n   143→    forecast[, c(\"observed\", \"predicted\", \".scoringutils_N\") := NULL]\n   144→\n   145→    forecast <- apply_metrics(\n   146→      forecast, metrics,\n   147→      observed, predicted\n   148→    )\n   149→    return(forecast)\n   150→  })\n   151→  scores <- rbindlist(split_result, fill = TRUE)\n   152→  scores <- as_scores(scores, metrics = names(metrics))\n   153→  return(scores[])\n   154→}\n   155→\n   156→\n   157→#' Get default metrics for sample-based forecasts\n   158→#'\n   159→#' @description\n   160→#' For sample-based forecasts, the default scoring rules are:\n   161→#' - \"crps\" = [crps_sample()]\n   162→#' - \"overprediction\" = [overprediction_sample()]\n   163→#' - \"underprediction\" = [underprediction_sample()]\n   164→#' - \"dispersion\" = [dispersion_sample()]\n   165→#' - \"log_score\" = [logs_sample()]\n   166→#' - \"dss\" = [dss_sample()]\n   167→#' - \"mad\" = [mad_sample()]\n   168→#' - \"bias\" = [bias_sample()]\n   169→#' - \"ae_median\" = [ae_median_sample()]\n   170→#' - \"se_mean\" = [se_mean_sample()]\n   171→#' @inheritSection illustration-input-metric-sample Input format\n   172→#' @inheritParams get_metrics.forecast_binary\n   173→#' @export\n   174→#' @family get_metrics functions\n   175→#' @keywords handle-metrics\n   176→#' @examples\n   177→#' get_metrics(example_sample_continuous, exclude = \"mad\")\n   178→get_metrics.forecast_sample <- function(x, select = NULL, exclude = NULL, ...) {\n   179→  all <- list(\n   180→    bias = bias_sample,\n   181→    dss = dss_sample,\n   182→    crps = crps_sample,\n   183→    overprediction = overprediction_sample,\n   184→    underprediction = underprediction_sample,\n   185→    dispersion = dispersion_sample,\n   186→    log_score = logs_sample,\n   187→    mad = mad_sample,\n   188→    ae_median = ae_median_sample,\n   189→    se_mean = se_mean_sample\n   190→  )\n   191→  select_metrics(all, select, exclude)\n   192→}\n   193→\n   194→\n   195→#' @rdname get_pit_histogram\n   196→#' @importFrom data.table `:=` as.data.table dcast\n   197→#' @importFrom checkmate assert_int assert_numeric\n   198→#' @inheritParams pit_histogram_sample\n   199→#' @seealso [pit_histogram_sample()]\n   200→#' @export\n   201→get_pit_histogram.forecast_sample <- function(forecast, num_bins = 10,\n   202→                                              breaks = NULL, by, integers = c(\n   203→                                                \"nonrandom\", \"random\", \"ignore\"\n   204→                                              ), n_replicates = NULL, ...) {\n   205→  integers <- match.arg(integers)\n   206→  assert_int(num_bins, lower = 1, null.ok = FALSE)\n   207→  assert_numeric(breaks, lower = 0, upper = 1, null.ok = TRUE)\n   208→  forecast <- clean_forecast(forecast, copy = TRUE, na.omit = TRUE)\n   209→  forecast <- as.data.table(forecast)\n   210→\n   211→  if (is.null(breaks)) {\n   212→    quantiles <- seq(0, 1, 1 / num_bins)\n   213→  } else {\n   214→    quantiles <- unique(c(0, breaks, 1))\n   215→  }\n   216→\n   217→  forecast_wide <- data.table::dcast(\n   218→    forecast,\n   219→    ... ~ paste0(\"InternalSampl_\", sample_id),\n   220→    value.var = \"predicted\"\n   221→  )\n   222→\n   223→  bins <- sprintf(\"[%s,%s)\", quantiles[-length(quantiles)], quantiles[-1])\n   224→  mids <- (quantiles[-length(quantiles)] + quantiles[-1]) / 2\n   225→\n   226→  pit_histogram <- forecast_wide[, .(\n   227→    density = pit_histogram_sample(\n   228→      observed = observed,\n   229→      predicted = as.matrix(.SD),\n   230→      quantiles = quantiles,\n   231→      integers = integers,\n   232→      n_replicates = n_replicates\n   233→    ),\n   234→    bin = bins,\n   235→    mid = mids\n   236→  ),\n   237→  by = by,\n   238→  .SDcols = grepl(\"InternalSampl_\", names(forecast_wide), fixed = TRUE)\n   239→  ]\n   240→\n   241→  return(pit_histogram[])\n   242→}\n   243→\n   244→\n   245→#' Continuous forecast example data\n   246→#'\n   247→#' A data set with continuous predictions for COVID-19 cases and deaths\n   248→#' constructed from data submitted to the European Forecast Hub.\n   249→#'\n   250→#' The data was created using the script create-example-data.R in the inst/\n   251→#' folder (or the top level folder in a compiled package).\n   252→#'\n   253→#' @format An object of class `forecast_sample` (see [as_forecast_sample()])\n   254→#' with the following columns:\n   255→#' \\describe{\n   256→#'   \\item{location}{the country for which a prediction was made}\n   257→#'   \\item{target_end_date}{the date for which a prediction was made}\n   258→#'   \\item{target_type}{the target to be predicted (cases or deaths)}\n   259→#'   \\item{observed}{observed values}\n   260→#'   \\item{location_name}{name of the country for which a prediction was made}\n   261→#'   \\item{forecast_date}{the date on which a prediction was made}\n   262→#'   \\item{model}{name of the model that generated the forecasts}\n   263→#'   \\item{horizon}{forecast horizon in weeks}\n   264→#'   \\item{predicted}{predicted value}\n   265→#'   \\item{sample_id}{id for the corresponding sample}\n   266→#' }\n   267→# nolint start\n   268→#' @source \\url{https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/}\n   269→# nolint end\n   270→\"example_sample_continuous\"\n   271→\n   272→\n   273→#' Discrete forecast example data\n   274→#'\n   275→#' A data set with integer predictions for COVID-19 cases and deaths\n   276→#' constructed from data submitted to the European Forecast Hub.\n   277→#'\n   278→#' The data was created using the script create-example-data.R in the inst/\n   279→#' folder (or the top level folder in a compiled package).\n   280→#'\n   281→#' @format An object of class `forecast_sample` (see [as_forecast_sample()])\n   282→#' with the following columns:\n   283→#' \\describe{\n   284→#'   \\item{location}{the country for which a prediction was made}\n   285→#'   \\item{target_end_date}{the date for which a prediction was made}\n   286→#'   \\item{target_type}{the target to be predicted (cases or deaths)}\n   287→#'   \\item{observed}{observed values}\n   288→#'   \\item{location_name}{name of the country for which a prediction was made}\n   289→#'   \\item{forecast_date}{the date on which a prediction was made}\n   290→#'   \\item{model}{name of the model that generated the forecasts}\n   291→#'   \\item{horizon}{forecast horizon in weeks}\n   292→#'   \\item{predicted}{predicted value}\n   293→#'   \\item{sample_id}{id for the corresponding sample}\n   294→#' }\n   295→# nolint start\n   296→#' @source \\url{https://github.com/european-modelling-hubs/covid19-forecast-hub-europe_archive/commit/a42867b1ea152c57e25b04f9faa26cfd4bfd8fa6/}\n   297→# nolint end\n   298→\"example_sample_discrete\"\n   299→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a254fb54-4d27-4e6f-b8fb-e8281aa66b9d"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01NKfX1bZybZcnchaEURQBWd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DdVZ6n4UE99jWGHSQzjCvy","name":"Bash","input":{"command":"find /Users/nikos/github-synced/scoringutils-pipeline/tests/testthat -type f -name \"*.R\" | sort"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":4435,"cache_read_input_tokens":21191,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":4435},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"dd554385-ff25-4301-becf-bea8911d1ac9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DdVZ6n4UE99jWGHSQzjCvy","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-check-input-helpers.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-binary.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-multivariate-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-nominal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-scores.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-forecast-unit.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-correlations.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-coverage.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-duplicate-forecasts.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-forecast-counts.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-forecast-type.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-get-protected-columns.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-helper-quantile-interval-range.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-inputs-scoring-functions.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-binary.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-interval-range.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-nominal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-ordinal.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-point.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-quantile.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics-sample.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-metrics.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-pairwise_comparison.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-plot_heatmap.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-plot_wis.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-score.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-summarise_scores.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-transform-forecasts.R","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"100aa257-fccc-4fc6-8fb5-441aa8b25861"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DtBW1BKTzcpekM1YRv8ke4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017hcqVTEV6p1V5pNfVP94cm","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1242,"cache_read_input_tokens":25626,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1242},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f9412b2d-6d1f-4b19-8b6e-3c7be7a25bbc"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017hcqVTEV6p1V5pNfVP94cm","type":"tool_result","content":"     1→data.table::setDTthreads(2) # restricts number of cores used on CRAN\n     2→\n     3→metrics_no_cov <- get_metrics(\n     4→  example_quantile,\n     5→  exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\n     6→)\n     7→metrics_no_cov_no_ae <- get_metrics(\n     8→  example_quantile,\n     9→  exclude = c(\n    10→    \"interval_coverage_50\", \"interval_coverage_90\",\n    11→    \"ae_median\"\n    12→  )\n    13→)\n    14→\n    15→example_quantile_df <- as.data.frame(na.omit(example_quantile))\n    16→checkmate::assert_number(length(class(example_quantile_df)))\n    17→\n    18→\n    19→# pre-computed scores\n    20→scores_quantile <- score(example_quantile)\n    21→scores_sample_continuous <- score(example_sample_continuous)\n    22→scores_sample_discrete <- score(example_sample_discrete)\n    23→scores_point <- score(example_point)\n    24→scores_binary <- score(example_binary)\n    25→scores_nominal <- score(example_nominal)\n    26→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"66b01ff0-f3cd-41db-b650-95d511803888"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DtBW1BKTzcpekM1YRv8ke4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01U14FA8ZTBdgVARSgdFd3Ct","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1242,"cache_read_input_tokens":25626,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1242},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d59e0c79-82f5-4ce4-b53b-558a40bc699a"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01U14FA8ZTBdgVARSgdFd3Ct","type":"tool_result","content":"     1→# ==============================================================================\n     2→# as_forecast_quantile() # nolint: commented_code_linter\n     3→# ==============================================================================\n     4→\n     5→test_that(\"as_forecast_quantile() works as expected\", {\n     6→  test <- na.omit(data.table::copy(example_quantile))\n     7→\n     8→  expect_s3_class(\n     9→    as_forecast_quantile(test),\n    10→    c(\"forecast_quantile\", \"forecast\", \"data.table\", \"data.frame\"),\n    11→    exact = TRUE\n    12→  )\n    13→\n    14→  # expect error when arguments are not correct\n    15→  expect_error(as_forecast_quantile(test, observed = 3), \"Must be of type 'character'\")\n    16→  expect_error(as_forecast_quantile(test, quantile_level = c(\"1\", \"2\")), \"Must have length 1\")\n    17→  expect_error(as_forecast_quantile(test, observed = \"missing\"), \"Must be a subset of\")\n    18→\n    19→  # expect no condition with columns already present\n    20→  expect_no_condition(\n    21→    as_forecast_quantile(test,\n    22→      observed = \"observed\", predicted = \"predicted\",\n    23→      forecast_unit = c(\n    24→        \"location\", \"model\", \"target_type\",\n    25→        \"target_end_date\", \"horizon\"\n    26→      ),\n    27→      quantile_level = \"quantile_level\"\n    28→    )\n    29→  )\n    30→})\n    31→\n    32→test_that(\"as_forecast_quantile() function works\", {\n    33→  check <- suppressMessages(as_forecast_quantile(example_quantile))\n    34→  expect_s3_class(check, \"forecast_quantile\")\n    35→})\n    36→\n    37→test_that(\"as_forecast_quantile() errors if there is both a sample_id and a quantile_level column\", {\n    38→  example <- as.data.table(example_quantile)[, sample_id := 1]\n    39→  expect_error(\n    40→    as_forecast_quantile(example),\n    41→    \"Found columns `quantile_level` and `sample_id`. Only one of these is allowed\"\n    42→  )\n    43→})\n    44→\n    45→test_that(\"as_forecast_quantile() warns if there are different numbers of quantiles\", {\n    46→  example <- as.data.table(example_quantile)[-1000, ]\n    47→  w <- suppressWarnings(as_forecast_quantile(na.omit(example)))\n    48→  expect_warning(\n    49→    as_forecast_quantile(na.omit(example)),\n    50→    \"Some forecasts have different numbers of rows\"\n    51→  )\n    52→  # printing should work without a warning because printing is silent\n    53→  expect_no_condition(w)\n    54→})\n    55→\n    56→test_that(\"as_forecast_quantile() function throws an error with duplicate forecasts\", {\n    57→  example <- rbind(\n    58→    example_quantile,\n    59→    example_quantile[1000:1010]\n    60→  )\n    61→\n    62→  expect_error(\n    63→    suppressMessages(suppressWarnings(as_forecast_quantile(example))),\n    64→    \"Assertion on 'data' failed: There are instances with more than one forecast for the same target. This can't be right and needs to be resolved. Maybe you need to check the unit of a single forecast and add missing columns? Use the function get_duplicate_forecasts() to identify duplicate rows.\", # nolint\n    65→    fixed = TRUE\n    66→  )\n    67→})\n    68→\n    69→test_that(\"as_forecast_quantile() function throws an error when no predictions or observed values are present\", {\n    70→  expect_error(\n    71→    suppressMessages(suppressWarnings(as_forecast_quantile(\n    72→      data.table::copy(example_quantile)[, predicted := NULL]\n    73→    ))),\n    74→    \"Assertion on 'data' failed: Column 'predicted' not found in data.\"\n    75→  )\n    76→\n    77→  expect_error(\n    78→    suppressMessages(suppressWarnings(as_forecast_quantile(\n    79→      data.table::copy(example_quantile)[, observed := NULL]\n    80→    ))),\n    81→    \"Assertion on 'data' failed: Column 'observed' not found in data.\"\n    82→  )\n    83→\n    84→  expect_error(\n    85→    suppressMessages(suppressWarnings(as_forecast_quantile(\n    86→      data.table::copy(example_quantile)[, c(\"observed\", \"predicted\") := NULL]\n    87→    ))),\n    88→    \"Assertion on 'data' failed: Columns 'observed', 'predicted' not found in data.\"\n    89→  )\n    90→})\n    91→\n    92→test_that(\"as_forecast_quantile() works with a data.frame\", {\n    93→  expect_no_condition(as_forecast_quantile(example_quantile_df))\n    94→})\n    95→\n    96→test_that(\"as_forecast_quantiles works\", {\n    97→  samples <- data.frame(\n    98→    date = as.Date(\"2020-01-01\") + 1:10,\n    99→    model = \"model1\",\n   100→    observed = 1:10,\n   101→    predicted = c(rep(0, 10), 2:11, 3:12, 4:13, rep(100, 10)),\n   102→    sample_id = rep(1:5, each = 10),\n   103→    stringsAsFactors = FALSE\n   104→  ) |>\n   105→    as_forecast_sample()\n   106→\n   107→  quantile <- data.frame(\n   108→    date = rep(as.Date(\"2020-01-01\") + 1:10, each = 2),\n   109→    model = \"model1\",\n   110→    observed = rep(1:10, each = 2),\n   111→    quantile_level = c(0.25, 0.75),\n   112→    predicted = rep(2:11, each = 2) + c(0, 2),\n   113→    stringsAsFactors = FALSE\n   114→  )\n   115→\n   116→  expect_no_condition(\n   117→    as_forecast_quantile(samples, probs = c(0.25, 0.75))\n   118→  )\n   119→\n   120→  wrongclass <- as_forecast_sample(samples)\n   121→  class(wrongclass) <- c(\"forecast_point\", \"data.table\", \"data.frame\")\n   122→  expect_error(\n   123→    as_forecast_quantile(wrongclass, quantile_level = c(0.25, 0.75)),\n   124→    \"Assertion on 'quantile_level' failed: Must be of type\"\n   125→  )\n   126→\n   127→\n   128→  quantile2 <- as_forecast_quantile(\n   129→    as_forecast_sample(samples),\n   130→    probs = c(0.25, 0.75)\n   131→  )\n   132→\n   133→  expect_identical(quantile, as.data.frame(quantile2))\n   134→\n   135→  # Verify that `type` is correctly scoped in as_forecast_quantile(), as it is\n   136→  # also an argument.\n   137→  # If it's not scoped well, the call to `as_forecast_quantile()` will fail.\n   138→  samples$type <- \"test\"\n   139→\n   140→  quantile3 <- as_forecast_quantile(\n   141→    as_forecast_sample(samples),\n   142→    probs = c(0.25, 0.75)\n   143→  )\n   144→  quantile3$type <- NULL\n   145→\n   146→  expect_identical(\n   147→    quantile2,\n   148→    quantile3\n   149→  )\n   150→})\n   151→\n   152→test_that(\"as_forecast_quantiles issue 557 fix\", {\n   153→  out <- example_sample_discrete |>\n   154→    na.omit() |>\n   155→    as_forecast_quantile(\n   156→      probs = c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)\n   157→    ) |>\n   158→    score()\n   159→\n   160→  expect_false(anyNA(out$interval_coverage_deviation))\n   161→})\n   162→\n   163→test_that(\"as_forecast_quantile doesn't modify column names in place\", {\n   164→  quantile_data <- data.table(\n   165→    my_quantile = c(0.25, 0.5),\n   166→    forecast_value = c(1, 2),\n   167→    observed_value = c(5, 5)\n   168→  )\n   169→  pre <- names(quantile_data)\n   170→\n   171→  quantile_forecast <- as_forecast_quantile(\n   172→    quantile_data,\n   173→    predicted = \"forecast_value\",\n   174→    observed = \"observed_value\",\n   175→    quantile_level = \"my_quantile\"\n   176→  )\n   177→\n   178→  post <- names(quantile_data)\n   179→  expect_identical(pre, post)\n   180→})\n   181→\n   182→test_that(\"as_forecast_quantile handles rounding issues correctly\", {\n   183→  quantile_data <- data.table(\n   184→    quantile_level = c(0.25, 0.75 + 1e-13, 0.25, 0.75),\n   185→    predicted = c(1, 2, 3, 4),\n   186→    observed = c(5, 5, 5, 5),\n   187→    location = c(1, 1, 2, 2)\n   188→  )\n   189→  quantile_forecast <- suppressWarnings(as_forecast_quantile(quantile_data))\n   190→  expect_warning(\n   191→    as_forecast_quantile(quantile_data),\n   192→    \"rounding issue\"\n   193→  )\n   194→  expect_no_condition(\n   195→    score(quantile_forecast, metrics = c(wis = wis))\n   196→  )\n   197→})\n   198→\n   199→\n   200→\n   201→\n   202→\n   203→# ==============================================================================\n   204→# is_forecast_quantile() # nolint: commented_code_linter\n   205→# ==============================================================================\n   206→test_that(\"is_forecast_quantile() works as expected\", {\n   207→  expect_true(is_forecast_quantile(example_quantile))\n   208→  expect_false(is_forecast_quantile(example_binary))\n   209→  expect_false(is_forecast_quantile(example_point))\n   210→  expect_false(is_forecast_quantile(example_sample_continuous))\n   211→  expect_false(is_forecast_quantile(example_nominal))\n   212→})\n   213→\n   214→# ==============================================================================\n   215→# score.forecast_quantile() # nolint: commented_code_linter\n   216→# ==============================================================================\n   217→test_that(\"score_quantile correctly handles separate results = FALSE\", {\n   218→  df <- example_quantile[model == \"EuroCOVIDhub-ensemble\" &\n   219→                           target_type == \"Cases\" & location == \"DE\"]\n   220→  metrics <- get_metrics(example_quantile)\n   221→  metrics$wis <- purrr::partial(wis, separate_results = FALSE)\n   222→  eval <- score(df[!is.na(predicted)], metrics = metrics)\n   223→\n   224→  expect_gt(\n   225→    nrow(eval), 1\n   226→  )\n   227→  expect_true(all(names(get_metrics(example_quantile)) %in% colnames(eval)))\n   228→\n   229→  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\n   230→})\n   231→\n   232→\n   233→test_that(\"score() quantile produces desired metrics\", {\n   234→  data <- data.frame(\n   235→    observed = rep(1:10, each = 3),\n   236→    predicted = rep(c(-0.3, 0, 0.3), 10) + rep(1:10, each = 3),\n   237→    model = \"Model 1\",\n   238→    date = as.Date(\"2020-01-01\") + rep(1:10, each = 3),\n   239→    quantile_level = rep(c(0.1, 0.5, 0.9), times = 10),\n   240→    stringsAsFactors = FALSE\n   241→  )\n   242→\n   243→  data <- suppressWarnings(suppressMessages(as_forecast_quantile(data)))\n   244→\n   245→  out <- score(forecast = data, metrics = metrics_no_cov)\n   246→  metrics <- c(\n   247→    \"dispersion\", \"underprediction\", \"overprediction\",\n   248→    \"bias\", \"ae_median\"\n   249→  )\n   250→\n   251→  expect_true(all(metrics %in% colnames(out)))\n   252→})\n   253→\n   254→\n   255→test_that(\"calculation of ae_median is correct for a quantile format case\", {\n   256→  eval <- summarise_scores(scores_quantile, by = \"model\")\n   257→\n   258→  example <- as.data.table(example_quantile)\n   259→  ae <- example[quantile_level == 0.5, ae := abs(observed - predicted)][!is.na(model), .(mean = mean(ae, na.rm = TRUE)),\n   260→    by = \"model\"\n   261→  ]$mean\n   262→\n   263→  expect_equal( # nolint: expect_identical_linter\n   264→    sort(eval$ae_median), sort(ae)\n   265→  )\n   266→})\n   267→\n   268→\n   269→test_that(\"all quantile and range formats yield the same result\", {\n   270→  eval1 <- summarise_scores(scores_quantile, by = \"model\")\n   271→\n   272→  df <- as.data.table(example_quantile)\n   273→\n   274→  ae <- df[\n   275→    quantile_level == 0.5, ae := abs(observed - predicted)\n   276→  ][\n   277→    !is.na(model), .(mean = mean(ae, na.rm = TRUE)),\n   278→    by = \"model\"\n   279→  ]$mean\n   280→\n   281→  expect_equal( # nolint: expect_identical_linter\n   282→    sort(eval1$ae_median), sort(ae)\n   283→  )\n   284→})\n   285→\n   286→test_that(\"WIS is the same with other metrics omitted or included\", {\n   287→  eval <- score(example_quantile,\n   288→    metrics = list(wis = wis)\n   289→  )\n   290→\n   291→  eval2 <- scores_quantile\n   292→\n   293→  expect_equal( # nolint: expect_identical_linter\n   294→    sum(eval$wis),\n   295→    sum(eval2$wis)\n   296→  )\n   297→})\n   298→\n   299→\n   300→test_that(\"score.forecast_quantile() errors with only NA values\", {\n   301→  # [.forecast()` will warn even before score()\n   302→  only_nas <- suppressWarnings(\n   303→    copy(example_quantile)[, predicted := NA_real_]\n   304→  )\n   305→  expect_error(\n   306→    score(only_nas),\n   307→    \"After removing rows with NA values in the data, no forecasts are left.\"\n   308→  )\n   309→})\n   310→\n   311→test_that(\"score.forecast_quantile() works as expected in edge cases\", {\n   312→  # only the median\n   313→  onlymedian <- example_quantile[quantile_level == 0.5]\n   314→  s <- expect_no_condition(\n   315→    score(onlymedian, metrics = get_metrics(\n   316→      example_quantile,\n   317→      exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\n   318→    ))\n   319→  )\n   320→  expect_equal( # nolint: expect_identical_linter\n   321→    s$wis, abs(onlymedian$observed - onlymedian$predicted)\n   322→  )\n   323→\n   324→  # only one symmetric interval is present\n   325→  oneinterval <- example_quantile[quantile_level %in% c(0.25, 0.75)] |>\n   326→    as_forecast_quantile()\n   327→  s <- suppressMessages(score(\n   328→    oneinterval,\n   329→    metrics = get_metrics(\n   330→      example_quantile,\n   331→      exclude = c(\"interval_coverage_90\", \"ae_median\")\n   332→    )\n   333→  ))\n   334→  expect_message(\n   335→    score(\n   336→      oneinterval,\n   337→      metrics = get_metrics(\n   338→        example_quantile,\n   339→        exclude = c(\"interval_coverage_90\", \"ae_median\")\n   340→      )\n   341→    ),\n   342→    \"Median not available\"\n   343→  )\n   344→})\n   345→\n   346→test_that(\"score() works even if only some quantiles are missing\", {\n   347→  # only the median is there\n   348→  onlymedian <- example_quantile[quantile_level == 0.5]\n   349→  expect_no_condition(\n   350→    score(onlymedian, metrics = get_metrics(\n   351→      example_quantile,\n   352→      exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\n   353→    ))\n   354→  )\n   355→\n   356→  # asymmetric intervals\n   357→  asymm <- example_quantile[quantile_level <= 0.6]\n   358→  metrics <- get_metrics(\n   359→    example_quantile,\n   360→    exclude = c(\"overprediction\", \"underprediction\", \"dispersion\")\n   361→  )\n   362→  metrics$wis <- purrr::partial(wis, na.rm = TRUE)\n   363→  score_a <- suppressWarnings({\n   364→    scores_temp <- score(asymm, metrics = metrics)\n   365→    summarise_scores(scores_temp, by = \"model\")\n   366→  })\n   367→  expect_warning(\n   368→    expect_warning({\n   369→      scores_temp <- score(asymm, metrics = metrics)\n   370→      summarise_scores(scores_temp, by = \"model\")\n   371→    },\n   372→    \"Computation for `interval_coverage_50` failed.\"\n   373→    ),\n   374→    \"Computation for `interval_coverage_90` failed.\"\n   375→  )\n   376→\n   377→  # expect a failure with the regular wis wihtout ma.rm=TRUE\n   378→  expect_warning(\n   379→    score(asymm, metrics = c(wis = wis)),\n   380→    \"Not all quantile levels specified form symmetric prediction intervals.\"\n   381→  )\n   382→\n   383→  # check that the result is equal to a case where we discard the entire\n   384→  # interval in terms of WIS\n   385→  inner <- example_quantile[quantile_level %in% c(0.4, 0.45, 0.5, 0.55, 0.6)]\n   386→  score_b <- score(inner, metrics = c(wis = wis)) |>\n   387→    summarise_scores(by = \"model\")\n   388→  expect_equal( # nolint: expect_identical_linter\n   389→    score_a$wis,\n   390→    score_b$wis\n   391→  )\n   392→\n   393→  # median is not there, but only in a single model\n   394→  test <- data.table::copy(example_quantile)\n   395→  test_no_median <- test[model == \"epiforecasts-EpiNow2\" & quantile_level != 0.5, ]\n   396→  test <- rbind(test[model != \"epiforecasts-EpiNow2\"], test_no_median)\n   397→\n   398→  test <- suppressWarnings(as_forecast_quantile(test))\n   399→  expect_message(\n   400→    expect_warning(\n   401→      score(test),\n   402→      \"Computation for `ae_median` failed.\"\n   403→    ),\n   404→    \"interpolating median from the two innermost quantiles\"\n   405→  )\n   406→})\n   407→\n   408→# ==============================================================================\n   409→# get_metrics.forecast_quantile() # nolint: commented_code_linter\n   410→# ==============================================================================\n   411→test_that(\"get_metrics.forecast_quantile() works as expected\", {\n   412→  expect_type(\n   413→    get_metrics(example_quantile), \"list\"\n   414→  )\n   415→})\n   416→\n   417→\n   418→# ==============================================================================\n   419→# get_pit_histogram.forecast_quantile() # nolint: commented_code_linter\n   420→# ==============================================================================\n   421→test_that(\"get_pit_histogram.forecast_quantile() works as expected\", {\n   422→  pit_quantile <- get_pit_histogram(example_quantile, by = \"model\")\n   423→\n   424→  expect_named(pit_quantile, c(\"model\", \"density\", \"bin\", \"mid\"))\n   425→  expect_s3_class(pit_quantile, c(\"data.table\", \"data.frame\"), exact = TRUE)\n   426→\n   427→  # check printing works\n   428→  expect_output(print(pit_quantile))\n   429→})\n   430→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"868a279b-a72f-4d9e-bca5-17fcdc51a0c5"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DtBW1BKTzcpekM1YRv8ke4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01D3T2Cj3FXGAn15fiDEbu5r","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1242,"cache_read_input_tokens":25626,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1242},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"90c5cab0-67d6-49cc-b8b8-812e0c6139f0"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01D3T2Cj3FXGAn15fiDEbu5r","type":"tool_result","content":"     1→# ==============================================================================\n     2→# as_forecast_point() # nolint: commented_code_linter\n     3→# ==============================================================================\n     4→\n     5→test_that(\"as_forecast_point() works\", {\n     6→  expect_no_condition(\n     7→    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))\n     8→  )\n     9→})\n    10→\n    11→\n    12→# ==============================================================================\n    13→# is_forecast_point() # nolint: commented_code_linter\n    14→# ==============================================================================\n    15→test_that(\"is_forecast_point() works as expected\", {\n    16→  expect_true(is_forecast_point(example_point))\n    17→  expect_false(is_forecast_point(example_binary))\n    18→  expect_false(is_forecast_point(example_quantile))\n    19→  expect_false(is_forecast_point(example_sample_continuous))\n    20→  expect_false(is_forecast_point(example_nominal))\n    21→})\n    22→\n    23→\n    24→# ==============================================================================\n    25→# assert_forecast.forecast_point() # nolint: commented_code_linter\n    26→# ==============================================================================\n    27→\n    28→test_that(\"assert_forecast.forecast_point() works as expected\", {\n    29→  test <- na.omit(data.table::as.data.table(example_point))\n    30→  test <- as_forecast_point(test)\n    31→\n    32→  # expect an error if column is changed to character after initial validation.\n    33→  expect_warning(\n    34→    test[, \"predicted\" := as.character(predicted)],\n    35→    \"Input looks like a point forecast, but found the following issue\"\n    36→  )\n    37→  expect_error(\n    38→    assert_forecast(test),\n    39→    \"Input looks like a point forecast, but found the following issue\"\n    40→  )\n    41→})\n    42→\n    43→test_that(\"assert_forecast.forecast_point() complains if the forecast type is wrong\", {\n    44→  expect_error(\n    45→    assert_forecast(na.omit(example_point), forecast_type = \"quantile\"),\n    46→    \"Forecast type determined by scoringutils based on input:\"\n    47→  )\n    48→})\n    49→\n    50→\n    51→# ==============================================================================\n    52→# score.forecast_point() # nolint: commented_code_linter\n    53→# ==============================================================================\n    54→test_that(\"function produces output for a point case\", {\n    55→  expect_named(\n    56→    scores_binary,\n    57→    c(get_forecast_unit(example_binary), names(get_metrics(example_binary)))\n    58→  )\n    59→\n    60→  eval <- summarise_scores(scores_point, by = c(\"model\", \"target_type\"))\n    61→\n    62→  expect_gt(\n    63→    nrow(eval), 1\n    64→  )\n    65→  expect_identical(\n    66→    colnames(eval),\n    67→    c(\"model\", \"target_type\", names(get_metrics(example_point)))\n    68→  )\n    69→\n    70→  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\n    71→})\n    72→\n    73→test_that(\"Changing metrics names works\", {\n    74→  metrics_test <- get_metrics(example_point)\n    75→  names(metrics_test)[1] <- \"just_testing\"\n    76→  eval <- suppressMessages(score(as_forecast_point(example_point),\n    77→    metrics = metrics_test\n    78→  ))\n    79→  eval_summarised <- summarise_scores(eval, by = \"model\")\n    80→  expect_identical(\n    81→    colnames(eval_summarised),\n    82→    c(\"model\", \"just_testing\", names(get_metrics(example_point))[-1])\n    83→  )\n    84→})\n    85→\n    86→test_that(\"score.forecast_point() errors with only NA values\", {\n    87→  # [.forecast()` will warn even before score()\n    88→  only_nas <- suppressWarnings(\n    89→    copy(example_point)[, predicted := NA_real_]\n    90→  )\n    91→  expect_error(\n    92→    score(only_nas),\n    93→    \"After removing rows with NA values in the data, no forecasts are left.\"\n    94→  )\n    95→})\n    96→\n    97→# ==============================================================================\n    98→# get_metrics.forecast_point() # nolint: commented_code_linter\n    99→# ==============================================================================\n   100→test_that(\"get_metrics.forecast_point() works as expected\", {\n   101→  expect_type(\n   102→    get_metrics(example_point), \"list\"\n   103→  )\n   104→\n   105→  expect_identical(\n   106→    get_metrics.scores(scores_point),\n   107→    c(\"ae_point\", \"se_point\", \"ape\")\n   108→  )\n   109→})\n   110→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"afa3fd8b-36e6-4485-9bba-d04ac43b37f4"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01Y2rYUHt9JZmmiiCiCNYidd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PRhXjHPsA4PZDMUny3Rxu2","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7809,"cache_read_input_tokens":26868,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7809},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a74669f8-6e50-4f0d-8105-d33719ac2ca7"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PRhXjHPsA4PZDMUny3Rxu2","type":"tool_result","content":"     1→# ==============================================================================\n     2→# as_forecast_sample() # nolint: commented_code_linter\n     3→# ==============================================================================\n     4→test_that(\"as_forecast_sample() works as expected\", {\n     5→  test <- na.omit(data.table::copy(example_sample_continuous))\n     6→  data.table::setnames(test,\n     7→    old = c(\"observed\", \"predicted\", \"sample_id\"),\n     8→    new = c(\"obs\", \"pred\", \"sample\")\n     9→  )\n    10→  expect_no_condition(\n    11→    as_forecast_sample(test,\n    12→      observed = \"obs\", predicted = \"pred\",\n    13→      forecast_unit = c(\n    14→        \"location\", \"model\", \"target_type\",\n    15→        \"target_end_date\", \"horizon\"\n    16→      ),\n    17→      sample_id = \"sample\"\n    18→    )\n    19→  )\n    20→})\n    21→\n    22→test_that(\"Running `as_forecast_sample()` twice returns the same object\", {\n    23→  ex <- na.omit(example_sample_continuous)\n    24→\n    25→  expect_identical(\n    26→    as_forecast_sample(as_forecast_sample(ex)),\n    27→    as_forecast_sample(ex)\n    28→  )\n    29→})\n    30→\n    31→\n    32→# ==============================================================================\n    33→# is_forecast_sample() # nolint: commented_code_linter\n    34→# ==============================================================================\n    35→test_that(\"is_forecast_sample() works as expected\", {\n    36→  expect_true(is_forecast_sample(example_sample_continuous))\n    37→  expect_false(is_forecast_sample(example_binary))\n    38→  expect_false(is_forecast_sample(example_point))\n    39→  expect_false(is_forecast_sample(example_quantile))\n    40→  expect_false(is_forecast_sample(example_nominal))\n    41→  expect_false(is_forecast_sample(1:10))\n    42→})\n    43→\n    44→\n    45→# ==============================================================================\n    46→# get_metrics.forecast_sample() # nolint: commented_code_linter\n    47→# ==============================================================================\n    48→\n    49→test_that(\"get_metrics.forecast_sample() works as expected\", {\n    50→  expect_type(\n    51→    get_metrics(example_sample_continuous), \"list\"\n    52→  )\n    53→  expect_type(\n    54→    get_metrics(example_sample_discrete), \"list\"\n    55→  )\n    56→})\n    57→\n    58→\n    59→# ==============================================================================\n    60→# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\n    61→# ==============================================================================\n    62→test_that(\"get_pit_histogram.forecast_sample() works as expected\", {\n    63→  pit_continuous <- get_pit_histogram(example_sample_continuous, by = c(\"model\", \"target_type\"))\n    64→  pit_integer <- get_pit_histogram(example_sample_discrete, by = c(\"model\", \"location\"))\n    65→\n    66→  expect_named(pit_continuous, c(\"model\", \"target_type\", \"density\", \"bin\", \"mid\"))\n    67→  expect_named(pit_integer, c(\"model\", \"location\", \"density\", \"bin\", \"mid\"))\n    68→\n    69→  # check printing works\n    70→  expect_output(print(pit_continuous))\n    71→  expect_output(print(pit_integer))\n    72→\n    73→  # check class is correct\n    74→  expect_s3_class(pit_continuous, c(\"data.table\", \"data.frame\"), exact = TRUE)\n    75→  expect_s3_class(pit_integer, c(\"data.table\", \"data.frame\"), exact = TRUE)\n    76→})\n    77→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"62b5062d-5393-407a-94ac-15c54124495d"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01Y2rYUHt9JZmmiiCiCNYidd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LWrAX62t2MgDY8WkNJdY14","name":"Bash","input":{"command":"find /Users/nikos/github-synced/scoringutils-pipeline/tests/testthat -type f -name \"*helper*\" -o -name \"*setup*\" | sort"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":7809,"cache_read_input_tokens":26868,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7809},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"21745834-67b2-4591-a42c-7142d1903800"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LWrAX62t2MgDY8WkNJdY14","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/_snaps/helper-quantile-interval-range.md\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-check-input-helpers.R\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-helper-quantile-interval-range.R","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6157cde6-538a-4fdf-a4db-a454c479bbdf"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01R4qBykCGMxn5dgXpYFn4jQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FP3V7Gaz9odM1WsSTJLtky","name":"Bash","input":{"command":"grep -r \"get_pit_histogram\" /Users/nikos/github-synced/scoringutils-pipeline/tests/testthat --include=\"*.R\" | head -20"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1415,"cache_read_input_tokens":34677,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1415},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a5503ac0-b104-4975-8807-17f6aa524149"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FP3V7Gaz9odM1WsSTJLtky","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R:# get_pit_histogram.forecast_quantile() # nolint: commented_code_linter\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R:test_that(\"get_pit_histogram.forecast_quantile() works as expected\", {\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R:  pit_quantile <- get_pit_histogram(example_quantile, by = \"model\")\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R:# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R:test_that(\"get_pit_histogram.forecast_sample() works as expected\", {\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R:  pit_continuous <- get_pit_histogram(example_sample_continuous, by = c(\"model\", \"target_type\"))\n/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R:  pit_integer <- get_pit_histogram(example_sample_discrete, by = c(\"model\", \"location\"))","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2271c272-bb3c-4532-be22-6239990353d3"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AdAYyRc5LpcMnLL1zo7XDe","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EqQGosR1Ja71yoKudkEWiC","name":"Bash","input":{"command":"grep -n \"as_forecast_doc_template\" /Users/nikos/github-synced/scoringutils-pipeline/R/*.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":663,"cache_read_input_tokens":36092,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":663},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"9fa991ba-de41-47e8-89eb-b2a0e6232968"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EqQGosR1Ja71yoKudkEWiC","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-binary.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-multivariate-sample.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-multivariate-sample.R:206:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-nominal.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-ordinal.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R:2:#' @inherit as_forecast_doc_template params description\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast.R:6:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast.R:50:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast.R:229:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/documentation-templates.R:30:#' @name as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/forecast-unit.R:18:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/forecast-unit.R:49:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-duplicate-forecasts.R:8:#' @inheritParams as_forecast_doc_template\n/Users/nikos/github-synced/scoringutils-pipeline/R/get-protected-columns.R:6:#' @inheritParams as_forecast_doc_template","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"acc04575-9dd8-4dd3-9a87-c66799a300e2"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01D5ppgdu5o3u8JYf5PffPQ3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VKTCTtBYyNXUeDhowdAsha","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/R/documentation-templates.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":812,"cache_read_input_tokens":36755,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":812},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"dbaae8b4-a4ba-485c-88c8-91d17fbf75f5"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VKTCTtBYyNXUeDhowdAsha","type":"tool_result","content":"     1→#' @title General information on creating a `forecast` object\n     2→#'\n     3→#' @description\n     4→#' Process and validate a data.frame (or similar) or similar with forecasts\n     5→#' and observations. If the input passes all input checks, those functions will\n     6→#' be converted to a `forecast` object. A forecast object is a `data.table` with\n     7→#' a class `forecast` and an additional class that depends on the forecast type.\n     8→#'\n     9→#' The arguments `observed`, `predicted`, etc. make it possible to rename\n    10→#' existing columns of the input data to match the required columns for a\n    11→#' forecast object. Using the argument `forecast_unit`, you can specify\n    12→#' the columns that uniquely identify a single forecast (and thereby removing\n    13→#' other, unneeded columns. See section \"Forecast Unit\" below for details).\n    14→#'\n    15→#' @param data A data.frame (or similar) with predicted and observed values.\n    16→#'   See the details section of for additional information\n    17→#'   on the required input format.\n    18→#' @param forecast_unit (optional) Name of the columns in `data` (after\n    19→#'   any renaming of columns) that denote the unit of a\n    20→#'   single forecast. See [get_forecast_unit()] for details.\n    21→#'   If `NULL` (the default), all columns that are not required columns are\n    22→#'   assumed to form the unit of a single forecast. If specified, all columns\n    23→#'   that are not part of the forecast unit (or required columns) will be removed.\n    24→#' @param observed (optional) Name of the column in `data` that contains the\n    25→#'   observed values. This column will be renamed to \"observed\".\n    26→#' @param predicted (optional) Name of the column in `data` that contains the\n    27→#'   predicted values. This column will be renamed to \"predicted\".\n    28→#' @inheritSection forecast_types Forecast unit\n    29→#' @keywords as_forecast\n    30→#' @name as_forecast_doc_template\n    31→NULL\n    32→\n    33→\n    34→#' @title Documentation template for forecast types\n    35→#'\n    36→#' @details # Forecast unit\n    37→#'\n    38→#' In order to score forecasts, `scoringutils` needs to know which of the rows\n    39→#' of the data belong together and jointly form a single forecast. This is\n    40→#' easy e.g. for point forecast, where there is one row per forecast. For\n    41→#' quantile or sample-based forecasts, however, there are multiple rows that\n    42→#' belong to a single forecast. (For a multivariate forecast, several univariate\n    43→#' forecasts are pooled together to form a joint forecast. In the multivariate\n    44→#' case, \"forecast unit\" still refers to the forecast unit of the univariate\n    45→#' forecasts that are pooled together to form the multivariate forecast.)\n    46→#'\n    47→#' The *forecast unit* or *unit of a single forecast* is then described by the\n    48→#' combination of columns that uniquely identify a single forecast.\n    49→#' For example, we could have forecasts made by different models in various\n    50→#' locations at different time points, each for several weeks into the future.\n    51→#' The forecast unit could then be described as\n    52→#' `forecast_unit = c(\"model\", \"location\", \"forecast_date\", \"forecast_horizon\")`.\n    53→#' `scoringutils` automatically tries to determine the unit of a single\n    54→#' forecast. It uses all existing columns for this, which means that no columns\n    55→#' must be present that are unrelated to the forecast unit. As a very simplistic\n    56→#' example, if you had an additional row, \"even\", that is one if the row number\n    57→#' is even and zero otherwise, then this would mess up scoring as `scoringutils`\n    58→#' then thinks that this column was relevant in defining the forecast unit.\n    59→#'\n    60→#' In order to avoid issues, we recommend setting the forecast unit explicitly,\n    61→#' using the `forecast_unit` argument. This will simply drop unneeded columns,\n    62→#' while making sure that all necessary, 'protected columns' like \"predicted\"\n    63→#' or \"observed\" are retained.\n    64→#'\n    65→#' @name forecast_types\n    66→#' @keywords internal\n    67→NULL\n    68→\n    69→#' Documentation template for check functions\n    70→#' @param data A data.frame or similar to be checked\n    71→#' @param observed Input to be checked. Should be a numeric vector with the\n    72→#'   observed values of size n.\n    73→#' @param columns A character vector of column names to check\n    74→#' @returns Returns TRUE if the check was successful and a string with an\n    75→#'   error message otherwise.\n    76→#' @name document_check_functions\n    77→#' @keywords internal\n    78→NULL\n    79→\n    80→#' Documentation template for assert functions\n    81→#' @param observed Input to be checked. Should be a numeric vector with the\n    82→#'   observed values of size n.\n    83→#' @returns Returns NULL invisibly if the assertion was successful and throws an\n    84→#'   error otherwise.\n    85→#' @name document_assert_functions\n    86→#' @keywords internal\n    87→NULL\n    88→\n    89→#' Documentation template for test functions\n    90→#' @returns Returns TRUE if the check was successful and FALSE otherwise\n    91→#' @name document_test_functions\n    92→#' @keywords internal\n    93→NULL\n    94→\n    95→#' Illustration of required inputs for sample-based forecasts\n    96→#' @details # Input format\n    97→#' \\if{html}{\n    98→#'   \\out{<div style=\"text-align: left\">}\n    99→#'   \\figure{metrics-sample.png}{options: style=\"width:750px;max-width:100\\%;\"}\n   100→#'   \\out{</div><p>}\n   101→#'   Overview of required input format for sample-based forecasts\n   102→#' }\n   103→#' \\if{latex}{\n   104→#'   \\figure{metrics-sample.png}\n   105→#' }\n   106→#' @name illustration-input-metric-sample\n   107→#' @keywords internal\n   108→NULL\n   109→\n   110→#' Illustration of required inputs for binary and point forecasts\n   111→#' @details # Input format\n   112→#' \\if{html}{\n   113→#'   \\out{<div style=\"text-align: left\">}\n   114→#'   \\figure{metrics-binary-point.png}{options: style=\"width:750px;max-width:100\\%;\"}\n   115→#'   \\out{</div><p>}\n   116→#'   Overview of required input format for binary and point forecasts\n   117→#' }\n   118→#' \\if{latex}{\n   119→#'   \\figure{metrics-binary-point.png}\n   120→#' }\n   121→#' @name illustration-input-metric-binary-point\n   122→#' @keywords internal\n   123→NULL\n   124→\n   125→#' Illustration of required inputs for quantile-based forecasts\n   126→#' @details # Input format\n   127→#' \\if{html}{\n   128→#'   \\out{<div style=\"text-align: left\">}\n   129→#'   \\figure{metrics-quantile.png}{options: style=\"width:750px;max-width:100\\%;\"}\n   130→#'   \\out{</div><p>}\n   131→#'   Overview of required input format for quantile-based forecasts\n   132→#' }\n   133→#' \\if{latex}{\n   134→#'   \\figure{metrics-quantile.png}\n   135→#' }\n   136→#' @name illustration-input-metric-quantile\n   137→#' @keywords internal\n   138→NULL\n   139→\n   140→#' Illustration of required inputs for nominal forecasts\n   141→#' @details # Input format\n   142→#' \\if{html}{\n   143→#'   \\out{<div style=\"text-align: left\">}\n   144→#'   \\figure{metrics-nominal.png}{options: style=\"width:750px;max-width:100\\%;\"}\n   145→#'   \\out{</div><p>}\n   146→#'   Overview of required input format for nominal forecasts\n   147→#' }\n   148→#' \\if{latex}{\n   149→#'   \\figure{metrics-nominal.png}\n   150→#' }\n   151→#' @name illustration-input-metric-nominal\n   152→#' @keywords internal\n   153→NULL\n   154→\n   155→#' Illustration of required inputs for ordinal forecasts\n   156→#' @details # Input format\n   157→#' \\if{html}{\n   158→#'   \\out{<div style=\"text-align: left\">}\n   159→#'   \\figure{metrics-ordinal.png}{options: style=\"width:750px;max-width:100\\%;\"}\n   160→#'   \\out{</div><p>}\n   161→#'   Overview of required input format for ordinal forecasts\n   162→#' }\n   163→#' \\if{latex}{\n   164→#'   \\figure{metrics-ordinal.png}\n   165→#' }\n   166→#' @name illustration-input-metric-ordinal\n   167→#' @keywords internal\n   168→NULL\n   169→"}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"28099ba4-6590-437c-ac8a-abc159a8d327"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DqmDfF8cLzjK2Ay38CA3cr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01U3VHvaVKZ9i3UB6AbmQRX9","name":"Bash","input":{"command":"find /Users/nikos/github-synced/scoringutils-pipeline -type f -name \"*793*\" 2>/dev/null"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":2612,"cache_read_input_tokens":37567,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2612},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"45b1f054-69ca-4d18-a80b-7adebfe6b172"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01U3VHvaVKZ9i3UB6AbmQRX9","type":"tool_result","content":"","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f5dda60f-c179-416f-a2f4-941d6bff3a15"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01VVeUXDzyBDPy9FeDfpZwWu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01D64CchW5sSPp1dpjRFTS6b","name":"Bash","input":{"command":"ls -la /Users/nikos/github-synced/scoringutils-pipeline/.ralph/issues/ 2>/dev/null | head -20"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":148,"cache_read_input_tokens":40179,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":148},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"9106caac-f98d-4f17-a2d6-ab03ffd17d98"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01D64CchW5sSPp1dpjRFTS6b","type":"tool_result","content":"total 256\ndrwxr-xr-x@ 17 nikos  staff    544 13 Feb 01:02 .\ndrwxr-xr-x@  7 nikos  staff    224 13 Feb 01:02 ..\n-rw-r--r--@  1 nikos  staff      0 13 Feb 00:14 .gitkeep\n-rw-r--r--@  1 nikos  staff   3530 13 Feb 00:24 1002-pkgdown-latex-rendering.md\n-rw-r--r--@  1 nikos  staff   7777 13 Feb 00:21 1022-pairwise-two-models.md\n-rw-r--r--@  1 nikos  staff   7254 13 Feb 00:19 1043-multivariate-print-joint-across.md\n-rw-r--r--@  1 nikos  staff   1514 13 Feb 00:15 1044-remove-commented-vignette-code.md\n-rw-r--r--@  1 nikos  staff   6175 13 Feb 01:02 807-cli-nolint-cleanup.md\n-rw-r--r--@  1 nikos  staff   7439 13 Feb 00:58 811-batch-failed-metric-warnings.md\n-rw-r--r--@  1 nikos  staff   8918 13 Feb 00:55 825-package-scaffolding.md\n-rw-r--r--@  1 nikos  staff   5434 13 Feb 00:50 839-remove-test-columns-not-present.md\n-rw-r--r--@  1 nikos  staff   6278 13 Feb 00:48 880-quantile-level-as-forecast-point.md\n-rw-r--r--@  1 nikos  staff  13488 13 Feb 00:45 895-quantile-prediction-order.md\n-rw-r--r--@  1 nikos  staff  15712 13 Feb 00:40 922-remove-check-columns-present.md\n-rw-r--r--@  1 nikos  staff   6910 13 Feb 00:36 942-discrimination-plot-binary.md\n-rw-r--r--@  1 nikos  staff   7091 13 Feb 00:33 975-print-scores-link.md\n-rw-r--r--@  1 nikos  staff  11033 13 Feb 00:28 983-as-forecast-data-frame-methods.md","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"c14648c0-eb00-4ff8-a1d7-c3cc7f827b58"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01JRTYTFkHZPkNU4UCCKmkZM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015GDCSAZbQqoAvY9TuueYiQ","name":"Bash","input":{"command":"git log --all --oneline | grep -i \"793\\|rdname\\|shared\" | head -20"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":810,"cache_read_input_tokens":40327,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":810},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"8bafe580-3ad6-4c36-a011-1f36549d4aa3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015GDCSAZbQqoAvY9TuueYiQ","type":"tool_result","content":"480e1741 Deploying to gh-pages from @ epiforecasts/scoringutils@0de32f5f30136e52604123793c074f7c22e70c85 🚀\nb67a3710 Deploying to gh-pages from @ epiforecasts/scoringutils@abd5746a2fc5254a757793e53099f6e6fbb62d2a 🚀\n7a917931 Merge branch 'scoringutils-review' into scoringutils-review3\n27932848 Add lifecycle badges\n2b7b5e6e Deploying to gh-pages from @ epiforecasts/scoringutils@f18caf7d92f307e9754ceae1de3e609e05f17931 🚀\n3eac4456 Deploying to gh-pages from @ epiforecasts/scoringutils@fa8f777fb09372d793669db7bd61764ede6e1ac5 🚀\n75da8dd9 Deploying to gh-pages from @ epiforecasts/scoringutils@26879346361ceba87e7e3a7579e1e5ad2571af8b 🚀\n26879346 add function alias summarize_scores for summarise_scores","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"8efe591c-e70f-473d-a1b3-ad685f99f99e"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01McNe5E2haLz1PLhMdh6s8w","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013jbuaXX8J8Bmio9V8euQR9","name":"Bash","input":{"command":"git log --all --grep=\"793\" --oneline"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":568,"cache_read_input_tokens":41137,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":568},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"29186534-05db-438e-aaa8-f182b41d0c67"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013jbuaXX8J8Bmio9V8euQR9","type":"tool_result","content":"480e1741 Deploying to gh-pages from @ epiforecasts/scoringutils@0de32f5f30136e52604123793c074f7c22e70c85 🚀\nb67a3710 Deploying to gh-pages from @ epiforecasts/scoringutils@abd5746a2fc5254a757793e53099f6e6fbb62d2a 🚀\n2b7b5e6e Deploying to gh-pages from @ epiforecasts/scoringutils@f18caf7d92f307e9754ceae1de3e609e05f17931 🚀\n3eac4456 Deploying to gh-pages from @ epiforecasts/scoringutils@fa8f777fb09372d793669db7bd61764ede6e1ac5 🚀\n75da8dd9 Deploying to gh-pages from @ epiforecasts/scoringutils@26879346361ceba87e7e3a7579e1e5ad2571af8b 🚀","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"5d0a9b08-ba96-4ffd-baf9-33443d4bdcca"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01VyNuhAbWThTTQ1bDepCra7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01D52aaVc2HQPnNkY2ghxpLw","name":"Bash","input":{"command":"grep -n \"@rdname\" /Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":408,"cache_read_input_tokens":41705,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":408},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"0bd05e74-e636-4dee-8725-919be7e67f19"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01D52aaVc2HQPnNkY2ghxpLw","type":"tool_result","content":"38:#' @rdname as_forecast_quantile\n79:#' @rdname assert_forecast\n93:#' @rdname is_forecast\n99:#' @rdname as_forecast_point\n125:#' @rdname score\n217:#' @rdname get_pit_histogram","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"4e6d55f8-46fa-44c0-9cb3-5f908b76ca5e"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01RiXsVACxPpZinKgqpBmTqV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016FQDfQRBD6JFHqVvW3yrss","name":"Bash","input":{"command":"grep -B5 -A5 \"^as_forecast_point.forecast_quantile\" /Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":219,"cache_read_input_tokens":42113,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":219},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"57c75704-b592-4def-b569-888aef3def9a"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016FQDfQRBD6JFHqVvW3yrss","type":"tool_result","content":"#' @description\n#' When converting a `forecast_quantile` object into a `forecast_point` object,\n#' the 0.5 quantile is extracted and returned as the point forecast.\n#' @export\n#' @keywords as_forecast\nas_forecast_point.forecast_quantile <- function(data, ...) {\n  assert_forecast(data, verbose = FALSE)\n  assert_subset(0.5, unique(data$quantile_level))\n\n  # At end of this function, the object will have be turned from a\n  # forecast_quantile to a forecast_point and we don't want to validate it as a","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"4171449c-2df5-4dcc-bbb6-f60e144445c2"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01FdpHu9eY2aDCcEuMRtkUsJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JJkT17HQz3DRepAz8Vvc3M","name":"Bash","input":{"command":"grep -B10 \"^as_forecast_quantile.forecast_sample\" /Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R | head -20"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":317,"cache_read_input_tokens":42332,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":317},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"bb6ebde6-f68a-4538-99ea-a165346a13a8"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JJkT17HQz3DRepAz8Vvc3M","type":"tool_result","content":"#' when the number of available samples is low.\n#' @param probs A numeric vector of quantile levels for which\n#'   quantiles will be computed. Corresponds to the `probs` argument in\n#'   [quantile()].\n#' @param type Type argument passed down to the quantile function. For more\n#'   information, see [quantile()].\n#' @importFrom stats quantile\n#' @importFrom methods hasArg\n#' @importFrom checkmate assert_numeric\n#' @export\nas_forecast_quantile.forecast_sample <- function(","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e6009cea-dfb3-42f9-9a78-219a75e51d6e"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01S5cao4KDLr2R4RgJ6Thdcc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KSz9E8r9A4myynRM8nA8k2","name":"Bash","input":{"command":"grep -B20 \"^get_pit_histogram.forecast_sample\" /Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R | head -40"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":313,"cache_read_input_tokens":42649,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":313},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e5ce8da9-1c90-44f3-b276-c35f86dc6948"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KSz9E8r9A4myynRM8nA8k2","type":"tool_result","content":"    dss = dss_sample,\n    crps = crps_sample,\n    overprediction = overprediction_sample,\n    underprediction = underprediction_sample,\n    dispersion = dispersion_sample,\n    log_score = logs_sample,\n    mad = mad_sample,\n    ae_median = ae_median_sample,\n    se_mean = se_mean_sample\n  )\n  select_metrics(all, select, exclude)\n}\n\n\n#' @rdname get_pit_histogram\n#' @importFrom data.table `:=` as.data.table dcast\n#' @importFrom checkmate assert_int assert_numeric\n#' @inheritParams pit_histogram_sample\n#' @seealso [pit_histogram_sample()]\n#' @export\nget_pit_histogram.forecast_sample <- function(forecast, num_bins = 10,","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e7f2b580-b410-4d19-8403-3043b1837b9d"}
{"type":"assistant","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01FpWzB5DWLHadkStkqt2Kep","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PtT5hJN3usC3MmJM4mGBET","name":"Bash","input":{"command":"cat /Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R | head -60"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":0,"cache_creation_input_tokens":486,"cache_read_input_tokens":42962,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":486},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"9f72920f-7456-4a85-8315-c71cac5c746d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PtT5hJN3usC3MmJM4mGBET","type":"tool_result","content":"#' @title Create a `forecast` object for point forecasts\n#' @inherit as_forecast_doc_template params description\n#' @details\n#' # Target format\n#'\n#' The input for all further scoring needs to be a data.frame or similar with\n#' the following columns:\n#' - `observed`: Column of type `numeric` with observed values.\n#' - `predicted`: Column of type `numeric` with predicted values.\n#'\n#' For convenience, we recommend an additional column `model` holding the name\n#' of the forecaster or model that produced a prediction, but this is not\n#' strictly necessary.\n#'\n#' See the [example_point] data set for an example.\n#' @param ... Unused\n#' @returns A `forecast` object of class `forecast_point`\n#' @family functions to create forecast objects\n#' @export\n#' @keywords as_forecast transform\nas_forecast_point <- function(data, ...) {\n  UseMethod(\"as_forecast_point\")\n}\n\n\n#' @rdname as_forecast_point\n#' @export\n#' @method as_forecast_point default\n#' @importFrom cli cli_warn\nas_forecast_point.default <- function(data,\n                                      forecast_unit = NULL,\n                                      observed = NULL,\n                                      predicted = NULL,\n                                      ...) {\n  data <- as_forecast_generic(\n    data,\n    forecast_unit,\n    observed = observed,\n    predicted = predicted\n  )\n  data <- new_forecast(data, \"forecast_point\")\n  assert_forecast(data)\n  return(data)\n}\n\n\n#' @export\n#' @rdname assert_forecast\n#' @importFrom cli cli_abort\n#' @keywords validate-forecast-object\nassert_forecast.forecast_point <- function(\n  forecast, forecast_type = NULL, verbose = TRUE, ...\n) {\n  forecast <- assert_forecast_generic(forecast, verbose)\n  assert_forecast_type(forecast, actual = \"point\", desired = forecast_type)\n  #nolint start: keyword_quote_linter object_usage_linter\n  input_check <- check_input_point(forecast$observed, forecast$predicted)\n  if (!isTRUE(input_check)) {\n    cli_abort(\n      c(","is_error":false}]},"parent_tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6de6c456-3b99-49f0-83fd-7cca1b7b9929"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01V83xNxowBp3PsosNrx1ASF","type":"tool_result","content":[{"type":"text","text":"Perfect! Now I have all the information I need to provide a comprehensive analysis. Let me create the final report:\n\n## Issue #793 Analysis: Removing Shared `@rdname` Tags for S3 Methods with Differing Arguments\n\nBased on my analysis of the scoringutils package, here's a comprehensive breakdown of the three affected methods:\n\n---\n\n### 1. **`as_forecast_quantile.forecast_sample`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R` (lines 75-116)\n\n**Generic definition** (`as_forecast_quantile`):\n```r\n#' @title Create a `forecast` object for quantile-based forecasts\n#' @inherit as_forecast_doc_template params description\n#' @details ...\n#' @param ... Unused\n#' @returns A `forecast` object of class `forecast_quantile`\n#' @export\nas_forecast_quantile <- function(data, ...) {\n  UseMethod(\"as_forecast_quantile\")\n}\n```\n\n**Default method** (`as_forecast_quantile.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R`, lines 38-75):\n```r\n#' @rdname as_forecast_quantile\n#' @param quantile_level (optional) Name of the column in `data` that contains\n#'   the quantile level of the predicted values. This column will be renamed to\n#'   \"quantile_level\". Only applicable to quantile-based forecasts.\n#' @export\n#' @method as_forecast_quantile default\nas_forecast_quantile.default <- function(data,\n                                         forecast_unit = NULL,\n                                         observed = NULL,\n                                         predicted = NULL,\n                                         quantile_level = NULL,\n                                         ...) { ... }\n```\n\n**Specific method** (`as_forecast_quantile.forecast_sample`):\n```r\n#' @rdname as_forecast_quantile\n#' @details # Converting from `forecast_sample` to `forecast_quantile`\n#' When creating a `forecast_quantile` object from a `forecast_sample` object,\n#' the quantiles are estimated by computing empircal quantiles from the samples\n#' via [quantile()]. Note that empirical quantiles are a biased estimator for\n#' the true quantiles in particular in the tails of the distribution and\n#' when the number of available samples is low.\n#' @param probs A numeric vector of quantile levels for which\n#'   quantiles will be computed. Corresponds to the `probs` argument in\n#'   [quantile()].\n#' @param type Type argument passed down to the quantile function. For more\n#'   information, see [quantile()].\n#' @importFrom stats quantile\n#' @importFrom methods hasArg\n#' @importFrom checkmate assert_numeric\n#' @export\nas_forecast_quantile.forecast_sample <- function(\n  data,\n  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),\n  type = 7,\n  ...\n) { ... }\n```\n\n**Key Differences**:\n- The `.default` method has parameters: `forecast_unit`, `observed`, `predicted`, `quantile_level`\n- The `.forecast_sample` method has parameters: `probs`, `type` (completely different!)\n- Sharing `@rdname as_forecast_quantile` causes documentation conflict because users see documentation for `quantile_level` and `forecast_unit` when they're actually using `probs` and `type`\n\n---\n\n### 2. **`as_forecast_point.forecast_quantile`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R` (lines 99-120)\n\n**Generic definition** (`as_forecast_point`):\n```r\n#' @title Create a `forecast` object for point forecasts\n#' @inherit as_forecast_doc_template params description\n#' @details ...\n#' @param ... Unused\n#' @returns A `forecast` object of class `forecast_point`\n#' @export\nas_forecast_point <- function(data, ...) {\n  UseMethod(\"as_forecast_point\")\n}\n```\n\n**Default method** (`as_forecast_point.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R`, lines 26-44):\n```r\n#' @rdname as_forecast_point\n#' @export\n#' @method as_forecast_point default\nas_forecast_point.default <- function(data,\n                                      forecast_unit = NULL,\n                                      observed = NULL,\n                                      predicted = NULL,\n                                      ...) { ... }\n```\n\n**Specific method** (`as_forecast_point.forecast_quantile`):\n```r\n#' @rdname as_forecast_point\n#' @description\n#' When converting a `forecast_quantile` object into a `forecast_point` object,\n#' the 0.5 quantile is extracted and returned as the point forecast.\n#' @export\nas_forecast_point.forecast_quantile <- function(data, ...) {\n  assert_forecast(data, verbose = FALSE)\n  ...\n}\n```\n\n**Key Differences**:\n- The `.default` method has parameters: `forecast_unit`, `observed`, `predicted`\n- The `.forecast_quantile` method only has: `data`, `...` (no other parameters!)\n- The `.forecast_quantile` method automatically extracts the 0.5 quantile and doesn't need the additional parameters\n- Sharing `@rdname` causes confusion about which parameters apply to which method\n\n---\n\n### 3. **`get_pit_histogram.forecast_sample`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R` (lines 195-242)\n\n**Generic definition** (`get_pit_histogram`):\n```r\n#' @title Probability integral transformation histogram\n#' @description Generate a Probability Integral Transformation (PIT) histogram\n#'   for validated forecast objects.\n#' @inherit score params\n#' @param num_bins The number of bins in the PIT histogram. For sample-based\n#'   forecasts, the default is 10 bins. For quantile-based forecasts, the\n#'   default is one bin for each available quantile.\n#'   ...\n#' @param breaks Numeric vector with the break points for the bins in the\n#'   PIT histogram. This is preferred when creating a PIT histogram based on\n#'   quantile-based data. Default is `NULL` and breaks will be determined by\n#'   `num_bins`. If `breaks` is used, `num_bins` will be ignored.\n#'   0 and 1 will always be added as left and right bounds, respectively.\n#' @param by Character vector with the columns according to which the\n#'   PIT values shall be grouped.\n#' @inheritParams pit_histogram_sample\n#' @returns A data.table with density values for each bin in the PIT histogram.\n#' @export\nget_pit_histogram <- function(forecast, num_bins, breaks, by, ...) {\n  UseMethod(\"get_pit_histogram\")\n}\n```\n\n**Default method** (`get_pit_histogram.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/get-pit-histogram.R`, lines 56-63):\n```r\n#' @rdname get_pit_histogram\n#' @export\nget_pit_histogram.default <- function(forecast, num_bins, breaks, by, ...) {\n  cli_abort(c(\n    \"!\" = \"The input needs to be a valid forecast object...\"\n  ))\n}\n```\n\n**Quantile method** (`get_pit_histogram.forecast_quantile` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R`, lines 217-268):\n```r\n#' @rdname get_pit_histogram\n#' @export\nget_pit_histogram.forecast_quantile <- function(forecast, num_bins = NULL,\n                                                breaks = NULL, by, ...) {\n  ...\n}\n```\n\n**Sample method** (`get_pit_histogram.forecast_sample`):\n```r\n#' @rdname get_pit_histogram\n#' @importFrom data.table `:=` as.data.table dcast\n#' @importFrom checkmate assert_int assert_numeric\n#' @inheritParams pit_histogram_sample\n#' @seealso [pit_histogram_sample()]\n#' @export\nget_pit_histogram.forecast_sample <- function(forecast, num_bins = 10,\n                                              breaks = NULL, by, integers = c(\n                                                \"nonrandom\", \"random\", \"ignore\"\n                                              ), n_replicates = NULL, ...) {\n  ...\n}\n```\n\n**Key Differences**:\n- The `.forecast_quantile` method has: `num_bins = NULL`, `breaks = NULL`\n- The `.forecast_sample` method has: `num_bins = 10`, `breaks = NULL`, `integers = c(...)`, `n_replicates = NULL`\n- The `.sample` method has **completely different additional parameters** (`integers`, `n_replicates`) that don't apply to quantile-based forecasts\n- Default values differ: `.forecast_quantile` defaults `num_bins` to NULL; `.forecast_sample` defaults to 10\n\n---\n\n## Related Tests\n\n**Test files**:\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R` (lines 421-429)\n  - Tests `get_pit_histogram.forecast_quantile()`\n  \n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R` (lines 62-76)\n  - Tests `get_pit_histogram.forecast_sample()`\n\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R` (lines 96-161)\n  - Tests `as_forecast_quantile()` (generic and `.forecast_sample` variant)\n\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R` (lines 5-9)\n  - Tests `as_forecast_point(as_forecast_quantile(...))`\n\n**Test helpers and setup**:\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R`: Sets up example data and pre-computed scores\n\n---\n\n## Summary of the Issue\n\nThe problem is that these three S3 methods are currently documented under shared `@rdname` tags, which causes roxygen2 to combine their documentation. However, they have **significantly different parameters**:\n\n1. **`as_forecast_quantile.forecast_sample`**: Has `probs` and `type` parameters that don't exist in the `.default` method\n2. **`as_forecast_point.forecast_quantile`**: Has only `data, ...` (no other parameters) while `.default` has `forecast_unit`, `observed`, `predicted`\n3. **`get_pit_histogram.forecast_sample`**: Has `integers` and `n_replicates` parameters that don't apply to `.forecast_quantile`\n\n**Solution**: Each of these specific methods should have its own `@rdname` tag (or separate documentation name) to generate their own documentation pages that accurately reflect their actual signatures and parameters."},{"type":"text","text":"agentId: a77e748 (for resuming to continue this agent's work if needed)\n<usage>total_tokens: 46997\ntool_uses: 24\nduration_ms: 65913</usage>"}]}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"53fddfb0-cb2e-4057-b7a9-c3aaaa43228f","tool_use_result":{"status":"completed","prompt":"I need to understand issue #793 in the scoringutils package. The issue is about removing shared `@rdname` tags for S3 methods whose arguments differ from the generic. The three affected methods are:\n\n1. `as_forecast_quantile.forecast_sample` \n2. `as_forecast_point.forecast_quantile`\n3. `get_pit_histogram.forecast_sample`\n\nPlease find and show me:\n\n1. The roxygen documentation blocks for each of these three methods AND their corresponding generic/default methods. Look in `R/class-forecast-quantile.R`, `R/class-forecast-point.R` (or wherever they're defined), and wherever `get_pit_histogram` is defined.\n\n2. Specifically, look at the `@rdname` tags and `@param` tags to understand how arguments differ between the generic/default and the specific methods.\n\n3. Any existing tests in `tests/testthat/` related to these three functions (search for test files mentioning `as_forecast_quantile`, `as_forecast_point`, `get_pit_histogram`).\n\n4. Show me `tests/testthat/helper-*.R` and `tests/testthat/setup.R` to understand test helpers and conventions.\n\nBe thorough - read the actual roxygen blocks in full.","agentId":"a77e748","content":[{"type":"text","text":"Perfect! Now I have all the information I need to provide a comprehensive analysis. Let me create the final report:\n\n## Issue #793 Analysis: Removing Shared `@rdname` Tags for S3 Methods with Differing Arguments\n\nBased on my analysis of the scoringutils package, here's a comprehensive breakdown of the three affected methods:\n\n---\n\n### 1. **`as_forecast_quantile.forecast_sample`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R` (lines 75-116)\n\n**Generic definition** (`as_forecast_quantile`):\n```r\n#' @title Create a `forecast` object for quantile-based forecasts\n#' @inherit as_forecast_doc_template params description\n#' @details ...\n#' @param ... Unused\n#' @returns A `forecast` object of class `forecast_quantile`\n#' @export\nas_forecast_quantile <- function(data, ...) {\n  UseMethod(\"as_forecast_quantile\")\n}\n```\n\n**Default method** (`as_forecast_quantile.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R`, lines 38-75):\n```r\n#' @rdname as_forecast_quantile\n#' @param quantile_level (optional) Name of the column in `data` that contains\n#'   the quantile level of the predicted values. This column will be renamed to\n#'   \"quantile_level\". Only applicable to quantile-based forecasts.\n#' @export\n#' @method as_forecast_quantile default\nas_forecast_quantile.default <- function(data,\n                                         forecast_unit = NULL,\n                                         observed = NULL,\n                                         predicted = NULL,\n                                         quantile_level = NULL,\n                                         ...) { ... }\n```\n\n**Specific method** (`as_forecast_quantile.forecast_sample`):\n```r\n#' @rdname as_forecast_quantile\n#' @details # Converting from `forecast_sample` to `forecast_quantile`\n#' When creating a `forecast_quantile` object from a `forecast_sample` object,\n#' the quantiles are estimated by computing empircal quantiles from the samples\n#' via [quantile()]. Note that empirical quantiles are a biased estimator for\n#' the true quantiles in particular in the tails of the distribution and\n#' when the number of available samples is low.\n#' @param probs A numeric vector of quantile levels for which\n#'   quantiles will be computed. Corresponds to the `probs` argument in\n#'   [quantile()].\n#' @param type Type argument passed down to the quantile function. For more\n#'   information, see [quantile()].\n#' @importFrom stats quantile\n#' @importFrom methods hasArg\n#' @importFrom checkmate assert_numeric\n#' @export\nas_forecast_quantile.forecast_sample <- function(\n  data,\n  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),\n  type = 7,\n  ...\n) { ... }\n```\n\n**Key Differences**:\n- The `.default` method has parameters: `forecast_unit`, `observed`, `predicted`, `quantile_level`\n- The `.forecast_sample` method has parameters: `probs`, `type` (completely different!)\n- Sharing `@rdname as_forecast_quantile` causes documentation conflict because users see documentation for `quantile_level` and `forecast_unit` when they're actually using `probs` and `type`\n\n---\n\n### 2. **`as_forecast_point.forecast_quantile`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R` (lines 99-120)\n\n**Generic definition** (`as_forecast_point`):\n```r\n#' @title Create a `forecast` object for point forecasts\n#' @inherit as_forecast_doc_template params description\n#' @details ...\n#' @param ... Unused\n#' @returns A `forecast` object of class `forecast_point`\n#' @export\nas_forecast_point <- function(data, ...) {\n  UseMethod(\"as_forecast_point\")\n}\n```\n\n**Default method** (`as_forecast_point.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-point.R`, lines 26-44):\n```r\n#' @rdname as_forecast_point\n#' @export\n#' @method as_forecast_point default\nas_forecast_point.default <- function(data,\n                                      forecast_unit = NULL,\n                                      observed = NULL,\n                                      predicted = NULL,\n                                      ...) { ... }\n```\n\n**Specific method** (`as_forecast_point.forecast_quantile`):\n```r\n#' @rdname as_forecast_point\n#' @description\n#' When converting a `forecast_quantile` object into a `forecast_point` object,\n#' the 0.5 quantile is extracted and returned as the point forecast.\n#' @export\nas_forecast_point.forecast_quantile <- function(data, ...) {\n  assert_forecast(data, verbose = FALSE)\n  ...\n}\n```\n\n**Key Differences**:\n- The `.default` method has parameters: `forecast_unit`, `observed`, `predicted`\n- The `.forecast_quantile` method only has: `data`, `...` (no other parameters!)\n- The `.forecast_quantile` method automatically extracts the 0.5 quantile and doesn't need the additional parameters\n- Sharing `@rdname` causes confusion about which parameters apply to which method\n\n---\n\n### 3. **`get_pit_histogram.forecast_sample`**\n\n**Location**: `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-sample.R` (lines 195-242)\n\n**Generic definition** (`get_pit_histogram`):\n```r\n#' @title Probability integral transformation histogram\n#' @description Generate a Probability Integral Transformation (PIT) histogram\n#'   for validated forecast objects.\n#' @inherit score params\n#' @param num_bins The number of bins in the PIT histogram. For sample-based\n#'   forecasts, the default is 10 bins. For quantile-based forecasts, the\n#'   default is one bin for each available quantile.\n#'   ...\n#' @param breaks Numeric vector with the break points for the bins in the\n#'   PIT histogram. This is preferred when creating a PIT histogram based on\n#'   quantile-based data. Default is `NULL` and breaks will be determined by\n#'   `num_bins`. If `breaks` is used, `num_bins` will be ignored.\n#'   0 and 1 will always be added as left and right bounds, respectively.\n#' @param by Character vector with the columns according to which the\n#'   PIT values shall be grouped.\n#' @inheritParams pit_histogram_sample\n#' @returns A data.table with density values for each bin in the PIT histogram.\n#' @export\nget_pit_histogram <- function(forecast, num_bins, breaks, by, ...) {\n  UseMethod(\"get_pit_histogram\")\n}\n```\n\n**Default method** (`get_pit_histogram.default` in `/Users/nikos/github-synced/scoringutils-pipeline/R/get-pit-histogram.R`, lines 56-63):\n```r\n#' @rdname get_pit_histogram\n#' @export\nget_pit_histogram.default <- function(forecast, num_bins, breaks, by, ...) {\n  cli_abort(c(\n    \"!\" = \"The input needs to be a valid forecast object...\"\n  ))\n}\n```\n\n**Quantile method** (`get_pit_histogram.forecast_quantile` in `/Users/nikos/github-synced/scoringutils-pipeline/R/class-forecast-quantile.R`, lines 217-268):\n```r\n#' @rdname get_pit_histogram\n#' @export\nget_pit_histogram.forecast_quantile <- function(forecast, num_bins = NULL,\n                                                breaks = NULL, by, ...) {\n  ...\n}\n```\n\n**Sample method** (`get_pit_histogram.forecast_sample`):\n```r\n#' @rdname get_pit_histogram\n#' @importFrom data.table `:=` as.data.table dcast\n#' @importFrom checkmate assert_int assert_numeric\n#' @inheritParams pit_histogram_sample\n#' @seealso [pit_histogram_sample()]\n#' @export\nget_pit_histogram.forecast_sample <- function(forecast, num_bins = 10,\n                                              breaks = NULL, by, integers = c(\n                                                \"nonrandom\", \"random\", \"ignore\"\n                                              ), n_replicates = NULL, ...) {\n  ...\n}\n```\n\n**Key Differences**:\n- The `.forecast_quantile` method has: `num_bins = NULL`, `breaks = NULL`\n- The `.forecast_sample` method has: `num_bins = 10`, `breaks = NULL`, `integers = c(...)`, `n_replicates = NULL`\n- The `.sample` method has **completely different additional parameters** (`integers`, `n_replicates`) that don't apply to quantile-based forecasts\n- Default values differ: `.forecast_quantile` defaults `num_bins` to NULL; `.forecast_sample` defaults to 10\n\n---\n\n## Related Tests\n\n**Test files**:\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R` (lines 421-429)\n  - Tests `get_pit_histogram.forecast_quantile()`\n  \n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R` (lines 62-76)\n  - Tests `get_pit_histogram.forecast_sample()`\n\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R` (lines 96-161)\n  - Tests `as_forecast_quantile()` (generic and `.forecast_sample` variant)\n\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R` (lines 5-9)\n  - Tests `as_forecast_point(as_forecast_quantile(...))`\n\n**Test helpers and setup**:\n- `/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R`: Sets up example data and pre-computed scores\n\n---\n\n## Summary of the Issue\n\nThe problem is that these three S3 methods are currently documented under shared `@rdname` tags, which causes roxygen2 to combine their documentation. However, they have **significantly different parameters**:\n\n1. **`as_forecast_quantile.forecast_sample`**: Has `probs` and `type` parameters that don't exist in the `.default` method\n2. **`as_forecast_point.forecast_quantile`**: Has only `data, ...` (no other parameters) while `.default` has `forecast_unit`, `observed`, `predicted`\n3. **`get_pit_histogram.forecast_sample`**: Has `integers` and `n_replicates` parameters that don't apply to `.forecast_quantile`\n\n**Solution**: Each of these specific methods should have its own `@rdname` tag (or separate documentation name) to generate their own documentation pages that accurately reflect their actual signatures and parameters."}],"totalDurationMs":65913,"totalTokens":46997,"totalToolUseCount":24,"usage":{"input_tokens":0,"cache_creation_input_tokens":696,"cache_read_input_tokens":43448,"output_tokens":2853,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":696,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[]}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01PoiN6t4ASm1C1Sp3Y1P5dX","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent. Now I have a clear understanding of the issue and affected code. This is a **documentation-only** change — modifying roxygen `@rdname` tags so that S3 methods with different parameter signatures get their own documentation pages. Let me think about what kind of tests are appropriate here."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3470,"cache_read_input_tokens":48190,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3470},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"ab4e517b-54c7-4634-a92a-b0a5a8301098"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01PoiN6t4ASm1C1Sp3Y1P5dX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CtJvsJTM6n8CoP5CwoyEAD","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"in_progress","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3470,"cache_read_input_tokens":48190,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3470},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6a72e05b-224d-469b-8815-6bdded110dfb"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CtJvsJTM6n8CoP5CwoyEAD","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"5b2b288e-6e8b-46ab-899a-2e4e27640a06","tool_use_result":{"oldTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"in_progress","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"pending","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"in_progress","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JLJ2QSBd9nzH8qByEbDKcx","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check how existing documentation tests work in this project and whether there are any patterns for testing roxygen/NAMESPACE exports."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":318,"cache_read_input_tokens":51660,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":318},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f2df1eb6-3b75-4459-a279-72f3b2b27262"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JLJ2QSBd9nzH8qByEbDKcx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011kawmgPu96G8kE4bSu3NWZ","name":"Grep","input":{"pattern":"rdname|roxygen|man/|\\.Rd","path":"/Users/nikos/github-synced/scoringutils-pipeline/tests","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":318,"cache_read_input_tokens":51660,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":318},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7fc18020-219d-4586-9af1-4446788bc60b"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011kawmgPu96G8kE4bSu3NWZ","type":"tool_result","content":"No matches found"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"532f564d-0ece-4176-8af2-ea4dfae5c1a1","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"","numLines":0}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01KcPtmJHAu6SR6uPfHm8Ct4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017C5sqBjCmXs6wCPXZF3J2e","name":"Grep","input":{"pattern":"help\\(|\\\\?|man_page|documentation","path":"/Users/nikos/github-synced/scoringutils-pipeline/tests","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":158,"cache_read_input_tokens":51978,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":158},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"61a99a5d-dc91-4c44-9435-f081430ad3e0"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017C5sqBjCmXs6wCPXZF3J2e","type":"tool_result","content":"<persisted-output>\nOutput too large (725.6KB). Full output saved to: /Users/nikos/.claude/projects/-Users-nikos-github-synced-scoringutils-pipeline/c911bcbe-fd63-4b04-947b-21bb95a8a4d6/tool-results/toolu_017C5sqBjCmXs6wCPXZF3J2e.txt\n\nPreview (first 2KB):\ntests/testthat.R:1:library(testthat)\ntests/testthat.R:2:library(scoringutils)\ntests/testthat.R:3:\ntests/testthat.R:4:test_check(\"scoringutils\")\ntests/testthat/test-plot_heatmap.R:1:test_that(\"plot_heatmap() works as expected\", {\ntests/testthat/test-plot_heatmap.R:2:  scores <- scores_quantile |>\ntests/testthat/test-plot_heatmap.R:3:    summarise_scores(by = c(\"model\", \"target_type\")) |>\ntests/testthat/test-plot_heatmap.R:4:    summarise_scores(by = c(\"model\", \"target_type\"), fun = round, digits = 2)\ntests/testthat/test-plot_heatmap.R:5:  p <- plot_heatmap(scores, x = \"target_type\", metric = \"bias\")\ntests/testthat/test-plot_heatmap.R:6:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-plot_heatmap.R:7:  skip_on_cran()\ntests/testthat/test-plot_heatmap.R:8:  vdiffr::expect_doppelganger(\"plot_heatmap\", p)\ntests/testthat/test-plot_heatmap.R:9:})\ntests/testthat/test-get-correlations.R:1:test_that(\"get_correlations() works as expected\", {\ntests/testthat/test-get-correlations.R:2:  # expect all to go well in the usual case\ntests/testthat/test-get-correlations.R:3:  correlations <- expect_no_condition(\ntests/testthat/test-get-correlations.R:4:    get_correlations(scores_quantile)\ntests/testthat/test-get-correlations.R:5:  )\ntests/testthat/test-get-correlations.R:6:  expect_identical(\ntests/testthat/test-get-correlations.R:7:    colnames(correlations), c(get_metrics.scores(scores_quantile), \"metric\")\ntests/testthat/test-get-correlations.R:8:  )\ntests/testthat/test-get-correlations.R:9:\ntests/testthat/test-get-correlations.R:10:  # expect no error if scores are unsummarised\ntests/testthat/test-get-correlations.R:11:  # (meaning that coverage will be a logical vector instead of a numeric)\ntests/testthat/test-get-correlations.R:12:  correlations2 <- expect_no_condition(\ntests/testthat/test-get-correlations.R:13:    get_correlations(scores_quantile)\ntests/testthat/test-get-correlations.R:14:  )\n...\n</persisted-output>"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6f78661d-8765-482f-9520-8ce2ad75c8b9","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"tests/testthat.R:1:library(testthat)\ntests/testthat.R:2:library(scoringutils)\ntests/testthat.R:3:\ntests/testthat.R:4:test_check(\"scoringutils\")\ntests/testthat/test-plot_heatmap.R:1:test_that(\"plot_heatmap() works as expected\", {\ntests/testthat/test-plot_heatmap.R:2:  scores <- scores_quantile |>\ntests/testthat/test-plot_heatmap.R:3:    summarise_scores(by = c(\"model\", \"target_type\")) |>\ntests/testthat/test-plot_heatmap.R:4:    summarise_scores(by = c(\"model\", \"target_type\"), fun = round, digits = 2)\ntests/testthat/test-plot_heatmap.R:5:  p <- plot_heatmap(scores, x = \"target_type\", metric = \"bias\")\ntests/testthat/test-plot_heatmap.R:6:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-plot_heatmap.R:7:  skip_on_cran()\ntests/testthat/test-plot_heatmap.R:8:  vdiffr::expect_doppelganger(\"plot_heatmap\", p)\ntests/testthat/test-plot_heatmap.R:9:})\ntests/testthat/test-get-correlations.R:1:test_that(\"get_correlations() works as expected\", {\ntests/testthat/test-get-correlations.R:2:  # expect all to go well in the usual case\ntests/testthat/test-get-correlations.R:3:  correlations <- expect_no_condition(\ntests/testthat/test-get-correlations.R:4:    get_correlations(scores_quantile)\ntests/testthat/test-get-correlations.R:5:  )\ntests/testthat/test-get-correlations.R:6:  expect_identical(\ntests/testthat/test-get-correlations.R:7:    colnames(correlations), c(get_metrics.scores(scores_quantile), \"metric\")\ntests/testthat/test-get-correlations.R:8:  )\ntests/testthat/test-get-correlations.R:9:\ntests/testthat/test-get-correlations.R:10:  # expect no error if scores are unsummarised\ntests/testthat/test-get-correlations.R:11:  # (meaning that coverage will be a logical vector instead of a numeric)\ntests/testthat/test-get-correlations.R:12:  correlations2 <- expect_no_condition(\ntests/testthat/test-get-correlations.R:13:    get_correlations(scores_quantile)\ntests/testthat/test-get-correlations.R:14:  )\ntests/testthat/test-get-correlations.R:15:  expect_identical(correlations, correlations2)\ntests/testthat/test-get-correlations.R:16:\ntests/testthat/test-get-correlations.R:17:  expect_s3_class(\ntests/testthat/test-get-correlations.R:18:    get_correlations(scores_quantile),\ntests/testthat/test-get-correlations.R:19:    c(\"scores\", \"data.table\", \"data.frame\"),\ntests/testthat/test-get-correlations.R:20:    exact = TRUE\ntests/testthat/test-get-correlations.R:21:  )\ntests/testthat/test-get-correlations.R:22:\ntests/testthat/test-get-correlations.R:23:  # passing a data.frame works as long as the metrics attribute is still there\ntests/testthat/test-get-correlations.R:24:  expect_no_condition(\ntests/testthat/test-get-correlations.R:25:    get_correlations(as.data.frame(scores_quantile))\ntests/testthat/test-get-correlations.R:26:  )\ntests/testthat/test-get-correlations.R:27:\ntests/testthat/test-get-correlations.R:28:  # check we get an error if metrics attribute is missing.\ntests/testthat/test-get-correlations.R:29:  expect_error(\ntests/testthat/test-get-correlations.R:30:    get_correlations(as.data.frame(as.matrix(scores_quantile))),\ntests/testthat/test-get-correlations.R:31:    \"Assertion on 'metrics' failed: Must be a subset of\"\ntests/testthat/test-get-correlations.R:32:  )\ntests/testthat/test-get-correlations.R:33:})\ntests/testthat/test-get-correlations.R:34:\ntests/testthat/test-get-correlations.R:35:# ==============================================================================\ntests/testthat/test-get-correlations.R:36:# plot_correlation() # nolint: commented_code_linter\ntests/testthat/test-get-correlations.R:37:# ==============================================================================\ntests/testthat/test-get-correlations.R:38:test_that(\"plot_correlations() works as expected\", {\ntests/testthat/test-get-correlations.R:39:  correlations <- get_correlations(\ntests/testthat/test-get-correlations.R:40:    summarise_scores(\ntests/testthat/test-get-correlations.R:41:      scores_quantile,\ntests/testthat/test-get-correlations.R:42:      by = get_forecast_unit(scores_quantile)\ntests/testthat/test-get-correlations.R:43:    )\ntests/testthat/test-get-correlations.R:44:  )\ntests/testthat/test-get-correlations.R:45:  p <- plot_correlations(correlations, digits = 2)\ntests/testthat/test-get-correlations.R:46:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-get-correlations.R:47:  skip_on_cran()\ntests/testthat/test-get-correlations.R:48:  vdiffr::expect_doppelganger(\"plot__correlation\", p)\ntests/testthat/test-get-correlations.R:49:\ntests/testthat/test-get-correlations.R:50:  # expect an error if you forgot to compute correlations\ntests/testthat/test-get-correlations.R:51:  expect_error(\ntests/testthat/test-get-correlations.R:52:    plot_correlations(summarise_scores(scores_quantile)),\ntests/testthat/test-get-correlations.R:53:    \"Did you forget to call `scoringutils::get_correlations()`?\"\ntests/testthat/test-get-correlations.R:54:  )\ntests/testthat/test-get-correlations.R:55:})\ntests/testthat/test-class-forecast-sample.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:2:# as_forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:4:test_that(\"as_forecast_sample() works as expected\", {\ntests/testthat/test-class-forecast-sample.R:5:  test <- na.omit(data.table::copy(example_sample_continuous))\ntests/testthat/test-class-forecast-sample.R:6:  data.table::setnames(test,\ntests/testthat/test-class-forecast-sample.R:7:    old = c(\"observed\", \"predicted\", \"sample_id\"),\ntests/testthat/test-class-forecast-sample.R:8:    new = c(\"obs\", \"pred\", \"sample\")\ntests/testthat/test-class-forecast-sample.R:9:  )\ntests/testthat/test-class-forecast-sample.R:10:  expect_no_condition(\ntests/testthat/test-class-forecast-sample.R:11:    as_forecast_sample(test,\ntests/testthat/test-class-forecast-sample.R:12:      observed = \"obs\", predicted = \"pred\",\ntests/testthat/test-class-forecast-sample.R:13:      forecast_unit = c(\ntests/testthat/test-class-forecast-sample.R:14:        \"location\", \"model\", \"target_type\",\ntests/testthat/test-class-forecast-sample.R:15:        \"target_end_date\", \"horizon\"\ntests/testthat/test-class-forecast-sample.R:16:      ),\ntests/testthat/test-class-forecast-sample.R:17:      sample_id = \"sample\"\ntests/testthat/test-class-forecast-sample.R:18:    )\ntests/testthat/test-class-forecast-sample.R:19:  )\ntests/testthat/test-class-forecast-sample.R:20:})\ntests/testthat/test-class-forecast-sample.R:21:\ntests/testthat/test-class-forecast-sample.R:22:test_that(\"Running `as_forecast_sample()` twice returns the same object\", {\ntests/testthat/test-class-forecast-sample.R:23:  ex <- na.omit(example_sample_continuous)\ntests/testthat/test-class-forecast-sample.R:24:\ntests/testthat/test-class-forecast-sample.R:25:  expect_identical(\ntests/testthat/test-class-forecast-sample.R:26:    as_forecast_sample(as_forecast_sample(ex)),\ntests/testthat/test-class-forecast-sample.R:27:    as_forecast_sample(ex)\ntests/testthat/test-class-forecast-sample.R:28:  )\ntests/testthat/test-class-forecast-sample.R:29:})\ntests/testthat/test-class-forecast-sample.R:30:\ntests/testthat/test-class-forecast-sample.R:31:\ntests/testthat/test-class-forecast-sample.R:32:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:33:# is_forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:34:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:35:test_that(\"is_forecast_sample() works as expected\", {\ntests/testthat/test-class-forecast-sample.R:36:  expect_true(is_forecast_sample(example_sample_continuous))\ntests/testthat/test-class-forecast-sample.R:37:  expect_false(is_forecast_sample(example_binary))\ntests/testthat/test-class-forecast-sample.R:38:  expect_false(is_forecast_sample(example_point))\ntests/testthat/test-class-forecast-sample.R:39:  expect_false(is_forecast_sample(example_quantile))\ntests/testthat/test-class-forecast-sample.R:40:  expect_false(is_forecast_sample(example_nominal))\ntests/testthat/test-class-forecast-sample.R:41:  expect_false(is_forecast_sample(1:10))\ntests/testthat/test-class-forecast-sample.R:42:})\ntests/testthat/test-class-forecast-sample.R:43:\ntests/testthat/test-class-forecast-sample.R:44:\ntests/testthat/test-class-forecast-sample.R:45:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:46:# get_metrics.forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:47:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:48:\ntests/testthat/test-class-forecast-sample.R:49:test_that(\"get_metrics.forecast_sample() works as expected\", {\ntests/testthat/test-class-forecast-sample.R:50:  expect_type(\ntests/testthat/test-class-forecast-sample.R:51:    get_metrics(example_sample_continuous), \"list\"\ntests/testthat/test-class-forecast-sample.R:52:  )\ntests/testthat/test-class-forecast-sample.R:53:  expect_type(\ntests/testthat/test-class-forecast-sample.R:54:    get_metrics(example_sample_discrete), \"list\"\ntests/testthat/test-class-forecast-sample.R:55:  )\ntests/testthat/test-class-forecast-sample.R:56:})\ntests/testthat/test-class-forecast-sample.R:57:\ntests/testthat/test-class-forecast-sample.R:58:\ntests/testthat/test-class-forecast-sample.R:59:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:60:# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:61:# ==============================================================================\ntests/testthat/test-class-forecast-sample.R:62:test_that(\"get_pit_histogram.forecast_sample() works as expected\", {\ntests/testthat/test-class-forecast-sample.R:63:  pit_continuous <- get_pit_histogram(example_sample_continuous, by = c(\"model\", \"target_type\"))\ntests/testthat/test-class-forecast-sample.R:64:  pit_integer <- get_pit_histogram(example_sample_discrete, by = c(\"model\", \"location\"))\ntests/testthat/test-class-forecast-sample.R:65:\ntests/testthat/test-class-forecast-sample.R:66:  expect_named(pit_continuous, c(\"model\", \"target_type\", \"density\", \"bin\", \"mid\"))\ntests/testthat/test-class-forecast-sample.R:67:  expect_named(pit_integer, c(\"model\", \"location\", \"density\", \"bin\", \"mid\"))\ntests/testthat/test-class-forecast-sample.R:68:\ntests/testthat/test-class-forecast-sample.R:69:  # check printing works\ntests/testthat/test-class-forecast-sample.R:70:  expect_output(print(pit_continuous))\ntests/testthat/test-class-forecast-sample.R:71:  expect_output(print(pit_integer))\ntests/testthat/test-class-forecast-sample.R:72:\ntests/testthat/test-class-forecast-sample.R:73:  # check class is correct\ntests/testthat/test-class-forecast-sample.R:74:  expect_s3_class(pit_continuous, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-sample.R:75:  expect_s3_class(pit_integer, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-sample.R:76:})\ntests/testthat/test-transform-forecasts.R:1:# ============================================================================ #\ntests/testthat/test-transform-forecasts.R:2:# `transform_forecasts()` # nolint: commented_code_linter\ntests/testthat/test-transform-forecasts.R:3:# ============================================================================ #\ntests/testthat/test-transform-forecasts.R:4:test_that(\"function transform_forecasts works\", {\ntests/testthat/test-transform-forecasts.R:5:  predictions_original <- example_quantile$predicted\ntests/testthat/test-transform-forecasts.R:6:  predictions <- example_quantile |>\ntests/testthat/test-transform-forecasts.R:7:    transform_forecasts(\ntests/testthat/test-transform-forecasts.R:8:      fun = function(x) pmax(0, x),\ntests/testthat/test-transform-forecasts.R:9:      append = FALSE\ntests/testthat/test-transform-forecasts.R:10:    )\ntests/testthat/test-transform-forecasts.R:11:\ntests/testthat/test-transform-forecasts.R:12:  expect_equal(predictions$predicted, pmax(0, predictions_original)) # nolint: expect_identical_linter\ntests/testthat/test-transform-forecasts.R:13:\ntests/testthat/test-transform-forecasts.R:14:  one <- transform_forecasts(predictions, offset = 1)\ntests/testthat/test-transform-forecasts.R:15:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-transform-forecasts.R:16:    one$predicted,\ntests/testthat/test-transform-forecasts.R:17:    c(predictions$predicted, log(predictions$predicted + 1))\ntests/testthat/test-transform-forecasts.R:18:  )\ntests/testthat/test-transform-forecasts.R:19:\ntests/testthat/test-transform-forecasts.R:20:  two <- transform_forecasts(predictions, fun = sqrt, label = \"sqrt\")\ntests/testthat/test-transform-forecasts.R:21:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-transform-forecasts.R:22:    two$predicted,\ntests/testthat/test-transform-forecasts.R:23:    c(predictions$predicted, sqrt(predictions$predicted))\ntests/testthat/test-transform-forecasts.R:24:  )\ntests/testthat/test-transform-forecasts.R:25:\ntests/testthat/test-transform-forecasts.R:26:\ntests/testthat/test-transform-forecasts.R:27:  # expect a warning + error if you add a second transformation with the same label\ntests/testthat/test-transform-forecasts.R:28:  expect_error(\ntests/testthat/test-transform-forecasts.R:29:    expect_warning(\ntests/testthat/test-transform-forecasts.R:30:      transform_forecasts(one, fun = sqrt),\ntests/testthat/test-transform-forecasts.R:31:      \"Appending new transformations with label 'log' even though that entry is already present in column 'scale'\"\ntests/testthat/test-transform-forecasts.R:32:    ),\ntests/testthat/test-transform-forecasts.R:33:    \"There are instances with more than one forecast for the same target. \"\ntests/testthat/test-transform-forecasts.R:34:  )\ntests/testthat/test-transform-forecasts.R:35:\ntests/testthat/test-transform-forecasts.R:36:\ntests/testthat/test-transform-forecasts.R:37:  # multiple transformations\ntests/testthat/test-transform-forecasts.R:38:  three <- transform_forecasts(one, fun = sqrt, label = \"sqrt\")\ntests/testthat/test-transform-forecasts.R:39:  expect_identical(unique(three$scale), c(\"natural\", \"log\", \"sqrt\"))\ntests/testthat/test-transform-forecasts.R:40:\ntests/testthat/test-transform-forecasts.R:41:  # expect_error if there is a scale column, but no value \"natural\"\ntests/testthat/test-transform-forecasts.R:42:  no_natural <- three[three$scale != \"natural\", ]\ntests/testthat/test-transform-forecasts.R:43:  expect_error(\ntests/testthat/test-transform-forecasts.R:44:    transform_forecasts(no_natural, fun = identity),\ntests/testthat/test-transform-forecasts.R:45:    \"If a column 'scale' is present, entries with scale =='natural' are required for the transformation.\"\ntests/testthat/test-transform-forecasts.R:46:  )\ntests/testthat/test-transform-forecasts.R:47:\ntests/testthat/test-transform-forecasts.R:48:  # multiple transformations without append\ntests/testthat/test-transform-forecasts.R:49:  four <- transform_forecasts(two, fun = log_shift, offset = 1, append = FALSE)\ntests/testthat/test-transform-forecasts.R:50:  compare <- c(\ntests/testthat/test-transform-forecasts.R:51:    one$predicted[one$scale == \"log\"],\ntests/testthat/test-transform-forecasts.R:52:    three$predicted[three$scale == \"sqrt\"]\ntests/testthat/test-transform-forecasts.R:53:  )\ntests/testthat/test-transform-forecasts.R:54:\ntests/testthat/test-transform-forecasts.R:55:  expect_equal(four$predicted, compare) # nolint: expect_identical_linter\ntests/testthat/test-transform-forecasts.R:56:})\ntests/testthat/test-transform-forecasts.R:57:\ntests/testthat/test-transform-forecasts.R:58:test_that(\"transform_forecasts() outputs an object of class forecast_*\", {\ntests/testthat/test-transform-forecasts.R:59:  transformed <- transform_forecasts(example_binary, fun = identity, append = FALSE)\ntests/testthat/test-transform-forecasts.R:60:  expect_s3_class(transformed, \"forecast_binary\")\ntests/testthat/test-transform-forecasts.R:61:})\ntests/testthat/test-transform-forecasts.R:62:\ntests/testthat/test-transform-forecasts.R:63:\ntests/testthat/test-transform-forecasts.R:64:# ============================================================================ #\ntests/testthat/test-transform-forecasts.R:65:# `log_shift()` # nolint: commented_code_linter\ntests/testthat/test-transform-forecasts.R:66:# ============================================================================ #\ntests/testthat/test-transform-forecasts.R:67:test_that(\"log_shift() works as expected\", {\ntests/testthat/test-transform-forecasts.R:68:  expect_equal(log_shift(1:10, 1), log(1:10 + 1)) # nolint: expect_identical_linter\ntests/testthat/test-transform-forecasts.R:69:\ntests/testthat/test-transform-forecasts.R:70:  # expect errors if there are values < 0\ntests/testthat/test-transform-forecasts.R:71:  expect_error(\ntests/testthat/test-transform-forecasts.R:72:    log_shift(c(1, 0, -1), 1),\ntests/testthat/test-transform-forecasts.R:73:    \"Detected input values < 0.\"\ntests/testthat/test-transform-forecasts.R:74:  )\ntests/testthat/test-transform-forecasts.R:75:\ntests/testthat/test-transform-forecasts.R:76:  # expect errors if there are zeros\ntests/testthat/test-transform-forecasts.R:77:  expect_warning(\ntests/testthat/test-transform-forecasts.R:78:    log_shift(c(1, 0, 1), offset = 0),\ntests/testthat/test-transform-forecasts.R:79:    \"Detected zeros in input values.\"\ntests/testthat/test-transform-forecasts.R:80:  )\ntests/testthat/test-transform-forecasts.R:81:\ntests/testthat/test-transform-forecasts.R:82:  # test that it does not accept a complex number\ntests/testthat/test-transform-forecasts.R:83:  expect_error(log_shift(1:10, offset = 1, base = 1i))\ntests/testthat/test-transform-forecasts.R:84:\ntests/testthat/test-transform-forecasts.R:85:  # test that it does not accept a negative base\ntests/testthat/test-transform-forecasts.R:86:  expect_error(\ntests/testthat/test-transform-forecasts.R:87:    log_shift(1:10, offset = 1, base = -1),\ntests/testthat/test-transform-forecasts.R:88:    \"Assertion on 'base' failed: Element 1 is not >= 0.\"\ntests/testthat/test-transform-forecasts.R:89:  )\ntests/testthat/test-transform-forecasts.R:90:\ntests/testthat/test-transform-forecasts.R:91:  # test output class is numeric as expected\ntests/testthat/test-transform-forecasts.R:92:  checkmate::expect_class(log_shift(1:10, 1), \"numeric\")\ntests/testthat/test-transform-forecasts.R:93:})\ntests/testthat/test-class-forecast-binary.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:2:# as_forecast_binary() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-binary.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:4:test_that(\"output of as_forecast_binary() is accepted as input to score()\", {\ntests/testthat/test-class-forecast-binary.R:5:  check <- suppressMessages(as_forecast_binary(example_binary))\ntests/testthat/test-class-forecast-binary.R:6:  score_check <- expect_no_error(score(na.omit(check)))\ntests/testthat/test-class-forecast-binary.R:7:  expect_identical(score_check, suppressMessages(score(as_forecast_binary(example_binary))))\ntests/testthat/test-class-forecast-binary.R:8:})\ntests/testthat/test-class-forecast-binary.R:9:\ntests/testthat/test-class-forecast-binary.R:10:\ntests/testthat/test-class-forecast-binary.R:11:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:12:# is_forecast_binary() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-binary.R:13:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:14:test_that(\"is_forecast_binary() works as expected\", {\ntests/testthat/test-class-forecast-binary.R:15:  expect_true(is_forecast_binary(example_binary))\ntests/testthat/test-class-forecast-binary.R:16:  expect_false(is_forecast_binary(example_point))\ntests/testthat/test-class-forecast-binary.R:17:  expect_false(is_forecast_binary(example_quantile))\ntests/testthat/test-class-forecast-binary.R:18:  expect_false(is_forecast_binary(example_sample_continuous))\ntests/testthat/test-class-forecast-binary.R:19:  expect_false(is_forecast_binary(example_nominal))\ntests/testthat/test-class-forecast-binary.R:20:})\ntests/testthat/test-class-forecast-binary.R:21:\ntests/testthat/test-class-forecast-binary.R:22:\ntests/testthat/test-class-forecast-binary.R:23:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:24:# assert_forecast.forecast_binary() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-binary.R:25:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:26:test_that(\"assert_forecast.forecast_binary works as expected\", {\ntests/testthat/test-class-forecast-binary.R:27:  test <- na.omit(as.data.table(example_binary))\ntests/testthat/test-class-forecast-binary.R:28:  test[, \"sample_id\" := seq_len(nrow(test))]\ntests/testthat/test-class-forecast-binary.R:29:\ntests/testthat/test-class-forecast-binary.R:30:  # error if there is a superfluous sample_id column\ntests/testthat/test-class-forecast-binary.R:31:  expect_error(\ntests/testthat/test-class-forecast-binary.R:32:    as_forecast_binary(test),\ntests/testthat/test-class-forecast-binary.R:33:    paste(\ntests/testthat/test-class-forecast-binary.R:34:      \"Input looks like a binary forecast, but an additional column\",\ntests/testthat/test-class-forecast-binary.R:35:      \"called `sample_id` or `quantile` was found.\"\ntests/testthat/test-class-forecast-binary.R:36:    )\ntests/testthat/test-class-forecast-binary.R:37:  )\ntests/testthat/test-class-forecast-binary.R:38:\ntests/testthat/test-class-forecast-binary.R:39:  # expect error if probabilties are not in [0, 1]\ntests/testthat/test-class-forecast-binary.R:40:  test <- na.omit(as.data.table(example_binary))\ntests/testthat/test-class-forecast-binary.R:41:  test[, \"predicted\" := predicted + 1]\ntests/testthat/test-class-forecast-binary.R:42:  expect_error(\ntests/testthat/test-class-forecast-binary.R:43:    as_forecast_binary(test),\ntests/testthat/test-class-forecast-binary.R:44:    \"Input looks like a binary forecast, but found the following issue\"\ntests/testthat/test-class-forecast-binary.R:45:  )\ntests/testthat/test-class-forecast-binary.R:46:})\ntests/testthat/test-class-forecast-binary.R:47:\ntests/testthat/test-class-forecast-binary.R:48:\ntests/testthat/test-class-forecast-binary.R:49:\ntests/testthat/test-class-forecast-binary.R:50:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:51:# score.forecast_binary() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-binary.R:52:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:53:test_that(\"function produces output for a binary case\", {\ntests/testthat/test-class-forecast-binary.R:54:  expect_named(\ntests/testthat/test-class-forecast-binary.R:55:    scores_binary,\ntests/testthat/test-class-forecast-binary.R:56:    c(get_forecast_unit(example_binary), names(get_metrics(example_binary)))\ntests/testthat/test-class-forecast-binary.R:57:  )\ntests/testthat/test-class-forecast-binary.R:58:\ntests/testthat/test-class-forecast-binary.R:59:  eval <- summarise_scores(scores_binary, by = c(\"model\", \"target_type\"))\ntests/testthat/test-class-forecast-binary.R:60:\ntests/testthat/test-class-forecast-binary.R:61:  expect_gt(\ntests/testthat/test-class-forecast-binary.R:62:    nrow(eval), 1\ntests/testthat/test-class-forecast-binary.R:63:  )\ntests/testthat/test-class-forecast-binary.R:64:  expect_identical(\ntests/testthat/test-class-forecast-binary.R:65:    colnames(eval),\ntests/testthat/test-class-forecast-binary.R:66:    c(\ntests/testthat/test-class-forecast-binary.R:67:      \"model\", \"target_type\",\ntests/testthat/test-class-forecast-binary.R:68:      \"brier_score\",\ntests/testthat/test-class-forecast-binary.R:69:      \"log_score\"\ntests/testthat/test-class-forecast-binary.R:70:    )\ntests/testthat/test-class-forecast-binary.R:71:  )\ntests/testthat/test-class-forecast-binary.R:72:\ntests/testthat/test-class-forecast-binary.R:73:  expect_true(\"brier_score\" %in% names(eval))\ntests/testthat/test-class-forecast-binary.R:74:\ntests/testthat/test-class-forecast-binary.R:75:  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-binary.R:76:})\ntests/testthat/test-class-forecast-binary.R:77:\ntests/testthat/test-class-forecast-binary.R:78:test_that(\"score.forecast_binary() errors with only NA values\", {\ntests/testthat/test-class-forecast-binary.R:79:  # [.forecast()` will warn even before score()\ntests/testthat/test-class-forecast-binary.R:80:  only_nas <- suppressWarnings(\ntests/testthat/test-class-forecast-binary.R:81:    copy(example_binary)[, predicted := NA_real_]\ntests/testthat/test-class-forecast-binary.R:82:  )\ntests/testthat/test-class-forecast-binary.R:83:  expect_error(\ntests/testthat/test-class-forecast-binary.R:84:    score(only_nas),\ntests/testthat/test-class-forecast-binary.R:85:    \"After removing rows with NA values in the data, no forecasts are left.\"\ntests/testthat/test-class-forecast-binary.R:86:  )\ntests/testthat/test-class-forecast-binary.R:87:})\ntests/testthat/test-class-forecast-binary.R:88:\ntests/testthat/test-class-forecast-binary.R:89:test_that(\"score() gives same result for binary as regular function\", {\ntests/testthat/test-class-forecast-binary.R:90:  manual_eval <- brier_score(\ntests/testthat/test-class-forecast-binary.R:91:    factor(example_binary$observed),\ntests/testthat/test-class-forecast-binary.R:92:    example_binary$predicted\ntests/testthat/test-class-forecast-binary.R:93:  )\ntests/testthat/test-class-forecast-binary.R:94:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-binary.R:95:    scores_binary$brier_score, manual_eval[!is.na(manual_eval)]\ntests/testthat/test-class-forecast-binary.R:96:  )\ntests/testthat/test-class-forecast-binary.R:97:})\ntests/testthat/test-class-forecast-binary.R:98:\ntests/testthat/test-class-forecast-binary.R:99:test_that(\ntests/testthat/test-class-forecast-binary.R:100:  \"passing additional functions to score binary works handles them\",\ntests/testthat/test-class-forecast-binary.R:101:  {\ntests/testthat/test-class-forecast-binary.R:102:    test_fun <- function(x, y, ...) {\ntests/testthat/test-class-forecast-binary.R:103:      if (hasArg(\"test\")) {\ntests/testthat/test-class-forecast-binary.R:104:        message(\"test argument found\")\ntests/testthat/test-class-forecast-binary.R:105:      }\ntests/testthat/test-class-forecast-binary.R:106:      return(y)\ntests/testthat/test-class-forecast-binary.R:107:    }\ntests/testthat/test-class-forecast-binary.R:108:\ntests/testthat/test-class-forecast-binary.R:109:    df <- as_forecast_binary(\ntests/testthat/test-class-forecast-binary.R:110:      example_binary[model == \"EuroCOVIDhub-ensemble\" &\ntests/testthat/test-class-forecast-binary.R:111:                       target_type == \"Cases\" & location == \"DE\"]\ntests/testthat/test-class-forecast-binary.R:112:    )\ntests/testthat/test-class-forecast-binary.R:113:\ntests/testthat/test-class-forecast-binary.R:114:    # passing a simple function works\ntests/testthat/test-class-forecast-binary.R:115:    expect_identical(\ntests/testthat/test-class-forecast-binary.R:116:      score(df,\ntests/testthat/test-class-forecast-binary.R:117:        metrics = list(identity = function(x, y) {\ntests/testthat/test-class-forecast-binary.R:118:          return(y)\ntests/testthat/test-class-forecast-binary.R:119:        })\ntests/testthat/test-class-forecast-binary.R:120:      )$identity,\ntests/testthat/test-class-forecast-binary.R:121:      df$predicted\ntests/testthat/test-class-forecast-binary.R:122:    )\ntests/testthat/test-class-forecast-binary.R:123:  }\ntests/testthat/test-class-forecast-binary.R:124:)\ntests/testthat/test-class-forecast-binary.R:125:\ntests/testthat/test-class-forecast-binary.R:126:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:127:# get_metrics.forecast_binary() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-binary.R:128:# ==============================================================================\ntests/testthat/test-class-forecast-binary.R:129:\ntests/testthat/test-class-forecast-binary.R:130:test_that(\"get_metrics.forecast_binary() works as expected\", {\ntests/testthat/test-class-forecast-binary.R:131:  expect_type(\ntests/testthat/test-class-forecast-binary.R:132:    get_metrics(example_binary), \"list\"\ntests/testthat/test-class-forecast-binary.R:133:  )\ntests/testthat/test-class-forecast-binary.R:134:})\ntests/testthat/test-metrics-interval-range.R:1:observed <- rnorm(30, mean = 1:30)\ntests/testthat/test-metrics-interval-range.R:2:interval_range <- rep(90, 30)\ntests/testthat/test-metrics-interval-range.R:3:alpha <- (100 - interval_range) / 100\ntests/testthat/test-metrics-interval-range.R:4:lower <- qnorm(alpha / 2, rnorm(30, mean = 1:30))\ntests/testthat/test-metrics-interval-range.R:5:upper <- qnorm((1 - alpha / 2), rnorm(30, mean = 11:40))\ntests/testthat/test-metrics-interval-range.R:6:\ntests/testthat/test-metrics-interval-range.R:7:\ntests/testthat/test-metrics-interval-range.R:8:# ==============================================================================\ntests/testthat/test-metrics-interval-range.R:9:# assert_input_interval() # nolint: commented_code_linter\ntests/testthat/test-metrics-interval-range.R:10:# ==============================================================================\ntests/testthat/test-metrics-interval-range.R:11:test_that(\"assert_input_interval() works as expected\", {\ntests/testthat/test-metrics-interval-range.R:12:  expect_no_condition(\ntests/testthat/test-metrics-interval-range.R:13:    assert_input_interval(observed, lower, upper, interval_range)\ntests/testthat/test-metrics-interval-range.R:14:  )\ntests/testthat/test-metrics-interval-range.R:15:\ntests/testthat/test-metrics-interval-range.R:16:  # expect error if upper < lower\ntests/testthat/test-metrics-interval-range.R:17:  expect_error(\ntests/testthat/test-metrics-interval-range.R:18:    assert_input_interval(observed, upper, lower, interval_range),\ntests/testthat/test-metrics-interval-range.R:19:    \"All values in `upper` need to be greater than or equal to the corresponding values in `lower`\"\ntests/testthat/test-metrics-interval-range.R:20:  )\ntests/testthat/test-metrics-interval-range.R:21:\ntests/testthat/test-metrics-interval-range.R:22:  # expect warning if interval range is < 1\ntests/testthat/test-metrics-interval-range.R:23:  expect_warning(\ntests/testthat/test-metrics-interval-range.R:24:    assert_input_interval(observed, lower, upper, 0.5),\ntests/testthat/test-metrics-interval-range.R:25:    \"Found interval ranges between 0 and 1. Are you sure that's right?\"\ntests/testthat/test-metrics-interval-range.R:26:  )\ntests/testthat/test-metrics-interval-range.R:27:})\ntests/testthat/test-metrics-interval-range.R:28:\ntests/testthat/test-metrics-interval-range.R:29:\ntests/testthat/test-metrics-interval-range.R:30:test_that(\"check_input_interval() works as expected\", {\ntests/testthat/test-metrics-interval-range.R:31:  expect_no_condition(\ntests/testthat/test-metrics-interval-range.R:32:    check_input_interval(observed, lower, upper, interval_range)\ntests/testthat/test-metrics-interval-range.R:33:  )\ntests/testthat/test-metrics-interval-range.R:34:  # expect message return if upper < lower\ntests/testthat/test-metrics-interval-range.R:35:  expect_match(\ntests/testthat/test-metrics-interval-range.R:36:    check_input_interval(observed, upper, lower, interval_range),\ntests/testthat/test-metrics-interval-range.R:37:    regexp = \"All values in `upper` need to be greater than or equal\"\ntests/testthat/test-metrics-interval-range.R:38:  )\ntests/testthat/test-metrics-interval-range.R:39:})\ntests/testthat/test-helper-quantile-interval-range.R:1:# ==============================================================================\ntests/testthat/test-helper-quantile-interval-range.R:2:# quantile_to_interval() # nolint: commented_code_linter\ntests/testthat/test-helper-quantile-interval-range.R:3:# ==============================================================================\ntests/testthat/test-helper-quantile-interval-range.R:4:\ntests/testthat/test-helper-quantile-interval-range.R:5:test_that(\"quantile_to_interval_dataframe() works\", {\ntests/testthat/test-helper-quantile-interval-range.R:6:  quantile <- data.frame(\ntests/testthat/test-helper-quantile-interval-range.R:7:    date = as.Date(\"2020-01-01\") + 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:8:    model = \"model1\",\ntests/testthat/test-helper-quantile-interval-range.R:9:    observed = 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:10:    predicted = c(2:11, 4:13),\ntests/testthat/test-helper-quantile-interval-range.R:11:    quantile_level = rep(c(0.25, 0.75), each = 10),\ntests/testthat/test-helper-quantile-interval-range.R:12:    stringsAsFactors = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:13:  )\ntests/testthat/test-helper-quantile-interval-range.R:14:  long <- data.frame(\ntests/testthat/test-helper-quantile-interval-range.R:15:    date = as.Date(\"2020-01-01\") + 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:16:    model = \"model1\",\ntests/testthat/test-helper-quantile-interval-range.R:17:    observed = 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:18:    predicted = c(2:11, 4:13),\ntests/testthat/test-helper-quantile-interval-range.R:19:    interval_range = 50,\ntests/testthat/test-helper-quantile-interval-range.R:20:    boundary = rep(c(\"lower\", \"upper\"), each = 10),\ntests/testthat/test-helper-quantile-interval-range.R:21:    stringsAsFactors = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:22:  )\ntests/testthat/test-helper-quantile-interval-range.R:23:  long2 <- as.data.frame(quantile_to_interval(\ntests/testthat/test-helper-quantile-interval-range.R:24:    quantile,\ntests/testthat/test-helper-quantile-interval-range.R:25:    keep_quantile_col = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:26:  ))\ntests/testthat/test-helper-quantile-interval-range.R:27:  data.table::setcolorder(long2, names(long))\ntests/testthat/test-helper-quantile-interval-range.R:28:  # for some reason this is needed to pass the unit tests on gh actions\ntests/testthat/test-helper-quantile-interval-range.R:29:  long2$boundary <- as.character(long2$boundary)\ntests/testthat/test-helper-quantile-interval-range.R:30:  long$boundary <- as.character(long$boundary)\ntests/testthat/test-helper-quantile-interval-range.R:31:  expect_identical(long, as.data.frame(long2))\ntests/testthat/test-helper-quantile-interval-range.R:32:\ntests/testthat/test-helper-quantile-interval-range.R:33:  # check that it handles NA values\ntests/testthat/test-helper-quantile-interval-range.R:34:  setDT(quantile)\ntests/testthat/test-helper-quantile-interval-range.R:35:  quantile[c(1, 3, 11, 13), c(\"observed\", \"predicted\", \"quantile_level\") := NA]\ntests/testthat/test-helper-quantile-interval-range.R:36:  # in this instance, a problem appears because there is an NA value both\ntests/testthat/test-helper-quantile-interval-range.R:37:  # for the upper and lower bound.\ntests/testthat/test-helper-quantile-interval-range.R:38:\ntests/testthat/test-helper-quantile-interval-range.R:39:  # the data.table behavior differs before/after v1.16.0\ntests/testthat/test-helper-quantile-interval-range.R:40:  #  - before, it's a 'message'\ntests/testthat/test-helper-quantile-interval-range.R:41:  #  - after, it's a 'warning'\ntests/testthat/test-helper-quantile-interval-range.R:42:  #  - the conditionMessage() also differs\ntests/testthat/test-helper-quantile-interval-range.R:43:  expected_condition <- tryCatch(\ntests/testthat/test-helper-quantile-interval-range.R:44:    dcast(data.table(a = c(1, 1), b = 2, c = 3), a ~ b, value.var = \"c\"),\ntests/testthat/test-helper-quantile-interval-range.R:45:    condition = identity\ntests/testthat/test-helper-quantile-interval-range.R:46:  )\ntests/testthat/test-helper-quantile-interval-range.R:47:  expect_condition(\ntests/testthat/test-helper-quantile-interval-range.R:48:    quantile_to_interval(\ntests/testthat/test-helper-quantile-interval-range.R:49:      quantile,\ntests/testthat/test-helper-quantile-interval-range.R:50:      keep_quantile_col = FALSE,\ntests/testthat/test-helper-quantile-interval-range.R:51:      format = \"wide\"\ntests/testthat/test-helper-quantile-interval-range.R:52:    ),\ntests/testthat/test-helper-quantile-interval-range.R:53:    class = class(expected_condition)[1L], # testthat 3e requires exactly one class\ntests/testthat/test-helper-quantile-interval-range.R:54:    regexp = \"[Aa]ggregate.*default.*length\"\ntests/testthat/test-helper-quantile-interval-range.R:55:  )\ntests/testthat/test-helper-quantile-interval-range.R:56:  quantile <- quantile[-c(1, 3), ]\ntests/testthat/test-helper-quantile-interval-range.R:57:  wide2 <- scoringutils:::quantile_to_interval( # nolint: undesirable_operator_linter\ntests/testthat/test-helper-quantile-interval-range.R:58:    quantile,\ntests/testthat/test-helper-quantile-interval-range.R:59:    keep_quantile_col = FALSE,\ntests/testthat/test-helper-quantile-interval-range.R:60:    format = \"wide\"\ntests/testthat/test-helper-quantile-interval-range.R:61:  )\ntests/testthat/test-helper-quantile-interval-range.R:62:  expect_identical(nrow(wide2), 10L)\ntests/testthat/test-helper-quantile-interval-range.R:63:  expect_false((\"NA\") %in% colnames(wide2))\ntests/testthat/test-helper-quantile-interval-range.R:64:  expect_equal(sum(wide2$lower, na.rm = TRUE), 59) # nolint: expect_identical_linter\ntests/testthat/test-helper-quantile-interval-range.R:65:})\ntests/testthat/test-helper-quantile-interval-range.R:66:\ntests/testthat/test-helper-quantile-interval-range.R:67:\ntests/testthat/test-helper-quantile-interval-range.R:68:test_that(\"sample_to_range_long works\", {\ntests/testthat/test-helper-quantile-interval-range.R:69:  samples <- data.frame(\ntests/testthat/test-helper-quantile-interval-range.R:70:    date = as.Date(\"2020-01-01\") + 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:71:    model = \"model1\",\ntests/testthat/test-helper-quantile-interval-range.R:72:    observed = 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:73:    predicted = c(rep(0, 10), 2:11, 3:12, 4:13, rep(100, 10)),\ntests/testthat/test-helper-quantile-interval-range.R:74:    sample_id = rep(1:5, each = 10),\ntests/testthat/test-helper-quantile-interval-range.R:75:    stringsAsFactors = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:76:  )\ntests/testthat/test-helper-quantile-interval-range.R:77:\ntests/testthat/test-helper-quantile-interval-range.R:78:  long <- data.frame(\ntests/testthat/test-helper-quantile-interval-range.R:79:    date = as.Date(\"2020-01-01\") + 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:80:    model = \"model1\",\ntests/testthat/test-helper-quantile-interval-range.R:81:    observed = 1:10,\ntests/testthat/test-helper-quantile-interval-range.R:82:    predicted = c(2:11, 4:13),\ntests/testthat/test-helper-quantile-interval-range.R:83:    interval_range = 50,\ntests/testthat/test-helper-quantile-interval-range.R:84:    boundary = rep(c(\"lower\", \"upper\"), each = 10),\ntests/testthat/test-helper-quantile-interval-range.R:85:    stringsAsFactors = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:86:  )\ntests/testthat/test-helper-quantile-interval-range.R:87:\ntests/testthat/test-helper-quantile-interval-range.R:88:  long2 <- scoringutils:::sample_to_interval_long(as_forecast_sample(samples), # nolint: undesirable_operator_linter\ntests/testthat/test-helper-quantile-interval-range.R:89:    interval_range = 50,\ntests/testthat/test-helper-quantile-interval-range.R:90:    keep_quantile_col = FALSE\ntests/testthat/test-helper-quantile-interval-range.R:91:  )\ntests/testthat/test-helper-quantile-interval-range.R:92:  long2 <- long2[order(model, boundary, date)]\ntests/testthat/test-helper-quantile-interval-range.R:93:  data.table::setcolorder(long2, names(long))\ntests/testthat/test-helper-quantile-interval-range.R:94:\ntests/testthat/test-helper-quantile-interval-range.R:95:  # for some reason this is needed to pass the unit tests on gh actions\ntests/testthat/test-helper-quantile-interval-range.R:96:  long2$boundary <- as.character(long2$boundary)\ntests/testthat/test-helper-quantile-interval-range.R:97:  long$boundary <- as.character(long$boundary)\ntests/testthat/test-helper-quantile-interval-range.R:98:\ntests/testthat/test-helper-quantile-interval-range.R:99:  expect_equal(long, as.data.frame(long2)) # nolint: expect_identical_linter\ntests/testthat/test-helper-quantile-interval-range.R:100:})\ntests/testthat/test-helper-quantile-interval-range.R:101:\ntests/testthat/test-helper-quantile-interval-range.R:102:test_that(\"quantile_to_range works - scalar and vector case\", {\ntests/testthat/test-helper-quantile-interval-range.R:103:  predicted <- 9:1\ntests/testthat/test-helper-quantile-interval-range.R:104:  quantile <- rev(seq(0.1, 0.9, 0.1))\ntests/testthat/test-helper-quantile-interval-range.R:105:  observed <- 5\ntests/testthat/test-helper-quantile-interval-range.R:106:\ntests/testthat/test-helper-quantile-interval-range.R:107:  # check output is produced\ntests/testthat/test-helper-quantile-interval-range.R:108:  out1 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:109:  expect_snapshot(out1)\ntests/testthat/test-helper-quantile-interval-range.R:110:\ntests/testthat/test-helper-quantile-interval-range.R:111:  # check order of predictions doesn't matter\ntests/testthat/test-helper-quantile-interval-range.R:112:  predicted <- 1:9\ntests/testthat/test-helper-quantile-interval-range.R:113:  quantile <- seq(0.1, 0.9, 0.1)\ntests/testthat/test-helper-quantile-interval-range.R:114:  out2 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:115:  expect_identical(out1, out2)\ntests/testthat/test-helper-quantile-interval-range.R:116:\ntests/testthat/test-helper-quantile-interval-range.R:117:  # check error if observed is a vector and predicted is a vector as well\ntests/testthat/test-helper-quantile-interval-range.R:118:  expect_error(\ntests/testthat/test-helper-quantile-interval-range.R:119:    quantile_to_interval(\ntests/testthat/test-helper-quantile-interval-range.R:120:      observed = c(1, 2), predicted = c(1, 2), quantile_level = c(0.1, 0.9)\ntests/testthat/test-helper-quantile-interval-range.R:121:    ),\ntests/testthat/test-helper-quantile-interval-range.R:122:    \"Assertion on 'predicted' failed: Must be of type 'matrix', not 'double'.\"\ntests/testthat/test-helper-quantile-interval-range.R:123:  )\ntests/testthat/test-helper-quantile-interval-range.R:124:\ntests/testthat/test-helper-quantile-interval-range.R:125:  # check NA values are handled gracefully - there should just be NA in the output\ntests/testthat/test-helper-quantile-interval-range.R:126:  predicted <- c(1:8, NA)\ntests/testthat/test-helper-quantile-interval-range.R:127:  quantile <- seq(0.1, 0.9, 0.1)\ntests/testthat/test-helper-quantile-interval-range.R:128:  observed <- 5\ntests/testthat/test-helper-quantile-interval-range.R:129:  out3 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:130:  expect_snapshot(out3)\ntests/testthat/test-helper-quantile-interval-range.R:131:\ntests/testthat/test-helper-quantile-interval-range.R:132:  # check non-symmetrical intervals are handled gracefully\ntests/testthat/test-helper-quantile-interval-range.R:133:  # result should be newly introduced ranges where one value is NA\ntests/testthat/test-helper-quantile-interval-range.R:134:  predicted <- 1:9\ntests/testthat/test-helper-quantile-interval-range.R:135:  quantile <- c(seq(0.1, 0.8, 0.1), 0.95)\ntests/testthat/test-helper-quantile-interval-range.R:136:  observed <- 5\ntests/testthat/test-helper-quantile-interval-range.R:137:  out4 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:138:  expect_snapshot(out4)\ntests/testthat/test-helper-quantile-interval-range.R:139:\ntests/testthat/test-helper-quantile-interval-range.R:140:  # check function works without a median\ntests/testthat/test-helper-quantile-interval-range.R:141:  predicted <- 1:8\ntests/testthat/test-helper-quantile-interval-range.R:142:  quantile <- c(seq(0.1, 0.4, 0.1), seq(0.6, 0.9, 0.1))\ntests/testthat/test-helper-quantile-interval-range.R:143:  observed <- 5\ntests/testthat/test-helper-quantile-interval-range.R:144:  expect_no_condition(\ntests/testthat/test-helper-quantile-interval-range.R:145:    quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:146:  )\ntests/testthat/test-helper-quantile-interval-range.R:147:\ntests/testthat/test-helper-quantile-interval-range.R:148:  # check a one-dimensional matrix works fine\ntests/testthat/test-helper-quantile-interval-range.R:149:  predicted <- matrix(1:9, nrow = 1)\ntests/testthat/test-helper-quantile-interval-range.R:150:  quantile <- seq(0.1, 0.9, 0.1)\ntests/testthat/test-helper-quantile-interval-range.R:151:  expect_no_condition(\ntests/testthat/test-helper-quantile-interval-range.R:152:    quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:153:  )\ntests/testthat/test-helper-quantile-interval-range.R:154:})\ntests/testthat/test-helper-quantile-interval-range.R:155:\ntests/testthat/test-helper-quantile-interval-range.R:156:test_that(\"quantile_to_range works - matrix case\", {\ntests/testthat/test-helper-quantile-interval-range.R:157:  n <- 5\ntests/testthat/test-helper-quantile-interval-range.R:158:  N <- 9\ntests/testthat/test-helper-quantile-interval-range.R:159:  predicted <- matrix(1:45, nrow = n, ncol = N)\ntests/testthat/test-helper-quantile-interval-range.R:160:  quantile <- seq(0.1, 0.9, 0.1)\ntests/testthat/test-helper-quantile-interval-range.R:161:  observed <- seq(21, 25, 1)\ntests/testthat/test-helper-quantile-interval-range.R:162:\ntests/testthat/test-helper-quantile-interval-range.R:163:  # check output is produced\ntests/testthat/test-helper-quantile-interval-range.R:164:  out1 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:165:  expect_snapshot(out1)\ntests/testthat/test-helper-quantile-interval-range.R:166:\ntests/testthat/test-helper-quantile-interval-range.R:167:  # check order of predictions doesn't matter\ntests/testthat/test-helper-quantile-interval-range.R:168:  predicted <- matrix(\ntests/testthat/test-helper-quantile-interval-range.R:169:    c(41:45, 36:40, 31:35, 26:30, 21:25, 16:20, 11:15, 6:10, 1:5),\ntests/testthat/test-helper-quantile-interval-range.R:170:    nrow = n,\ntests/testthat/test-helper-quantile-interval-range.R:171:    ncol = N\ntests/testthat/test-helper-quantile-interval-range.R:172:  )\ntests/testthat/test-helper-quantile-interval-range.R:173:  quantile <- rev(seq(0.1, 0.9, 0.1))\ntests/testthat/test-helper-quantile-interval-range.R:174:  out2 <- quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:175:  expect_identical(out1, out2)\ntests/testthat/test-helper-quantile-interval-range.R:176:\ntests/testthat/test-helper-quantile-interval-range.R:177:  # check NA values are fine\ntests/testthat/test-helper-quantile-interval-range.R:178:  predicted[1, 1] <- NA\ntests/testthat/test-helper-quantile-interval-range.R:179:  expect_no_condition(\ntests/testthat/test-helper-quantile-interval-range.R:180:    quantile_to_interval(observed, predicted, quantile)\ntests/testthat/test-helper-quantile-interval-range.R:181:  )\ntests/testthat/test-helper-quantile-interval-range.R:182:})\ntests/testthat/test-helper-quantile-interval-range.R:183:\ntests/testthat/test-helper-quantile-interval-range.R:184:\ntests/testthat/test-helper-quantile-interval-range.R:185:test_that(\"quantile_to_interval works - data.frame case\", {\ntests/testthat/test-helper-quantile-interval-range.R:186:  dt <- data.table(\ntests/testthat/test-helper-quantile-interval-range.R:187:    observed = 5,\ntests/testthat/test-helper-quantile-interval-range.R:188:    predicted = 1:9,\ntests/testthat/test-helper-quantile-interval-range.R:189:    quantile_level = seq(0.1, 0.9, 0.1)\ntests/testthat/test-helper-quantile-interval-range.R:190:  )\ntests/testthat/test-helper-quantile-interval-range.R:191:\ntests/testthat/test-helper-quantile-interval-range.R:192:  expect_no_condition(\ntests/testthat/test-helper-quantile-interval-range.R:193:    quantile_to_interval(dt)\ntests/testthat/test-helper-quantile-interval-range.R:194:  )\ntests/testthat/test-helper-quantile-interval-range.R:195:\ntests/testthat/test-helper-quantile-interval-range.R:196:  expect_no_condition(\ntests/testthat/test-helper-quantile-interval-range.R:197:    quantile_to_interval(dt, format = \"wide\")\ntests/testthat/test-helper-quantile-interval-range.R:198:  )\ntests/testthat/test-helper-quantile-interval-range.R:199:\ntests/testthat/test-helper-quantile-interval-range.R:200:  # check that the number of rows after transformation is equal to the number\ntests/testthat/test-helper-quantile-interval-range.R:201:  # of rows plus the number of medians added (as upper boundary of a 0%\ntests/testthat/test-helper-quantile-interval-range.R:202:  # prediction interval)\ntests/testthat/test-helper-quantile-interval-range.R:203:  ex <- example_quantile[!is.na(predicted)]\ntests/testthat/test-helper-quantile-interval-range.R:204:  n_preds <- nrow(ex)\ntests/testthat/test-helper-quantile-interval-range.R:205:  n_medians <- nrow(ex[quantile_level == 0.5])\ntests/testthat/test-helper-quantile-interval-range.R:206:  ex_interval <- quantile_to_interval(ex, keep_quantile_col = TRUE)\ntests/testthat/test-helper-quantile-interval-range.R:207:  expect_identical(\ntests/testthat/test-helper-quantile-interval-range.R:208:    nrow(ex_interval),\ntests/testthat/test-helper-quantile-interval-range.R:209:    n_preds + n_medians\ntests/testthat/test-helper-quantile-interval-range.R:210:  )\ntests/testthat/test-helper-quantile-interval-range.R:211:\ntests/testthat/test-helper-quantile-interval-range.R:212:  expect_identical(\ntests/testthat/test-helper-quantile-interval-range.R:213:    colnames(ex_interval),\ntests/testthat/test-helper-quantile-interval-range.R:214:    c(colnames(ex), \"boundary\", \"interval_range\")\ntests/testthat/test-helper-quantile-interval-range.R:215:  )\ntests/testthat/test-helper-quantile-interval-range.R:216:\ntests/testthat/test-helper-quantile-interval-range.R:217:  expect_error(\ntests/testthat/test-helper-quantile-interval-range.R:218:    quantile_to_interval(x = \"not working\"),\ntests/testthat/test-helper-quantile-interval-range.R:219:    \"Input must be either a data.frame or a numeric vector.\"\ntests/testthat/test-helper-quantile-interval-range.R:220:  )\ntests/testthat/test-helper-quantile-interval-range.R:221:})\ntests/testthat/test-plot_wis.R:1:sum_scores <- suppressMessages(\ntests/testthat/test-plot_wis.R:2:  summarise_scores(scores_quantile, by = c(\"model\", \"target_type\"))\ntests/testthat/test-plot_wis.R:3:)\ntests/testthat/test-plot_wis.R:4:\ntests/testthat/test-plot_wis.R:5:test_that(\"plot_wis() throws an error if WIS components are missing\", {\ntests/testthat/test-plot_wis.R:6:  ex_forecast <- as_forecast_quantile(na.omit(example_quantile))\ntests/testthat/test-plot_wis.R:7:  ex_score <- score(ex_forecast, metrics = get_metrics(ex_forecast, select = \"wis\"))\ntests/testthat/test-plot_wis.R:8:\ntests/testthat/test-plot_wis.R:9:  expect_error(\ntests/testthat/test-plot_wis.R:10:    plot_wis(ex_score),\ntests/testthat/test-plot_wis.R:11:    \"Columns 'overprediction', 'underprediction', 'dispersion' not found in data.\"\ntests/testthat/test-plot_wis.R:12:  )\ntests/testthat/test-plot_wis.R:13:})\ntests/testthat/test-plot_wis.R:14:\ntests/testthat/test-plot_wis.R:15:\ntests/testthat/test-plot_wis.R:16:test_that(\"plot_wis() works as expected with relative contributions\", {\ntests/testthat/test-plot_wis.R:17:  p <- plot_wis(sum_scores,\ntests/testthat/test-plot_wis.R:18:    x = \"model\",\ntests/testthat/test-plot_wis.R:19:    relative_contributions = TRUE\ntests/testthat/test-plot_wis.R:20:  ) +\ntests/testthat/test-plot_wis.R:21:    facet_wrap(~target_type)\ntests/testthat/test-plot_wis.R:22:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-plot_wis.R:23:  skip_on_cran()\ntests/testthat/test-plot_wis.R:24:  vdiffr::expect_doppelganger(\"plot_wis\", p)\ntests/testthat/test-plot_wis.R:25:})\ntests/testthat/test-plot_wis.R:26:\ntests/testthat/test-plot_wis.R:27:test_that(\"plot_wis() works as expected without relative contributions\", {\ntests/testthat/test-plot_wis.R:28:  p <- plot_wis(sum_scores,\ntests/testthat/test-plot_wis.R:29:    x = \"model\",\ntests/testthat/test-plot_wis.R:30:    relative_contributions = FALSE\ntests/testthat/test-plot_wis.R:31:  ) +\ntests/testthat/test-plot_wis.R:32:    facet_wrap(~target_type)\ntests/testthat/test-plot_wis.R:33:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-plot_wis.R:34:  skip_on_cran()\ntests/testthat/test-plot_wis.R:35:  vdiffr::expect_doppelganger(\"plot_wis_no_relative\", p)\ntests/testthat/test-plot_wis.R:36:})\ntests/testthat/test-plot_wis.R:37:\ntests/testthat/test-plot_wis.R:38:test_that(\"plot_wis() works as expected when flipped\", {\ntests/testthat/test-plot_wis.R:39:  p <- plot_wis(sum_scores,\ntests/testthat/test-plot_wis.R:40:    x = \"model\",\ntests/testthat/test-plot_wis.R:41:    relative_contributions = TRUE,\ntests/testthat/test-plot_wis.R:42:    flip = TRUE\ntests/testthat/test-plot_wis.R:43:  ) +\ntests/testthat/test-plot_wis.R:44:    facet_wrap(~target_type)\ntests/testthat/test-plot_wis.R:45:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-plot_wis.R:46:  skip_on_cran()\ntests/testthat/test-plot_wis.R:47:  vdiffr::expect_doppelganger(\"plot_wis_flip\", p)\ntests/testthat/test-plot_wis.R:48:})\ntests/testthat/test-class-forecast-multivariate-sample.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:2:# as_forecast_multivariate_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:4:test_that(\"as_forecast_multivariate_sample() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:5:  test <- na.omit(data.table::copy(example_sample_continuous))\ntests/testthat/test-class-forecast-multivariate-sample.R:6:  data.table::setnames(test,\ntests/testthat/test-class-forecast-multivariate-sample.R:7:    old = c(\"observed\", \"predicted\", \"sample_id\"),\ntests/testthat/test-class-forecast-multivariate-sample.R:8:    new = c(\"obs\", \"pred\", \"sample\")\ntests/testthat/test-class-forecast-multivariate-sample.R:9:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:10:  expect_no_condition(\ntests/testthat/test-class-forecast-multivariate-sample.R:11:    as_forecast_multivariate_sample(test,\ntests/testthat/test-class-forecast-multivariate-sample.R:12:      observed = \"obs\", predicted = \"pred\",\ntests/testthat/test-class-forecast-multivariate-sample.R:13:      forecast_unit = c(\ntests/testthat/test-class-forecast-multivariate-sample.R:14:        \"location\", \"model\", \"target_type\",\ntests/testthat/test-class-forecast-multivariate-sample.R:15:        \"target_end_date\", \"horizon\"\ntests/testthat/test-class-forecast-multivariate-sample.R:16:      ),\ntests/testthat/test-class-forecast-multivariate-sample.R:17:      joint_across = \"location\",\ntests/testthat/test-class-forecast-multivariate-sample.R:18:      sample_id = \"sample\"\ntests/testthat/test-class-forecast-multivariate-sample.R:19:    )\ntests/testthat/test-class-forecast-multivariate-sample.R:20:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:21:})\ntests/testthat/test-class-forecast-multivariate-sample.R:22:\ntests/testthat/test-class-forecast-multivariate-sample.R:23:test_that(\"as_forecast_multivariate_sample() creates expected structure\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:24:  test <- na.omit(data.table::copy(example_sample_continuous))\ntests/testthat/test-class-forecast-multivariate-sample.R:25:  data.table::setnames(test,\ntests/testthat/test-class-forecast-multivariate-sample.R:26:    old = c(\"observed\", \"predicted\", \"sample_id\"),\ntests/testthat/test-class-forecast-multivariate-sample.R:27:    new = c(\"obs\", \"pred\", \"sample\")\ntests/testthat/test-class-forecast-multivariate-sample.R:28:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:29:\ntests/testthat/test-class-forecast-multivariate-sample.R:30:  result <- as_forecast_multivariate_sample(test,\ntests/testthat/test-class-forecast-multivariate-sample.R:31:    observed = \"obs\", predicted = \"pred\",\ntests/testthat/test-class-forecast-multivariate-sample.R:32:    forecast_unit = c(\ntests/testthat/test-class-forecast-multivariate-sample.R:33:      \"location\", \"model\", \"target_type\",\ntests/testthat/test-class-forecast-multivariate-sample.R:34:      \"target_end_date\", \"horizon\"\ntests/testthat/test-class-forecast-multivariate-sample.R:35:    ),\ntests/testthat/test-class-forecast-multivariate-sample.R:36:    joint_across = \"location\",\ntests/testthat/test-class-forecast-multivariate-sample.R:37:    sample_id = \"sample\"\ntests/testthat/test-class-forecast-multivariate-sample.R:38:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:39:\ntests/testthat/test-class-forecast-multivariate-sample.R:40:  # Snapshot the print output to capture the structure\ntests/testthat/test-class-forecast-multivariate-sample.R:41:  expect_snapshot(print(result))\ntests/testthat/test-class-forecast-multivariate-sample.R:42:\ntests/testthat/test-class-forecast-multivariate-sample.R:43:  # Snapshot the class and structure\ntests/testthat/test-class-forecast-multivariate-sample.R:44:  expect_snapshot({\ntests/testthat/test-class-forecast-multivariate-sample.R:45:    cat(\"Class:\", class(result), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:46:    cat(\"Forecast type:\", scoringutils:::get_forecast_type(result), \"\\n\") # nolint: undesirable_operator_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:47:    cat(\"Forecast unit:\", toString(get_forecast_unit(result)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:48:    cat(\"Number of rows:\", nrow(result), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:49:    cat(\"Number of columns:\", ncol(result), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:50:    cat(\"Column names:\", toString(names(result)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:51:    cat(\"Number of unique groups:\", length(unique(result$.mv_group_id)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:52:  })\ntests/testthat/test-class-forecast-multivariate-sample.R:53:})\ntests/testthat/test-class-forecast-multivariate-sample.R:54:\ntests/testthat/test-class-forecast-multivariate-sample.R:55:\ntests/testthat/test-class-forecast-multivariate-sample.R:56:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:57:# is_forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:58:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:59:test_that(\"is_forecast_sample() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:60:  expect_true(is_forecast_sample_multivariate(example_multivariate_sample))\ntests/testthat/test-class-forecast-multivariate-sample.R:61:  expect_false(is_forecast_sample_multivariate(example_binary))\ntests/testthat/test-class-forecast-multivariate-sample.R:62:  expect_false(is_forecast_sample(example_multivariate_sample))\ntests/testthat/test-class-forecast-multivariate-sample.R:63:})\ntests/testthat/test-class-forecast-multivariate-sample.R:64:\ntests/testthat/test-class-forecast-multivariate-sample.R:65:\ntests/testthat/test-class-forecast-multivariate-sample.R:66:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:67:# get_metrics.forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:68:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:69:\ntests/testthat/test-class-forecast-multivariate-sample.R:70:test_that(\"get_metrics.forecast_sample_multivariate() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:71:  expect_type(\ntests/testthat/test-class-forecast-multivariate-sample.R:72:    get_metrics(example_multivariate_sample), \"list\"\ntests/testthat/test-class-forecast-multivariate-sample.R:73:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:74:})\ntests/testthat/test-class-forecast-multivariate-sample.R:75:\ntests/testthat/test-class-forecast-multivariate-sample.R:76:\ntests/testthat/test-class-forecast-multivariate-sample.R:77:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:78:# set_grouping() and get_grouping()\ntests/testthat/test-class-forecast-multivariate-sample.R:79:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:80:test_that(\"set_grouping() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:81:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:82:  grouping <- c(\"model\", \"target_type\", \"target_end_date\", \"horizon\")\ntests/testthat/test-class-forecast-multivariate-sample.R:83:\ntests/testthat/test-class-forecast-multivariate-sample.R:84:  # Test basic functionality\ntests/testthat/test-class-forecast-multivariate-sample.R:85:  result <- set_grouping(data, grouping)\ntests/testthat/test-class-forecast-multivariate-sample.R:86:  expect_true(\".mv_group_id\" %in% names(result))\ntests/testthat/test-class-forecast-multivariate-sample.R:87:  expect_type(result$.mv_group_id, \"integer\")\ntests/testthat/test-class-forecast-multivariate-sample.R:88:\ntests/testthat/test-class-forecast-multivariate-sample.R:89:  # Test that groups are consistent\ntests/testthat/test-class-forecast-multivariate-sample.R:90:  group_counts <- as.data.table(result)[, .N, by = .mv_group_id]\ntests/testthat/test-class-forecast-multivariate-sample.R:91:  expect_true(all(group_counts$N > 0))\ntests/testthat/test-class-forecast-multivariate-sample.R:92:})\ntests/testthat/test-class-forecast-multivariate-sample.R:93:\ntests/testthat/test-class-forecast-multivariate-sample.R:94:test_that(\"get_grouping() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:95:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:96:  grouping <- c(\"model\", \"target_type\", \"target_end_date\", \"horizon\")\ntests/testthat/test-class-forecast-multivariate-sample.R:97:  joint_across <- setdiff(get_forecast_unit(data), grouping)\ntests/testthat/test-class-forecast-multivariate-sample.R:98:  data <- scoringutils:::set_grouping(data, joint_across) # nolint: undesirable_operator_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:99:\ntests/testthat/test-class-forecast-multivariate-sample.R:100:  # Test that get_grouping returns the correct columns\ntests/testthat/test-class-forecast-multivariate-sample.R:101:  result <- get_grouping(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:102:  expect_type(result, \"character\")\ntests/testthat/test-class-forecast-multivariate-sample.R:103:  expect_true(all(grouping %in% result))\ntests/testthat/test-class-forecast-multivariate-sample.R:104:})\ntests/testthat/test-class-forecast-multivariate-sample.R:105:\ntests/testthat/test-class-forecast-multivariate-sample.R:106:test_that(\"get_grouping() falls back to forecast_unit when mv_group_id is missing\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:107:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:108:\ntests/testthat/test-class-forecast-multivariate-sample.R:109:  # Remove the mv_group_id column\ntests/testthat/test-class-forecast-multivariate-sample.R:110:  data_bad <- as.data.table(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:111:  data_bad[, .mv_group_id := NULL]\ntests/testthat/test-class-forecast-multivariate-sample.R:112:\ntests/testthat/test-class-forecast-multivariate-sample.R:113:  expect_error(\ntests/testthat/test-class-forecast-multivariate-sample.R:114:    get_grouping(data_bad),\ntests/testthat/test-class-forecast-multivariate-sample.R:115:    \"No column `.mv_group_id` found in the forecast object.\"\ntests/testthat/test-class-forecast-multivariate-sample.R:116:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:117:})\ntests/testthat/test-class-forecast-multivariate-sample.R:118:\ntests/testthat/test-class-forecast-multivariate-sample.R:119:test_that(\"set_grouping() preserves existing keys correctly\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:120:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:121:  grouping <- c(\"model\", \"target_type\", \"target_end_date\", \"horizon\")\ntests/testthat/test-class-forecast-multivariate-sample.R:122:\ntests/testthat/test-class-forecast-multivariate-sample.R:123:  # Test case 1: No existing keys\ntests/testthat/test-class-forecast-multivariate-sample.R:124:  data_no_keys <- copy(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:125:  nokeys <- NULL\ntests/testthat/test-class-forecast-multivariate-sample.R:126:  setkeyv(data_no_keys, nokeys) # Ensure no keys\ntests/testthat/test-class-forecast-multivariate-sample.R:127:  expect_null(key(data_no_keys))\ntests/testthat/test-class-forecast-multivariate-sample.R:128:\ntests/testthat/test-class-forecast-multivariate-sample.R:129:  result_no_keys <- set_grouping(data_no_keys, grouping)\ntests/testthat/test-class-forecast-multivariate-sample.R:130:  expect_null(key(result_no_keys)) # Should still have no keys\ntests/testthat/test-class-forecast-multivariate-sample.R:131:\ntests/testthat/test-class-forecast-multivariate-sample.R:132:  # Test case 2: With existing keys\ntests/testthat/test-class-forecast-multivariate-sample.R:133:  data_with_keys <- copy(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:134:  keys <- c(\"location\", \"model\")\ntests/testthat/test-class-forecast-multivariate-sample.R:135:  setkeyv(data_with_keys, keys) # Set some keys\ntests/testthat/test-class-forecast-multivariate-sample.R:136:  original_keys <- key(data_with_keys)\ntests/testthat/test-class-forecast-multivariate-sample.R:137:  expect_identical(original_keys, c(\"location\", \"model\"))\ntests/testthat/test-class-forecast-multivariate-sample.R:138:\ntests/testthat/test-class-forecast-multivariate-sample.R:139:  result_with_keys <- scoringutils:::set_grouping(data_with_keys, grouping) # nolint: undesirable_operator_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:140:  expect_identical(key(result_with_keys), original_keys) # Should preserve original keys\ntests/testthat/test-class-forecast-multivariate-sample.R:141:\ntests/testthat/test-class-forecast-multivariate-sample.R:142:  # Test case 3: Verify functionality still works with keys preserved\ntests/testthat/test-class-forecast-multivariate-sample.R:143:  expect_true(\".mv_group_id\" %in% names(result_with_keys))\ntests/testthat/test-class-forecast-multivariate-sample.R:144:  expect_type(result_with_keys$.mv_group_id, \"integer\")\ntests/testthat/test-class-forecast-multivariate-sample.R:145:\ntests/testthat/test-class-forecast-multivariate-sample.R:146:  # Test that groups are consistent\ntests/testthat/test-class-forecast-multivariate-sample.R:147:  group_counts <- as.data.table(result_with_keys)[, .N, by = .mv_group_id]\ntests/testthat/test-class-forecast-multivariate-sample.R:148:  expect_true(all(group_counts$N > 0))\ntests/testthat/test-class-forecast-multivariate-sample.R:149:})\ntests/testthat/test-class-forecast-multivariate-sample.R:150:\ntests/testthat/test-class-forecast-multivariate-sample.R:151:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:152:# score.forecast_sample_multivariate() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-multivariate-sample.R:153:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:154:test_that(\"score.forecast_sample_multivariate() works as expected\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:155:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:156:\ntests/testthat/test-class-forecast-multivariate-sample.R:157:  # Test basic scoring\ntests/testthat/test-class-forecast-multivariate-sample.R:158:  scores <- score(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:159:  expect_true(is.data.table(scores))\ntests/testthat/test-class-forecast-multivariate-sample.R:160:  expect_true(\"energy_score\" %in% names(scores))\ntests/testthat/test-class-forecast-multivariate-sample.R:161:\ntests/testthat/test-class-forecast-multivariate-sample.R:162:  # Test with specific metrics\ntests/testthat/test-class-forecast-multivariate-sample.R:163:  scores <- score(data, metrics = list(energy_score = energy_score_multivariate))\ntests/testthat/test-class-forecast-multivariate-sample.R:164:  expect_true(is.data.table(scores))\ntests/testthat/test-class-forecast-multivariate-sample.R:165:  expect_true(\"energy_score\" %in% names(scores))\ntests/testthat/test-class-forecast-multivariate-sample.R:166:\ntests/testthat/test-class-forecast-multivariate-sample.R:167:  # Test that scores are numeric\ntests/testthat/test-class-forecast-multivariate-sample.R:168:  expect_type(scores$energy_score, \"double\")\ntests/testthat/test-class-forecast-multivariate-sample.R:169:})\ntests/testthat/test-class-forecast-multivariate-sample.R:170:\ntests/testthat/test-class-forecast-multivariate-sample.R:171:test_that(\"score.forecast_sample_multivariate() creates expected output structure\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:172:  data <- example_multivariate_sample\ntests/testthat/test-class-forecast-multivariate-sample.R:173:\ntests/testthat/test-class-forecast-multivariate-sample.R:174:  # Test basic scoring and capture snapshot\ntests/testthat/test-class-forecast-multivariate-sample.R:175:  scores <- score(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:176:\ntests/testthat/test-class-forecast-multivariate-sample.R:177:  # Snapshot the print output to capture the structure\ntests/testthat/test-class-forecast-multivariate-sample.R:178:  expect_snapshot(print(scores))\ntests/testthat/test-class-forecast-multivariate-sample.R:179:\ntests/testthat/test-class-forecast-multivariate-sample.R:180:  # Snapshot the detailed structure\ntests/testthat/test-class-forecast-multivariate-sample.R:181:  expect_snapshot({\ntests/testthat/test-class-forecast-multivariate-sample.R:182:    cat(\"Class:\", class(scores), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:183:    cat(\"Number of rows:\", nrow(scores), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:184:    cat(\"Number of columns:\", ncol(scores), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:185:    cat(\"Column names:\", toString(names(scores)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:186:    cat(\"Energy score range:\", paste(range(scores$energy_score, na.rm = TRUE), collapse = \" to \"), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:187:    cat(\"Number of non-NA energy scores:\", sum(!is.na(scores$energy_score)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:188:    cat(\"Sample of energy scores:\", toString(head(scores$energy_score, 5)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:189:  })\ntests/testthat/test-class-forecast-multivariate-sample.R:190:\ntests/testthat/test-class-forecast-multivariate-sample.R:191:  # Test with specific metrics and capture snapshot\ntests/testthat/test-class-forecast-multivariate-sample.R:192:  scores_specific <- score(data, metrics = list(energy_score = energy_score_multivariate))\ntests/testthat/test-class-forecast-multivariate-sample.R:193:\ntests/testthat/test-class-forecast-multivariate-sample.R:194:  expect_snapshot({\ntests/testthat/test-class-forecast-multivariate-sample.R:195:    cat(\"=== Specific Metrics Test ===\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:196:    cat(\"Class:\", class(scores_specific), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:197:    cat(\"Number of rows:\", nrow(scores_specific), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:198:    cat(\"Number of columns:\", ncol(scores_specific), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:199:    cat(\"Column names:\", toString(names(scores_specific)), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:200:    cat(\"Energy score range:\", paste(range(scores_specific$energy_score, na.rm = TRUE), collapse = \" to \"), \"\\n\")\ntests/testthat/test-class-forecast-multivariate-sample.R:201:  })\ntests/testthat/test-class-forecast-multivariate-sample.R:202:})\ntests/testthat/test-class-forecast-multivariate-sample.R:203:\ntests/testthat/test-class-forecast-multivariate-sample.R:204:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:205:# Error cases for as_forecast_multivariate_sample()\ntests/testthat/test-class-forecast-multivariate-sample.R:206:# ==============================================================================\ntests/testthat/test-class-forecast-multivariate-sample.R:207:test_that(\"as_forecast_multivariate_sample() handles errors appropriately\", {\ntests/testthat/test-class-forecast-multivariate-sample.R:208:  data <- as.data.table(example_multivariate_sample)\ntests/testthat/test-class-forecast-multivariate-sample.R:209:\ntests/testthat/test-class-forecast-multivariate-sample.R:210:  # Test with missing required columns\ntests/testthat/test-class-forecast-multivariate-sample.R:211:  data_bad <- data[, !\"sample_id\"]\ntests/testthat/test-class-forecast-multivariate-sample.R:212:  expect_error(\ntests/testthat/test-class-forecast-multivariate-sample.R:213:    as_forecast_multivariate_sample(\ntests/testthat/test-class-forecast-multivariate-sample.R:214:      data_bad, joint_across = c(\"location\", \"location_name\")\ntests/testthat/test-class-forecast-multivariate-sample.R:215:    ),\ntests/testthat/test-class-forecast-multivariate-sample.R:216:    \"Assertion on 'forecast' failed: Column 'sample_id' not found in data.\"\ntests/testthat/test-class-forecast-multivariate-sample.R:217:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:218:\ntests/testthat/test-class-forecast-multivariate-sample.R:219:  # Test with inconsistent sample lengths within groups\ntests/testthat/test-class-forecast-multivariate-sample.R:220:  data_bad <- copy(data)\ntests/testthat/test-class-forecast-multivariate-sample.R:221:  data_bad <- rbind(data_bad[1000:1010], data_bad)\ntests/testthat/test-class-forecast-multivariate-sample.R:222:  expect_error(\ntests/testthat/test-class-forecast-multivariate-sample.R:223:    as_forecast_multivariate_sample(\ntests/testthat/test-class-forecast-multivariate-sample.R:224:      data_bad, joint_across = c(\"location\", \"location_name\")\ntests/testthat/test-class-forecast-multivariate-sample.R:225:    ),\ntests/testthat/test-class-forecast-multivariate-sample.R:226:    \"All univariate forecasts.*must have the same number of samples\"\ntests/testthat/test-class-forecast-multivariate-sample.R:227:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:228:\ntests/testthat/test-class-forecast-multivariate-sample.R:229:  # Test with inconsistent sample lengths after forecast object creation\ntests/testthat/test-class-forecast-multivariate-sample.R:230:  expect_warning(\ntests/testthat/test-class-forecast-multivariate-sample.R:231:    example_multivariate_sample[-(1000:1010), ],\ntests/testthat/test-class-forecast-multivariate-sample.R:232:    \"Found the following group with an inconsistent sample length\"\ntests/testthat/test-class-forecast-multivariate-sample.R:233:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:234:\ntests/testthat/test-class-forecast-multivariate-sample.R:235:  # Test with invalid grouping columns\ntests/testthat/test-class-forecast-multivariate-sample.R:236:  expect_error(\ntests/testthat/test-class-forecast-multivariate-sample.R:237:    as_forecast_multivariate_sample(data,\ntests/testthat/test-class-forecast-multivariate-sample.R:238:      joint_across = \"nonexistent_column\"\ntests/testthat/test-class-forecast-multivariate-sample.R:239:    ),\ntests/testthat/test-class-forecast-multivariate-sample.R:240:    \"Must be a subset of\"\ntests/testthat/test-class-forecast-multivariate-sample.R:241:  )\ntests/testthat/test-class-forecast-multivariate-sample.R:242:})\ntests/testthat/test-summarise_scores.R:1:test_that(\"summarise_scores() works as expected with by = forecast unit\", {\ntests/testthat/test-summarise_scores.R:2:  summarised_scores <- expect_no_condition(\ntests/testthat/test-summarise_scores.R:3:    summarise_scores(scores_quantile)\ntests/testthat/test-summarise_scores.R:4:  )\ntests/testthat/test-summarise_scores.R:5:  expect_s3_class(summarised_scores, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-summarise_scores.R:6:})\ntests/testthat/test-summarise_scores.R:7:\ntests/testthat/test-summarise_scores.R:8:test_that(\"summarise_scores() works as expected with by = forecast unit\", {\ntests/testthat/test-summarise_scores.R:9:  # the only effect of running summarise_scores with by = forecast unit is\ntests/testthat/test-summarise_scores.R:10:  # that coverage is now a numeric instead of a boolean\ntests/testthat/test-summarise_scores.R:11:  summarised_scores <- summarise_scores(\ntests/testthat/test-summarise_scores.R:12:    scores_quantile,\ntests/testthat/test-summarise_scores.R:13:    by = get_forecast_unit(scores_quantile)\ntests/testthat/test-summarise_scores.R:14:  )\ntests/testthat/test-summarise_scores.R:15:\ntests/testthat/test-summarise_scores.R:16:  expect_identical(dim(summarised_scores), dim(scores_quantile))\ntests/testthat/test-summarise_scores.R:17:  expect_equal(summarised_scores$wis, scores_quantile$wis) # nolint: expect_identical_linter\ntests/testthat/test-summarise_scores.R:18:\ntests/testthat/test-summarise_scores.R:19:  s2 <- summarise_scores(scores_quantile,\ntests/testthat/test-summarise_scores.R:20:    by = c(\ntests/testthat/test-summarise_scores.R:21:      \"location\", \"target_end_date\", \"target_type\",\ntests/testthat/test-summarise_scores.R:22:      \"location_name\", \"forecast_date\", \"model\",\ntests/testthat/test-summarise_scores.R:23:      \"horizon\"\ntests/testthat/test-summarise_scores.R:24:    )\ntests/testthat/test-summarise_scores.R:25:  )\ntests/testthat/test-summarise_scores.R:26:  expect_identical(dim(summarised_scores), dim(s2))\ntests/testthat/test-summarise_scores.R:27:})\ntests/testthat/test-summarise_scores.R:28:\ntests/testthat/test-summarise_scores.R:29:test_that(\"summarise_scores() handles wrong by argument well\", {\ntests/testthat/test-summarise_scores.R:30:  expect_error(\ntests/testthat/test-summarise_scores.R:31:    summarise_scores(scores_quantile, by = \"not_present\"),\ntests/testthat/test-summarise_scores.R:32:    \"Assertion on 'by' failed: Must be a subset of\",\ntests/testthat/test-summarise_scores.R:33:    fixed = TRUE\ntests/testthat/test-summarise_scores.R:34:  )\ntests/testthat/test-summarise_scores.R:35:\ntests/testthat/test-summarise_scores.R:36:  expect_error(\ntests/testthat/test-summarise_scores.R:37:    summarise_scores(scores_quantile, by = \"sample_id\"),\ntests/testthat/test-summarise_scores.R:38:    \"Assertion on 'by' failed: Must be a subset of\",\ntests/testthat/test-summarise_scores.R:39:    fixed = TRUE\ntests/testthat/test-summarise_scores.R:40:  )\ntests/testthat/test-summarise_scores.R:41:})\ntests/testthat/test-summarise_scores.R:42:\ntests/testthat/test-summarise_scores.R:43:test_that(\"summarise_scores() handles the `metrics` attribute correctly\", {\ntests/testthat/test-summarise_scores.R:44:  test <- data.table::copy(scores_quantile)\ntests/testthat/test-summarise_scores.R:45:  attr(test, \"metrics\") <- NULL\ntests/testthat/test-summarise_scores.R:46:\ntests/testthat/test-summarise_scores.R:47:  expect_error(\ntests/testthat/test-summarise_scores.R:48:    summarise_scores(test, by = \"model\"),\ntests/testthat/test-summarise_scores.R:49:    \"Input needs an attribute `metrics` with the names\"\ntests/testthat/test-summarise_scores.R:50:  )\ntests/testthat/test-summarise_scores.R:51:\ntests/testthat/test-summarise_scores.R:52:  # expect warning if a score name changed\ntests/testthat/test-summarise_scores.R:53:  test <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-summarise_scores.R:54:  data.table::setnames(test, old = \"crps\", new = \"crp2\")\ntests/testthat/test-summarise_scores.R:55:  expect_warning(\ntests/testthat/test-summarise_scores.R:56:    summarise_scores(test, by = \"model\"),\ntests/testthat/test-summarise_scores.R:57:    \"The following scores have been previously computed, but are no longer\"\ntests/testthat/test-summarise_scores.R:58:  )\ntests/testthat/test-summarise_scores.R:59:})\ntests/testthat/test-summarise_scores.R:60:\ntests/testthat/test-summarise_scores.R:61:test_that(\"summarise_scores() handles data.frames correctly\", {\ntests/testthat/test-summarise_scores.R:62:  test <- as.data.frame(scores_quantile)\ntests/testthat/test-summarise_scores.R:63:  expect_no_condition(\ntests/testthat/test-summarise_scores.R:64:    summarise_scores(test, by = \"model\")\ntests/testthat/test-summarise_scores.R:65:  )\ntests/testthat/test-summarise_scores.R:66:})\ntests/testthat/test-summarise_scores.R:67:\ntests/testthat/test-summarise_scores.R:68:test_that(\"summarise_scores() errors if `by = NULL\", {\ntests/testthat/test-summarise_scores.R:69:  expect_error(\ntests/testthat/test-summarise_scores.R:70:    summarise_scores(scores_quantile, by = NULL),\ntests/testthat/test-summarise_scores.R:71:    \"Assertion on 'by' failed: Must be a subset of\"\ntests/testthat/test-summarise_scores.R:72:  )\ntests/testthat/test-summarise_scores.R:73:})\ntests/testthat/test-pairwise_comparison.R:1:test_that(\"get_pairwise_comparisons() works\", {\ntests/testthat/test-pairwise_comparison.R:2:  # define some toy data using a format suitable for github.com/reichlab/covidHubUtils\ntests/testthat/test-pairwise_comparison.R:3:  test_truth <- data.frame(\ntests/testthat/test-pairwise_comparison.R:4:    model = rep(\"truth_source\", 30),\ntests/testthat/test-pairwise_comparison.R:5:    location = paste0(\"location_\", rep(1:3, each = 10)),\ntests/testthat/test-pairwise_comparison.R:6:    target_end_date = as.Date(\"2020-01-01\") + rep(1:10, times = 3),\ntests/testthat/test-pairwise_comparison.R:7:    target_variable = \"inc death\",\ntests/testthat/test-pairwise_comparison.R:8:    value = c(\ntests/testthat/test-pairwise_comparison.R:9:      sort(c(4, 1, 5, 5, 6)), sort(c(12, 4, 5, 12, 53)),\ntests/testthat/test-pairwise_comparison.R:10:      sort(c(8, 6, 3, 1, 46)), sort(c(6, 3, 5, 8, 5)),\ntests/testthat/test-pairwise_comparison.R:11:      sort(c(3, 1, 5, 7, 7)), sort(c(3, 2, 6, 8, 5))\ntests/testthat/test-pairwise_comparison.R:12:    ),\ntests/testthat/test-pairwise_comparison.R:13:    stringsAsFactors = FALSE\ntests/testthat/test-pairwise_comparison.R:14:  )\ntests/testthat/test-pairwise_comparison.R:15:\ntests/testthat/test-pairwise_comparison.R:16:  test_forecasts <- data.table::as.data.table(test_truth)\ntests/testthat/test-pairwise_comparison.R:17:  test_forecasts <- data.table::CJ(\ntests/testthat/test-pairwise_comparison.R:18:    model = \"m\",\ntests/testthat/test-pairwise_comparison.R:19:    model_sd = c(1, 2, 3, 4),\ntests/testthat/test-pairwise_comparison.R:20:    samples = 1:100\ntests/testthat/test-pairwise_comparison.R:21:  )\ntests/testthat/test-pairwise_comparison.R:22:  test_forecasts[, model := paste0(model, model_sd)]\ntests/testthat/test-pairwise_comparison.R:23:  test_forecasts <- merge(\ntests/testthat/test-pairwise_comparison.R:24:    test_forecasts[, dummy_id := 1],\ntests/testthat/test-pairwise_comparison.R:25:    data.table::as.data.table(test_truth)[, dummy_id := 1][, model := NULL],\ntests/testthat/test-pairwise_comparison.R:26:    by = \"dummy_id\", allow.cartesian = TRUE\ntests/testthat/test-pairwise_comparison.R:27:  )[, dummy_id := NULL]\ntests/testthat/test-pairwise_comparison.R:28:\ntests/testthat/test-pairwise_comparison.R:29:  set.seed(123)\ntests/testthat/test-pairwise_comparison.R:30:  test_forecasts[, value := sapply(value, function(x) {\ntests/testthat/test-pairwise_comparison.R:31:    abs(rnorm(n = 1, mean = x, sd = model_sd))\ntests/testthat/test-pairwise_comparison.R:32:  }),\ntests/testthat/test-pairwise_comparison.R:33:  by = .(model, target_end_date, location, target_variable)\ntests/testthat/test-pairwise_comparison.R:34:  ]\ntests/testthat/test-pairwise_comparison.R:35:\ntests/testthat/test-pairwise_comparison.R:36:  quantiles <- c(0.05, 0.25, 0.5, 0.75, 0.95)\ntests/testthat/test-pairwise_comparison.R:37:  test_forecasts <- test_forecasts[,\ntests/testthat/test-pairwise_comparison.R:38:    .(quantile_level = quantiles, value = quantile(value, quantiles)),\ntests/testthat/test-pairwise_comparison.R:39:    by = .(\ntests/testthat/test-pairwise_comparison.R:40:      model, location, target_end_date, target_variable\ntests/testthat/test-pairwise_comparison.R:41:    )\ntests/testthat/test-pairwise_comparison.R:42:  ]\ntests/testthat/test-pairwise_comparison.R:43:\ntests/testthat/test-pairwise_comparison.R:44:  # make a version of that data that conforms to scoringutils format\ntests/testthat/test-pairwise_comparison.R:45:  truth_formatted <- data.table::as.data.table(test_truth)\ntests/testthat/test-pairwise_comparison.R:46:  truth_formatted[, `:=`(model = NULL)]\ntests/testthat/test-pairwise_comparison.R:47:  data.table::setnames(truth_formatted, old = \"value\", new = \"observed\")\ntests/testthat/test-pairwise_comparison.R:48:  forecasts_formatted <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-pairwise_comparison.R:49:  data.table::setnames(forecasts_formatted, old = \"value\", new = \"predicted\")\ntests/testthat/test-pairwise_comparison.R:50:\ntests/testthat/test-pairwise_comparison.R:51:  data_formatted <- merge(\ntests/testthat/test-pairwise_comparison.R:52:    forecasts_formatted,\ntests/testthat/test-pairwise_comparison.R:53:    truth_formatted\ntests/testthat/test-pairwise_comparison.R:54:  ) |>\ntests/testthat/test-pairwise_comparison.R:55:    as_forecast_quantile()\ntests/testthat/test-pairwise_comparison.R:56:\ntests/testthat/test-pairwise_comparison.R:57:  # evaluate the toy forecasts, once with and once without a baseline model specified\ntests/testthat/test-pairwise_comparison.R:58:  eval <- score(data_formatted)\ntests/testthat/test-pairwise_comparison.R:59:\ntests/testthat/test-pairwise_comparison.R:60:  # check with relative skills\ntests/testthat/test-pairwise_comparison.R:61:  eval_without_rel_skill <- summarise_scores(\ntests/testthat/test-pairwise_comparison.R:62:    eval,\ntests/testthat/test-pairwise_comparison.R:63:    by = c(\ntests/testthat/test-pairwise_comparison.R:64:      \"model\", \"location\", \"target_end_date\",\ntests/testthat/test-pairwise_comparison.R:65:      \"target_variable\"\ntests/testthat/test-pairwise_comparison.R:66:    )\ntests/testthat/test-pairwise_comparison.R:67:  )\ntests/testthat/test-pairwise_comparison.R:68:  eval_without_baseline <- suppressMessages(\ntests/testthat/test-pairwise_comparison.R:69:    add_relative_skill(eval_without_rel_skill)\ntests/testthat/test-pairwise_comparison.R:70:  )\ntests/testthat/test-pairwise_comparison.R:71:\ntests/testthat/test-pairwise_comparison.R:72:  eval_with_baseline <- suppressMessages(\ntests/testthat/test-pairwise_comparison.R:73:    add_relative_skill(eval_without_rel_skill, baseline = \"m1\")\ntests/testthat/test-pairwise_comparison.R:74:  )\ntests/testthat/test-pairwise_comparison.R:75:\ntests/testthat/test-pairwise_comparison.R:76:\ntests/testthat/test-pairwise_comparison.R:77:  # extract the relative_skill values\ntests/testthat/test-pairwise_comparison.R:78:  relative_skills_without <- eval_without_baseline[, .(\ntests/testthat/test-pairwise_comparison.R:79:    model = unique(model),\ntests/testthat/test-pairwise_comparison.R:80:    relative_skill = unique(wis_relative_skill)\ntests/testthat/test-pairwise_comparison.R:81:  )]\ntests/testthat/test-pairwise_comparison.R:82:  relative_skills_with <- eval_with_baseline[, .(\ntests/testthat/test-pairwise_comparison.R:83:    model = unique(model),\ntests/testthat/test-pairwise_comparison.R:84:    relative_skill = unique(wis_scaled_relative_skill)\ntests/testthat/test-pairwise_comparison.R:85:  )]\ntests/testthat/test-pairwise_comparison.R:86:\ntests/testthat/test-pairwise_comparison.R:87:  # prepare scores for the code Johannes Bracher wrote\ntests/testthat/test-pairwise_comparison.R:88:  scores_johannes <- data.table::copy(eval_without_baseline) # doesn't matter which one\ntests/testthat/test-pairwise_comparison.R:89:  data.table::setnames(scores_johannes,\ntests/testthat/test-pairwise_comparison.R:90:    old = c(\"location\", \"target_end_date\", \"wis\"),\ntests/testthat/test-pairwise_comparison.R:91:    new = c(\"unit\", \"timezero\", \"wis\")\ntests/testthat/test-pairwise_comparison.R:92:  )\ntests/testthat/test-pairwise_comparison.R:93:\ntests/testthat/test-pairwise_comparison.R:94:\ntests/testthat/test-pairwise_comparison.R:95:  # -----------------------------------------------------------------------------#\ntests/testthat/test-pairwise_comparison.R:96:  ## rerun code from Johannes Bracher to see whether results agree\ntests/testthat/test-pairwise_comparison.R:97:  pairwise_comparison_jb <- function(scores, mx, my, subset = rep(TRUE, nrow(scores)),\ntests/testthat/test-pairwise_comparison.R:98:                                     permutation_test = FALSE) {\ntests/testthat/test-pairwise_comparison.R:99:    # apply subset:\ntests/testthat/test-pairwise_comparison.R:100:    scores <- scores[subset, ]\ntests/testthat/test-pairwise_comparison.R:101:\ntests/testthat/test-pairwise_comparison.R:102:    # subsets of available scores for both models:\ntests/testthat/test-pairwise_comparison.R:103:    subx <- subset(scores, model == mx)\ntests/testthat/test-pairwise_comparison.R:104:    suby <- subset(scores, model == my)\ntests/testthat/test-pairwise_comparison.R:105:\ntests/testthat/test-pairwise_comparison.R:106:    # merge together and restrict to overlap:\ntests/testthat/test-pairwise_comparison.R:107:    sub <- merge(subx, suby,\ntests/testthat/test-pairwise_comparison.R:108:      by = c(\"timezero\", \"unit\"),\ntests/testthat/test-pairwise_comparison.R:109:      all.x = FALSE, all.y = FALSE\ntests/testthat/test-pairwise_comparison.R:110:    )\ntests/testthat/test-pairwise_comparison.R:111:\ntests/testthat/test-pairwise_comparison.R:112:    # compute ratio:\ntests/testthat/test-pairwise_comparison.R:113:    ratio <- sum(sub$wis.x) / sum(sub$wis.y)\ntests/testthat/test-pairwise_comparison.R:114:\ntests/testthat/test-pairwise_comparison.R:115:    # perform permutation tests:\ntests/testthat/test-pairwise_comparison.R:116:    if (permutation_test) {\ntests/testthat/test-pairwise_comparison.R:117:      pval <- scoringutils:::permutation_test(sub$wis.x, sub$wis.y, # nolint: undesirable_operator_linter\ntests/testthat/test-pairwise_comparison.R:118:        n_permutation = 999,\ntests/testthat/test-pairwise_comparison.R:119:        comparison_mode = \"difference\"\ntests/testthat/test-pairwise_comparison.R:120:      )\ntests/testthat/test-pairwise_comparison.R:121:\ntests/testthat/test-pairwise_comparison.R:122:      # aggregate by forecast date:\ntests/testthat/test-pairwise_comparison.R:123:      sub_fcd <- aggregate(cbind(wis.x, wis.y) ~ timezero, data = sub, FUN = mean)\ntests/testthat/test-pairwise_comparison.R:124:      pval_fcd <- scoringutils:::permutation_test(sub_fcd$wis.x, sub_fcd$wis.y, # nolint: undesirable_operator_linter\ntests/testthat/test-pairwise_comparison.R:125:        n_permutation = 999\ntests/testthat/test-pairwise_comparison.R:126:      )\ntests/testthat/test-pairwise_comparison.R:127:    } else {\ntests/testthat/test-pairwise_comparison.R:128:      pval <- NULL\ntests/testthat/test-pairwise_comparison.R:129:      pval_fcd <- NULL\ntests/testthat/test-pairwise_comparison.R:130:    }\ntests/testthat/test-pairwise_comparison.R:131:\ntests/testthat/test-pairwise_comparison.R:132:    return(list(ratio = ratio, pval = pval, pval_fcd = pval_fcd, mx = mx, my = my))\ntests/testthat/test-pairwise_comparison.R:133:  }\ntests/testthat/test-pairwise_comparison.R:134:\ntests/testthat/test-pairwise_comparison.R:135:  models <- paste0(\"m\", 1:4)\ntests/testthat/test-pairwise_comparison.R:136:  # matrices to store:\ntests/testthat/test-pairwise_comparison.R:137:  results_ratio <- results_pval <- results_pval_fcd <- matrix(\ntests/testthat/test-pairwise_comparison.R:138:    ncol = length(models),\ntests/testthat/test-pairwise_comparison.R:139:    nrow = length(models),\ntests/testthat/test-pairwise_comparison.R:140:    dimnames = list(models, models)\ntests/testthat/test-pairwise_comparison.R:141:  )\ntests/testthat/test-pairwise_comparison.R:142:\ntests/testthat/test-pairwise_comparison.R:143:  set.seed(123) # set seed for permutation tests\ntests/testthat/test-pairwise_comparison.R:144:  for (mx in seq_along(models)) {\ntests/testthat/test-pairwise_comparison.R:145:    for (my in 1:mx) {\ntests/testthat/test-pairwise_comparison.R:146:      pwc <- pairwise_comparison_jb(\ntests/testthat/test-pairwise_comparison.R:147:        scores = scores_johannes, mx = models[mx], my = models[my],\ntests/testthat/test-pairwise_comparison.R:148:        permutation_test = TRUE\ntests/testthat/test-pairwise_comparison.R:149:      )\ntests/testthat/test-pairwise_comparison.R:150:      results_ratio[mx, my] <- pwc$ratio\ntests/testthat/test-pairwise_comparison.R:151:      results_ratio[my, mx] <- 1 / pwc$ratio\ntests/testthat/test-pairwise_comparison.R:152:      results_pval[mx, my] <-\ntests/testthat/test-pairwise_comparison.R:153:        results_pval[my, mx] <- pwc$pval\ntests/testthat/test-pairwise_comparison.R:154:      results_pval_fcd[mx, my] <-\ntests/testthat/test-pairwise_comparison.R:155:        results_pval_fcd[my, mx] <- pwc$pval_fcd\ntests/testthat/test-pairwise_comparison.R:156:    }\ntests/testthat/test-pairwise_comparison.R:157:  }\ntests/testthat/test-pairwise_comparison.R:158:  # -----------------------------------------------------------------------------#\ntests/testthat/test-pairwise_comparison.R:159:\ntests/testthat/test-pairwise_comparison.R:160:  # compare results without a baseline specified\ntests/testthat/test-pairwise_comparison.R:161:  geometric_mean_ratios <- exp(rowMeans(log(results_ratio), na.rm = TRUE))\ntests/testthat/test-pairwise_comparison.R:162:  names(geometric_mean_ratios) <- NULL\ntests/testthat/test-pairwise_comparison.R:163:  expect_equal(relative_skills_without$relative_skill, geometric_mean_ratios) # nolint: expect_identical_linter\ntests/testthat/test-pairwise_comparison.R:164:\ntests/testthat/test-pairwise_comparison.R:165:  # comparison with a baseline\ntests/testthat/test-pairwise_comparison.R:166:  ind_baseline <- which(rownames(results_ratio) == \"m1\")\ntests/testthat/test-pairwise_comparison.R:167:  geometric_mean_ratios <- exp(rowMeans(log(results_ratio[, -ind_baseline]), na.rm = TRUE))\ntests/testthat/test-pairwise_comparison.R:168:  ratios_baseline <- results_ratio[, \"m1\"]\ntests/testthat/test-pairwise_comparison.R:169:  ratios_scaled <- geometric_mean_ratios / geometric_mean_ratios[\"m1\"]\ntests/testthat/test-pairwise_comparison.R:170:\ntests/testthat/test-pairwise_comparison.R:171:  names(ratios_scaled) <- NULL\ntests/testthat/test-pairwise_comparison.R:172:  expect_equal(relative_skills_with$relative_skill, ratios_scaled) # nolint: expect_identical_linter\ntests/testthat/test-pairwise_comparison.R:173:\ntests/testthat/test-pairwise_comparison.R:174:\ntests/testthat/test-pairwise_comparison.R:175:  # scoringutils can also do pairwise comparisons for different subcategories\ntests/testthat/test-pairwise_comparison.R:176:  # comparison for a subset of the data vs. spliting by category within scoringutils\ntests/testthat/test-pairwise_comparison.R:177:  scores_johannes_subset <- scores_johannes[unit == \"location_3\"]\ntests/testthat/test-pairwise_comparison.R:178:  results_ratio <- results_pval <- results_pval_fcd <- matrix(\ntests/testthat/test-pairwise_comparison.R:179:    ncol = length(models),\ntests/testthat/test-pairwise_comparison.R:180:    nrow = length(models),\ntests/testthat/test-pairwise_comparison.R:181:    dimnames = list(models, models)\ntests/testthat/test-pairwise_comparison.R:182:  )\ntests/testthat/test-pairwise_comparison.R:183:\ntests/testthat/test-pairwise_comparison.R:184:  set.seed(123) # set seed for permutation tests\ntests/testthat/test-pairwise_comparison.R:185:  for (mx in seq_along(models)) {\ntests/testthat/test-pairwise_comparison.R:186:    for (my in 1:mx) {\ntests/testthat/test-pairwise_comparison.R:187:      pwc <- pairwise_comparison_jb(\ntests/testthat/test-pairwise_comparison.R:188:        scores = scores_johannes_subset, mx = models[mx], my = models[my],\ntests/testthat/test-pairwise_comparison.R:189:        permutation_test = TRUE\ntests/testthat/test-pairwise_comparison.R:190:      )\ntests/testthat/test-pairwise_comparison.R:191:      results_ratio[mx, my] <- pwc$ratio\ntests/testthat/test-pairwise_comparison.R:192:      results_ratio[my, mx] <- 1 / pwc$ratio\ntests/testthat/test-pairwise_comparison.R:193:      results_pval[mx, my] <-\ntests/testthat/test-pairwise_comparison.R:194:        results_pval[my, mx] <- pwc$pval\ntests/testthat/test-pairwise_comparison.R:195:      results_pval_fcd[mx, my] <-\ntests/testthat/test-pairwise_comparison.R:196:        results_pval_fcd[my, mx] <- pwc$pval_fcd\ntests/testthat/test-pairwise_comparison.R:197:    }\ntests/testthat/test-pairwise_comparison.R:198:  }\ntests/testthat/test-pairwise_comparison.R:199:  ind_baseline <- which(rownames(results_ratio) == \"m1\")\ntests/testthat/test-pairwise_comparison.R:200:  geometric_mean_ratios <- exp(rowMeans(log(results_ratio[, -ind_baseline]), na.rm = TRUE))\ntests/testthat/test-pairwise_comparison.R:201:  ratios_baseline <- results_ratio[, \"m1\"]\ntests/testthat/test-pairwise_comparison.R:202:  ratios_scaled <- geometric_mean_ratios / geometric_mean_ratios[\"m1\"]\ntests/testthat/test-pairwise_comparison.R:203:  names(ratios_scaled) <- NULL\ntests/testthat/test-pairwise_comparison.R:204:\ntests/testthat/test-pairwise_comparison.R:205:  eval <- score(data_formatted)\ntests/testthat/test-pairwise_comparison.R:206:  eval_summarised <- summarise_scores(eval, by = c(\"model\", \"location\"))\ntests/testthat/test-pairwise_comparison.R:207:  eval_with_baseline <- add_relative_skill(eval, by = \"location\", baseline = \"m1\")\ntests/testthat/test-pairwise_comparison.R:208:  eval_with_baseline <- summarise_scores(eval_with_baseline, by = c(\"model\", \"location\"))\ntests/testthat/test-pairwise_comparison.R:209:\ntests/testthat/test-pairwise_comparison.R:210:  relative_skills_with <- eval_with_baseline[\ntests/testthat/test-pairwise_comparison.R:211:    location == \"location_3\",\ntests/testthat/test-pairwise_comparison.R:212:    .(\ntests/testthat/test-pairwise_comparison.R:213:      model = unique(model),\ntests/testthat/test-pairwise_comparison.R:214:      relative_skill = unique(wis_scaled_relative_skill)\ntests/testthat/test-pairwise_comparison.R:215:    )\ntests/testthat/test-pairwise_comparison.R:216:  ]\ntests/testthat/test-pairwise_comparison.R:217:\ntests/testthat/test-pairwise_comparison.R:218:  expect_equal(relative_skills_with$relative_skill, ratios_scaled) # nolint: expect_identical_linter\ntests/testthat/test-pairwise_comparison.R:219:})\ntests/testthat/test-pairwise_comparison.R:220:\ntests/testthat/test-pairwise_comparison.R:221:test_that(\"get_pairwise_comparisons() work in score() with integer data\", {\ntests/testthat/test-pairwise_comparison.R:222:  eval <- suppressMessages(score(forecast = as_forecast_sample(example_sample_discrete)))\ntests/testthat/test-pairwise_comparison.R:223:  eval_summarised <- summarise_scores(eval, by = c(\"model\", \"target_type\"))\ntests/testthat/test-pairwise_comparison.R:224:  eval <- add_relative_skill(eval_summarised)\ntests/testthat/test-pairwise_comparison.R:225:  expect_true(\"crps_relative_skill\" %in% colnames(eval))\ntests/testthat/test-pairwise_comparison.R:226:})\ntests/testthat/test-pairwise_comparison.R:227:\ntests/testthat/test-pairwise_comparison.R:228:\ntests/testthat/test-pairwise_comparison.R:229:test_that(\"get_pairwise_comparisons() work in score() with binary data\", {\ntests/testthat/test-pairwise_comparison.R:230:  eval <- suppressMessages(score(forecast = as_forecast_binary(example_binary)))\ntests/testthat/test-pairwise_comparison.R:231:  eval_summarised <- summarise_scores(eval, by = c(\"model\", \"target_type\"))\ntests/testthat/test-pairwise_comparison.R:232:  eval <- add_relative_skill(eval_summarised)\ntests/testthat/test-pairwise_comparison.R:233:  expect_true(\"brier_score_relative_skill\" %in% colnames(eval))\ntests/testthat/test-pairwise_comparison.R:234:})\ntests/testthat/test-pairwise_comparison.R:235:\ntests/testthat/test-pairwise_comparison.R:236:\ntests/testthat/test-pairwise_comparison.R:237:# tests for pairwise comparison function ---------------------------------------\ntests/testthat/test-pairwise_comparison.R:238:\ntests/testthat/test-pairwise_comparison.R:239:test_that(\"get_pairwise_comparisons() works\", {\ntests/testthat/test-pairwise_comparison.R:240:  df <- data.frame(\ntests/testthat/test-pairwise_comparison.R:241:    model = rep(c(\"model1\", \"model2\", \"model3\"), each = 10),\ntests/testthat/test-pairwise_comparison.R:242:    date = as.Date(\"2020-01-01\") + rep(1:5, each = 2),\ntests/testthat/test-pairwise_comparison.R:243:    location = c(1, 2),\ntests/testthat/test-pairwise_comparison.R:244:    wis = (abs(rnorm(30))),\ntests/testthat/test-pairwise_comparison.R:245:    ae_median = (abs(rnorm(30))),\ntests/testthat/test-pairwise_comparison.R:246:    stringsAsFactors = FALSE\ntests/testthat/test-pairwise_comparison.R:247:  )\ntests/testthat/test-pairwise_comparison.R:248:  attr(df, \"metrics\") <- c(\"wis\", \"ae_median\")\ntests/testthat/test-pairwise_comparison.R:249:\ntests/testthat/test-pairwise_comparison.R:250:  res <- suppressMessages(get_pairwise_comparisons(df, baseline = \"model1\"))\ntests/testthat/test-pairwise_comparison.R:251:\ntests/testthat/test-pairwise_comparison.R:252:  colnames <- c(\ntests/testthat/test-pairwise_comparison.R:253:    \"model\", \"compare_against\", \"mean_scores_ratio\",\ntests/testthat/test-pairwise_comparison.R:254:    \"pval\", \"adj_pval\", \"wis_relative_skill\", \"wis_scaled_relative_skill\"\ntests/testthat/test-pairwise_comparison.R:255:  )\ntests/testthat/test-pairwise_comparison.R:256:\ntests/testthat/test-pairwise_comparison.R:257:  expect_true(all(colnames %in% colnames(res)))\ntests/testthat/test-pairwise_comparison.R:258:\ntests/testthat/test-pairwise_comparison.R:259:  # output class is as expected\ntests/testthat/test-pairwise_comparison.R:260:  expect_s3_class(res, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-pairwise_comparison.R:261:  expect_s3_class(\ntests/testthat/test-pairwise_comparison.R:262:    get_pairwise_comparisons(scores_quantile),\ntests/testthat/test-pairwise_comparison.R:263:    c(\"data.table\", \"data.frame\"),\ntests/testthat/test-pairwise_comparison.R:264:    exact = TRUE\ntests/testthat/test-pairwise_comparison.R:265:  )\ntests/testthat/test-pairwise_comparison.R:266:})\ntests/testthat/test-pairwise_comparison.R:267:\ntests/testthat/test-pairwise_comparison.R:268:\ntests/testthat/test-pairwise_comparison.R:269:test_that(\"get_pairwise_comparisons() and `add_relative_skill()` give same result\", {\ntests/testthat/test-pairwise_comparison.R:270:  eval <- scores_sample_continuous\ntests/testthat/test-pairwise_comparison.R:271:\ntests/testthat/test-pairwise_comparison.R:272:  pairwise <- get_pairwise_comparisons(eval,\ntests/testthat/test-pairwise_comparison.R:273:    compare = \"model\",\ntests/testthat/test-pairwise_comparison.R:274:    metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:275:  )\ntests/testthat/test-pairwise_comparison.R:276:\ntests/testthat/test-pairwise_comparison.R:277:  eval2 <- add_relative_skill(scores_sample_continuous, compare = \"model\")\ntests/testthat/test-pairwise_comparison.R:278:  eval2 <- summarise_scores(eval2, by = \"model\")\ntests/testthat/test-pairwise_comparison.R:279:\ntests/testthat/test-pairwise_comparison.R:280:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-pairwise_comparison.R:281:    sort(unique(pairwise$crps_relative_skill)), sort(eval2$crps_relative_skill)\ntests/testthat/test-pairwise_comparison.R:282:  )\ntests/testthat/test-pairwise_comparison.R:283:})\ntests/testthat/test-pairwise_comparison.R:284:\ntests/testthat/test-pairwise_comparison.R:285:test_that(\"get_pairwise_comparisons() realises when there is no baseline model\", {\ntests/testthat/test-pairwise_comparison.R:286:  expect_error(\ntests/testthat/test-pairwise_comparison.R:287:    get_pairwise_comparisons(scores_quantile, baseline = \"missing_model\"),\ntests/testthat/test-pairwise_comparison.R:288:    \"Assertion on 'baseline' failed: Must be a subset of\"\ntests/testthat/test-pairwise_comparison.R:289:  )\ntests/testthat/test-pairwise_comparison.R:290:})\ntests/testthat/test-pairwise_comparison.R:291:\ntests/testthat/test-pairwise_comparison.R:292:test_that(\"Basic input checks for `add_relative_skill() work\", {\ntests/testthat/test-pairwise_comparison.R:293:  eval <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-pairwise_comparison.R:294:\ntests/testthat/test-pairwise_comparison.R:295:  # check that model column + columns in 'by' + baseline model are present\ntests/testthat/test-pairwise_comparison.R:296:  expect_error(\ntests/testthat/test-pairwise_comparison.R:297:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:298:      eval,\ntests/testthat/test-pairwise_comparison.R:299:      compare = \"model\", by = \"missing\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:300:    ),\ntests/testthat/test-pairwise_comparison.R:301:    \"Not all columns specified in `by` are present:\" # nolint: nonportable_path_linter\ntests/testthat/test-pairwise_comparison.R:302:  )\ntests/testthat/test-pairwise_comparison.R:303:\ntests/testthat/test-pairwise_comparison.R:304:  # check that none of the columns in `by` are in `compare`\ntests/testthat/test-pairwise_comparison.R:305:  expect_error(\ntests/testthat/test-pairwise_comparison.R:306:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:307:      eval,\ntests/testthat/test-pairwise_comparison.R:308:      by = c(\"model\", \"target_type\"), metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:309:    ),\ntests/testthat/test-pairwise_comparison.R:310:    \"Must be disjunct from \\\\{'model'\\\\}\" # nolint: nonportable_path_linter\ntests/testthat/test-pairwise_comparison.R:311:  )\ntests/testthat/test-pairwise_comparison.R:312:\ntests/testthat/test-pairwise_comparison.R:313:  # error if baseline is not present\ntests/testthat/test-pairwise_comparison.R:314:  expect_error(\ntests/testthat/test-pairwise_comparison.R:315:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:316:      eval,\ntests/testthat/test-pairwise_comparison.R:317:      compare = \"model\", baseline = \"missing\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:318:    ),\ntests/testthat/test-pairwise_comparison.R:319:    \"Assertion on 'baseline' failed: Must be a subset of\"\ntests/testthat/test-pairwise_comparison.R:320:  )\ntests/testthat/test-pairwise_comparison.R:321:\ntests/testthat/test-pairwise_comparison.R:322:  # error if not enough models are present\ntests/testthat/test-pairwise_comparison.R:323:  eval_few <- eval[model %in% c(\"EuroCOVIDhub-ensemble\", \"EuroCOVIDhub-baseline\")]\ntests/testthat/test-pairwise_comparison.R:324:  expect_no_error(\ntests/testthat/test-pairwise_comparison.R:325:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:326:      eval_few,\ntests/testthat/test-pairwise_comparison.R:327:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:328:    )\ntests/testthat/test-pairwise_comparison.R:329:  )\ntests/testthat/test-pairwise_comparison.R:330:  expect_error(\ntests/testthat/test-pairwise_comparison.R:331:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:332:      eval_few,\ntests/testthat/test-pairwise_comparison.R:333:      compare = \"model\", baseline = \"EuroCOVIDhub-baseline\",\ntests/testthat/test-pairwise_comparison.R:334:      metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:335:    ),\ntests/testthat/test-pairwise_comparison.R:336:    \"More than one non-baseline model is needed to compute pairwise compairisons.\"\ntests/testthat/test-pairwise_comparison.R:337:  )\ntests/testthat/test-pairwise_comparison.R:338:\ntests/testthat/test-pairwise_comparison.R:339:  # error if no relative skill metric is found\ntests/testthat/test-pairwise_comparison.R:340:  expect_error(\ntests/testthat/test-pairwise_comparison.R:341:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:342:      eval,\ntests/testthat/test-pairwise_comparison.R:343:      compare = \"model\",\ntests/testthat/test-pairwise_comparison.R:344:      metric = \"missing\"\ntests/testthat/test-pairwise_comparison.R:345:    )\ntests/testthat/test-pairwise_comparison.R:346:  )\ntests/testthat/test-pairwise_comparison.R:347:  eval_nometric <- data.table::copy(eval)[, \"crps\" := NULL]\ntests/testthat/test-pairwise_comparison.R:348:  expect_error(\ntests/testthat/test-pairwise_comparison.R:349:    suppressWarnings(add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:350:      eval_nometric,\ntests/testthat/test-pairwise_comparison.R:351:      compare = \"model\"\ntests/testthat/test-pairwise_comparison.R:352:    )),\ntests/testthat/test-pairwise_comparison.R:353:    \"Assertion on 'metric' failed: Must be a subset of \"\ntests/testthat/test-pairwise_comparison.R:354:  )\ntests/testthat/test-pairwise_comparison.R:355:\ntests/testthat/test-pairwise_comparison.R:356:  # error if no model column is found\ntests/testthat/test-pairwise_comparison.R:357:  eval_nomodel <- data.table::copy(eval)[, \"model\" := NULL]\ntests/testthat/test-pairwise_comparison.R:358:  expect_error(\ntests/testthat/test-pairwise_comparison.R:359:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:360:      eval_nomodel,\ntests/testthat/test-pairwise_comparison.R:361:      by = \"target_type\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:362:    ),\ntests/testthat/test-pairwise_comparison.R:363:    \"Assertion on 'scores' failed: Column 'model' not found in data.\"\ntests/testthat/test-pairwise_comparison.R:364:  )\ntests/testthat/test-pairwise_comparison.R:365:\ntests/testthat/test-pairwise_comparison.R:366:  # error if there isn't a metrics attribute\ntests/testthat/test-pairwise_comparison.R:367:  eval_noattribute <- data.table::copy(eval)\ntests/testthat/test-pairwise_comparison.R:368:  attr(eval_noattribute, \"metrics\") <- NULL\ntests/testthat/test-pairwise_comparison.R:369:  expect_error(\ntests/testthat/test-pairwise_comparison.R:370:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:371:      eval_noattribute,\ntests/testthat/test-pairwise_comparison.R:372:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:373:    ),\ntests/testthat/test-pairwise_comparison.R:374:    \"needs an attribute `metrics`\"\ntests/testthat/test-pairwise_comparison.R:375:  )\ntests/testthat/test-pairwise_comparison.R:376:\ntests/testthat/test-pairwise_comparison.R:377:  # warning if there are NAs in the column for which a relative metric is computed\ntests/testthat/test-pairwise_comparison.R:378:  eval_nas <- data.table::copy(eval)\ntests/testthat/test-pairwise_comparison.R:379:  eval_nas[1:10, \"crps\" := NA]\ntests/testthat/test-pairwise_comparison.R:380:  expect_warning(\ntests/testthat/test-pairwise_comparison.R:381:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:382:      eval_nas,\ntests/testthat/test-pairwise_comparison.R:383:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:384:    ),\ntests/testthat/test-pairwise_comparison.R:385:    \"Some values for the metric `crps` are NA. These have been removed.\"\ntests/testthat/test-pairwise_comparison.R:386:  )\ntests/testthat/test-pairwise_comparison.R:387:\ntests/testthat/test-pairwise_comparison.R:388:  # warning if there are no values left after removing NAs\ntests/testthat/test-pairwise_comparison.R:389:  eval_nas[, \"crps\" := NA]\ntests/testthat/test-pairwise_comparison.R:390:  expect_error(\ntests/testthat/test-pairwise_comparison.R:391:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:392:      eval_nas,\ntests/testthat/test-pairwise_comparison.R:393:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:394:    ),\ntests/testthat/test-pairwise_comparison.R:395:    \"After removing \\\"NA\\\" values for `crps`, no values were left.\"\ntests/testthat/test-pairwise_comparison.R:396:  )\ntests/testthat/test-pairwise_comparison.R:397:\ntests/testthat/test-pairwise_comparison.R:398:  # error if not all values for the relative skill metric have the same sign\ntests/testthat/test-pairwise_comparison.R:399:  eval_diffsign <- data.table::copy(eval)\ntests/testthat/test-pairwise_comparison.R:400:  eval_diffsign[1:10, \"crps\" := -eval_diffsign[1:10, \"crps\"]]\ntests/testthat/test-pairwise_comparison.R:401:  expect_error(\ntests/testthat/test-pairwise_comparison.R:402:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:403:      eval_diffsign,\ntests/testthat/test-pairwise_comparison.R:404:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:405:    ),\ntests/testthat/test-pairwise_comparison.R:406:    \"To compute pairwise comparisons, all values of `crps` must have the same sign.\"\ntests/testthat/test-pairwise_comparison.R:407:  )\ntests/testthat/test-pairwise_comparison.R:408:\ntests/testthat/test-pairwise_comparison.R:409:  # message if `by` is equal to the forecast unit\ntests/testthat/test-pairwise_comparison.R:410:  fu <- get_forecast_unit(eval)\ntests/testthat/test-pairwise_comparison.R:411:  expect_message(\ntests/testthat/test-pairwise_comparison.R:412:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:413:      eval,\ntests/testthat/test-pairwise_comparison.R:414:      compare = \"model\", by = setdiff(fu, \"model\"), metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:415:    ),\ntests/testthat/test-pairwise_comparison.R:416:    \"relative skill can only be computed if the combination\"\ntests/testthat/test-pairwise_comparison.R:417:  )\ntests/testthat/test-pairwise_comparison.R:418:\ntests/testthat/test-pairwise_comparison.R:419:  # warning if by is equal to the forecast unit and also by is \"model\"\ntests/testthat/test-pairwise_comparison.R:420:  eval_summ <- summarise_scores(eval, by = \"model\")\ntests/testthat/test-pairwise_comparison.R:421:  expect_warning(\ntests/testthat/test-pairwise_comparison.R:422:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:423:      eval_summ,\ntests/testthat/test-pairwise_comparison.R:424:      compare = \"model\", metric = \"crps\"\ntests/testthat/test-pairwise_comparison.R:425:    ),\ntests/testthat/test-pairwise_comparison.R:426:    \"`compare` is set to the unit of a single forecast.\"\ntests/testthat/test-pairwise_comparison.R:427:  )\ntests/testthat/test-pairwise_comparison.R:428:})\ntests/testthat/test-pairwise_comparison.R:429:\ntests/testthat/test-pairwise_comparison.R:430:test_that(\"get_pairwise_comparisons() throws errors with wrong inputs\", {\ntests/testthat/test-pairwise_comparison.R:431:  test <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-pairwise_comparison.R:432:  test <- test[, \"model\" := NULL]\ntests/testthat/test-pairwise_comparison.R:433:\ntests/testthat/test-pairwise_comparison.R:434:  # expect error if no model column is found\ntests/testthat/test-pairwise_comparison.R:435:  expect_error(\ntests/testthat/test-pairwise_comparison.R:436:    get_pairwise_comparisons(test, compare = \"model\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:437:    \"Assertion on 'scores' failed: Column 'model' not found in data.\"\ntests/testthat/test-pairwise_comparison.R:438:  )\ntests/testthat/test-pairwise_comparison.R:439:})\ntests/testthat/test-pairwise_comparison.R:440:\ntests/testthat/test-pairwise_comparison.R:441:test_that(\"pairwise_comparison_one_group() throws error with wrong inputs\", {\ntests/testthat/test-pairwise_comparison.R:442:  test <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-pairwise_comparison.R:443:  test <- test[, \"model\" := NULL]\ntests/testthat/test-pairwise_comparison.R:444:\ntests/testthat/test-pairwise_comparison.R:445:  # expect error if no model column is found\ntests/testthat/test-pairwise_comparison.R:446:  expect_error(\ntests/testthat/test-pairwise_comparison.R:447:    pairwise_comparison_one_group(test, compare = \"model\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:448:    \"pairwise comparisons require a column as given by `compare`\"\ntests/testthat/test-pairwise_comparison.R:449:  )\ntests/testthat/test-pairwise_comparison.R:450:\ntests/testthat/test-pairwise_comparison.R:451:  # expect error as a result if scores has zero rows\ntests/testthat/test-pairwise_comparison.R:452:  test <- data.table::copy(scores_sample_continuous)[model == \"impossible\"]\ntests/testthat/test-pairwise_comparison.R:453:  expect_error(\ntests/testthat/test-pairwise_comparison.R:454:    pairwise_comparison_one_group(test, compare = \"model\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:455:    \"not enough comparators\"\ntests/testthat/test-pairwise_comparison.R:456:  )\ntests/testthat/test-pairwise_comparison.R:457:\ntests/testthat/test-pairwise_comparison.R:458:  # expect error if there aren't enough models\ntests/testthat/test-pairwise_comparison.R:459:  test <- data.table::copy(scores_sample_continuous)[model == \"EuroCOVIDhub-ensemble\"]\ntests/testthat/test-pairwise_comparison.R:460:  expect_error(\ntests/testthat/test-pairwise_comparison.R:461:    pairwise_comparison_one_group(test, compare = \"model\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:462:    \"not enough comparators\"\ntests/testthat/test-pairwise_comparison.R:463:  )\ntests/testthat/test-pairwise_comparison.R:464:\ntests/testthat/test-pairwise_comparison.R:465:  # expect error if baseline model is missing\ntests/testthat/test-pairwise_comparison.R:466:  test <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-pairwise_comparison.R:467:  expect_error(\ntests/testthat/test-pairwise_comparison.R:468:    pairwise_comparison_one_group(test, compare = \"model\", baseline = \"missing\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:469:    \"Baseline comparator `missing` missing\"\ntests/testthat/test-pairwise_comparison.R:470:  )\ntests/testthat/test-pairwise_comparison.R:471:})\ntests/testthat/test-pairwise_comparison.R:472:\ntests/testthat/test-pairwise_comparison.R:473:test_that(\"compare_forecasts() throws error with wrong inputs\", {\ntests/testthat/test-pairwise_comparison.R:474:  test <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-pairwise_comparison.R:475:  test <- test[, \"model\" := NULL]\ntests/testthat/test-pairwise_comparison.R:476:\ntests/testthat/test-pairwise_comparison.R:477:  # expect error if no model column is found\ntests/testthat/test-pairwise_comparison.R:478:  expect_error(\ntests/testthat/test-pairwise_comparison.R:479:    compare_forecasts(test, compare = \"model\", metric = \"crps\"),\ntests/testthat/test-pairwise_comparison.R:480:    \"pairwise comparisons require a column as given by `compare`\"\ntests/testthat/test-pairwise_comparison.R:481:  )\ntests/testthat/test-pairwise_comparison.R:482:})\ntests/testthat/test-pairwise_comparison.R:483:\ntests/testthat/test-pairwise_comparison.R:484:test_that(\"add_relative_skill() works with point forecasts\", {\ntests/testthat/test-pairwise_comparison.R:485:  pw_point <- expect_no_condition(\ntests/testthat/test-pairwise_comparison.R:486:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:487:      scores_point,\ntests/testthat/test-pairwise_comparison.R:488:      metric = \"se_point\"\ntests/testthat/test-pairwise_comparison.R:489:    )\ntests/testthat/test-pairwise_comparison.R:490:  )\ntests/testthat/test-pairwise_comparison.R:491:  pw_point <- summarise_scores(pw_point, by = \"model\")\ntests/testthat/test-pairwise_comparison.R:492:\ntests/testthat/test-pairwise_comparison.R:493:  pw_manual <- get_pairwise_comparisons(\ntests/testthat/test-pairwise_comparison.R:494:    scores_point,\ntests/testthat/test-pairwise_comparison.R:495:    compare = \"model\", metric = \"se_point\"\ntests/testthat/test-pairwise_comparison.R:496:  )\ntests/testthat/test-pairwise_comparison.R:497:\ntests/testthat/test-pairwise_comparison.R:498:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-pairwise_comparison.R:499:    pw_point$relative_skill,\ntests/testthat/test-pairwise_comparison.R:500:    unique(pw_manual$relative_skill)\ntests/testthat/test-pairwise_comparison.R:501:  )\ntests/testthat/test-pairwise_comparison.R:502:})\ntests/testthat/test-pairwise_comparison.R:503:\ntests/testthat/test-pairwise_comparison.R:504:test_that(\"add_relative_skill() can compute relative measures\", {\ntests/testthat/test-pairwise_comparison.R:505:  scores_with <- add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:506:    scores_quantile\ntests/testthat/test-pairwise_comparison.R:507:  )\ntests/testthat/test-pairwise_comparison.R:508:  expect_s3_class(\ntests/testthat/test-pairwise_comparison.R:509:    scores_with,\ntests/testthat/test-pairwise_comparison.R:510:    c(\"scores\", \"data.table\", \"data.frame\"),\ntests/testthat/test-pairwise_comparison.R:511:    exact = TRUE\ntests/testthat/test-pairwise_comparison.R:512:  )\ntests/testthat/test-pairwise_comparison.R:513:\ntests/testthat/test-pairwise_comparison.R:514:  scores_with <- summarise_scores(scores_with, by = \"model\")\ntests/testthat/test-pairwise_comparison.R:515:\ntests/testthat/test-pairwise_comparison.R:516:  expect_equal(\ntests/testthat/test-pairwise_comparison.R:517:    scores_with[, wis_relative_skill],\ntests/testthat/test-pairwise_comparison.R:518:    c(1.6, 0.81, 0.75, 1.03),\ntests/testthat/test-pairwise_comparison.R:519:    tolerance = 0.01\ntests/testthat/test-pairwise_comparison.R:520:  )\ntests/testthat/test-pairwise_comparison.R:521:\ntests/testthat/test-pairwise_comparison.R:522:  scores_with <- add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:523:    scores_quantile,\ntests/testthat/test-pairwise_comparison.R:524:    compare = \"model\",\ntests/testthat/test-pairwise_comparison.R:525:    metric = \"ae_median\"\ntests/testthat/test-pairwise_comparison.R:526:  )\ntests/testthat/test-pairwise_comparison.R:527:  scores_with <- summarise_scores(scores_with, by = \"model\")\ntests/testthat/test-pairwise_comparison.R:528:\ntests/testthat/test-pairwise_comparison.R:529:  expect_equal(\ntests/testthat/test-pairwise_comparison.R:530:    scores_with[, ae_median_relative_skill],\ntests/testthat/test-pairwise_comparison.R:531:    c(1.6, 0.78, 0.77, 1.04),\ntests/testthat/test-pairwise_comparison.R:532:    tolerance = 0.01\ntests/testthat/test-pairwise_comparison.R:533:  )\ntests/testthat/test-pairwise_comparison.R:534:})\ntests/testthat/test-pairwise_comparison.R:535:\ntests/testthat/test-pairwise_comparison.R:536:# test more esoteric options to make at least sure they don't produce an error\ntests/testthat/test-pairwise_comparison.R:537:test_that(\"permutation_tests work as expected\", {\ntests/testthat/test-pairwise_comparison.R:538:  expect_no_condition(\ntests/testthat/test-pairwise_comparison.R:539:    get_pairwise_comparisons(\ntests/testthat/test-pairwise_comparison.R:540:      scores_quantile,\ntests/testthat/test-pairwise_comparison.R:541:      test_type = \"permutation\",\ntests/testthat/test-pairwise_comparison.R:542:      one_sided = TRUE,\ntests/testthat/test-pairwise_comparison.R:543:      n_permutations = 50\ntests/testthat/test-pairwise_comparison.R:544:    )\ntests/testthat/test-pairwise_comparison.R:545:  )\ntests/testthat/test-pairwise_comparison.R:546:})\ntests/testthat/test-pairwise_comparison.R:547:\ntests/testthat/test-pairwise_comparison.R:548:\ntests/testthat/test-pairwise_comparison.R:549:# ==============================================================================\ntests/testthat/test-pairwise_comparison.R:550:# plot_pairwise_comparison() # nolint: commented_code_linter\ntests/testthat/test-pairwise_comparison.R:551:# ==============================================================================\ntests/testthat/test-pairwise_comparison.R:552:pairwise <- get_pairwise_comparisons(scores_quantile, by = \"target_type\")\ntests/testthat/test-pairwise_comparison.R:553:\ntests/testthat/test-pairwise_comparison.R:554:test_that(\"plot_pairwise_comparisons() works as expected\", {\ntests/testthat/test-pairwise_comparison.R:555:  p <- plot_pairwise_comparisons(pairwise) +\ntests/testthat/test-pairwise_comparison.R:556:    ggplot2::facet_wrap(~target_type)\ntests/testthat/test-pairwise_comparison.R:557:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-pairwise_comparison.R:558:  skip_on_cran()\ntests/testthat/test-pairwise_comparison.R:559:  vdiffr::expect_doppelganger(\"plot_pairwise_comparison\", p)\ntests/testthat/test-pairwise_comparison.R:560:})\ntests/testthat/test-pairwise_comparison.R:561:\ntests/testthat/test-pairwise_comparison.R:562:test_that(\"plot_pairwise_comparisons() works when showing p values\", {\ntests/testthat/test-pairwise_comparison.R:563:  p <- plot_pairwise_comparisons(pairwise, type = \"pval\") +\ntests/testthat/test-pairwise_comparison.R:564:    ggplot2::facet_wrap(~target_type)\ntests/testthat/test-pairwise_comparison.R:565:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-pairwise_comparison.R:566:  skip_on_cran()\ntests/testthat/test-pairwise_comparison.R:567:  vdiffr::expect_doppelganger(\"plot_pairwise_comparison_pval\", p)\ntests/testthat/test-pairwise_comparison.R:568:})\ntests/testthat/test-pairwise_comparison.R:569:\ntests/testthat/test-pairwise_comparison.R:570:test_that(\"add_relative_skill() works without warnings when not computing p-values\", {\ntests/testthat/test-pairwise_comparison.R:571:  forecast_quantile <- example_quantile |>\ntests/testthat/test-pairwise_comparison.R:572:    na.omit() |>\ntests/testthat/test-pairwise_comparison.R:573:    as_forecast_quantile(\ntests/testthat/test-pairwise_comparison.R:574:      forecast_unit = c(\ntests/testthat/test-pairwise_comparison.R:575:        \"location\", \"forecast_date\", \"target_end_date\",\ntests/testthat/test-pairwise_comparison.R:576:        \"target_type\", \"model\", \"horizon\"\ntests/testthat/test-pairwise_comparison.R:577:      )\ntests/testthat/test-pairwise_comparison.R:578:    )\ntests/testthat/test-pairwise_comparison.R:579:\ntests/testthat/test-pairwise_comparison.R:580:  scores <- forecast_quantile |>\ntests/testthat/test-pairwise_comparison.R:581:    score(metrics = get_metrics(forecast_quantile, \"ae_median\"))\ntests/testthat/test-pairwise_comparison.R:582:\ntests/testthat/test-pairwise_comparison.R:583:  scores_w_rel_skill <- expect_no_warning(\ntests/testthat/test-pairwise_comparison.R:584:    add_relative_skill(\ntests/testthat/test-pairwise_comparison.R:585:      scores,\ntests/testthat/test-pairwise_comparison.R:586:      compare = \"model\",\ntests/testthat/test-pairwise_comparison.R:587:      by = \"location\",\ntests/testthat/test-pairwise_comparison.R:588:      metric = \"ae_median\",\ntests/testthat/test-pairwise_comparison.R:589:      test_type = NULL\ntests/testthat/test-pairwise_comparison.R:590:    )\ntests/testthat/test-pairwise_comparison.R:591:  )\ntests/testthat/test-pairwise_comparison.R:592:\ntests/testthat/test-pairwise_comparison.R:593:  # Additional checks to ensure the function worked correctly\ntests/testthat/test-pairwise_comparison.R:594:  expect_true(\"ae_median_relative_skill\" %in% names(scores_w_rel_skill))\ntests/testthat/test-pairwise_comparison.R:595:  expect_type(scores_w_rel_skill$ae_median_relative_skill, \"double\")\ntests/testthat/test-pairwise_comparison.R:596:  expect_false(anyNA(scores_w_rel_skill$ae_median_relative_skill))\ntests/testthat/test-pairwise_comparison.R:597:})\ntests/testthat/test-metrics-quantile.R:1:observed <- c(1, -15, 22)\ntests/testthat/test-metrics-quantile.R:2:predicted <- rbind(\ntests/testthat/test-metrics-quantile.R:3:  c(-1, 0, 1, 2, 3),\ntests/testthat/test-metrics-quantile.R:4:  c(-2, 1, 2, 2, 4),\ntests/testthat/test-metrics-quantile.R:5:  c(-2, 0, 3, 3, 4)\ntests/testthat/test-metrics-quantile.R:6:)\ntests/testthat/test-metrics-quantile.R:7:quantile_level <- c(0.1, 0.25, 0.5, 0.75, 0.9)\ntests/testthat/test-metrics-quantile.R:8:\ntests/testthat/test-metrics-quantile.R:9:# covidHubUtils test:\ntests/testthat/test-metrics-quantile.R:10:y <- c(1, -15, 22)\ntests/testthat/test-metrics-quantile.R:11:forecast_quantiles_matrix <- rbind(\ntests/testthat/test-metrics-quantile.R:12:  c(-1, 0, 1, 2, 3),\ntests/testthat/test-metrics-quantile.R:13:  c(-2, 1, 2, 2, 4),\ntests/testthat/test-metrics-quantile.R:14:  c(-2, 0, 3, 3, 4)\ntests/testthat/test-metrics-quantile.R:15:)\ntests/testthat/test-metrics-quantile.R:16:forecast_quantile_probs <- c(0.1, 0.25, 0.5, 0.75, 0.9)\ntests/testthat/test-metrics-quantile.R:17:\ntests/testthat/test-metrics-quantile.R:18:\ntests/testthat/test-metrics-quantile.R:19:# ==============================================================================\ntests/testthat/test-metrics-quantile.R:20:# check_input_quantile() # nolint: commented_code_linter\ntests/testthat/test-metrics-quantile.R:21:# ==============================================================================\ntests/testthat/test-metrics-quantile.R:22:test_that(\"check_input_quantile() works as expected\", {\ntests/testthat/test-metrics-quantile.R:23:  # expect no error if dimensions are ok\ntests/testthat/test-metrics-quantile.R:24:  expect_true(\ntests/testthat/test-metrics-quantile.R:25:    check_input_quantile(\ntests/testthat/test-metrics-quantile.R:26:      1:10, matrix(1:20, nrow = 10),\ntests/testthat/test-metrics-quantile.R:27:      quantile_level = c(0.1, 0.9)\ntests/testthat/test-metrics-quantile.R:28:    )\ntests/testthat/test-metrics-quantile.R:29:  )\ntests/testthat/test-metrics-quantile.R:30:\ntests/testthat/test-metrics-quantile.R:31:  # expect error if dimensions are not ok\ntests/testthat/test-metrics-quantile.R:32:  expect_match(\ntests/testthat/test-metrics-quantile.R:33:    check_input_quantile(\ntests/testthat/test-metrics-quantile.R:34:      1:10, matrix(1:20, nrow = 10),\ntests/testthat/test-metrics-quantile.R:35:      quantile_level = seq(0.1, 0.9, length.out = 8)\ntests/testthat/test-metrics-quantile.R:36:    ),\ntests/testthat/test-metrics-quantile.R:37:    \"Assertion on 'predicted' failed: Must have exactly 8 cols, but has 2 cols.\"\ntests/testthat/test-metrics-quantile.R:38:  )\ntests/testthat/test-metrics-quantile.R:39:})\ntests/testthat/test-metrics-quantile.R:40:\ntests/testthat/test-metrics-quantile.R:41:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:42:# Input handling ===============================================================\ntests/testthat/test-metrics-quantile.R:43:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:44:test_that(\"Input checking for quantile forecasts works\", {\ntests/testthat/test-metrics-quantile.R:45:  # everything correct\ntests/testthat/test-metrics-quantile.R:46:  expect_no_condition(\ntests/testthat/test-metrics-quantile.R:47:    scoringutils:::assert_input_quantile(observed, predicted, quantile_level) # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:48:  )\ntests/testthat/test-metrics-quantile.R:49:\ntests/testthat/test-metrics-quantile.R:50:  # quantile_level > 1 # nolint: commented_code_linter\ntests/testthat/test-metrics-quantile.R:51:  expect_error(\ntests/testthat/test-metrics-quantile.R:52:    scoringutils:::assert_input_quantile(observed, predicted, quantile_level + 1), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:53:    \"Assertion on 'quantile_level' failed: Element 1 is not <= 1.\"\ntests/testthat/test-metrics-quantile.R:54:  )\ntests/testthat/test-metrics-quantile.R:55:\ntests/testthat/test-metrics-quantile.R:56:  # quantile_level < 0 # nolint: commented_code_linter\ntests/testthat/test-metrics-quantile.R:57:  expect_error(\ntests/testthat/test-metrics-quantile.R:58:    scoringutils:::assert_input_quantile(observed, predicted, quantile_level - 1), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:59:    \"Assertion on 'quantile_level' failed: Element 1 is not >= 0.\"\ntests/testthat/test-metrics-quantile.R:60:  )\ntests/testthat/test-metrics-quantile.R:61:\ntests/testthat/test-metrics-quantile.R:62:  # 10 observations, but only 3 forecasts\ntests/testthat/test-metrics-quantile.R:63:  expect_error(\ntests/testthat/test-metrics-quantile.R:64:    scoringutils:::assert_input_quantile(1:10, predicted, quantile_level), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:65:    \"Assertion on 'predicted' failed: Must have exactly 10 rows, but has 3 rows.\"\ntests/testthat/test-metrics-quantile.R:66:  )\ntests/testthat/test-metrics-quantile.R:67:\ntests/testthat/test-metrics-quantile.R:68:  # observed value is a factor\ntests/testthat/test-metrics-quantile.R:69:  expect_error(\ntests/testthat/test-metrics-quantile.R:70:    scoringutils:::assert_input_quantile(factor(1:10), predicted, quantile_level), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:71:    \"Assertion on 'observed' failed: Must be of type 'numeric', not 'factor'.\"\ntests/testthat/test-metrics-quantile.R:72:  )\ntests/testthat/test-metrics-quantile.R:73:\ntests/testthat/test-metrics-quantile.R:74:  # observed is a single number and does not have the same length as predicted\ntests/testthat/test-metrics-quantile.R:75:  # There seems to be an issue with the error message: there is one \\n to many\ntests/testthat/test-metrics-quantile.R:76:  # such that the test fails when executed alone, but works when executed\ntests/testthat/test-metrics-quantile.R:77:  # together with others.\ntests/testthat/test-metrics-quantile.R:78:  expect_error(\ntests/testthat/test-metrics-quantile.R:79:    scoringutils:::assert_input_quantile(1, predicted, quantile_level), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:80:    \"Assertion failed.*check_numeric_vector.*check_matrix\"\ntests/testthat/test-metrics-quantile.R:81:  )\ntests/testthat/test-metrics-quantile.R:82:\ntests/testthat/test-metrics-quantile.R:83:  # predicted is a vector\ntests/testthat/test-metrics-quantile.R:84:  expect_error(\ntests/testthat/test-metrics-quantile.R:85:    scoringutils:::assert_input_quantile(observed, as.vector(predicted), quantile_level), # nolint: undesirable_operator_linter\ntests/testthat/test-metrics-quantile.R:86:    \"Assertion on 'predicted' failed: Must be of type 'matrix', not 'double'.\"\ntests/testthat/test-metrics-quantile.R:87:  )\ntests/testthat/test-metrics-quantile.R:88:})\ntests/testthat/test-metrics-quantile.R:89:\ntests/testthat/test-metrics-quantile.R:90:\ntests/testthat/test-metrics-quantile.R:91:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:92:# wis ==========================================================================\ntests/testthat/test-metrics-quantile.R:93:# ============================================================================ #a\ntests/testthat/test-metrics-quantile.R:94:test_that(\"wis works standalone, median only\", {\ntests/testthat/test-metrics-quantile.R:95:  y <- c(1, -15, 22)\ntests/testthat/test-metrics-quantile.R:96:  lower <- upper <- predicted_quantile <- c(1, 2, 3)\ntests/testthat/test-metrics-quantile.R:97:  quantile_probs <- 0.5\ntests/testthat/test-metrics-quantile.R:98:\ntests/testthat/test-metrics-quantile.R:99:  actual <- interval_score(y,\ntests/testthat/test-metrics-quantile.R:100:    lower = lower, upper = upper,\ntests/testthat/test-metrics-quantile.R:101:    weigh = TRUE,\ntests/testthat/test-metrics-quantile.R:102:    interval_range = 0\ntests/testthat/test-metrics-quantile.R:103:  )\ntests/testthat/test-metrics-quantile.R:104:\ntests/testthat/test-metrics-quantile.R:105:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:106:    observed = y,\ntests/testthat/test-metrics-quantile.R:107:    predicted = matrix(predicted_quantile),\ntests/testthat/test-metrics-quantile.R:108:    quantile_level = quantile_probs\ntests/testthat/test-metrics-quantile.R:109:  )\ntests/testthat/test-metrics-quantile.R:110:\ntests/testthat/test-metrics-quantile.R:111:  expected <- abs(y - lower)\ntests/testthat/test-metrics-quantile.R:112:\ntests/testthat/test-metrics-quantile.R:113:  expect_identical(actual, expected)\ntests/testthat/test-metrics-quantile.R:114:})\ntests/testthat/test-metrics-quantile.R:115:\ntests/testthat/test-metrics-quantile.R:116:test_that(\"`wis()` works within score for median forecast\", {\ntests/testthat/test-metrics-quantile.R:117:  test_data <- data.frame(\ntests/testthat/test-metrics-quantile.R:118:    observed = c(1, -15, 22),\ntests/testthat/test-metrics-quantile.R:119:    predicted = 1:3,\ntests/testthat/test-metrics-quantile.R:120:    quantile_level = rep(0.5, each = 3),\ntests/testthat/test-metrics-quantile.R:121:    model = \"model1\",\ntests/testthat/test-metrics-quantile.R:122:    date = 1:3,\ntests/testthat/test-metrics-quantile.R:123:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:124:  ) |>\ntests/testthat/test-metrics-quantile.R:125:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:126:\ntests/testthat/test-metrics-quantile.R:127:  metrics <- get_metrics(example_quantile) |>\ntests/testthat/test-metrics-quantile.R:128:    select_metrics(select = c(\"ae_median\", \"wis\"))\ntests/testthat/test-metrics-quantile.R:129:  metrics$wis <- purrr::partial(metrics$wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:130:\ntests/testthat/test-metrics-quantile.R:131:  eval <- score(test_data, metrics = metrics)\ntests/testthat/test-metrics-quantile.R:132:  expect_equal(eval$ae_median, eval$wis) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:133:})\ntests/testthat/test-metrics-quantile.R:134:\ntests/testthat/test-metrics-quantile.R:135:test_that(\"`wis()` equals `interval_score()`, 1 interval only\", {\ntests/testthat/test-metrics-quantile.R:136:  y <- c(1, -15, 22)\ntests/testthat/test-metrics-quantile.R:137:  lower <- c(0, 1, 0)\ntests/testthat/test-metrics-quantile.R:138:  upper <- c(2, 2, 3)\ntests/testthat/test-metrics-quantile.R:139:  quantile_probs <- c(0.25, 0.75)\ntests/testthat/test-metrics-quantile.R:140:  predicted <- matrix(c(lower, upper), ncol = 2)\ntests/testthat/test-metrics-quantile.R:141:\ntests/testthat/test-metrics-quantile.R:142:  alpha <- 0.5\ntests/testthat/test-metrics-quantile.R:143:  expected <- (upper - lower) * (alpha / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:144:\ntests/testthat/test-metrics-quantile.R:145:  actual <- interval_score(\ntests/testthat/test-metrics-quantile.R:146:    y,\ntests/testthat/test-metrics-quantile.R:147:    lower = lower, upper = upper,\ntests/testthat/test-metrics-quantile.R:148:    weigh = TRUE,\ntests/testthat/test-metrics-quantile.R:149:    interval_range = 50\ntests/testthat/test-metrics-quantile.R:150:  )\ntests/testthat/test-metrics-quantile.R:151:\ntests/testthat/test-metrics-quantile.R:152:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:153:    observed = y,\ntests/testthat/test-metrics-quantile.R:154:    predicted = predicted,\ntests/testthat/test-metrics-quantile.R:155:    quantile_level = quantile_probs\ntests/testthat/test-metrics-quantile.R:156:  )\ntests/testthat/test-metrics-quantile.R:157:\ntests/testthat/test-metrics-quantile.R:158:  expect_identical(actual, expected)\ntests/testthat/test-metrics-quantile.R:159:  expect_identical(actual_wis, expected)\ntests/testthat/test-metrics-quantile.R:160:})\ntests/testthat/test-metrics-quantile.R:161:\ntests/testthat/test-metrics-quantile.R:162:test_that(\"wis() works within score for one interval\", {\ntests/testthat/test-metrics-quantile.R:163:  test_data <- data.frame(\ntests/testthat/test-metrics-quantile.R:164:    observed = rep(c(1, -15, 22), times = 2),\ntests/testthat/test-metrics-quantile.R:165:    quantile_level = rep(c(0.25, 0.75), each = 3),\ntests/testthat/test-metrics-quantile.R:166:    predicted = c(0, 1, 0, 2, 2, 3),\ntests/testthat/test-metrics-quantile.R:167:    model = \"model1\",\ntests/testthat/test-metrics-quantile.R:168:    date = rep(1:3, times = 2),\ntests/testthat/test-metrics-quantile.R:169:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:170:  ) |>\ntests/testthat/test-metrics-quantile.R:171:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:172:\ntests/testthat/test-metrics-quantile.R:173:  metrics <- get_metrics(example_quantile) |>\ntests/testthat/test-metrics-quantile.R:174:    select_metrics(select = \"wis\")\ntests/testthat/test-metrics-quantile.R:175:  metrics$wis <- purrr::partial(metrics$wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:176:\ntests/testthat/test-metrics-quantile.R:177:  eval <- score(test_data, metrics = metrics)\ntests/testthat/test-metrics-quantile.R:178:\ntests/testthat/test-metrics-quantile.R:179:  eval <- summarise_scores(eval, by = c(\"model\", \"date\"))\ntests/testthat/test-metrics-quantile.R:180:\ntests/testthat/test-metrics-quantile.R:181:  lower <- c(0, 1, 0)\ntests/testthat/test-metrics-quantile.R:182:  upper <- c(2, 2, 3)\ntests/testthat/test-metrics-quantile.R:183:  alpha <- 0.5\ntests/testthat/test-metrics-quantile.R:184:\ntests/testthat/test-metrics-quantile.R:185:  expected <- (upper - lower) * (alpha / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:186:\ntests/testthat/test-metrics-quantile.R:187:  expect_equal(expected, eval$wis) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:188:})\ntests/testthat/test-metrics-quantile.R:189:\ntests/testthat/test-metrics-quantile.R:190:test_that(\"`wis()` works 1 interval and median\", {\ntests/testthat/test-metrics-quantile.R:191:  test_data <- data.frame(\ntests/testthat/test-metrics-quantile.R:192:    observed = rep(c(1, -15, 22), times = 3),\ntests/testthat/test-metrics-quantile.R:193:    quantile_level = rep(c(0.25, 0.5, 0.75), each = 3),\ntests/testthat/test-metrics-quantile.R:194:    predicted = c(0, 1, 0, 1, 2, 3, 2, 2, 3),\ntests/testthat/test-metrics-quantile.R:195:    model = \"model1\",\ntests/testthat/test-metrics-quantile.R:196:    date = rep(1:3, times = 3),\ntests/testthat/test-metrics-quantile.R:197:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:198:  ) |>\ntests/testthat/test-metrics-quantile.R:199:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:200:\ntests/testthat/test-metrics-quantile.R:201:  metrics <- get_metrics(example_quantile, select = \"wis\")\ntests/testthat/test-metrics-quantile.R:202:  metrics$wis <- purrr::partial(metrics$wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:203:\ntests/testthat/test-metrics-quantile.R:204:  eval <- score(test_data, metrics = metrics)\ntests/testthat/test-metrics-quantile.R:205:\ntests/testthat/test-metrics-quantile.R:206:  eval <- summarise_scores(eval, by = c(\"model\", \"date\"))\ntests/testthat/test-metrics-quantile.R:207:\ntests/testthat/test-metrics-quantile.R:208:  y <- c(1, -15, 22)\ntests/testthat/test-metrics-quantile.R:209:  quantile <- rbind(c(0, 1, 2), c(1, 2, 2), c(0, 3, 3))\ntests/testthat/test-metrics-quantile.R:210:  quantile_probs <- c(0.25, 0.5, 0.75)\ntests/testthat/test-metrics-quantile.R:211:\ntests/testthat/test-metrics-quantile.R:212:  alpha <- 0.5\ntests/testthat/test-metrics-quantile.R:213:  expected <- 0.5 * (\ntests/testthat/test-metrics-quantile.R:214:    abs(y - quantile[, 2]) +\ntests/testthat/test-metrics-quantile.R:215:      (quantile[, 3] - quantile[, 1]) * (alpha / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:216:  )\ntests/testthat/test-metrics-quantile.R:217:\ntests/testthat/test-metrics-quantile.R:218:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:219:    observed = y,\ntests/testthat/test-metrics-quantile.R:220:    predicted = quantile,\ntests/testthat/test-metrics-quantile.R:221:    quantile_level = quantile_probs,\ntests/testthat/test-metrics-quantile.R:222:    count_median_twice = TRUE\ntests/testthat/test-metrics-quantile.R:223:  )\ntests/testthat/test-metrics-quantile.R:224:\ntests/testthat/test-metrics-quantile.R:225:  expect_equal(eval$wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:226:  expect_equal(actual_wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:227:})\ntests/testthat/test-metrics-quantile.R:228:\ntests/testthat/test-metrics-quantile.R:229:test_that(\"wis works, 2 intervals and median\", {\ntests/testthat/test-metrics-quantile.R:230:  test_data <- data.frame(\ntests/testthat/test-metrics-quantile.R:231:    observed = rep(c(1, -15, 22), times = 5),\ntests/testthat/test-metrics-quantile.R:232:    quantile_level = rep(c(0.1, 0.25, 0.5, 0.75, 0.9), each = 3),\ntests/testthat/test-metrics-quantile.R:233:    predicted = c(\ntests/testthat/test-metrics-quantile.R:234:      -1, -2, -2, 0, 1, 0, 1, 2, 3,\ntests/testthat/test-metrics-quantile.R:235:      2, 2, 3, 3, 4, 4\ntests/testthat/test-metrics-quantile.R:236:    ),\ntests/testthat/test-metrics-quantile.R:237:    model = \"model1\",\ntests/testthat/test-metrics-quantile.R:238:    date = rep(1:3, times = 5),\ntests/testthat/test-metrics-quantile.R:239:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:240:  ) |>\ntests/testthat/test-metrics-quantile.R:241:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:242:\ntests/testthat/test-metrics-quantile.R:243:  metrics <- get_metrics(example_quantile, select = \"wis\")\ntests/testthat/test-metrics-quantile.R:244:  metrics$wis <- purrr::partial(metrics$wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:245:\ntests/testthat/test-metrics-quantile.R:246:  eval <- score(test_data, metrics = metrics)\ntests/testthat/test-metrics-quantile.R:247:\ntests/testthat/test-metrics-quantile.R:248:  eval <- summarise_scores(eval, by = c(\"model\", \"date\"))\ntests/testthat/test-metrics-quantile.R:249:\ntests/testthat/test-metrics-quantile.R:250:  quantile <- forecast_quantiles_matrix\ntests/testthat/test-metrics-quantile.R:251:  quantile_probs <- c(0.1, 0.25, 0.5, 0.75, 0.9)\ntests/testthat/test-metrics-quantile.R:252:\ntests/testthat/test-metrics-quantile.R:253:  alpha1 <- 0.2\ntests/testthat/test-metrics-quantile.R:254:  alpha2 <- 0.5\ntests/testthat/test-metrics-quantile.R:255:\ntests/testthat/test-metrics-quantile.R:256:  expected <- (1 / 3) * (\ntests/testthat/test-metrics-quantile.R:257:    abs(y - quantile[, 3]) +\ntests/testthat/test-metrics-quantile.R:258:      (quantile[, 5] - quantile[, 1]) * (alpha1 / 2) + c(0, (-2) - (-15), 22 - 4) +\ntests/testthat/test-metrics-quantile.R:259:      (quantile[, 4] - quantile[, 2]) * (alpha2 / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:260:  )\ntests/testthat/test-metrics-quantile.R:261:\ntests/testthat/test-metrics-quantile.R:262:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:263:    observed = y,\ntests/testthat/test-metrics-quantile.R:264:    predicted = quantile,\ntests/testthat/test-metrics-quantile.R:265:    quantile_level = quantile_probs,\ntests/testthat/test-metrics-quantile.R:266:    count_median_twice = TRUE\ntests/testthat/test-metrics-quantile.R:267:  )\ntests/testthat/test-metrics-quantile.R:268:\ntests/testthat/test-metrics-quantile.R:269:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:270:    as.numeric(eval$wis),\ntests/testthat/test-metrics-quantile.R:271:    as.numeric(expected)\ntests/testthat/test-metrics-quantile.R:272:  )\ntests/testthat/test-metrics-quantile.R:273:  expect_equal(actual_wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:274:})\ntests/testthat/test-metrics-quantile.R:275:\ntests/testthat/test-metrics-quantile.R:276:# additional tests from the covidhubutils repo\ntests/testthat/test-metrics-quantile.R:277:test_that(\"wis is correct, median only - test corresponds to covidHubUtils\", {\ntests/testthat/test-metrics-quantile.R:278:  forecast_quantiles_matrix <- forecast_quantiles_matrix[, 3, drop = FALSE]\ntests/testthat/test-metrics-quantile.R:279:  forecast_quantile_probs <- forecast_quantile_probs[3]\ntests/testthat/test-metrics-quantile.R:280:\ntests/testthat/test-metrics-quantile.R:281:  target_end_dates <- as.Date(\"2020-01-01\") + c(7, 14, 7)\ntests/testthat/test-metrics-quantile.R:282:  horizons <- c(\"1\", \"2\", \"1\")\ntests/testthat/test-metrics-quantile.R:283:  locations <- c(\"01\", \"01\", \"02\")\ntests/testthat/test-metrics-quantile.R:284:  target_variables <- rep(\"inc death\", length(y))\ntests/testthat/test-metrics-quantile.R:285:\ntests/testthat/test-metrics-quantile.R:286:  forecast_target_end_dates <-\ntests/testthat/test-metrics-quantile.R:287:    rep(target_end_dates, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:288:  forecast_horizons <- rep(horizons, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:289:  forecast_locations <- rep(locations, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:290:  forecast_target_variables <-\ntests/testthat/test-metrics-quantile.R:291:    rep(target_variables, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:292:  forecast_quantile_probs <- rep(forecast_quantile_probs, each = length(y))\ntests/testthat/test-metrics-quantile.R:293:  forecast_quantiles <- forecast_quantiles_matrix\ntests/testthat/test-metrics-quantile.R:294:  dim(forecast_quantiles) <- prod(dim(forecast_quantiles))\ntests/testthat/test-metrics-quantile.R:295:\ntests/testthat/test-metrics-quantile.R:296:  test_truth <- data.frame(\ntests/testthat/test-metrics-quantile.R:297:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-quantile.R:298:    target_variable = target_variables,\ntests/testthat/test-metrics-quantile.R:299:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-quantile.R:300:    location = locations,\ntests/testthat/test-metrics-quantile.R:301:    value = y,\ntests/testthat/test-metrics-quantile.R:302:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:303:  )\ntests/testthat/test-metrics-quantile.R:304:\ntests/testthat/test-metrics-quantile.R:305:  n_forecasts <- length(forecast_quantiles)\ntests/testthat/test-metrics-quantile.R:306:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-quantile.R:307:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:308:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-quantile.R:309:    location = forecast_locations,\ntests/testthat/test-metrics-quantile.R:310:    horizon = forecast_horizons,\ntests/testthat/test-metrics-quantile.R:311:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:312:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-quantile.R:313:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-quantile.R:314:    type = rep(\"quantile\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:315:    quantile_level = forecast_quantile_probs,\ntests/testthat/test-metrics-quantile.R:316:    value = forecast_quantiles,\ntests/testthat/test-metrics-quantile.R:317:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:318:  )\ntests/testthat/test-metrics-quantile.R:319:  # make a version that conforms to scoringutils format\ntests/testthat/test-metrics-quantile.R:320:  truth_formatted <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-quantile.R:321:  truth_formatted[, `:=`(model = NULL)]\ntests/testthat/test-metrics-quantile.R:322:  data.table::setnames(truth_formatted, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-quantile.R:323:\ntests/testthat/test-metrics-quantile.R:324:  forecasts_formated <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-quantile.R:325:  data.table::setnames(forecasts_formated, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-quantile.R:326:\ntests/testthat/test-metrics-quantile.R:327:  data_formatted <- merge(forecasts_formated, truth_formatted)\ntests/testthat/test-metrics-quantile.R:328:\ntests/testthat/test-metrics-quantile.R:329:  metrics <- get_metrics(example_quantile, select = \"wis\")\ntests/testthat/test-metrics-quantile.R:330:  metrics$wis <- purrr::partial(metrics$wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:331:\ntests/testthat/test-metrics-quantile.R:332:  eval <- score(\ntests/testthat/test-metrics-quantile.R:333:    as_forecast_quantile(data_formatted),\ntests/testthat/test-metrics-quantile.R:334:    metrics = metrics\ntests/testthat/test-metrics-quantile.R:335:  )\ntests/testthat/test-metrics-quantile.R:336:\ntests/testthat/test-metrics-quantile.R:337:  expected <- abs(y - forecast_quantiles_matrix[, 1])\ntests/testthat/test-metrics-quantile.R:338:\ntests/testthat/test-metrics-quantile.R:339:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:340:    observed = y,\ntests/testthat/test-metrics-quantile.R:341:    predicted = matrix(forecast_quantiles_matrix),\ntests/testthat/test-metrics-quantile.R:342:    quantile_level = 0.5,\ntests/testthat/test-metrics-quantile.R:343:    count_median_twice = FALSE\ntests/testthat/test-metrics-quantile.R:344:  )\ntests/testthat/test-metrics-quantile.R:345:\ntests/testthat/test-metrics-quantile.R:346:  expect_equal(eval$wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:347:  expect_equal(actual_wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:348:})\ntests/testthat/test-metrics-quantile.R:349:\ntests/testthat/test-metrics-quantile.R:350:test_that(\"wis is correct, 1 interval only - test corresponds to covidHubUtils\", {\ntests/testthat/test-metrics-quantile.R:351:  forecast_quantiles_matrix <- forecast_quantiles_matrix[, c(1, 5), drop = FALSE]\ntests/testthat/test-metrics-quantile.R:352:  forecast_quantile_probs <- forecast_quantile_probs[c(1, 5)]\ntests/testthat/test-metrics-quantile.R:353:\ntests/testthat/test-metrics-quantile.R:354:  target_end_dates <- as.Date(\"2020-01-01\") + c(7, 14, 7)\ntests/testthat/test-metrics-quantile.R:355:  horizons <- c(\"1\", \"2\", \"1\")\ntests/testthat/test-metrics-quantile.R:356:  locations <- c(\"01\", \"01\", \"02\")\ntests/testthat/test-metrics-quantile.R:357:  target_variables <- rep(\"inc death\", length(y))\ntests/testthat/test-metrics-quantile.R:358:\ntests/testthat/test-metrics-quantile.R:359:  forecast_target_end_dates <-\ntests/testthat/test-metrics-quantile.R:360:    rep(target_end_dates, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:361:  forecast_horizons <- rep(horizons, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:362:  forecast_locations <- rep(locations, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:363:  forecast_target_variables <-\ntests/testthat/test-metrics-quantile.R:364:    rep(target_variables, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:365:  forecast_quantile_probs <- rep(forecast_quantile_probs, each = length(y))\ntests/testthat/test-metrics-quantile.R:366:  forecast_quantiles <- forecast_quantiles_matrix\ntests/testthat/test-metrics-quantile.R:367:  dim(forecast_quantiles) <- prod(dim(forecast_quantiles))\ntests/testthat/test-metrics-quantile.R:368:\ntests/testthat/test-metrics-quantile.R:369:  test_truth <- data.frame(\ntests/testthat/test-metrics-quantile.R:370:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-quantile.R:371:    target_variable = target_variables,\ntests/testthat/test-metrics-quantile.R:372:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-quantile.R:373:    location = locations,\ntests/testthat/test-metrics-quantile.R:374:    value = y,\ntests/testthat/test-metrics-quantile.R:375:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:376:  )\ntests/testthat/test-metrics-quantile.R:377:\ntests/testthat/test-metrics-quantile.R:378:  n_forecasts <- length(forecast_quantiles)\ntests/testthat/test-metrics-quantile.R:379:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-quantile.R:380:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:381:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-quantile.R:382:    location = forecast_locations,\ntests/testthat/test-metrics-quantile.R:383:    horizon = forecast_horizons,\ntests/testthat/test-metrics-quantile.R:384:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:385:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-quantile.R:386:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-quantile.R:387:    type = rep(\"quantile\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:388:    quantile_level = forecast_quantile_probs,\ntests/testthat/test-metrics-quantile.R:389:    value = forecast_quantiles,\ntests/testthat/test-metrics-quantile.R:390:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:391:  )\ntests/testthat/test-metrics-quantile.R:392:\ntests/testthat/test-metrics-quantile.R:393:  # make a version that conforms to scoringutils format\ntests/testthat/test-metrics-quantile.R:394:  truth_formatted <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-quantile.R:395:  truth_formatted[, `:=`(model = NULL)]\ntests/testthat/test-metrics-quantile.R:396:  data.table::setnames(truth_formatted, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-quantile.R:397:\ntests/testthat/test-metrics-quantile.R:398:  forecasts_formated <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-quantile.R:399:  data.table::setnames(forecasts_formated, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-quantile.R:400:\ntests/testthat/test-metrics-quantile.R:401:  data_formatted <- merge(forecasts_formated, truth_formatted) |>\ntests/testthat/test-metrics-quantile.R:402:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:403:\ntests/testthat/test-metrics-quantile.R:404:  metrics <- get_metrics(example_quantile, select = \"wis\")\ntests/testthat/test-metrics-quantile.R:405:\ntests/testthat/test-metrics-quantile.R:406:  eval <- suppressMessages(score(data_formatted, metrics = metrics))\ntests/testthat/test-metrics-quantile.R:407:\ntests/testthat/test-metrics-quantile.R:408:  eval <- summarise_scores(eval,\ntests/testthat/test-metrics-quantile.R:409:    by = c(\ntests/testthat/test-metrics-quantile.R:410:      \"model\", \"location\", \"target_variable\",\ntests/testthat/test-metrics-quantile.R:411:      \"target_end_date\", \"forecast_date\", \"horizon\"\ntests/testthat/test-metrics-quantile.R:412:    )\ntests/testthat/test-metrics-quantile.R:413:  )\ntests/testthat/test-metrics-quantile.R:414:\ntests/testthat/test-metrics-quantile.R:415:  alpha1 <- 0.2\ntests/testthat/test-metrics-quantile.R:416:  expected <- (forecast_quantiles_matrix[, 2] - forecast_quantiles_matrix[, 1]) * (alpha1 / 2) +\ntests/testthat/test-metrics-quantile.R:417:    c(0, (-2) - (-15), 22 - 4)\ntests/testthat/test-metrics-quantile.R:418:\ntests/testthat/test-metrics-quantile.R:419:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:420:    observed = y,\ntests/testthat/test-metrics-quantile.R:421:    predicted = forecast_quantiles_matrix,\ntests/testthat/test-metrics-quantile.R:422:    quantile_level = c(0.1, 0.9)\ntests/testthat/test-metrics-quantile.R:423:  )\ntests/testthat/test-metrics-quantile.R:424:\ntests/testthat/test-metrics-quantile.R:425:  expect_equal(eval$wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:426:  expect_equal(actual_wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:427:})\ntests/testthat/test-metrics-quantile.R:428:\ntests/testthat/test-metrics-quantile.R:429:test_that(\"wis is correct, 2 intervals and median - test corresponds to covidHubUtils\", {\ntests/testthat/test-metrics-quantile.R:430:  target_end_dates <- as.Date(\"2020-01-01\") + c(7, 14, 7)\ntests/testthat/test-metrics-quantile.R:431:  horizons <- c(\"1\", \"2\", \"1\")\ntests/testthat/test-metrics-quantile.R:432:  locations <- c(\"01\", \"01\", \"02\")\ntests/testthat/test-metrics-quantile.R:433:  target_variables <- rep(\"inc death\", length(y))\ntests/testthat/test-metrics-quantile.R:434:\ntests/testthat/test-metrics-quantile.R:435:  forecast_target_end_dates <-\ntests/testthat/test-metrics-quantile.R:436:    rep(target_end_dates, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:437:  forecast_horizons <- rep(horizons, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:438:  forecast_locations <- rep(locations, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:439:  forecast_target_variables <-\ntests/testthat/test-metrics-quantile.R:440:    rep(target_variables, times = ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-quantile.R:441:  forecast_quantile_probs <- rep(forecast_quantile_probs, each = length(y))\ntests/testthat/test-metrics-quantile.R:442:  forecast_quantiles <- forecast_quantiles_matrix\ntests/testthat/test-metrics-quantile.R:443:  dim(forecast_quantiles) <- prod(dim(forecast_quantiles))\ntests/testthat/test-metrics-quantile.R:444:\ntests/testthat/test-metrics-quantile.R:445:  test_truth <- data.frame(\ntests/testthat/test-metrics-quantile.R:446:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-quantile.R:447:    target_variable = target_variables,\ntests/testthat/test-metrics-quantile.R:448:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-quantile.R:449:    location = locations,\ntests/testthat/test-metrics-quantile.R:450:    value = y,\ntests/testthat/test-metrics-quantile.R:451:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:452:  )\ntests/testthat/test-metrics-quantile.R:453:\ntests/testthat/test-metrics-quantile.R:454:  n_forecasts <- length(forecast_quantiles)\ntests/testthat/test-metrics-quantile.R:455:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-quantile.R:456:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:457:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-quantile.R:458:    location = forecast_locations,\ntests/testthat/test-metrics-quantile.R:459:    horizon = forecast_horizons,\ntests/testthat/test-metrics-quantile.R:460:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:461:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-quantile.R:462:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-quantile.R:463:    type = rep(\"quantile\", n_forecasts),\ntests/testthat/test-metrics-quantile.R:464:    quantile_level = forecast_quantile_probs,\ntests/testthat/test-metrics-quantile.R:465:    value = forecast_quantiles,\ntests/testthat/test-metrics-quantile.R:466:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-quantile.R:467:  )\ntests/testthat/test-metrics-quantile.R:468:\ntests/testthat/test-metrics-quantile.R:469:  # make a version that conforms to scoringutils format\ntests/testthat/test-metrics-quantile.R:470:  truth_formatted <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-quantile.R:471:  truth_formatted[, `:=`(model = NULL)]\ntests/testthat/test-metrics-quantile.R:472:  data.table::setnames(truth_formatted, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-quantile.R:473:\ntests/testthat/test-metrics-quantile.R:474:  forecasts_formated <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-quantile.R:475:  data.table::setnames(forecasts_formated, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-quantile.R:476:\ntests/testthat/test-metrics-quantile.R:477:  data_formatted <- merge(forecasts_formated, truth_formatted) |>\ntests/testthat/test-metrics-quantile.R:478:    as_forecast_quantile()\ntests/testthat/test-metrics-quantile.R:479:\ntests/testthat/test-metrics-quantile.R:480:  eval <- score(data_formatted, metrics = metrics_no_cov)\ntests/testthat/test-metrics-quantile.R:481:\ntests/testthat/test-metrics-quantile.R:482:  eval <- summarise_scores(eval,\ntests/testthat/test-metrics-quantile.R:483:    by = c(\ntests/testthat/test-metrics-quantile.R:484:      \"model\", \"location\", \"target_variable\",\ntests/testthat/test-metrics-quantile.R:485:      \"target_end_date\", \"forecast_date\", \"horizon\"\ntests/testthat/test-metrics-quantile.R:486:    )\ntests/testthat/test-metrics-quantile.R:487:  )\ntests/testthat/test-metrics-quantile.R:488:\ntests/testthat/test-metrics-quantile.R:489:  alpha1 <- 0.2\ntests/testthat/test-metrics-quantile.R:490:  alpha2 <- 0.5\ntests/testthat/test-metrics-quantile.R:491:  expected <- (1 / 2.5) * (\ntests/testthat/test-metrics-quantile.R:492:    0.5 * abs(y - forecast_quantiles_matrix[, 3]) +\ntests/testthat/test-metrics-quantile.R:493:      (forecast_quantiles_matrix[, 5] - forecast_quantiles_matrix[, 1]) * (alpha1 / 2) + c(0, (-2) - (-15), 22 - 4) +\ntests/testthat/test-metrics-quantile.R:494:      (forecast_quantiles_matrix[, 4] - forecast_quantiles_matrix[, 2]) * (alpha2 / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:495:  )\ntests/testthat/test-metrics-quantile.R:496:\ntests/testthat/test-metrics-quantile.R:497:  actual_wis <- wis(\ntests/testthat/test-metrics-quantile.R:498:    observed = y,\ntests/testthat/test-metrics-quantile.R:499:    predicted = forecast_quantiles_matrix,\ntests/testthat/test-metrics-quantile.R:500:    quantile_level = c(0.1, 0.25, 0.5, 0.75, 0.9),\ntests/testthat/test-metrics-quantile.R:501:    count_median_twice = FALSE\ntests/testthat/test-metrics-quantile.R:502:  )\ntests/testthat/test-metrics-quantile.R:503:  expect_equal(eval$wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:504:  expect_equal(actual_wis, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:505:\ntests/testthat/test-metrics-quantile.R:506:  # check whether `count_median_twice = TRUE` also works\ntests/testthat/test-metrics-quantile.R:507:  expected2 <- (1 / 3) * (\ntests/testthat/test-metrics-quantile.R:508:    abs(y - forecast_quantiles_matrix[, 3]) +\ntests/testthat/test-metrics-quantile.R:509:      (forecast_quantiles_matrix[, 5] - forecast_quantiles_matrix[, 1]) * (alpha1 / 2) + c(0, (-2) - (-15), 22 - 4) +\ntests/testthat/test-metrics-quantile.R:510:      (forecast_quantiles_matrix[, 4] - forecast_quantiles_matrix[, 2]) * (alpha2 / 2) + c(0, 1 - (-15), 22 - 3)\ntests/testthat/test-metrics-quantile.R:511:  )\ntests/testthat/test-metrics-quantile.R:512:\ntests/testthat/test-metrics-quantile.R:513:  actual_wis2 <- wis(\ntests/testthat/test-metrics-quantile.R:514:    observed = y,\ntests/testthat/test-metrics-quantile.R:515:    predicted = forecast_quantiles_matrix,\ntests/testthat/test-metrics-quantile.R:516:    quantile_level = c(0.1, 0.25, 0.5, 0.75, 0.9),\ntests/testthat/test-metrics-quantile.R:517:    count_median_twice = TRUE\ntests/testthat/test-metrics-quantile.R:518:  )\ntests/testthat/test-metrics-quantile.R:519:\ntests/testthat/test-metrics-quantile.R:520:  metrics <- get_metrics(example_quantile, \"wis\")\ntests/testthat/test-metrics-quantile.R:521:  metrics$wis <- purrr::partial(wis, count_median_twice = TRUE)\ntests/testthat/test-metrics-quantile.R:522:  eval2 <- eval <- score(data_formatted, metrics = metrics)\ntests/testthat/test-metrics-quantile.R:523:  eval2 <- summarise_scores(eval2,\ntests/testthat/test-metrics-quantile.R:524:    by = c(\ntests/testthat/test-metrics-quantile.R:525:      \"model\", \"location\", \"target_variable\",\ntests/testthat/test-metrics-quantile.R:526:      \"target_end_date\", \"forecast_date\", \"horizon\"\ntests/testthat/test-metrics-quantile.R:527:    )\ntests/testthat/test-metrics-quantile.R:528:  )\ntests/testthat/test-metrics-quantile.R:529:  expect_equal(eval2$wis, expected2) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:530:  expect_equal(actual_wis2, expected2) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:531:})\ntests/testthat/test-metrics-quantile.R:532:\ntests/testthat/test-metrics-quantile.R:533:test_that(\"Quantlie score and interval score yield the same result, weigh = FALSE\", {\ntests/testthat/test-metrics-quantile.R:534:  # calling quantile_score and wis should return the same result if all\ntests/testthat/test-metrics-quantile.R:535:  # quantiles form central prediction intervals\ntests/testthat/test-metrics-quantile.R:536:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:537:    quantile_score(observed, predicted, quantile_level),\ntests/testthat/test-metrics-quantile.R:538:    wis(observed, predicted, quantile_level)\ntests/testthat/test-metrics-quantile.R:539:  )\ntests/testthat/test-metrics-quantile.R:540:\ntests/testthat/test-metrics-quantile.R:541:  observed <- rnorm(10, mean = 1:10)\ntests/testthat/test-metrics-quantile.R:542:  alphas <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:543:\ntests/testthat/test-metrics-quantile.R:544:  for (alpha in alphas) {\ntests/testthat/test-metrics-quantile.R:545:    lower <- qnorm(alpha / 2, rnorm(10, mean = 1:10))\ntests/testthat/test-metrics-quantile.R:546:    upper <- qnorm((1 - alpha / 2), rnorm(10, mean = 11:20))\ntests/testthat/test-metrics-quantile.R:547:\ntests/testthat/test-metrics-quantile.R:548:    w <- FALSE\ntests/testthat/test-metrics-quantile.R:549:    is <- interval_score(\ntests/testthat/test-metrics-quantile.R:550:      observed = observed,\ntests/testthat/test-metrics-quantile.R:551:      lower = lower,\ntests/testthat/test-metrics-quantile.R:552:      upper = upper,\ntests/testthat/test-metrics-quantile.R:553:      interval_range = (1 - alpha) * 100,\ntests/testthat/test-metrics-quantile.R:554:      weigh = w\ntests/testthat/test-metrics-quantile.R:555:    )\ntests/testthat/test-metrics-quantile.R:556:\ntests/testthat/test-metrics-quantile.R:557:    wis <- wis(\ntests/testthat/test-metrics-quantile.R:558:      observed = observed,\ntests/testthat/test-metrics-quantile.R:559:      predicted = cbind(lower, upper),\ntests/testthat/test-metrics-quantile.R:560:      quantile_level = c(alpha / 2, 1 - alpha / 2),\ntests/testthat/test-metrics-quantile.R:561:      count_median_twice = FALSE,\ntests/testthat/test-metrics-quantile.R:562:      weigh = w\ntests/testthat/test-metrics-quantile.R:563:    )\ntests/testthat/test-metrics-quantile.R:564:\ntests/testthat/test-metrics-quantile.R:565:    qs_lower <- quantile_score(observed,\ntests/testthat/test-metrics-quantile.R:566:      predicted = matrix(lower),\ntests/testthat/test-metrics-quantile.R:567:      quantile_level = alpha / 2,\ntests/testthat/test-metrics-quantile.R:568:      weigh = w\ntests/testthat/test-metrics-quantile.R:569:    )\ntests/testthat/test-metrics-quantile.R:570:    qs_upper <- quantile_score(observed,\ntests/testthat/test-metrics-quantile.R:571:      predicted = matrix(upper),\ntests/testthat/test-metrics-quantile.R:572:      quantile_level = 1 - alpha / 2,\ntests/testthat/test-metrics-quantile.R:573:      weigh = w\ntests/testthat/test-metrics-quantile.R:574:    )\ntests/testthat/test-metrics-quantile.R:575:    expect_equal((qs_lower + qs_upper) / 2, is) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:576:    expect_equal(wis, is) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:577:  }\ntests/testthat/test-metrics-quantile.R:578:})\ntests/testthat/test-metrics-quantile.R:579:\ntests/testthat/test-metrics-quantile.R:580:\ntests/testthat/test-metrics-quantile.R:581:test_that(\"wis errors when there are no valid forecast intervals\", {\ntests/testthat/test-metrics-quantile.R:582:  # test that wis throws an error when there are no valid forecast intervals\ntests/testthat/test-metrics-quantile.R:583:  # (i.e. the quantiles do not form central prediction intervals)\ntests/testthat/test-metrics-quantile.R:584:  observed <- 0.1\ntests/testthat/test-metrics-quantile.R:585:  predicted <- c(\ntests/testthat/test-metrics-quantile.R:586:    0.1032978, 0.1078166, 0.1906849, 0.1969254, 0.2017249,\ntests/testthat/test-metrics-quantile.R:587:    0.2078487, 0.2810377, 0.3062168, 0.4006721, 0.8219655\ntests/testthat/test-metrics-quantile.R:588:  )\ntests/testthat/test-metrics-quantile.R:589:  quantile_level <- c(\ntests/testthat/test-metrics-quantile.R:590:    0.600, 0.650, 0.700, 0.750, 0.800,\ntests/testthat/test-metrics-quantile.R:591:    0.850, 0.900, 0.950, 0.975, 0.990\ntests/testthat/test-metrics-quantile.R:592:  )\ntests/testthat/test-metrics-quantile.R:593:\ntests/testthat/test-metrics-quantile.R:594:  expect_error(\ntests/testthat/test-metrics-quantile.R:595:    wis(observed, predicted, quantile_level),\ntests/testthat/test-metrics-quantile.R:596:    \"No valid forecast intervals found.\"\ntests/testthat/test-metrics-quantile.R:597:  )\ntests/testthat/test-metrics-quantile.R:598:})\ntests/testthat/test-metrics-quantile.R:599:\ntests/testthat/test-metrics-quantile.R:600:\ntests/testthat/test-metrics-quantile.R:601:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:602:# Quantile score ============================================================= #\ntests/testthat/test-metrics-quantile.R:603:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:604:test_that(\"Quantlie score and interval score yield the same result, weigh = TRUE\", {\ntests/testthat/test-metrics-quantile.R:605:  observed <- rnorm(10, mean = 1:10)\ntests/testthat/test-metrics-quantile.R:606:  alphas <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:607:\ntests/testthat/test-metrics-quantile.R:608:  for (alpha in alphas) {\ntests/testthat/test-metrics-quantile.R:609:    lower <- qnorm(alpha / 2, rnorm(10, mean = 1:10))\ntests/testthat/test-metrics-quantile.R:610:    upper <- qnorm((1 - alpha / 2), rnorm(10, mean = 11:20))\ntests/testthat/test-metrics-quantile.R:611:\ntests/testthat/test-metrics-quantile.R:612:    w <- TRUE\ntests/testthat/test-metrics-quantile.R:613:    is <- interval_score(\ntests/testthat/test-metrics-quantile.R:614:      observed = observed,\ntests/testthat/test-metrics-quantile.R:615:      lower = lower,\ntests/testthat/test-metrics-quantile.R:616:      upper = upper,\ntests/testthat/test-metrics-quantile.R:617:      interval_range = (1 - alpha) * 100,\ntests/testthat/test-metrics-quantile.R:618:      weigh = w\ntests/testthat/test-metrics-quantile.R:619:    )\ntests/testthat/test-metrics-quantile.R:620:\ntests/testthat/test-metrics-quantile.R:621:    wis <- wis(\ntests/testthat/test-metrics-quantile.R:622:      observed = observed,\ntests/testthat/test-metrics-quantile.R:623:      predicted = cbind(lower, upper),\ntests/testthat/test-metrics-quantile.R:624:      quantile_level = c(alpha / 2, 1 - alpha / 2),\ntests/testthat/test-metrics-quantile.R:625:      count_median_twice = FALSE,\ntests/testthat/test-metrics-quantile.R:626:      weigh = w\ntests/testthat/test-metrics-quantile.R:627:    )\ntests/testthat/test-metrics-quantile.R:628:\ntests/testthat/test-metrics-quantile.R:629:    qs_lower <- quantile_score(observed,\ntests/testthat/test-metrics-quantile.R:630:      predicted = matrix(lower),\ntests/testthat/test-metrics-quantile.R:631:      quantile_level = alpha / 2,\ntests/testthat/test-metrics-quantile.R:632:      weigh = w\ntests/testthat/test-metrics-quantile.R:633:    )\ntests/testthat/test-metrics-quantile.R:634:    qs_upper <- quantile_score(observed,\ntests/testthat/test-metrics-quantile.R:635:      predicted = matrix(upper),\ntests/testthat/test-metrics-quantile.R:636:      quantile_level = 1 - alpha / 2,\ntests/testthat/test-metrics-quantile.R:637:      weigh = w\ntests/testthat/test-metrics-quantile.R:638:    )\ntests/testthat/test-metrics-quantile.R:639:    expect_equal((qs_lower + qs_upper) / 2, is) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:640:    expect_equal(wis, is) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:641:  }\ntests/testthat/test-metrics-quantile.R:642:})\ntests/testthat/test-metrics-quantile.R:643:\ntests/testthat/test-metrics-quantile.R:644:test_that(\"wis works with separate results\", {\ntests/testthat/test-metrics-quantile.R:645:  wis <- wis(\ntests/testthat/test-metrics-quantile.R:646:    observed = y,\ntests/testthat/test-metrics-quantile.R:647:    predicted = forecast_quantiles_matrix,\ntests/testthat/test-metrics-quantile.R:648:    quantile_level = forecast_quantile_probs,\ntests/testthat/test-metrics-quantile.R:649:    separate_results = TRUE\ntests/testthat/test-metrics-quantile.R:650:  )\ntests/testthat/test-metrics-quantile.R:651:  expect_equal(wis$wis, wis$dispersion + wis$overprediction + wis$underprediction) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:652:})\ntests/testthat/test-metrics-quantile.R:653:\ntests/testthat/test-metrics-quantile.R:654:\ntests/testthat/test-metrics-quantile.R:655:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:656:# overprediction, underprediction, dispersion ================================ #\ntests/testthat/test-metrics-quantile.R:657:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:658:test_that(\"wis is the sum of overprediction, underprediction, dispersion\", {\ntests/testthat/test-metrics-quantile.R:659:  wis <- wis(\ntests/testthat/test-metrics-quantile.R:660:    observed = y,\ntests/testthat/test-metrics-quantile.R:661:    predicted = forecast_quantiles_matrix,\ntests/testthat/test-metrics-quantile.R:662:    quantile_level = forecast_quantile_probs\ntests/testthat/test-metrics-quantile.R:663:  )\ntests/testthat/test-metrics-quantile.R:664:\ntests/testthat/test-metrics-quantile.R:665:  d <- dispersion_quantile(y, forecast_quantiles_matrix, forecast_quantile_probs)\ntests/testthat/test-metrics-quantile.R:666:  o <- overprediction_quantile(y, forecast_quantiles_matrix, forecast_quantile_probs)\ntests/testthat/test-metrics-quantile.R:667:  u <- underprediction_quantile(y, forecast_quantiles_matrix, forecast_quantile_probs)\ntests/testthat/test-metrics-quantile.R:668:\ntests/testthat/test-metrics-quantile.R:669:  expect_equal(wis, d + o + u) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:670:})\ntests/testthat/test-metrics-quantile.R:671:\ntests/testthat/test-metrics-quantile.R:672:\ntests/testthat/test-metrics-quantile.R:673:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:674:# `interval_coverage` =============================================== #\ntests/testthat/test-metrics-quantile.R:675:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:676:test_that(\"interval_coverage works\", {\ntests/testthat/test-metrics-quantile.R:677:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:678:    interval_coverage(observed, predicted, quantile_level, interval_range = 50),\ntests/testthat/test-metrics-quantile.R:679:    c(TRUE, FALSE, FALSE)\ntests/testthat/test-metrics-quantile.R:680:  )\ntests/testthat/test-metrics-quantile.R:681:})\ntests/testthat/test-metrics-quantile.R:682:\ntests/testthat/test-metrics-quantile.R:683:test_that(\"interval_coverage rejects wrong inputs\", {\ntests/testthat/test-metrics-quantile.R:684:  expect_error(\ntests/testthat/test-metrics-quantile.R:685:    interval_coverage(observed, predicted, quantile_level, interval_range = c(50, 0)),\ntests/testthat/test-metrics-quantile.R:686:    \"Assertion on 'interval_range' failed: Must have length 1.\"\ntests/testthat/test-metrics-quantile.R:687:  )\ntests/testthat/test-metrics-quantile.R:688:})\ntests/testthat/test-metrics-quantile.R:689:\ntests/testthat/test-metrics-quantile.R:690:test_that(\"interval_coverage_quantile throws a warning when a required quantile is not available\", {\ntests/testthat/test-metrics-quantile.R:691:  dropped_quantile_pred <- predicted[, -4]\ntests/testthat/test-metrics-quantile.R:692:  dropped_quantiles <- quantile_level[-4]\ntests/testthat/test-metrics-quantile.R:693:  expect_error(\ntests/testthat/test-metrics-quantile.R:694:    interval_coverage(\ntests/testthat/test-metrics-quantile.R:695:      observed, dropped_quantile_pred, dropped_quantiles,\ntests/testthat/test-metrics-quantile.R:696:      interval_range = 50\ntests/testthat/test-metrics-quantile.R:697:    ),\ntests/testthat/test-metrics-quantile.R:698:    paste(\ntests/testthat/test-metrics-quantile.R:699:      \"To compute the interval coverage for an interval range of \\\"50%\\\",\",\ntests/testthat/test-metrics-quantile.R:700:      \"the 0.25 and 0.75 quantiles are required\"\ntests/testthat/test-metrics-quantile.R:701:    )\ntests/testthat/test-metrics-quantile.R:702:  )\ntests/testthat/test-metrics-quantile.R:703:})\ntests/testthat/test-metrics-quantile.R:704:\ntests/testthat/test-metrics-quantile.R:705:\ntests/testthat/test-metrics-quantile.R:706:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:707:# `bias_quantile` ============================================================ #\ntests/testthat/test-metrics-quantile.R:708:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:709:test_that(\"bias_quantile() works as expected\", {\ntests/testthat/test-metrics-quantile.R:710:  predicted <- c(1, 2, 3)\ntests/testthat/test-metrics-quantile.R:711:  quantiles <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:712:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:713:    bias_quantile(observed = 2, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:714:    0\ntests/testthat/test-metrics-quantile.R:715:  )\ntests/testthat/test-metrics-quantile.R:716:  predicted <- c(0, 1, 2)\ntests/testthat/test-metrics-quantile.R:717:  quantiles <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:718:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:719:    bias_quantile(observed = 2, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:720:    -0.8\ntests/testthat/test-metrics-quantile.R:721:  )\ntests/testthat/test-metrics-quantile.R:722:\ntests/testthat/test-metrics-quantile.R:723:  predicted <- c(\ntests/testthat/test-metrics-quantile.R:724:    705.500, 1127.000, 4006.250, 4341.500, 4709.000, 4821.996,\ntests/testthat/test-metrics-quantile.R:725:    5340.500, 5451.000, 5703.500, 6087.014, 6329.500, 6341.000,\ntests/testthat/test-metrics-quantile.R:726:    6352.500, 6594.986, 6978.500, 7231.000, 7341.500, 7860.004,\ntests/testthat/test-metrics-quantile.R:727:    7973.000, 8340.500, 8675.750, 11555.000, 11976.500\ntests/testthat/test-metrics-quantile.R:728:  )\ntests/testthat/test-metrics-quantile.R:729:\ntests/testthat/test-metrics-quantile.R:730:  quantile_level <- c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)\ntests/testthat/test-metrics-quantile.R:731:\ntests/testthat/test-metrics-quantile.R:732:  observed <- 8062\ntests/testthat/test-metrics-quantile.R:733:  expect_equal(bias_quantile(observed, predicted, quantile_level), -0.8)\ntests/testthat/test-metrics-quantile.R:734:})\ntests/testthat/test-metrics-quantile.R:735:\ntests/testthat/test-metrics-quantile.R:736:test_that(\"bias_quantile handles matrix input\", {\ntests/testthat/test-metrics-quantile.R:737:  observed <- seq(10, 0, length.out = 4)\ntests/testthat/test-metrics-quantile.R:738:  predicted <- matrix(1:12, ncol = 3)\ntests/testthat/test-metrics-quantile.R:739:  quantiles <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:740:  expect_equal(\ntests/testthat/test-metrics-quantile.R:741:    bias_quantile(observed, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:742:    c(-1.0, -0.8, 0.8, 1.0)\ntests/testthat/test-metrics-quantile.R:743:  )\ntests/testthat/test-metrics-quantile.R:744:})\ntests/testthat/test-metrics-quantile.R:745:\ntests/testthat/test-metrics-quantile.R:746:\ntests/testthat/test-metrics-quantile.R:747:test_that(\"bias_quantile() handles vector that is too long\", {\ntests/testthat/test-metrics-quantile.R:748:  predicted <- c(NA, 1, 2, 3)\ntests/testthat/test-metrics-quantile.R:749:  quantiles <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:750:\ntests/testthat/test-metrics-quantile.R:751:  expect_error(\ntests/testthat/test-metrics-quantile.R:752:    bias_quantile(observed = 2, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:753:    \"Assertion on 'quantile_level' failed: Must have length 4, but has length 3.\"\ntests/testthat/test-metrics-quantile.R:754:  )\ntests/testthat/test-metrics-quantile.R:755:})\ntests/testthat/test-metrics-quantile.R:756:\ntests/testthat/test-metrics-quantile.R:757:test_that(\"bias_quantile() handles NA values\", {\ntests/testthat/test-metrics-quantile.R:758:  predicted <- c(NA, 1, 2)\ntests/testthat/test-metrics-quantile.R:759:  quantiles <- c(0.1, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:760:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:761:    bias_quantile(observed = 2, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:762:    -0.8\ntests/testthat/test-metrics-quantile.R:763:  )\ntests/testthat/test-metrics-quantile.R:764:  predicted <- c(0, 1, 2)\ntests/testthat/test-metrics-quantile.R:765:  quantiles <- c(0.1, 0.5, NA)\ntests/testthat/test-metrics-quantile.R:766:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:767:    bias_quantile(observed = 2, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:768:    -1\ntests/testthat/test-metrics-quantile.R:769:  )\ntests/testthat/test-metrics-quantile.R:770:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:771:    bias_quantile(observed = 2, predicted, quantiles, na.rm = FALSE),\ntests/testthat/test-metrics-quantile.R:772:    NA_real_\ntests/testthat/test-metrics-quantile.R:773:  )\ntests/testthat/test-metrics-quantile.R:774:})\ntests/testthat/test-metrics-quantile.R:775:\ntests/testthat/test-metrics-quantile.R:776:test_that(\"bias_quantile() errors if no predictions\", {\ntests/testthat/test-metrics-quantile.R:777:  expect_error(\ntests/testthat/test-metrics-quantile.R:778:    bias_quantile(observed = 2, numeric(0), numeric(0)),\ntests/testthat/test-metrics-quantile.R:779:    \"Assertion on 'quantile_level' failed: Must have length >= 1, but has length 0\"\ntests/testthat/test-metrics-quantile.R:780:  )\ntests/testthat/test-metrics-quantile.R:781:})\ntests/testthat/test-metrics-quantile.R:782:\ntests/testthat/test-metrics-quantile.R:783:test_that(\"bias_quantile() returns correct bias if value below the median\", {\ntests/testthat/test-metrics-quantile.R:784:  predicted <- c(1, 2, 4, 5)\ntests/testthat/test-metrics-quantile.R:785:  quantiles <- c(0.1, 0.3, 0.7, 0.9)\ntests/testthat/test-metrics-quantile.R:786:  suppressMessages(\ntests/testthat/test-metrics-quantile.R:787:    expect_equal(bias_quantile(observed = 1, predicted, quantiles), 0.8)\ntests/testthat/test-metrics-quantile.R:788:  )\ntests/testthat/test-metrics-quantile.R:789:})\ntests/testthat/test-metrics-quantile.R:790:\ntests/testthat/test-metrics-quantile.R:791:test_that(\"bias_quantile() returns correct bias if value above median\", {\ntests/testthat/test-metrics-quantile.R:792:  predicted <- c(1, 2, 4, 5)\ntests/testthat/test-metrics-quantile.R:793:  quantiles <- c(0.1, 0.3, 0.7, 0.9)\ntests/testthat/test-metrics-quantile.R:794:  suppressMessages(\ntests/testthat/test-metrics-quantile.R:795:    expect_equal(bias_quantile(observed = 5, predicted, quantiles), -0.8)\ntests/testthat/test-metrics-quantile.R:796:  )\ntests/testthat/test-metrics-quantile.R:797:})\ntests/testthat/test-metrics-quantile.R:798:\ntests/testthat/test-metrics-quantile.R:799:test_that(\"bias_quantile() returns correct bias if value at the median\", {\ntests/testthat/test-metrics-quantile.R:800:  predicted <- c(1, 2, 3, 4)\ntests/testthat/test-metrics-quantile.R:801:  quantiles <- c(0.1, 0.3, 0.5, 0.7)\ntests/testthat/test-metrics-quantile.R:802:\ntests/testthat/test-metrics-quantile.R:803:  expect_equal(bias_quantile(observed = 3, predicted, quantiles), 0) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:804:})\ntests/testthat/test-metrics-quantile.R:805:\ntests/testthat/test-metrics-quantile.R:806:test_that(\"bias_quantile() returns 1 if true value below min prediction\", {\ntests/testthat/test-metrics-quantile.R:807:  predicted <- c(2, 3, 4, 5)\ntests/testthat/test-metrics-quantile.R:808:  quantiles <- c(0.1, 0.3, 0.7, 0.9)\ntests/testthat/test-metrics-quantile.R:809:\ntests/testthat/test-metrics-quantile.R:810:  suppressMessages(\ntests/testthat/test-metrics-quantile.R:811:    expect_equal(bias_quantile(observed = 1, predicted, quantiles), 1) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:812:  )\ntests/testthat/test-metrics-quantile.R:813:})\ntests/testthat/test-metrics-quantile.R:814:\ntests/testthat/test-metrics-quantile.R:815:test_that(\"bias_quantile() returns -1 if true value above max prediction\", {\ntests/testthat/test-metrics-quantile.R:816:  predicted <- c(1, 2, 3, 4)\ntests/testthat/test-metrics-quantile.R:817:  quantiles <- c(0.1, 0.3, 0.5, 0.7)\ntests/testthat/test-metrics-quantile.R:818:\ntests/testthat/test-metrics-quantile.R:819:  expect_equal(bias_quantile(observed = 6, predicted, quantiles), -1) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:820:})\ntests/testthat/test-metrics-quantile.R:821:\ntests/testthat/test-metrics-quantile.R:822:test_that(\"bias_quantile(): quantiles must be between 0 and 1\", {\ntests/testthat/test-metrics-quantile.R:823:  predicted <- 1:4\ntests/testthat/test-metrics-quantile.R:824:\ntests/testthat/test-metrics-quantile.R:825:  # Failing example\ntests/testthat/test-metrics-quantile.R:826:  quantiles <- c(-0.1, 0.3, 0.5, 0.8)\ntests/testthat/test-metrics-quantile.R:827:  expect_error(\ntests/testthat/test-metrics-quantile.R:828:    bias_quantile(observed = 3, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:829:    \"Assertion on 'quantile_level' failed: Element 1 is not >= 0.\"\ntests/testthat/test-metrics-quantile.R:830:  )\ntests/testthat/test-metrics-quantile.R:831:\ntests/testthat/test-metrics-quantile.R:832:  # Passing counter example\ntests/testthat/test-metrics-quantile.R:833:  quantiles <- c(0.1, 0.3, 0.5, 0.8)\ntests/testthat/test-metrics-quantile.R:834:  expect_silent(bias_quantile(observed = 3, predicted, quantiles))\ntests/testthat/test-metrics-quantile.R:835:})\ntests/testthat/test-metrics-quantile.R:836:\ntests/testthat/test-metrics-quantile.R:837:test_that(\"bias_quantile(): quantiles must be increasing\", {\ntests/testthat/test-metrics-quantile.R:838:  predicted <- 1:4\ntests/testthat/test-metrics-quantile.R:839:\ntests/testthat/test-metrics-quantile.R:840:  # Failing example\ntests/testthat/test-metrics-quantile.R:841:  quantiles <- c(0.8, 0.3, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:842:  expect_error(\ntests/testthat/test-metrics-quantile.R:843:    bias_quantile(observed = 3, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:844:    \"Predictions must not be decreasing with increasing quantile level\"\ntests/testthat/test-metrics-quantile.R:845:  )\ntests/testthat/test-metrics-quantile.R:846:\ntests/testthat/test-metrics-quantile.R:847:  # Passing counter example\ntests/testthat/test-metrics-quantile.R:848:  quantiles <- c(0.3, 0.5, 0.8, 0.9)\ntests/testthat/test-metrics-quantile.R:849:  expect_silent(bias_quantile(observed = 3, predicted, quantiles))\ntests/testthat/test-metrics-quantile.R:850:})\ntests/testthat/test-metrics-quantile.R:851:\ntests/testthat/test-metrics-quantile.R:852:test_that(\"bias_quantile(): predictions must be increasing\", {\ntests/testthat/test-metrics-quantile.R:853:  predicted <- c(1, 2, 4, 3)\ntests/testthat/test-metrics-quantile.R:854:  quantiles <- c(0.1, 0.3, 0.5, 0.9)\ntests/testthat/test-metrics-quantile.R:855:\ntests/testthat/test-metrics-quantile.R:856:  expect_error(\ntests/testthat/test-metrics-quantile.R:857:    bias_quantile(observed = 3, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:858:    \"Predictions must not be decreasing with increasing quantile level\"\ntests/testthat/test-metrics-quantile.R:859:  )\ntests/testthat/test-metrics-quantile.R:860:  expect_silent(bias_quantile(observed = 3, 1:4, quantiles))\ntests/testthat/test-metrics-quantile.R:861:})\ntests/testthat/test-metrics-quantile.R:862:\ntests/testthat/test-metrics-quantile.R:863:test_that(\"bias_quantile(): quantile levels must be unique\", {\ntests/testthat/test-metrics-quantile.R:864:  predicted <- 1:4\ntests/testthat/test-metrics-quantile.R:865:\ntests/testthat/test-metrics-quantile.R:866:  # Failing example\ntests/testthat/test-metrics-quantile.R:867:  quantiles <- c(0.3, 0.3, 0.5, 0.8)\ntests/testthat/test-metrics-quantile.R:868:  expect_error(\ntests/testthat/test-metrics-quantile.R:869:    bias_quantile(observed = 3, predicted, quantiles),\ntests/testthat/test-metrics-quantile.R:870:    \"Assertion on 'quantile_level' failed: Contains duplicated values, position 2.\"\ntests/testthat/test-metrics-quantile.R:871:  )\ntests/testthat/test-metrics-quantile.R:872:\ntests/testthat/test-metrics-quantile.R:873:  # Passing example\ntests/testthat/test-metrics-quantile.R:874:  quantiles <- c(0.3, 0.5, 0.8, 0.9)\ntests/testthat/test-metrics-quantile.R:875:  expect_silent(bias_quantile(observed = 3, predicted, quantiles))\ntests/testthat/test-metrics-quantile.R:876:})\ntests/testthat/test-metrics-quantile.R:877:\ntests/testthat/test-metrics-quantile.R:878:test_that(\"bias_quantile only produces one message\", {\ntests/testthat/test-metrics-quantile.R:879:  expect_message(\ntests/testthat/test-metrics-quantile.R:880:    bias_quantile(observed, predicted[, -3], quantile_level[-3]),\ntests/testthat/test-metrics-quantile.R:881:    \"Median not available, interpolating median from the two innermost quantiles in order to compute bias.\"\ntests/testthat/test-metrics-quantile.R:882:  )\ntests/testthat/test-metrics-quantile.R:883:})\ntests/testthat/test-metrics-quantile.R:884:\ntests/testthat/test-metrics-quantile.R:885:test_that(\"bias_quantile() works with point forecasts\", {\ntests/testthat/test-metrics-quantile.R:886:  predicted <- 1\ntests/testthat/test-metrics-quantile.R:887:  observed <- 1\ntests/testthat/test-metrics-quantile.R:888:  quantile_level <- 0.5\ntests/testthat/test-metrics-quantile.R:889:  expect_equal(bias_quantile(observed, predicted, quantile_level), 0) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:890:})\ntests/testthat/test-metrics-quantile.R:891:\ntests/testthat/test-metrics-quantile.R:892:\ntests/testthat/test-metrics-quantile.R:893:test_that(\"bias_quantile() handles cases where median is not available\", {\ntests/testthat/test-metrics-quantile.R:894:  predicted <- c(1, 10)\ntests/testthat/test-metrics-quantile.R:895:  observed <- 15\ntests/testthat/test-metrics-quantile.R:896:  quantile_level <- c(0.2, 0.4)\ntests/testthat/test-metrics-quantile.R:897:\ntests/testthat/test-metrics-quantile.R:898:  expect_error(\ntests/testthat/test-metrics-quantile.R:899:    bias_quantile(observed, predicted, quantile_level),\ntests/testthat/test-metrics-quantile.R:900:    \"Assertion on 'quantile_level\\\\[quantile_leve\\\\l >= 0.5]' failed: Must have length >= 1, but has length 0.\"\ntests/testthat/test-metrics-quantile.R:901:  )\ntests/testthat/test-metrics-quantile.R:902:})\ntests/testthat/test-metrics-quantile.R:903:\ntests/testthat/test-metrics-quantile.R:904:# `interpolate_median` ======================================================= #\ntests/testthat/test-metrics-quantile.R:905:test_that(\"interpolation in `interpolate_median` works\", {\ntests/testthat/test-metrics-quantile.R:906:  predicted <- c(1, 10)\ntests/testthat/test-metrics-quantile.R:907:  observed <- 15\ntests/testthat/test-metrics-quantile.R:908:  quantile_level <- c(0.4, 0.6)\ntests/testthat/test-metrics-quantile.R:909:\ntests/testthat/test-metrics-quantile.R:910:  # median is missing, symmetric quantile levels given\ntests/testthat/test-metrics-quantile.R:911:  expect_equal(interpolate_median(predicted, quantile_level), mean(predicted)) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:912:  quantile_level <- c(0.1, 0.9)\ntests/testthat/test-metrics-quantile.R:913:  expect_equal(interpolate_median(predicted, quantile_level), mean(predicted)) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:914:\ntests/testthat/test-metrics-quantile.R:915:  1 + 0.4 / 0.8 * (10 - 1)\ntests/testthat/test-metrics-quantile.R:916:\ntests/testthat/test-metrics-quantile.R:917:  # asymmetric quantile levels given\ntests/testthat/test-metrics-quantile.R:918:  quantile_level <- c(0.3, 0.6)\ntests/testthat/test-metrics-quantile.R:919:  expect_equal(interpolate_median(predicted, quantile_level), 1 + 0.2 / 0.3 * (10 - 1)) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:920:\ntests/testthat/test-metrics-quantile.R:921:  quantile_level <- c(0.2, 0.6)\ntests/testthat/test-metrics-quantile.R:922:  expect_equal(interpolate_median(predicted, quantile_level), 1 + 0.3 / 0.4 * (10 - 1)) # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:923:})\ntests/testthat/test-metrics-quantile.R:924:\ntests/testthat/test-metrics-quantile.R:925:\ntests/testthat/test-metrics-quantile.R:926:\ntests/testthat/test-metrics-quantile.R:927:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:928:# `ae_median_quantile` ======================================================= #\ntests/testthat/test-metrics-quantile.R:929:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:930:\ntests/testthat/test-metrics-quantile.R:931:test_that(\"ae_median_quantile() works as_expected\", {\ntests/testthat/test-metrics-quantile.R:932:  observed <- 1:30\ntests/testthat/test-metrics-quantile.R:933:  predicted_values <- matrix(2:31)\ntests/testthat/test-metrics-quantile.R:934:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:935:    ae_median_quantile(observed, predicted_values, quantile_level = 0.5),\ntests/testthat/test-metrics-quantile.R:936:    as.numeric(predicted_values - observed)\ntests/testthat/test-metrics-quantile.R:937:  )\ntests/testthat/test-metrics-quantile.R:938:\ntests/testthat/test-metrics-quantile.R:939:  # using a vector as input for predicted does not work if there are several\ntests/testthat/test-metrics-quantile.R:940:  # observed values\ntests/testthat/test-metrics-quantile.R:941:  expect_error(\ntests/testthat/test-metrics-quantile.R:942:    ae_median_quantile(observed, as.numeric(predicted_values), quantile_level = 0.5),\ntests/testthat/test-metrics-quantile.R:943:    \"Assertion on 'predicted' failed: Must be of type 'matrix', not 'double'.\"\ntests/testthat/test-metrics-quantile.R:944:  )\ntests/testthat/test-metrics-quantile.R:945:\ntests/testthat/test-metrics-quantile.R:946:  # it does work if there is only a single observed value - in this case\ntests/testthat/test-metrics-quantile.R:947:  # the vector gets treated as one forecast - which means that we need to\ntests/testthat/test-metrics-quantile.R:948:  # supply multiple quantile levels now, because it assumes that single forecast\ntests/testthat/test-metrics-quantile.R:949:  # is represented by several quantiles\ntests/testthat/test-metrics-quantile.R:950:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:951:    ae_median_quantile(observed[1], as.numeric(predicted_values)[1:3], quantile_level = c(0.1, 0.5, 0.7)),\ntests/testthat/test-metrics-quantile.R:952:    2\ntests/testthat/test-metrics-quantile.R:953:  )\ntests/testthat/test-metrics-quantile.R:954:\ntests/testthat/test-metrics-quantile.R:955:  # test that we get a warning if there are inputs without a 0.5 quantile\ntests/testthat/test-metrics-quantile.R:956:  expect_error(\ntests/testthat/test-metrics-quantile.R:957:    ae_median_quantile(observed, predicted_values, quantile_level = 0.6),\ntests/testthat/test-metrics-quantile.R:958:    \"In order to compute the absolute error of the median, \"\ntests/testthat/test-metrics-quantile.R:959:  )\ntests/testthat/test-metrics-quantile.R:960:})\ntests/testthat/test-metrics-quantile.R:961:\ntests/testthat/test-metrics-quantile.R:962:\ntests/testthat/test-metrics-quantile.R:963:\ntests/testthat/test-metrics-quantile.R:964:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:965:# quantile_score() =============================================================\ntests/testthat/test-metrics-quantile.R:966:# ============================================================================ #\ntests/testthat/test-metrics-quantile.R:967:test_that(\"quantile_score() works regardless of whether input is vector or matrix\", {\ntests/testthat/test-metrics-quantile.R:968:  observed <- rnorm(1, mean = 2)\ntests/testthat/test-metrics-quantile.R:969:  alpha <- seq(0.2, 0.8, 0.2)\ntests/testthat/test-metrics-quantile.R:970:  predicted <- rnorm(4, mean = 1:4)\ntests/testthat/test-metrics-quantile.R:971:\ntests/testthat/test-metrics-quantile.R:972:\ntests/testthat/test-metrics-quantile.R:973:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-quantile.R:974:    quantile_score(observed, predicted, quantile_level = alpha),\ntests/testthat/test-metrics-quantile.R:975:    quantile_score(observed, t(matrix(predicted)), quantile_level = alpha)\ntests/testthat/test-metrics-quantile.R:976:  )\ntests/testthat/test-metrics-quantile.R:977:})\ntests/testthat/test-score.R:1:# =============================================================================\ntests/testthat/test-score.R:2:# new_scores() # nolint: commented_code_linter\ntests/testthat/test-score.R:3:# =============================================================================\ntests/testthat/test-score.R:4:\ntests/testthat/test-score.R:5:test_that(\"new_scores() works\", {\ntests/testthat/test-score.R:6:  expect_s3_class(\ntests/testthat/test-score.R:7:    new_scores(data.frame(), metrics = \"\"),\ntests/testthat/test-score.R:8:    c(\"scores\", \"data.table\", \"data.frame\"),\ntests/testthat/test-score.R:9:    exact = TRUE\ntests/testthat/test-score.R:10:  )\ntests/testthat/test-score.R:11:\ntests/testthat/test-score.R:12:  expect_error(\ntests/testthat/test-score.R:13:    new_scores(data.frame()),\ntests/testthat/test-score.R:14:    \"missing, with no default\"\ntests/testthat/test-score.R:15:  )\ntests/testthat/test-score.R:16:})\ntests/testthat/test-score.R:17:\ntests/testthat/test-score.R:18:test_that(\"as_scores() works\", {\ntests/testthat/test-score.R:19:  expect_s3_class(\ntests/testthat/test-score.R:20:    scoringutils:::as_scores(data.frame(wis = 1), metrics = \"wis\"), # nolint: undesirable_operator_linter\ntests/testthat/test-score.R:21:    c(\"scores\", \"data.table\", \"data.frame\")\ntests/testthat/test-score.R:22:  )\ntests/testthat/test-score.R:23:})\ntests/testthat/test-score.R:24:\ntests/testthat/test-score.R:25:test_that(\"assert_scores() works\", {\ntests/testthat/test-score.R:26:  expect_error(\ntests/testthat/test-score.R:27:    assert_scores(data.frame()),\ntests/testthat/test-score.R:28:    \"Must inherit from class 'scores'\"\ntests/testthat/test-score.R:29:  )\ntests/testthat/test-score.R:30:})\ntests/testthat/test-score.R:31:\ntests/testthat/test-score.R:32:test_that(\"Output of `score()` has the class `scores()`\", {\ntests/testthat/test-score.R:33:  expect_no_condition(assert_scores(scores_point))\ntests/testthat/test-score.R:34:  expect_no_condition(assert_scores(scores_binary))\ntests/testthat/test-score.R:35:  expect_no_condition(assert_scores(scores_sample_continuous))\ntests/testthat/test-score.R:36:  expect_no_condition(assert_scores(scores_quantile))\ntests/testthat/test-score.R:37:})\ntests/testthat/test-score.R:38:\ntests/testthat/test-score.R:39:# =============================================================================\ntests/testthat/test-score.R:40:# score() # nolint: commented_code_linter\ntests/testthat/test-score.R:41:# =============================================================================\ntests/testthat/test-score.R:42:\ntests/testthat/test-score.R:43:# common error handling --------------------------------------------------------\ntests/testthat/test-score.R:44:test_that(\"function throws an error if data is not a forecast object\", {\ntests/testthat/test-score.R:45:  expect_error(\ntests/testthat/test-score.R:46:    score(forecast = NULL),\ntests/testthat/test-score.R:47:    \"The input needs to be a valid forecast object.\"\ntests/testthat/test-score.R:48:  )\ntests/testthat/test-score.R:49:})\ntests/testthat/test-score.R:50:\ntests/testthat/test-score.R:51:test_that(\"Manipulating scores objects with .[ works as expected\", {\ntests/testthat/test-score.R:52:  expect_no_condition(scores_point[1:10])\ntests/testthat/test-score.R:53:\ntests/testthat/test-score.R:54:  expect_no_condition(scores_point[, .(model, ae_point)])\ntests/testthat/test-score.R:55:\ntests/testthat/test-score.R:56:  ex <- score(example_quantile)\ntests/testthat/test-score.R:57:  expect_no_condition(ex[, extra_col := \"something\"])\ntests/testthat/test-score.R:58:})\ntests/testthat/test-score.R:59:\ntests/testthat/test-score.R:60:\ntests/testthat/test-score.R:61:# test integer and continuous case ---------------------------------------------\ntests/testthat/test-score.R:62:test_that(\"function produces output for a continuous format case\", {\ntests/testthat/test-score.R:63:  eval <- scores_sample_continuous\ntests/testthat/test-score.R:64:\ntests/testthat/test-score.R:65:  # [.forecast()` will warn even before score()\ntests/testthat/test-score.R:66:  only_nas <- suppressWarnings(\ntests/testthat/test-score.R:67:    copy(example_sample_continuous)[, predicted := NA_real_]\ntests/testthat/test-score.R:68:  )\ntests/testthat/test-score.R:69:  expect_error(\ntests/testthat/test-score.R:70:    score(as_forecast_sample(only_nas)),\ntests/testthat/test-score.R:71:    \"After removing rows with NA values in the data, no forecasts are left.\"\ntests/testthat/test-score.R:72:  )\ntests/testthat/test-score.R:73:\ntests/testthat/test-score.R:74:  expect_gt(\ntests/testthat/test-score.R:75:    nrow(eval), 1\ntests/testthat/test-score.R:76:  )\ntests/testthat/test-score.R:77:\ntests/testthat/test-score.R:78:  expect_identical(\ntests/testthat/test-score.R:79:    nrow(eval),\ntests/testthat/test-score.R:80:    887L\ntests/testthat/test-score.R:81:  )\ntests/testthat/test-score.R:82:\ntests/testthat/test-score.R:83:  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-score.R:84:})\ntests/testthat/test-score.R:85:\ntests/testthat/test-score.R:86:test_that(\"function throws an error if data is missing\", {\ntests/testthat/test-score.R:87:  expect_error(suppressMessages(score(forecast = NULL)))\ntests/testthat/test-score.R:88:})\ntests/testthat/test-score.R:89:\ntests/testthat/test-score.R:90:test_that(\"score() works with only one sample\", {\ntests/testthat/test-score.R:91:  # with only one sample, dss returns NaN and log_score fails\ntests/testthat/test-score.R:92:  onesample <- na.omit(example_sample_continuous)[sample_id == 20]\ntests/testthat/test-score.R:93:  scoreonesample <- suppressWarnings(score(onesample))\ntests/testthat/test-score.R:94:  expect_warning(\ntests/testthat/test-score.R:95:    score(onesample),\ntests/testthat/test-score.R:96:    \"Computation for `log_score` failed. Error: need at least 2 data points.\"\ntests/testthat/test-score.R:97:  )\ntests/testthat/test-score.R:98:\ntests/testthat/test-score.R:99:  # verify that all goes well with two samples\ntests/testthat/test-score.R:100:  twosample <- na.omit(example_sample_continuous)[sample_id %in% c(20, 21)]\ntests/testthat/test-score.R:101:  expect_no_condition(score(twosample))\ntests/testthat/test-score.R:102:})\ntests/testthat/test-score.R:103:\ntests/testthat/test-score.R:104:\ntests/testthat/test-score.R:105:# test nominal case ------------------------------------------------------------\ntests/testthat/test-score.R:106:test_that(\"function produces output for a nominal format case\", {\ntests/testthat/test-score.R:107:  expect_no_condition(score(as_forecast_nominal(na.omit(example_nominal))))\ntests/testthat/test-score.R:108:})\ntests/testthat/test-score.R:109:\ntests/testthat/test-score.R:110:\ntests/testthat/test-score.R:111:# =============================================================================\ntests/testthat/test-score.R:112:# apply_metrics() # nolint: commented_code_linter\ntests/testthat/test-score.R:113:# =============================================================================\ntests/testthat/test-score.R:114:\ntests/testthat/test-score.R:115:test_that(\"apply_metrics() works\", {\ntests/testthat/test-score.R:116:  dt <- data.table::data.table(x = 1:10)\ntests/testthat/test-score.R:117:  scoringutils:::apply_metrics( # nolint: undesirable_operator_linter\ntests/testthat/test-score.R:118:    forecast = dt, metrics = list(test = function(x) x + 1),\ntests/testthat/test-score.R:119:    dt$x\ntests/testthat/test-score.R:120:  )\ntests/testthat/test-score.R:121:  expect_equal(dt$test, 2:11) # nolint: expect_identical_linter\ntests/testthat/test-score.R:122:\ntests/testthat/test-score.R:123:  # additional named argument works\ntests/testthat/test-score.R:124:  expect_no_condition(\ntests/testthat/test-score.R:125:    scoringutils:::apply_metrics( # nolint: undesirable_operator_linter\ntests/testthat/test-score.R:126:      forecast = dt, metrics = list(test = function(x) x + 1),\ntests/testthat/test-score.R:127:      dt$x, y = dt$test\ntests/testthat/test-score.R:128:    )\ntests/testthat/test-score.R:129:  )\ntests/testthat/test-score.R:130:\ntests/testthat/test-score.R:131:  # additional unnamed argument does not work\ntests/testthat/test-score.R:132:  expect_warning(\ntests/testthat/test-score.R:133:    scoringutils:::apply_metrics( # nolint: undesirable_operator_linter\ntests/testthat/test-score.R:134:      forecast = dt, metrics = list(test = function(x) x + 1),\ntests/testthat/test-score.R:135:      dt$x, dt$test\ntests/testthat/test-score.R:136:    )\ntests/testthat/test-score.R:137:  )\ntests/testthat/test-score.R:138:})\ntests/testthat/test-score.R:139:\ntests/testthat/test-score.R:140:# attributes\ntests/testthat/test-score.R:141:test_that(\"`[` preserves attributes\", {\ntests/testthat/test-score.R:142:  test <- data.table::copy(scores_binary)\ntests/testthat/test-score.R:143:  class(test) <- c(\"scores\", \"data.frame\")\ntests/testthat/test-score.R:144:  expect_true(\"metrics\" %in% names(attributes(test)))\ntests/testthat/test-score.R:145:  expect_true(\"metrics\" %in% names(attributes(test[1:9])))\ntests/testthat/test-score.R:146:})\ntests/testthat/test-score.R:147:\ntests/testthat/test-score.R:148:\ntests/testthat/test-score.R:149:# =============================================================================\ntests/testthat/test-score.R:150:# assert_scores() # nolint: commented_code_linter\ntests/testthat/test-score.R:151:# =============================================================================\ntests/testthat/test-score.R:152:test_that(\"assert_scores() works\", {\ntests/testthat/test-score.R:153:  expect_no_condition(assert_scores(scores_binary))\ntests/testthat/test-score.R:154:  expect_null(\ntests/testthat/test-score.R:155:    assert_scores(scores_binary)\ntests/testthat/test-score.R:156:  )\ntests/testthat/test-score.R:157:})\ntests/testthat/test-score.R:158:\ntests/testthat/test-score.R:159:# ==============================================================================\ntests/testthat/test-score.R:160:# validate_metrics() # nolint: commented_code_linter\ntests/testthat/test-score.R:161:# ==============================================================================\ntests/testthat/test-score.R:162:test_that(\"validate_metrics() works as expected\", {\ntests/testthat/test-score.R:163:  test_fun <- function(x, y, ...) {\ntests/testthat/test-score.R:164:    if (hasArg(\"test\")) {\ntests/testthat/test-score.R:165:      message(\"test argument found\")\ntests/testthat/test-score.R:166:    }\ntests/testthat/test-score.R:167:    return(y)\ntests/testthat/test-score.R:168:  }\ntests/testthat/test-score.R:169:  ## Additional tests for validate_metrics()\ntests/testthat/test-score.R:170:  # passing in something that's not a function or a known metric\ntests/testthat/test-score.R:171:  expect_warning(\ntests/testthat/test-score.R:172:    expect_warning(\ntests/testthat/test-score.R:173:      score(as_forecast_binary(na.omit(example_binary)), metrics = list(\ntests/testthat/test-score.R:174:        test1 = test_fun, test = test_fun, hi = \"hi\", \"2\" = 3\ntests/testthat/test-score.R:175:      )),\ntests/testthat/test-score.R:176:      \"`Metrics` element number 3 is not a valid function\"\ntests/testthat/test-score.R:177:    ),\ntests/testthat/test-score.R:178:    \"`Metrics` element number 4 is not a valid function\"\ntests/testthat/test-score.R:179:  )\ntests/testthat/test-score.R:180:})\ntests/testthat/test-score.R:181:\ntests/testthat/test-score.R:182:\ntests/testthat/test-score.R:183:# ==============================================================================\ntests/testthat/test-score.R:184:# run_safely() # nolint: commented_code_linter\ntests/testthat/test-score.R:185:# ==============================================================================\ntests/testthat/test-score.R:186:test_that(\"run_safely() works as expected\", {\ntests/testthat/test-score.R:187:  f <- function(x) {\ntests/testthat/test-score.R:188:    x\ntests/testthat/test-score.R:189:  }\ntests/testthat/test-score.R:190:  expect_identical(run_safely(2, fun = f), 2)\ntests/testthat/test-score.R:191:  expect_identical(run_safely(2, y = 3, fun = f), 2)\ntests/testthat/test-score.R:192:  expect_warning(\ntests/testthat/test-score.R:193:    run_safely(fun = f, metric_name = \"f\"),\ntests/testthat/test-score.R:194:    'Computation for `f` failed. Error: argument \"x\" is missing, with no default',\ntests/testthat/test-score.R:195:    fixed = TRUE\ntests/testthat/test-score.R:196:  )\ntests/testthat/test-score.R:197:  expect_null(suppressWarnings(run_safely(y = 3, fun = f, metric_name = \"f\")))\ntests/testthat/test-score.R:198:})\ntests/testthat/test-metrics.R:1:# ==============================================================================\ntests/testthat/test-metrics.R:2:# select_metrics() # nolint: commented_code_linter\ntests/testthat/test-metrics.R:3:# ==============================================================================\ntests/testthat/test-metrics.R:4:\ntests/testthat/test-metrics.R:5:test_that(\"`select_metrics` works as expected\", {\ntests/testthat/test-metrics.R:6:  expect_identical(\ntests/testthat/test-metrics.R:7:    scoringutils::select_metrics(get_metrics(example_point), select = NULL),\ntests/testthat/test-metrics.R:8:    get_metrics(example_point)\ntests/testthat/test-metrics.R:9:  )\ntests/testthat/test-metrics.R:10:\ntests/testthat/test-metrics.R:11:  expect_identical(\ntests/testthat/test-metrics.R:12:    scoringutils::select_metrics(get_metrics(example_point), select = NULL),\ntests/testthat/test-metrics.R:13:    scoringutils::select_metrics(get_metrics(example_point))\ntests/testthat/test-metrics.R:14:  )\ntests/testthat/test-metrics.R:15:\ntests/testthat/test-metrics.R:16:  expect_named(\ntests/testthat/test-metrics.R:17:    scoringutils::select_metrics(get_metrics(example_point), select = \"ape\"),\ntests/testthat/test-metrics.R:18:    \"ape\"\ntests/testthat/test-metrics.R:19:  )\ntests/testthat/test-metrics.R:20:\ntests/testthat/test-metrics.R:21:  expect_length(\ntests/testthat/test-metrics.R:22:    scoringutils::select_metrics(\ntests/testthat/test-metrics.R:23:      get_metrics(example_point), select = NULL, exclude = \"ape\"\ntests/testthat/test-metrics.R:24:    ),\ntests/testthat/test-metrics.R:25:    length(get_metrics(example_point)) - 1\ntests/testthat/test-metrics.R:26:  )\ntests/testthat/test-metrics.R:27:\ntests/testthat/test-metrics.R:28:  # if both select and exclude are specified, exclude is ignored\ntests/testthat/test-metrics.R:29:  expect_named(\ntests/testthat/test-metrics.R:30:    scoringutils::select_metrics(\ntests/testthat/test-metrics.R:31:      get_metrics(example_point), select = \"ape\", exclude = \"ape\"\ntests/testthat/test-metrics.R:32:    ),\ntests/testthat/test-metrics.R:33:    \"ape\"\ntests/testthat/test-metrics.R:34:  )\ntests/testthat/test-metrics.R:35:\ntests/testthat/test-metrics.R:36:  # expect error if possibilities is not a list\ntests/testthat/test-metrics.R:37:  expect_error(\ntests/testthat/test-metrics.R:38:    scoringutils::select_metrics(get_metrics, select = NULL),\ntests/testthat/test-metrics.R:39:    \"Assertion on 'metrics' failed: Must be of type 'list', not 'closure'.\"\ntests/testthat/test-metrics.R:40:  )\ntests/testthat/test-metrics.R:41:\ntests/testthat/test-metrics.R:42:  expect_type(\ntests/testthat/test-metrics.R:43:    scoringutils::select_metrics(get_metrics(example_point), select = NULL),\ntests/testthat/test-metrics.R:44:    \"list\"\ntests/testthat/test-metrics.R:45:  )\ntests/testthat/test-metrics.R:46:})\ntests/testthat/test-metrics.R:47:\ntests/testthat/test-metrics.R:48:\ntests/testthat/test-metrics.R:49:# ==============================================================================\ntests/testthat/test-metrics.R:50:# get_metrics() # nolint: commented_code_linter\ntests/testthat/test-metrics.R:51:# ==============================================================================\ntests/testthat/test-metrics.R:52:# See additional tests for individual classes.\ntests/testthat/test-metrics.R:53:test_that(\"selecting metrics in get_metrics() works as expected\", {\ntests/testthat/test-metrics.R:54:  expect_named(\ntests/testthat/test-metrics.R:55:    get_metrics(example_point, select = \"ape\"),\ntests/testthat/test-metrics.R:56:    \"ape\"\ntests/testthat/test-metrics.R:57:  )\ntests/testthat/test-metrics.R:58:\ntests/testthat/test-metrics.R:59:  expect_length(\ntests/testthat/test-metrics.R:60:    get_metrics(example_binary, select = NULL, exclude = \"brier_score\"),\ntests/testthat/test-metrics.R:61:    length(get_metrics(example_binary)) - 1\ntests/testthat/test-metrics.R:62:  )\ntests/testthat/test-metrics.R:63:\ntests/testthat/test-metrics.R:64:  # if both select and exclude are specified, exclude is ignored\ntests/testthat/test-metrics.R:65:  expect_named(\ntests/testthat/test-metrics.R:66:    scoringutils::select_metrics(\ntests/testthat/test-metrics.R:67:      get_metrics(example_quantile), select = \"wis\", exclude = \"wis\"\ntests/testthat/test-metrics.R:68:    ),\ntests/testthat/test-metrics.R:69:    \"wis\"\ntests/testthat/test-metrics.R:70:  )\ntests/testthat/test-metrics.R:71:\ntests/testthat/test-metrics.R:72:  # expect error if select is not included in the default possibilities\ntests/testthat/test-metrics.R:73:  expect_error(\ntests/testthat/test-metrics.R:74:    get_metrics(example_sample_continuous, select = \"not-included\"),\ntests/testthat/test-metrics.R:75:    \"Must be a subset of\"\ntests/testthat/test-metrics.R:76:  )\ntests/testthat/test-metrics.R:77:\ntests/testthat/test-metrics.R:78:  # expect error if exclude is not included in the default possibilities\ntests/testthat/test-metrics.R:79:  expect_error(\ntests/testthat/test-metrics.R:80:    get_metrics(example_quantile, exclude = \"not-included\"),\ntests/testthat/test-metrics.R:81:    \"Must be a subset of\"\ntests/testthat/test-metrics.R:82:  )\ntests/testthat/test-metrics.R:83:})\ntests/testthat/test-metrics.R:84:\ntests/testthat/test-metrics.R:85:\ntests/testthat/test-metrics.R:86:# ==============================================================================\ntests/testthat/test-metrics.R:87:# Customising metrics using purrr::partial()\ntests/testthat/test-metrics.R:88:# ==============================================================================\ntests/testthat/test-metrics.R:89:test_that(\"customising metrics via purr::partial works correctly\", {\ntests/testthat/test-metrics.R:90:  # Create a customised metric function\ntests/testthat/test-metrics.R:91:  custom_metric <- purrr::partial(mean, na.rm = TRUE)\ntests/testthat/test-metrics.R:92:\ntests/testthat/test-metrics.R:93:  # Use the customised metric function\ntests/testthat/test-metrics.R:94:  values <- c(1, 2, NA, 4, 5)\ntests/testthat/test-metrics.R:95:  expect_equal(custom_metric(values), 3) # nolint: expect_identical_linter\ntests/testthat/test-metrics.R:96:\ntests/testthat/test-metrics.R:97:  # Test with a different metric function\ntests/testthat/test-metrics.R:98:  custom_metric <- purrr::partial(sum, na.rm = TRUE)\ntests/testthat/test-metrics.R:99:  expect_equal(custom_metric(values), 12) # nolint: expect_identical_linter\ntests/testthat/test-metrics.R:100:\ntests/testthat/test-metrics.R:101:  # Test with no additional arguments\ntests/testthat/test-metrics.R:102:  custom_metric <- purrr::partial(mean)\ntests/testthat/test-metrics.R:103:  expect_true(is.na(custom_metric(values)))\ntests/testthat/test-metrics.R:104:\ntests/testthat/test-metrics.R:105:  # make sure that unquoting argument works even if original object is\ntests/testthat/test-metrics.R:106:  # deleted, meaning that the object is stored as part of the function\ntests/testthat/test-metrics.R:107:  argument <- c(\"hi\", \"hello\", \"I'm here\")\ntests/testthat/test-metrics.R:108:  custom_metric <- purrr::partial(print, x = !!argument)\ntests/testthat/test-metrics.R:109:  expect_output(custom_metric(), \"I'm here\")\ntests/testthat/test-metrics.R:110:\ntests/testthat/test-metrics.R:111:  argument <- NULL\ntests/testthat/test-metrics.R:112:  expect_output(custom_metric(), \"I'm here\")\ntests/testthat/test-metrics.R:113:\ntests/testthat/test-metrics.R:114:  # make sure that all of this still works even if argument is called \"dots\"\ntests/testthat/test-metrics.R:115:  # which is used internally\ntests/testthat/test-metrics.R:116:  dots <- \"test\"\ntests/testthat/test-metrics.R:117:  expect_output(\ntests/testthat/test-metrics.R:118:    # dots argument should be ignored and output should stay the same\ntests/testthat/test-metrics.R:119:    expect_identical(custom_metric(dots = dots), c(\"hi\", \"hello\", \"I'm here\")),\ntests/testthat/test-metrics.R:120:    \"I'm here\"\ntests/testthat/test-metrics.R:121:  )\ntests/testthat/test-metrics.R:122:})\ntests/testthat/test-metrics.R:123:\ntests/testthat/test-metrics.R:124:test_that(\"purrr::partial() has the expected output class\", {\ntests/testthat/test-metrics.R:125:  custom_metric <- purrr::partial(mean, na.rm = TRUE)\ntests/testthat/test-metrics.R:126:  checkmate::expect_class(custom_metric, \"function\")\ntests/testthat/test-metrics.R:127:})\ntests/testthat/test-metrics-nominal.R:1:factor_levels <- c(\"one\", \"two\", \"three\")\ntests/testthat/test-metrics-nominal.R:2:predicted_label <- factor(c(\"one\", \"two\", \"three\"), levels = factor_levels)\ntests/testthat/test-metrics-nominal.R:3:observed <- factor(c(\"one\", \"two\", \"two\"), levels = factor_levels)\ntests/testthat/test-metrics-nominal.R:4:predicted <- matrix(\ntests/testthat/test-metrics-nominal.R:5:  c(\ntests/testthat/test-metrics-nominal.R:6:    0.8, 0.1, 0.4,\ntests/testthat/test-metrics-nominal.R:7:    0.1, 0.2, 0.4,\ntests/testthat/test-metrics-nominal.R:8:    0.1, 0.7, 0.2\ntests/testthat/test-metrics-nominal.R:9:  ),\ntests/testthat/test-metrics-nominal.R:10:  nrow = 3\ntests/testthat/test-metrics-nominal.R:11:)\ntests/testthat/test-metrics-nominal.R:12:\ntests/testthat/test-metrics-nominal.R:13:# ============================================================================ #\ntests/testthat/test-metrics-nominal.R:14:# Input handling ===============================================================\ntests/testthat/test-metrics-nominal.R:15:# ============================================================================ #\ntests/testthat/test-metrics-nominal.R:16:test_that(\"Input checking for nominal forecasts works\", {\ntests/testthat/test-metrics-nominal.R:17:  # everything correct\ntests/testthat/test-metrics-nominal.R:18:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:19:    assert_input_nominal(observed, predicted, predicted_label)\ntests/testthat/test-metrics-nominal.R:20:  )\ntests/testthat/test-metrics-nominal.R:21:\ntests/testthat/test-metrics-nominal.R:22:  # works with a single observations\ntests/testthat/test-metrics-nominal.R:23:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:24:    assert_input_nominal(observed[1], predicted[1, ], predicted_label)\ntests/testthat/test-metrics-nominal.R:25:  )\ntests/testthat/test-metrics-nominal.R:26:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:27:    assert_input_nominal(observed[1], matrix(predicted[1, ], nrow = 1), predicted_label)\ntests/testthat/test-metrics-nominal.R:28:  )\ntests/testthat/test-metrics-nominal.R:29:\ntests/testthat/test-metrics-nominal.R:30:  # observed and predicted_label have different level lengths\ntests/testthat/test-metrics-nominal.R:31:  observed_wrong <- factor(observed, levels = c(\"one\", \"two\"))\ntests/testthat/test-metrics-nominal.R:32:  expect_error(\ntests/testthat/test-metrics-nominal.R:33:    assert_input_nominal(observed_wrong, predicted, predicted_label),\ntests/testthat/test-metrics-nominal.R:34:    \"Assertion on 'predicted_label' failed: Must have length 2, but has length 3.\"\ntests/testthat/test-metrics-nominal.R:35:  )\ntests/testthat/test-metrics-nominal.R:36:\ntests/testthat/test-metrics-nominal.R:37:  # observed and predicted_label have different levels, resulting in an `NA` in predicted_label\ntests/testthat/test-metrics-nominal.R:38:  predicted_label_wrong <- factor(predicted_label, levels = c(\"one\", \"two\", \"four\"))\ntests/testthat/test-metrics-nominal.R:39:  expect_error(\ntests/testthat/test-metrics-nominal.R:40:    assert_input_nominal(observed, predicted, predicted_label_wrong),\ntests/testthat/test-metrics-nominal.R:41:    \"Assertion on 'predicted_label' failed: Contains missing values\"\ntests/testthat/test-metrics-nominal.R:42:  )\ntests/testthat/test-metrics-nominal.R:43:\ntests/testthat/test-metrics-nominal.R:44:  # 6 observations, but only 3 forecasts\ntests/testthat/test-metrics-nominal.R:45:  observed_wrong <- factor(\ntests/testthat/test-metrics-nominal.R:46:    c(\"one\", \"two\", \"one\", \"one\", \"two\", \"three\"),\ntests/testthat/test-metrics-nominal.R:47:    levels = c(\"one\", \"two\", \"three\")\ntests/testthat/test-metrics-nominal.R:48:  )\ntests/testthat/test-metrics-nominal.R:49:  expect_error(\ntests/testthat/test-metrics-nominal.R:50:    assert_input_nominal(observed_wrong, predicted, predicted_label),\ntests/testthat/test-metrics-nominal.R:51:    \"Assertion on 'predicted' failed: Must have exactly 6 rows, but has 3 rows.\"\ntests/testthat/test-metrics-nominal.R:52:  )\ntests/testthat/test-metrics-nominal.R:53:\ntests/testthat/test-metrics-nominal.R:54:  # observed value or predicted_label is not factor\ntests/testthat/test-metrics-nominal.R:55:  expect_error(\ntests/testthat/test-metrics-nominal.R:56:    assert_input_nominal(as.numeric(observed), predicted, predicted_label),\ntests/testthat/test-metrics-nominal.R:57:    \"Assertion on 'observed' failed: Must be of type 'factor', not 'double'.\"\ntests/testthat/test-metrics-nominal.R:58:  )\ntests/testthat/test-metrics-nominal.R:59:  expect_error(\ntests/testthat/test-metrics-nominal.R:60:    assert_input_nominal(observed, predicted, as.character(predicted_label)),\ntests/testthat/test-metrics-nominal.R:61:    \"Assertion on 'predicted_label' failed: Must be of type 'factor', not 'character'.\"\ntests/testthat/test-metrics-nominal.R:62:  )\ntests/testthat/test-metrics-nominal.R:63:\ntests/testthat/test-metrics-nominal.R:64:  # a single observation\ntests/testthat/test-metrics-nominal.R:65:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:66:    assert_input_nominal(observed[1], predicted[1, ], predicted_label)\ntests/testthat/test-metrics-nominal.R:67:  )\ntests/testthat/test-metrics-nominal.R:68:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:69:    assert_input_nominal(observed[1], as.numeric(predicted[1, ]), predicted_label)\ntests/testthat/test-metrics-nominal.R:70:  )\ntests/testthat/test-metrics-nominal.R:71:\ntests/testthat/test-metrics-nominal.R:72:  # wrong dimensions\ntests/testthat/test-metrics-nominal.R:73:  expect_error(\ntests/testthat/test-metrics-nominal.R:74:    assert_input_nominal(observed[1], predicted, predicted_label),\ntests/testthat/test-metrics-nominal.R:75:    \"One of the following must apply:\"\ntests/testthat/test-metrics-nominal.R:76:  )\ntests/testthat/test-metrics-nominal.R:77:\ntests/testthat/test-metrics-nominal.R:78:  # NA values in observed are permitted\ntests/testthat/test-metrics-nominal.R:79:  observed2 <- factor(c(\"one\", \"two\", \"missing\"), levels = c(\"one\", \"two\", \"three\"))\ntests/testthat/test-metrics-nominal.R:80:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:81:    assert_input_nominal(observed2, predicted, predicted_label)\ntests/testthat/test-metrics-nominal.R:82:  )\ntests/testthat/test-metrics-nominal.R:83:\ntests/testthat/test-metrics-nominal.R:84:  # NA values in predicted are permitted and treated as zeros\ntests/testthat/test-metrics-nominal.R:85:  # (as long as probabilities still sum to one)\ntests/testthat/test-metrics-nominal.R:86:  predicted2 <- predicted\ntests/testthat/test-metrics-nominal.R:87:  predicted2[2, 2] <- NA\ntests/testthat/test-metrics-nominal.R:88:  expect_error(\ntests/testthat/test-metrics-nominal.R:89:    assert_input_nominal(observed, predicted2, predicted_label),\ntests/testthat/test-metrics-nominal.R:90:    \"Probabilities belonging to a single forecast must sum to one\"\ntests/testthat/test-metrics-nominal.R:91:  )\ntests/testthat/test-metrics-nominal.R:92:  predicted2[2, 1] <- 0.3\ntests/testthat/test-metrics-nominal.R:93:  expect_no_condition(\ntests/testthat/test-metrics-nominal.R:94:    assert_input_nominal(observed, predicted2, predicted_label)\ntests/testthat/test-metrics-nominal.R:95:  )\ntests/testthat/test-metrics-nominal.R:96:})\ntests/testthat/test-metrics-nominal.R:97:\ntests/testthat/test-metrics-nominal.R:98:\ntests/testthat/test-metrics-nominal.R:99:# ============================================================================ #\ntests/testthat/test-metrics-nominal.R:100:# logs nominal =============================================================== #\ntests/testthat/test-metrics-nominal.R:101:# ============================================================================ #\ntests/testthat/test-metrics-nominal.R:102:test_that(\"logs_categorical() works as expected\", {\ntests/testthat/test-metrics-nominal.R:103:  res <- expect_no_condition(\ntests/testthat/test-metrics-nominal.R:104:    logs_categorical(observed, predicted, predicted_label)\ntests/testthat/test-metrics-nominal.R:105:  )\ntests/testthat/test-metrics-nominal.R:106:  res_manual <- -log(c(predicted[1, 1], predicted[2, 2], predicted[3, 2]))\ntests/testthat/test-metrics-nominal.R:107:  expect_equal(res, res_manual) # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:108:\ntests/testthat/test-metrics-nominal.R:109:  # works with a single observations\ntests/testthat/test-metrics-nominal.R:110:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:111:    logs_categorical(observed[1], predicted[1, ], predicted_label),\ntests/testthat/test-metrics-nominal.R:112:    res_manual[1]\ntests/testthat/test-metrics-nominal.R:113:  )\ntests/testthat/test-metrics-nominal.R:114:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:115:    logs_categorical(observed[1], matrix(predicted[1, ], nrow = 1), predicted_label),\ntests/testthat/test-metrics-nominal.R:116:    res_manual[1]\ntests/testthat/test-metrics-nominal.R:117:  )\ntests/testthat/test-metrics-nominal.R:118:\ntests/testthat/test-metrics-nominal.R:119:  # log scores still work if there are NA values in probabilities that have\ntests/testthat/test-metrics-nominal.R:120:  # not materialised\ntests/testthat/test-metrics-nominal.R:121:  predicted2 <- predicted\ntests/testthat/test-metrics-nominal.R:122:  predicted2[2, c(1, 3)] <- c(NA, 0.8)\ntests/testthat/test-metrics-nominal.R:123:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:124:    logs_categorical(observed, predicted2, predicted_label),\ntests/testthat/test-metrics-nominal.R:125:    res_manual\ntests/testthat/test-metrics-nominal.R:126:  )\ntests/testthat/test-metrics-nominal.R:127:\ntests/testthat/test-metrics-nominal.R:128:  # relevant NAs in predictions lead to NA outcomes\ntests/testthat/test-metrics-nominal.R:129:  predicted2[1, 1:2] <- c(NA, 0.9)\ntests/testthat/test-metrics-nominal.R:130:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:131:    logs_categorical(observed, predicted2, predicted_label),\ntests/testthat/test-metrics-nominal.R:132:    c(NA, res_manual[-1])\ntests/testthat/test-metrics-nominal.R:133:  )\ntests/testthat/test-metrics-nominal.R:134:\ntests/testthat/test-metrics-nominal.R:135:  # NA values in observed values lead to NAs in result\ntests/testthat/test-metrics-nominal.R:136:  observed2 <- factor(c(NA, \"two\", \"two\"), levels = c(\"one\", \"two\", \"three\"))\ntests/testthat/test-metrics-nominal.R:137:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-nominal.R:138:    logs_categorical(observed2, predicted, predicted_label),\ntests/testthat/test-metrics-nominal.R:139:    c(NA, res_manual[-1])\ntests/testthat/test-metrics-nominal.R:140:  )\ntests/testthat/test-metrics-nominal.R:141:})\ntests/testthat/test-class-scores.R:1:# ==============================================================================\ntests/testthat/test-class-scores.R:2:# get_metrics.scores() # nolint: commented_code_linter\ntests/testthat/test-class-scores.R:3:# ==============================================================================\ntests/testthat/test-class-scores.R:4:test_that(\"get_metrics.scores() works as expected\", {\ntests/testthat/test-class-scores.R:5:  expect_null(\ntests/testthat/test-class-scores.R:6:    get_metrics.scores(as.data.frame(as.matrix(scores_point)))\ntests/testthat/test-class-scores.R:7:  )\ntests/testthat/test-class-scores.R:8:\ntests/testthat/test-class-scores.R:9:  expect_true(\ntests/testthat/test-class-scores.R:10:    \"brier_score\" %in% get_metrics.scores(scores_binary)\ntests/testthat/test-class-scores.R:11:  )\ntests/testthat/test-class-scores.R:12:\ntests/testthat/test-class-scores.R:13:  expect_identical(\ntests/testthat/test-class-scores.R:14:    get_metrics.scores(scores_sample_continuous),\ntests/testthat/test-class-scores.R:15:    attr(scores_sample_continuous, \"metrics\")\ntests/testthat/test-class-scores.R:16:  )\ntests/testthat/test-class-scores.R:17:\ntests/testthat/test-class-scores.R:18:  # check that function errors if `error = TRUE` and not otherwise\ntests/testthat/test-class-scores.R:19:  expect_error(\ntests/testthat/test-class-scores.R:20:    get_metrics.scores(example_quantile, error = TRUE),\ntests/testthat/test-class-scores.R:21:    \"Input needs an attribute\"\ntests/testthat/test-class-scores.R:22:  )\ntests/testthat/test-class-scores.R:23:  expect_no_condition(\ntests/testthat/test-class-scores.R:24:    get_metrics.scores(scores_sample_continuous)\ntests/testthat/test-class-scores.R:25:  )\ntests/testthat/test-class-scores.R:26:\ntests/testthat/test-class-scores.R:27:  # expect warning if some column changed\ntests/testthat/test-class-scores.R:28:  ex <- data.table::copy(scores_sample_continuous)\ntests/testthat/test-class-scores.R:29:  data.table::setnames(ex, old = \"crps\", new = \"changed\")\ntests/testthat/test-class-scores.R:30:  expect_warning(\ntests/testthat/test-class-scores.R:31:    get_metrics.scores(ex),\ntests/testthat/test-class-scores.R:32:    \"scores have been previously computed, but are no longer column names\"\ntests/testthat/test-class-scores.R:33:  )\ntests/testthat/test-class-scores.R:34:})\ntests/testthat/test-get-forecast-counts.R:1:# ==============================================================================\ntests/testthat/test-get-forecast-counts.R:2:# `get_forecast_counts()` # nolint: commented_code_linter\ntests/testthat/test-get-forecast-counts.R:3:# ==============================================================================\ntests/testthat/test-get-forecast-counts.R:4:test_that(\"get_forecast_counts() works as expected\", {\ntests/testthat/test-get-forecast-counts.R:5:  af <- data.table::copy(example_quantile)\ntests/testthat/test-get-forecast-counts.R:6:  af <- get_forecast_counts(\ntests/testthat/test-get-forecast-counts.R:7:    af,\ntests/testthat/test-get-forecast-counts.R:8:    by = c(\"model\", \"target_type\", \"target_end_date\")\ntests/testthat/test-get-forecast-counts.R:9:  )\ntests/testthat/test-get-forecast-counts.R:10:\ntests/testthat/test-get-forecast-counts.R:11:  expect_type(af, \"list\")\ntests/testthat/test-get-forecast-counts.R:12:  expect_type(af$target_type, \"character\")\ntests/testthat/test-get-forecast-counts.R:13:  expect_type(af$count, \"integer\")\ntests/testthat/test-get-forecast-counts.R:14:  expect_identical(nrow(af[is.na(count)]), 0L)\ntests/testthat/test-get-forecast-counts.R:15:  af <- get_forecast_counts(example_quantile, by = \"model\")\ntests/testthat/test-get-forecast-counts.R:16:  expect_identical(nrow(af), 4L)\ntests/testthat/test-get-forecast-counts.R:17:  expect_identical(af$count, c(256L, 256L, 128L, 247L))\ntests/testthat/test-get-forecast-counts.R:18:\ntests/testthat/test-get-forecast-counts.R:19:  # Ensure the returning object class is exactly same as a data.table.\ntests/testthat/test-get-forecast-counts.R:20:  expect_s3_class(af, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-get-forecast-counts.R:21:\ntests/testthat/test-get-forecast-counts.R:22:  # Setting `collapse = c()` means that all quantiles and samples are counted\ntests/testthat/test-get-forecast-counts.R:23:  af <- get_forecast_counts(\ntests/testthat/test-get-forecast-counts.R:24:    example_quantile, by = \"model\", collapse = character(0)\ntests/testthat/test-get-forecast-counts.R:25:  )\ntests/testthat/test-get-forecast-counts.R:26:  expect_identical(nrow(af), 4L)\ntests/testthat/test-get-forecast-counts.R:27:  expect_identical(af$count, c(5888L, 5888L, 2944L, 5681L))\ntests/testthat/test-get-forecast-counts.R:28:\ntests/testthat/test-get-forecast-counts.R:29:  af <- get_forecast_counts(example_quantile)\ntests/testthat/test-get-forecast-counts.R:30:  expect_identical(nrow(af), 50688L)\ntests/testthat/test-get-forecast-counts.R:31:\ntests/testthat/test-get-forecast-counts.R:32:  expect_error(\ntests/testthat/test-get-forecast-counts.R:33:    get_forecast_counts(example_quantile, by = NULL),\ntests/testthat/test-get-forecast-counts.R:34:    \"Assertion on 'by' failed: Must be a subset of\"\ntests/testthat/test-get-forecast-counts.R:35:  )\ntests/testthat/test-get-forecast-counts.R:36:\ntests/testthat/test-get-forecast-counts.R:37:  # check whether collapsing also works for model-based forecasts\ntests/testthat/test-get-forecast-counts.R:38:  af <- get_forecast_counts(example_sample_discrete, by = \"model\")\ntests/testthat/test-get-forecast-counts.R:39:  expect_identical(nrow(af), 4L)\ntests/testthat/test-get-forecast-counts.R:40:\ntests/testthat/test-get-forecast-counts.R:41:  af <- get_forecast_counts(\ntests/testthat/test-get-forecast-counts.R:42:    example_sample_discrete, by = \"model\", collapse = character(0)\ntests/testthat/test-get-forecast-counts.R:43:  )\ntests/testthat/test-get-forecast-counts.R:44:  expect_identical(af$count, c(10240L, 10240L, 5120L, 9880L))\ntests/testthat/test-get-forecast-counts.R:45:})\ntests/testthat/test-get-forecast-counts.R:46:\ntests/testthat/test-get-forecast-counts.R:47:\ntests/testthat/test-get-forecast-counts.R:48:# ==============================================================================\ntests/testthat/test-get-forecast-counts.R:49:# `plot_forecast_counts()` # nolint: commented_code_linter\ntests/testthat/test-get-forecast-counts.R:50:# ==============================================================================\ntests/testthat/test-get-forecast-counts.R:51:test_that(\"plot_forecast_counts() works as expected\", {\ntests/testthat/test-get-forecast-counts.R:52:  available_forecasts <- na.omit(example_quantile) |>\ntests/testthat/test-get-forecast-counts.R:53:    as_forecast_quantile() |>\ntests/testthat/test-get-forecast-counts.R:54:    get_forecast_counts(\ntests/testthat/test-get-forecast-counts.R:55:      by = c(\"model\", \"target_type\", \"target_end_date\")\ntests/testthat/test-get-forecast-counts.R:56:    )\ntests/testthat/test-get-forecast-counts.R:57:  p <- plot_forecast_counts(available_forecasts,\ntests/testthat/test-get-forecast-counts.R:58:    x = \"target_end_date\", show_counts = FALSE\ntests/testthat/test-get-forecast-counts.R:59:  ) +\ntests/testthat/test-get-forecast-counts.R:60:    facet_wrap(\"target_type\")\ntests/testthat/test-get-forecast-counts.R:61:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-get-forecast-counts.R:62:  skip_on_cran()\ntests/testthat/test-get-forecast-counts.R:63:  vdiffr::expect_doppelganger(\"plot_available_forecasts\", p)\ntests/testthat/test-get-forecast-counts.R:64:})\ntests/testthat/test-class-forecast-nominal.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:2:# as_forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-nominal.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:4:test_that(\"as_forecast.forecast_nominal() works as expected\", {\ntests/testthat/test-class-forecast-nominal.R:5:  ex <- data.table::copy(example_nominal) |>\ntests/testthat/test-class-forecast-nominal.R:6:    na.omit()\ntests/testthat/test-class-forecast-nominal.R:7:\ntests/testthat/test-class-forecast-nominal.R:8:\ntests/testthat/test-class-forecast-nominal.R:9:  expect_s3_class(\ntests/testthat/test-class-forecast-nominal.R:10:    as_forecast_nominal(ex),\ntests/testthat/test-class-forecast-nominal.R:11:    c(\"forecast_nominal\", \"forecast\", \"data.table\", \"data.frame\"),\ntests/testthat/test-class-forecast-nominal.R:12:    exact = TRUE\ntests/testthat/test-class-forecast-nominal.R:13:  )\ntests/testthat/test-class-forecast-nominal.R:14:\ntests/testthat/test-class-forecast-nominal.R:15:  setnames(ex, old = \"predicted_label\", new = \"label\")\ntests/testthat/test-class-forecast-nominal.R:16:  expect_no_condition(\ntests/testthat/test-class-forecast-nominal.R:17:    as_forecast_nominal(ex, predicted_label = \"label\")\ntests/testthat/test-class-forecast-nominal.R:18:  )\ntests/testthat/test-class-forecast-nominal.R:19:})\ntests/testthat/test-class-forecast-nominal.R:20:\ntests/testthat/test-class-forecast-nominal.R:21:test_that(\"as_forecast.forecast_nominal() breaks when rows with zero probability are missing\", {\ntests/testthat/test-class-forecast-nominal.R:22:  ex_faulty <- as.data.table(example_nominal)\ntests/testthat/test-class-forecast-nominal.R:23:  ex_faulty <- ex_faulty[predicted != 0]\ntests/testthat/test-class-forecast-nominal.R:24:  expect_warning(\ntests/testthat/test-class-forecast-nominal.R:25:    expect_error(\ntests/testthat/test-class-forecast-nominal.R:26:      as_forecast_nominal(ex_faulty),\ntests/testthat/test-class-forecast-nominal.R:27:      \"Found incomplete forecasts\"\ntests/testthat/test-class-forecast-nominal.R:28:    ),\ntests/testthat/test-class-forecast-nominal.R:29:    \"Some forecasts have different numbers of rows\"\ntests/testthat/test-class-forecast-nominal.R:30:  )\ntests/testthat/test-class-forecast-nominal.R:31:})\ntests/testthat/test-class-forecast-nominal.R:32:\ntests/testthat/test-class-forecast-nominal.R:33:\ntests/testthat/test-class-forecast-nominal.R:34:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:35:# is_forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-nominal.R:36:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:37:test_that(\"is_forecast_nominal() works as expected\", {\ntests/testthat/test-class-forecast-nominal.R:38:  expect_true(is_forecast_nominal(example_nominal))\ntests/testthat/test-class-forecast-nominal.R:39:  expect_false(is_forecast_nominal(example_binary))\ntests/testthat/test-class-forecast-nominal.R:40:  expect_false(is_forecast_nominal(example_point))\ntests/testthat/test-class-forecast-nominal.R:41:  expect_false(is_forecast_nominal(example_quantile))\ntests/testthat/test-class-forecast-nominal.R:42:  expect_false(is_forecast_nominal(example_sample_continuous))\ntests/testthat/test-class-forecast-nominal.R:43:  expect_false(is_forecast_nominal(1:10))\ntests/testthat/test-class-forecast-nominal.R:44:})\ntests/testthat/test-class-forecast-nominal.R:45:\ntests/testthat/test-class-forecast-nominal.R:46:\ntests/testthat/test-class-forecast-nominal.R:47:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:48:# get_metrics.forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-nominal.R:49:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:50:\ntests/testthat/test-class-forecast-nominal.R:51:test_that(\"get_metrics.forecast_nominal() works as expected\", {\ntests/testthat/test-class-forecast-nominal.R:52:  expect_type(\ntests/testthat/test-class-forecast-nominal.R:53:    get_metrics(example_nominal), \"list\"\ntests/testthat/test-class-forecast-nominal.R:54:  )\ntests/testthat/test-class-forecast-nominal.R:55:})\ntests/testthat/test-class-forecast-nominal.R:56:\ntests/testthat/test-class-forecast-nominal.R:57:\ntests/testthat/test-class-forecast-nominal.R:58:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:59:# Printing # nolint: commented_code_linter\ntests/testthat/test-class-forecast-nominal.R:60:# ==============================================================================\ntests/testthat/test-class-forecast-nominal.R:61:test_that(\"Printing works as expected\", {\ntests/testthat/test-class-forecast-nominal.R:62:  suppressMessages(\ntests/testthat/test-class-forecast-nominal.R:63:    expect_message(\ntests/testthat/test-class-forecast-nominal.R:64:      expect_message(\ntests/testthat/test-class-forecast-nominal.R:65:        capture.output(print(example_nominal)),\ntests/testthat/test-class-forecast-nominal.R:66:        \"Forecast type: nominal\"\ntests/testthat/test-class-forecast-nominal.R:67:      ),\ntests/testthat/test-class-forecast-nominal.R:68:      \"Forecast unit:\"\ntests/testthat/test-class-forecast-nominal.R:69:    )\ntests/testthat/test-class-forecast-nominal.R:70:  )\ntests/testthat/test-class-forecast-nominal.R:71:})\ntests/testthat/test-check-input-helpers.R:1:test_that(\"Check equal length works if all arguments have length 1\", {\ntests/testthat/test-check-input-helpers.R:2:  out <- interval_score(\ntests/testthat/test-check-input-helpers.R:3:    observed = 5,\ntests/testthat/test-check-input-helpers.R:4:    lower = 4,\ntests/testthat/test-check-input-helpers.R:5:    upper = 6,\ntests/testthat/test-check-input-helpers.R:6:    interval_range = 95,\ntests/testthat/test-check-input-helpers.R:7:    weigh = TRUE,\ntests/testthat/test-check-input-helpers.R:8:    separate_results = FALSE\ntests/testthat/test-check-input-helpers.R:9:  )\ntests/testthat/test-check-input-helpers.R:10:  expect_equal(out, 0.05)\ntests/testthat/test-check-input-helpers.R:11:})\ntests/testthat/test-check-input-helpers.R:12:\ntests/testthat/test-check-input-helpers.R:13:\ntests/testthat/test-check-input-helpers.R:14:test_that(\"check_columns_present works\", {\ntests/testthat/test-check-input-helpers.R:15:  expect_identical(\ntests/testthat/test-check-input-helpers.R:16:    capture.output(\ntests/testthat/test-check-input-helpers.R:17:      check_columns_present(example_binary, c(\"loc1\", \"loc2\", \"loc3\"))\ntests/testthat/test-check-input-helpers.R:18:    ),\ntests/testthat/test-check-input-helpers.R:19:    paste(\ntests/testthat/test-check-input-helpers.R:20:      \"[1] \\\"Columns 'loc1', 'loc2', 'loc3' not found in data\\\"\"\ntests/testthat/test-check-input-helpers.R:21:    )\ntests/testthat/test-check-input-helpers.R:22:  )\ntests/testthat/test-check-input-helpers.R:23:  expect_identical(\ntests/testthat/test-check-input-helpers.R:24:    capture.output(\ntests/testthat/test-check-input-helpers.R:25:      check_columns_present(example_binary, \"loc1\")\ntests/testthat/test-check-input-helpers.R:26:    ),\ntests/testthat/test-check-input-helpers.R:27:    paste(\ntests/testthat/test-check-input-helpers.R:28:      \"[1] \\\"Column 'loc1' not found in data\\\"\"\ntests/testthat/test-check-input-helpers.R:29:    )\ntests/testthat/test-check-input-helpers.R:30:  )\ntests/testthat/test-check-input-helpers.R:31:  expect_true(\ntests/testthat/test-check-input-helpers.R:32:    check_columns_present(example_binary, \"location_name\")\ntests/testthat/test-check-input-helpers.R:33:  )\ntests/testthat/test-check-input-helpers.R:34:  expect_true(\ntests/testthat/test-check-input-helpers.R:35:    check_columns_present(example_binary, columns = NULL)\ntests/testthat/test-check-input-helpers.R:36:  )\ntests/testthat/test-check-input-helpers.R:37:})\ntests/testthat/test-check-input-helpers.R:38:\ntests/testthat/test-check-input-helpers.R:39:test_that(\"test_columns_not_present works\", {\ntests/testthat/test-check-input-helpers.R:40:  expect_true(\ntests/testthat/test-check-input-helpers.R:41:    test_columns_not_present(example_binary, \"sample_id\")\ntests/testthat/test-check-input-helpers.R:42:  )\ntests/testthat/test-check-input-helpers.R:43:  expect_false(\ntests/testthat/test-check-input-helpers.R:44:    test_columns_not_present(example_binary, \"location\")\ntests/testthat/test-check-input-helpers.R:45:  )\ntests/testthat/test-check-input-helpers.R:46:})\ntests/testthat/test-check-input-helpers.R:47:\ntests/testthat/test-check-input-helpers.R:48:test_that(\"check_columns_present() works\", {\ntests/testthat/test-check-input-helpers.R:49:  expect_identical(\ntests/testthat/test-check-input-helpers.R:50:    check_columns_present(example_quantile, c(\"observed\", \"predicted\", \"nop\")),\ntests/testthat/test-check-input-helpers.R:51:    \"Column 'nop' not found in data\"\ntests/testthat/test-check-input-helpers.R:52:  )\ntests/testthat/test-check-input-helpers.R:53:  expect_true(\ntests/testthat/test-check-input-helpers.R:54:    check_columns_present(example_quantile, c(\"observed\", \"predicted\"))\ntests/testthat/test-check-input-helpers.R:55:  )\ntests/testthat/test-check-input-helpers.R:56:})\ntests/testthat/test-inputs-scoring-functions.R:1:# ==============================================================================\ntests/testthat/test-inputs-scoring-functions.R:2:# assert_dims_ok_point() # nolint: commented_code_linter\ntests/testthat/test-inputs-scoring-functions.R:3:# ==============================================================================\ntests/testthat/test-inputs-scoring-functions.R:4:\ntests/testthat/test-inputs-scoring-functions.R:5:test_that(\"assert_dims_ok_point() works as expected\", {\ntests/testthat/test-inputs-scoring-functions.R:6:  # expect no error if dimensions are ok\ntests/testthat/test-inputs-scoring-functions.R:7:  expect_no_condition(assert_dims_ok_point(1:10, 1:10))\ntests/testthat/test-inputs-scoring-functions.R:8:\ntests/testthat/test-inputs-scoring-functions.R:9:  expect_error(\ntests/testthat/test-inputs-scoring-functions.R:10:    assert_dims_ok_point(1:3, matrix(1:6, nrow = 3, ncol = 2)),\ntests/testthat/test-inputs-scoring-functions.R:11:    \"Assertion failed. One of the following must apply:\"\ntests/testthat/test-inputs-scoring-functions.R:12:  )\ntests/testthat/test-inputs-scoring-functions.R:13:\ntests/testthat/test-inputs-scoring-functions.R:14:\ntests/testthat/test-inputs-scoring-functions.R:15:  # expect error if dimensions are not ok\ntests/testthat/test-inputs-scoring-functions.R:16:  expect_error(\ntests/testthat/test-inputs-scoring-functions.R:17:    assert_dims_ok_point(1:10, 1:11),\ntests/testthat/test-inputs-scoring-functions.R:18:    \"`observed` and `predicted` must either be of length 1 or of equal length.\"\ntests/testthat/test-inputs-scoring-functions.R:19:  )\ntests/testthat/test-inputs-scoring-functions.R:20:})\ntests/testthat/test-inputs-scoring-functions.R:21:\ntests/testthat/test-inputs-scoring-functions.R:22:\ntests/testthat/test-inputs-scoring-functions.R:23:# ==============================================================================\ntests/testthat/test-inputs-scoring-functions.R:24:# check_input_sample() # nolint: commented_code_linter\ntests/testthat/test-inputs-scoring-functions.R:25:# ==============================================================================\ntests/testthat/test-inputs-scoring-functions.R:26:\ntests/testthat/test-inputs-scoring-functions.R:27:test_that(\"check_input_sample() works as expected\", {\ntests/testthat/test-inputs-scoring-functions.R:28:  # expect no error if dimensions are ok\ntests/testthat/test-inputs-scoring-functions.R:29:  expect_true(check_input_sample(1:10, matrix(1:20, nrow = 10)))\ntests/testthat/test-inputs-scoring-functions.R:30:\ntests/testthat/test-inputs-scoring-functions.R:31:  # expect error if dimensions are not ok\ntests/testthat/test-inputs-scoring-functions.R:32:  expect_match(\ntests/testthat/test-inputs-scoring-functions.R:33:    check_input_sample(1:10, 1:11),\ntests/testthat/test-inputs-scoring-functions.R:34:    \"Assertion on 'predicted' failed: Must be of type 'matrix', not 'integer'.\"\ntests/testthat/test-inputs-scoring-functions.R:35:  )\ntests/testthat/test-inputs-scoring-functions.R:36:})\ntests/testthat/test-class-forecast-quantile.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:2:# as_forecast_quantile() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-quantile.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:4:\ntests/testthat/test-class-forecast-quantile.R:5:test_that(\"as_forecast_quantile() works as expected\", {\ntests/testthat/test-class-forecast-quantile.R:6:  test <- na.omit(data.table::copy(example_quantile))\ntests/testthat/test-class-forecast-quantile.R:7:\ntests/testthat/test-class-forecast-quantile.R:8:  expect_s3_class(\ntests/testthat/test-class-forecast-quantile.R:9:    as_forecast_quantile(test),\ntests/testthat/test-class-forecast-quantile.R:10:    c(\"forecast_quantile\", \"forecast\", \"data.table\", \"data.frame\"),\ntests/testthat/test-class-forecast-quantile.R:11:    exact = TRUE\ntests/testthat/test-class-forecast-quantile.R:12:  )\ntests/testthat/test-class-forecast-quantile.R:13:\ntests/testthat/test-class-forecast-quantile.R:14:  # expect error when arguments are not correct\ntests/testthat/test-class-forecast-quantile.R:15:  expect_error(as_forecast_quantile(test, observed = 3), \"Must be of type 'character'\")\ntests/testthat/test-class-forecast-quantile.R:16:  expect_error(as_forecast_quantile(test, quantile_level = c(\"1\", \"2\")), \"Must have length 1\")\ntests/testthat/test-class-forecast-quantile.R:17:  expect_error(as_forecast_quantile(test, observed = \"missing\"), \"Must be a subset of\")\ntests/testthat/test-class-forecast-quantile.R:18:\ntests/testthat/test-class-forecast-quantile.R:19:  # expect no condition with columns already present\ntests/testthat/test-class-forecast-quantile.R:20:  expect_no_condition(\ntests/testthat/test-class-forecast-quantile.R:21:    as_forecast_quantile(test,\ntests/testthat/test-class-forecast-quantile.R:22:      observed = \"observed\", predicted = \"predicted\",\ntests/testthat/test-class-forecast-quantile.R:23:      forecast_unit = c(\ntests/testthat/test-class-forecast-quantile.R:24:        \"location\", \"model\", \"target_type\",\ntests/testthat/test-class-forecast-quantile.R:25:        \"target_end_date\", \"horizon\"\ntests/testthat/test-class-forecast-quantile.R:26:      ),\ntests/testthat/test-class-forecast-quantile.R:27:      quantile_level = \"quantile_level\"\ntests/testthat/test-class-forecast-quantile.R:28:    )\ntests/testthat/test-class-forecast-quantile.R:29:  )\ntests/testthat/test-class-forecast-quantile.R:30:})\ntests/testthat/test-class-forecast-quantile.R:31:\ntests/testthat/test-class-forecast-quantile.R:32:test_that(\"as_forecast_quantile() function works\", {\ntests/testthat/test-class-forecast-quantile.R:33:  check <- suppressMessages(as_forecast_quantile(example_quantile))\ntests/testthat/test-class-forecast-quantile.R:34:  expect_s3_class(check, \"forecast_quantile\")\ntests/testthat/test-class-forecast-quantile.R:35:})\ntests/testthat/test-class-forecast-quantile.R:36:\ntests/testthat/test-class-forecast-quantile.R:37:test_that(\"as_forecast_quantile() errors if there is both a sample_id and a quantile_level column\", {\ntests/testthat/test-class-forecast-quantile.R:38:  example <- as.data.table(example_quantile)[, sample_id := 1]\ntests/testthat/test-class-forecast-quantile.R:39:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:40:    as_forecast_quantile(example),\ntests/testthat/test-class-forecast-quantile.R:41:    \"Found columns `quantile_level` and `sample_id`. Only one of these is allowed\"\ntests/testthat/test-class-forecast-quantile.R:42:  )\ntests/testthat/test-class-forecast-quantile.R:43:})\ntests/testthat/test-class-forecast-quantile.R:44:\ntests/testthat/test-class-forecast-quantile.R:45:test_that(\"as_forecast_quantile() warns if there are different numbers of quantiles\", {\ntests/testthat/test-class-forecast-quantile.R:46:  example <- as.data.table(example_quantile)[-1000, ]\ntests/testthat/test-class-forecast-quantile.R:47:  w <- suppressWarnings(as_forecast_quantile(na.omit(example)))\ntests/testthat/test-class-forecast-quantile.R:48:  expect_warning(\ntests/testthat/test-class-forecast-quantile.R:49:    as_forecast_quantile(na.omit(example)),\ntests/testthat/test-class-forecast-quantile.R:50:    \"Some forecasts have different numbers of rows\"\ntests/testthat/test-class-forecast-quantile.R:51:  )\ntests/testthat/test-class-forecast-quantile.R:52:  # printing should work without a warning because printing is silent\ntests/testthat/test-class-forecast-quantile.R:53:  expect_no_condition(w)\ntests/testthat/test-class-forecast-quantile.R:54:})\ntests/testthat/test-class-forecast-quantile.R:55:\ntests/testthat/test-class-forecast-quantile.R:56:test_that(\"as_forecast_quantile() function throws an error with duplicate forecasts\", {\ntests/testthat/test-class-forecast-quantile.R:57:  example <- rbind(\ntests/testthat/test-class-forecast-quantile.R:58:    example_quantile,\ntests/testthat/test-class-forecast-quantile.R:59:    example_quantile[1000:1010]\ntests/testthat/test-class-forecast-quantile.R:60:  )\ntests/testthat/test-class-forecast-quantile.R:61:\ntests/testthat/test-class-forecast-quantile.R:62:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:63:    suppressMessages(suppressWarnings(as_forecast_quantile(example))),\ntests/testthat/test-class-forecast-quantile.R:64:    \"Assertion on 'data' failed: There are instances with more than one forecast for the same target. This can't be right and needs to be resolved. Maybe you need to check the unit of a single forecast and add missing columns? Use the function get_duplicate_forecasts() to identify duplicate rows.\", # nolint\ntests/testthat/test-class-forecast-quantile.R:65:    fixed = TRUE\ntests/testthat/test-class-forecast-quantile.R:66:  )\ntests/testthat/test-class-forecast-quantile.R:67:})\ntests/testthat/test-class-forecast-quantile.R:68:\ntests/testthat/test-class-forecast-quantile.R:69:test_that(\"as_forecast_quantile() function throws an error when no predictions or observed values are present\", {\ntests/testthat/test-class-forecast-quantile.R:70:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:71:    suppressMessages(suppressWarnings(as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:72:      data.table::copy(example_quantile)[, predicted := NULL]\ntests/testthat/test-class-forecast-quantile.R:73:    ))),\ntests/testthat/test-class-forecast-quantile.R:74:    \"Assertion on 'data' failed: Column 'predicted' not found in data.\"\ntests/testthat/test-class-forecast-quantile.R:75:  )\ntests/testthat/test-class-forecast-quantile.R:76:\ntests/testthat/test-class-forecast-quantile.R:77:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:78:    suppressMessages(suppressWarnings(as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:79:      data.table::copy(example_quantile)[, observed := NULL]\ntests/testthat/test-class-forecast-quantile.R:80:    ))),\ntests/testthat/test-class-forecast-quantile.R:81:    \"Assertion on 'data' failed: Column 'observed' not found in data.\"\ntests/testthat/test-class-forecast-quantile.R:82:  )\ntests/testthat/test-class-forecast-quantile.R:83:\ntests/testthat/test-class-forecast-quantile.R:84:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:85:    suppressMessages(suppressWarnings(as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:86:      data.table::copy(example_quantile)[, c(\"observed\", \"predicted\") := NULL]\ntests/testthat/test-class-forecast-quantile.R:87:    ))),\ntests/testthat/test-class-forecast-quantile.R:88:    \"Assertion on 'data' failed: Columns 'observed', 'predicted' not found in data.\"\ntests/testthat/test-class-forecast-quantile.R:89:  )\ntests/testthat/test-class-forecast-quantile.R:90:})\ntests/testthat/test-class-forecast-quantile.R:91:\ntests/testthat/test-class-forecast-quantile.R:92:test_that(\"as_forecast_quantile() works with a data.frame\", {\ntests/testthat/test-class-forecast-quantile.R:93:  expect_no_condition(as_forecast_quantile(example_quantile_df))\ntests/testthat/test-class-forecast-quantile.R:94:})\ntests/testthat/test-class-forecast-quantile.R:95:\ntests/testthat/test-class-forecast-quantile.R:96:test_that(\"as_forecast_quantiles works\", {\ntests/testthat/test-class-forecast-quantile.R:97:  samples <- data.frame(\ntests/testthat/test-class-forecast-quantile.R:98:    date = as.Date(\"2020-01-01\") + 1:10,\ntests/testthat/test-class-forecast-quantile.R:99:    model = \"model1\",\ntests/testthat/test-class-forecast-quantile.R:100:    observed = 1:10,\ntests/testthat/test-class-forecast-quantile.R:101:    predicted = c(rep(0, 10), 2:11, 3:12, 4:13, rep(100, 10)),\ntests/testthat/test-class-forecast-quantile.R:102:    sample_id = rep(1:5, each = 10),\ntests/testthat/test-class-forecast-quantile.R:103:    stringsAsFactors = FALSE\ntests/testthat/test-class-forecast-quantile.R:104:  ) |>\ntests/testthat/test-class-forecast-quantile.R:105:    as_forecast_sample()\ntests/testthat/test-class-forecast-quantile.R:106:\ntests/testthat/test-class-forecast-quantile.R:107:  quantile <- data.frame(\ntests/testthat/test-class-forecast-quantile.R:108:    date = rep(as.Date(\"2020-01-01\") + 1:10, each = 2),\ntests/testthat/test-class-forecast-quantile.R:109:    model = \"model1\",\ntests/testthat/test-class-forecast-quantile.R:110:    observed = rep(1:10, each = 2),\ntests/testthat/test-class-forecast-quantile.R:111:    quantile_level = c(0.25, 0.75),\ntests/testthat/test-class-forecast-quantile.R:112:    predicted = rep(2:11, each = 2) + c(0, 2),\ntests/testthat/test-class-forecast-quantile.R:113:    stringsAsFactors = FALSE\ntests/testthat/test-class-forecast-quantile.R:114:  )\ntests/testthat/test-class-forecast-quantile.R:115:\ntests/testthat/test-class-forecast-quantile.R:116:  expect_no_condition(\ntests/testthat/test-class-forecast-quantile.R:117:    as_forecast_quantile(samples, probs = c(0.25, 0.75))\ntests/testthat/test-class-forecast-quantile.R:118:  )\ntests/testthat/test-class-forecast-quantile.R:119:\ntests/testthat/test-class-forecast-quantile.R:120:  wrongclass <- as_forecast_sample(samples)\ntests/testthat/test-class-forecast-quantile.R:121:  class(wrongclass) <- c(\"forecast_point\", \"data.table\", \"data.frame\")\ntests/testthat/test-class-forecast-quantile.R:122:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:123:    as_forecast_quantile(wrongclass, quantile_level = c(0.25, 0.75)),\ntests/testthat/test-class-forecast-quantile.R:124:    \"Assertion on 'quantile_level' failed: Must be of type\"\ntests/testthat/test-class-forecast-quantile.R:125:  )\ntests/testthat/test-class-forecast-quantile.R:126:\ntests/testthat/test-class-forecast-quantile.R:127:\ntests/testthat/test-class-forecast-quantile.R:128:  quantile2 <- as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:129:    as_forecast_sample(samples),\ntests/testthat/test-class-forecast-quantile.R:130:    probs = c(0.25, 0.75)\ntests/testthat/test-class-forecast-quantile.R:131:  )\ntests/testthat/test-class-forecast-quantile.R:132:\ntests/testthat/test-class-forecast-quantile.R:133:  expect_identical(quantile, as.data.frame(quantile2))\ntests/testthat/test-class-forecast-quantile.R:134:\ntests/testthat/test-class-forecast-quantile.R:135:  # Verify that `type` is correctly scoped in as_forecast_quantile(), as it is\ntests/testthat/test-class-forecast-quantile.R:136:  # also an argument.\ntests/testthat/test-class-forecast-quantile.R:137:  # If it's not scoped well, the call to `as_forecast_quantile()` will fail.\ntests/testthat/test-class-forecast-quantile.R:138:  samples$type <- \"test\"\ntests/testthat/test-class-forecast-quantile.R:139:\ntests/testthat/test-class-forecast-quantile.R:140:  quantile3 <- as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:141:    as_forecast_sample(samples),\ntests/testthat/test-class-forecast-quantile.R:142:    probs = c(0.25, 0.75)\ntests/testthat/test-class-forecast-quantile.R:143:  )\ntests/testthat/test-class-forecast-quantile.R:144:  quantile3$type <- NULL\ntests/testthat/test-class-forecast-quantile.R:145:\ntests/testthat/test-class-forecast-quantile.R:146:  expect_identical(\ntests/testthat/test-class-forecast-quantile.R:147:    quantile2,\ntests/testthat/test-class-forecast-quantile.R:148:    quantile3\ntests/testthat/test-class-forecast-quantile.R:149:  )\ntests/testthat/test-class-forecast-quantile.R:150:})\ntests/testthat/test-class-forecast-quantile.R:151:\ntests/testthat/test-class-forecast-quantile.R:152:test_that(\"as_forecast_quantiles issue 557 fix\", {\ntests/testthat/test-class-forecast-quantile.R:153:  out <- example_sample_discrete |>\ntests/testthat/test-class-forecast-quantile.R:154:    na.omit() |>\ntests/testthat/test-class-forecast-quantile.R:155:    as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:156:      probs = c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)\ntests/testthat/test-class-forecast-quantile.R:157:    ) |>\ntests/testthat/test-class-forecast-quantile.R:158:    score()\ntests/testthat/test-class-forecast-quantile.R:159:\ntests/testthat/test-class-forecast-quantile.R:160:  expect_false(anyNA(out$interval_coverage_deviation))\ntests/testthat/test-class-forecast-quantile.R:161:})\ntests/testthat/test-class-forecast-quantile.R:162:\ntests/testthat/test-class-forecast-quantile.R:163:test_that(\"as_forecast_quantile doesn't modify column names in place\", {\ntests/testthat/test-class-forecast-quantile.R:164:  quantile_data <- data.table(\ntests/testthat/test-class-forecast-quantile.R:165:    my_quantile = c(0.25, 0.5),\ntests/testthat/test-class-forecast-quantile.R:166:    forecast_value = c(1, 2),\ntests/testthat/test-class-forecast-quantile.R:167:    observed_value = c(5, 5)\ntests/testthat/test-class-forecast-quantile.R:168:  )\ntests/testthat/test-class-forecast-quantile.R:169:  pre <- names(quantile_data)\ntests/testthat/test-class-forecast-quantile.R:170:\ntests/testthat/test-class-forecast-quantile.R:171:  quantile_forecast <- as_forecast_quantile(\ntests/testthat/test-class-forecast-quantile.R:172:    quantile_data,\ntests/testthat/test-class-forecast-quantile.R:173:    predicted = \"forecast_value\",\ntests/testthat/test-class-forecast-quantile.R:174:    observed = \"observed_value\",\ntests/testthat/test-class-forecast-quantile.R:175:    quantile_level = \"my_quantile\"\ntests/testthat/test-class-forecast-quantile.R:176:  )\ntests/testthat/test-class-forecast-quantile.R:177:\ntests/testthat/test-class-forecast-quantile.R:178:  post <- names(quantile_data)\ntests/testthat/test-class-forecast-quantile.R:179:  expect_identical(pre, post)\ntests/testthat/test-class-forecast-quantile.R:180:})\ntests/testthat/test-class-forecast-quantile.R:181:\ntests/testthat/test-class-forecast-quantile.R:182:test_that(\"as_forecast_quantile handles rounding issues correctly\", {\ntests/testthat/test-class-forecast-quantile.R:183:  quantile_data <- data.table(\ntests/testthat/test-class-forecast-quantile.R:184:    quantile_level = c(0.25, 0.75 + 1e-13, 0.25, 0.75),\ntests/testthat/test-class-forecast-quantile.R:185:    predicted = c(1, 2, 3, 4),\ntests/testthat/test-class-forecast-quantile.R:186:    observed = c(5, 5, 5, 5),\ntests/testthat/test-class-forecast-quantile.R:187:    location = c(1, 1, 2, 2)\ntests/testthat/test-class-forecast-quantile.R:188:  )\ntests/testthat/test-class-forecast-quantile.R:189:  quantile_forecast <- suppressWarnings(as_forecast_quantile(quantile_data))\ntests/testthat/test-class-forecast-quantile.R:190:  expect_warning(\ntests/testthat/test-class-forecast-quantile.R:191:    as_forecast_quantile(quantile_data),\ntests/testthat/test-class-forecast-quantile.R:192:    \"rounding issue\"\ntests/testthat/test-class-forecast-quantile.R:193:  )\ntests/testthat/test-class-forecast-quantile.R:194:  expect_no_condition(\ntests/testthat/test-class-forecast-quantile.R:195:    score(quantile_forecast, metrics = c(wis = wis))\ntests/testthat/test-class-forecast-quantile.R:196:  )\ntests/testthat/test-class-forecast-quantile.R:197:})\ntests/testthat/test-class-forecast-quantile.R:198:\ntests/testthat/test-class-forecast-quantile.R:199:\ntests/testthat/test-class-forecast-quantile.R:200:\ntests/testthat/test-class-forecast-quantile.R:201:\ntests/testthat/test-class-forecast-quantile.R:202:\ntests/testthat/test-class-forecast-quantile.R:203:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:204:# is_forecast_quantile() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-quantile.R:205:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:206:test_that(\"is_forecast_quantile() works as expected\", {\ntests/testthat/test-class-forecast-quantile.R:207:  expect_true(is_forecast_quantile(example_quantile))\ntests/testthat/test-class-forecast-quantile.R:208:  expect_false(is_forecast_quantile(example_binary))\ntests/testthat/test-class-forecast-quantile.R:209:  expect_false(is_forecast_quantile(example_point))\ntests/testthat/test-class-forecast-quantile.R:210:  expect_false(is_forecast_quantile(example_sample_continuous))\ntests/testthat/test-class-forecast-quantile.R:211:  expect_false(is_forecast_quantile(example_nominal))\ntests/testthat/test-class-forecast-quantile.R:212:})\ntests/testthat/test-class-forecast-quantile.R:213:\ntests/testthat/test-class-forecast-quantile.R:214:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:215:# score.forecast_quantile() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-quantile.R:216:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:217:test_that(\"score_quantile correctly handles separate results = FALSE\", {\ntests/testthat/test-class-forecast-quantile.R:218:  df <- example_quantile[model == \"EuroCOVIDhub-ensemble\" &\ntests/testthat/test-class-forecast-quantile.R:219:                           target_type == \"Cases\" & location == \"DE\"]\ntests/testthat/test-class-forecast-quantile.R:220:  metrics <- get_metrics(example_quantile)\ntests/testthat/test-class-forecast-quantile.R:221:  metrics$wis <- purrr::partial(wis, separate_results = FALSE)\ntests/testthat/test-class-forecast-quantile.R:222:  eval <- score(df[!is.na(predicted)], metrics = metrics)\ntests/testthat/test-class-forecast-quantile.R:223:\ntests/testthat/test-class-forecast-quantile.R:224:  expect_gt(\ntests/testthat/test-class-forecast-quantile.R:225:    nrow(eval), 1\ntests/testthat/test-class-forecast-quantile.R:226:  )\ntests/testthat/test-class-forecast-quantile.R:227:  expect_true(all(names(get_metrics(example_quantile)) %in% colnames(eval)))\ntests/testthat/test-class-forecast-quantile.R:228:\ntests/testthat/test-class-forecast-quantile.R:229:  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-quantile.R:230:})\ntests/testthat/test-class-forecast-quantile.R:231:\ntests/testthat/test-class-forecast-quantile.R:232:\ntests/testthat/test-class-forecast-quantile.R:233:test_that(\"score() quantile produces desired metrics\", {\ntests/testthat/test-class-forecast-quantile.R:234:  data <- data.frame(\ntests/testthat/test-class-forecast-quantile.R:235:    observed = rep(1:10, each = 3),\ntests/testthat/test-class-forecast-quantile.R:236:    predicted = rep(c(-0.3, 0, 0.3), 10) + rep(1:10, each = 3),\ntests/testthat/test-class-forecast-quantile.R:237:    model = \"Model 1\",\ntests/testthat/test-class-forecast-quantile.R:238:    date = as.Date(\"2020-01-01\") + rep(1:10, each = 3),\ntests/testthat/test-class-forecast-quantile.R:239:    quantile_level = rep(c(0.1, 0.5, 0.9), times = 10),\ntests/testthat/test-class-forecast-quantile.R:240:    stringsAsFactors = FALSE\ntests/testthat/test-class-forecast-quantile.R:241:  )\ntests/testthat/test-class-forecast-quantile.R:242:\ntests/testthat/test-class-forecast-quantile.R:243:  data <- suppressWarnings(suppressMessages(as_forecast_quantile(data)))\ntests/testthat/test-class-forecast-quantile.R:244:\ntests/testthat/test-class-forecast-quantile.R:245:  out <- score(forecast = data, metrics = metrics_no_cov)\ntests/testthat/test-class-forecast-quantile.R:246:  metrics <- c(\ntests/testthat/test-class-forecast-quantile.R:247:    \"dispersion\", \"underprediction\", \"overprediction\",\ntests/testthat/test-class-forecast-quantile.R:248:    \"bias\", \"ae_median\"\ntests/testthat/test-class-forecast-quantile.R:249:  )\ntests/testthat/test-class-forecast-quantile.R:250:\ntests/testthat/test-class-forecast-quantile.R:251:  expect_true(all(metrics %in% colnames(out)))\ntests/testthat/test-class-forecast-quantile.R:252:})\ntests/testthat/test-class-forecast-quantile.R:253:\ntests/testthat/test-class-forecast-quantile.R:254:\ntests/testthat/test-class-forecast-quantile.R:255:test_that(\"calculation of ae_median is correct for a quantile format case\", {\ntests/testthat/test-class-forecast-quantile.R:256:  eval <- summarise_scores(scores_quantile, by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:257:\ntests/testthat/test-class-forecast-quantile.R:258:  example <- as.data.table(example_quantile)\ntests/testthat/test-class-forecast-quantile.R:259:  ae <- example[quantile_level == 0.5, ae := abs(observed - predicted)][!is.na(model), .(mean = mean(ae, na.rm = TRUE)),\ntests/testthat/test-class-forecast-quantile.R:260:    by = \"model\"\ntests/testthat/test-class-forecast-quantile.R:261:  ]$mean\ntests/testthat/test-class-forecast-quantile.R:262:\ntests/testthat/test-class-forecast-quantile.R:263:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-quantile.R:264:    sort(eval$ae_median), sort(ae)\ntests/testthat/test-class-forecast-quantile.R:265:  )\ntests/testthat/test-class-forecast-quantile.R:266:})\ntests/testthat/test-class-forecast-quantile.R:267:\ntests/testthat/test-class-forecast-quantile.R:268:\ntests/testthat/test-class-forecast-quantile.R:269:test_that(\"all quantile and range formats yield the same result\", {\ntests/testthat/test-class-forecast-quantile.R:270:  eval1 <- summarise_scores(scores_quantile, by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:271:\ntests/testthat/test-class-forecast-quantile.R:272:  df <- as.data.table(example_quantile)\ntests/testthat/test-class-forecast-quantile.R:273:\ntests/testthat/test-class-forecast-quantile.R:274:  ae <- df[\ntests/testthat/test-class-forecast-quantile.R:275:    quantile_level == 0.5, ae := abs(observed - predicted)\ntests/testthat/test-class-forecast-quantile.R:276:  ][\ntests/testthat/test-class-forecast-quantile.R:277:    !is.na(model), .(mean = mean(ae, na.rm = TRUE)),\ntests/testthat/test-class-forecast-quantile.R:278:    by = \"model\"\ntests/testthat/test-class-forecast-quantile.R:279:  ]$mean\ntests/testthat/test-class-forecast-quantile.R:280:\ntests/testthat/test-class-forecast-quantile.R:281:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-quantile.R:282:    sort(eval1$ae_median), sort(ae)\ntests/testthat/test-class-forecast-quantile.R:283:  )\ntests/testthat/test-class-forecast-quantile.R:284:})\ntests/testthat/test-class-forecast-quantile.R:285:\ntests/testthat/test-class-forecast-quantile.R:286:test_that(\"WIS is the same with other metrics omitted or included\", {\ntests/testthat/test-class-forecast-quantile.R:287:  eval <- score(example_quantile,\ntests/testthat/test-class-forecast-quantile.R:288:    metrics = list(wis = wis)\ntests/testthat/test-class-forecast-quantile.R:289:  )\ntests/testthat/test-class-forecast-quantile.R:290:\ntests/testthat/test-class-forecast-quantile.R:291:  eval2 <- scores_quantile\ntests/testthat/test-class-forecast-quantile.R:292:\ntests/testthat/test-class-forecast-quantile.R:293:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-quantile.R:294:    sum(eval$wis),\ntests/testthat/test-class-forecast-quantile.R:295:    sum(eval2$wis)\ntests/testthat/test-class-forecast-quantile.R:296:  )\ntests/testthat/test-class-forecast-quantile.R:297:})\ntests/testthat/test-class-forecast-quantile.R:298:\ntests/testthat/test-class-forecast-quantile.R:299:\ntests/testthat/test-class-forecast-quantile.R:300:test_that(\"score.forecast_quantile() errors with only NA values\", {\ntests/testthat/test-class-forecast-quantile.R:301:  # [.forecast()` will warn even before score()\ntests/testthat/test-class-forecast-quantile.R:302:  only_nas <- suppressWarnings(\ntests/testthat/test-class-forecast-quantile.R:303:    copy(example_quantile)[, predicted := NA_real_]\ntests/testthat/test-class-forecast-quantile.R:304:  )\ntests/testthat/test-class-forecast-quantile.R:305:  expect_error(\ntests/testthat/test-class-forecast-quantile.R:306:    score(only_nas),\ntests/testthat/test-class-forecast-quantile.R:307:    \"After removing rows with NA values in the data, no forecasts are left.\"\ntests/testthat/test-class-forecast-quantile.R:308:  )\ntests/testthat/test-class-forecast-quantile.R:309:})\ntests/testthat/test-class-forecast-quantile.R:310:\ntests/testthat/test-class-forecast-quantile.R:311:test_that(\"score.forecast_quantile() works as expected in edge cases\", {\ntests/testthat/test-class-forecast-quantile.R:312:  # only the median\ntests/testthat/test-class-forecast-quantile.R:313:  onlymedian <- example_quantile[quantile_level == 0.5]\ntests/testthat/test-class-forecast-quantile.R:314:  s <- expect_no_condition(\ntests/testthat/test-class-forecast-quantile.R:315:    score(onlymedian, metrics = get_metrics(\ntests/testthat/test-class-forecast-quantile.R:316:      example_quantile,\ntests/testthat/test-class-forecast-quantile.R:317:      exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\ntests/testthat/test-class-forecast-quantile.R:318:    ))\ntests/testthat/test-class-forecast-quantile.R:319:  )\ntests/testthat/test-class-forecast-quantile.R:320:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-quantile.R:321:    s$wis, abs(onlymedian$observed - onlymedian$predicted)\ntests/testthat/test-class-forecast-quantile.R:322:  )\ntests/testthat/test-class-forecast-quantile.R:323:\ntests/testthat/test-class-forecast-quantile.R:324:  # only one symmetric interval is present\ntests/testthat/test-class-forecast-quantile.R:325:  oneinterval <- example_quantile[quantile_level %in% c(0.25, 0.75)] |>\ntests/testthat/test-class-forecast-quantile.R:326:    as_forecast_quantile()\ntests/testthat/test-class-forecast-quantile.R:327:  s <- suppressMessages(score(\ntests/testthat/test-class-forecast-quantile.R:328:    oneinterval,\ntests/testthat/test-class-forecast-quantile.R:329:    metrics = get_metrics(\ntests/testthat/test-class-forecast-quantile.R:330:      example_quantile,\ntests/testthat/test-class-forecast-quantile.R:331:      exclude = c(\"interval_coverage_90\", \"ae_median\")\ntests/testthat/test-class-forecast-quantile.R:332:    )\ntests/testthat/test-class-forecast-quantile.R:333:  ))\ntests/testthat/test-class-forecast-quantile.R:334:  expect_message(\ntests/testthat/test-class-forecast-quantile.R:335:    score(\ntests/testthat/test-class-forecast-quantile.R:336:      oneinterval,\ntests/testthat/test-class-forecast-quantile.R:337:      metrics = get_metrics(\ntests/testthat/test-class-forecast-quantile.R:338:        example_quantile,\ntests/testthat/test-class-forecast-quantile.R:339:        exclude = c(\"interval_coverage_90\", \"ae_median\")\ntests/testthat/test-class-forecast-quantile.R:340:      )\ntests/testthat/test-class-forecast-quantile.R:341:    ),\ntests/testthat/test-class-forecast-quantile.R:342:    \"Median not available\"\ntests/testthat/test-class-forecast-quantile.R:343:  )\ntests/testthat/test-class-forecast-quantile.R:344:})\ntests/testthat/test-class-forecast-quantile.R:345:\ntests/testthat/test-class-forecast-quantile.R:346:test_that(\"score() works even if only some quantiles are missing\", {\ntests/testthat/test-class-forecast-quantile.R:347:  # only the median is there\ntests/testthat/test-class-forecast-quantile.R:348:  onlymedian <- example_quantile[quantile_level == 0.5]\ntests/testthat/test-class-forecast-quantile.R:349:  expect_no_condition(\ntests/testthat/test-class-forecast-quantile.R:350:    score(onlymedian, metrics = get_metrics(\ntests/testthat/test-class-forecast-quantile.R:351:      example_quantile,\ntests/testthat/test-class-forecast-quantile.R:352:      exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\ntests/testthat/test-class-forecast-quantile.R:353:    ))\ntests/testthat/test-class-forecast-quantile.R:354:  )\ntests/testthat/test-class-forecast-quantile.R:355:\ntests/testthat/test-class-forecast-quantile.R:356:  # asymmetric intervals\ntests/testthat/test-class-forecast-quantile.R:357:  asymm <- example_quantile[quantile_level <= 0.6]\ntests/testthat/test-class-forecast-quantile.R:358:  metrics <- get_metrics(\ntests/testthat/test-class-forecast-quantile.R:359:    example_quantile,\ntests/testthat/test-class-forecast-quantile.R:360:    exclude = c(\"overprediction\", \"underprediction\", \"dispersion\")\ntests/testthat/test-class-forecast-quantile.R:361:  )\ntests/testthat/test-class-forecast-quantile.R:362:  metrics$wis <- purrr::partial(wis, na.rm = TRUE)\ntests/testthat/test-class-forecast-quantile.R:363:  score_a <- suppressWarnings({\ntests/testthat/test-class-forecast-quantile.R:364:    scores_temp <- score(asymm, metrics = metrics)\ntests/testthat/test-class-forecast-quantile.R:365:    summarise_scores(scores_temp, by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:366:  })\ntests/testthat/test-class-forecast-quantile.R:367:  expect_warning(\ntests/testthat/test-class-forecast-quantile.R:368:    expect_warning({\ntests/testthat/test-class-forecast-quantile.R:369:      scores_temp <- score(asymm, metrics = metrics)\ntests/testthat/test-class-forecast-quantile.R:370:      summarise_scores(scores_temp, by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:371:    },\ntests/testthat/test-class-forecast-quantile.R:372:    \"Computation for `interval_coverage_50` failed.\"\ntests/testthat/test-class-forecast-quantile.R:373:    ),\ntests/testthat/test-class-forecast-quantile.R:374:    \"Computation for `interval_coverage_90` failed.\"\ntests/testthat/test-class-forecast-quantile.R:375:  )\ntests/testthat/test-class-forecast-quantile.R:376:\ntests/testthat/test-class-forecast-quantile.R:377:  # expect a failure with the regular wis wihtout ma.rm=TRUE\ntests/testthat/test-class-forecast-quantile.R:378:  expect_warning(\ntests/testthat/test-class-forecast-quantile.R:379:    score(asymm, metrics = c(wis = wis)),\ntests/testthat/test-class-forecast-quantile.R:380:    \"Not all quantile levels specified form symmetric prediction intervals.\"\ntests/testthat/test-class-forecast-quantile.R:381:  )\ntests/testthat/test-class-forecast-quantile.R:382:\ntests/testthat/test-class-forecast-quantile.R:383:  # check that the result is equal to a case where we discard the entire\ntests/testthat/test-class-forecast-quantile.R:384:  # interval in terms of WIS\ntests/testthat/test-class-forecast-quantile.R:385:  inner <- example_quantile[quantile_level %in% c(0.4, 0.45, 0.5, 0.55, 0.6)]\ntests/testthat/test-class-forecast-quantile.R:386:  score_b <- score(inner, metrics = c(wis = wis)) |>\ntests/testthat/test-class-forecast-quantile.R:387:    summarise_scores(by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:388:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-class-forecast-quantile.R:389:    score_a$wis,\ntests/testthat/test-class-forecast-quantile.R:390:    score_b$wis\ntests/testthat/test-class-forecast-quantile.R:391:  )\ntests/testthat/test-class-forecast-quantile.R:392:\ntests/testthat/test-class-forecast-quantile.R:393:  # median is not there, but only in a single model\ntests/testthat/test-class-forecast-quantile.R:394:  test <- data.table::copy(example_quantile)\ntests/testthat/test-class-forecast-quantile.R:395:  test_no_median <- test[model == \"epiforecasts-EpiNow2\" & quantile_level != 0.5, ]\ntests/testthat/test-class-forecast-quantile.R:396:  test <- rbind(test[model != \"epiforecasts-EpiNow2\"], test_no_median)\ntests/testthat/test-class-forecast-quantile.R:397:\ntests/testthat/test-class-forecast-quantile.R:398:  test <- suppressWarnings(as_forecast_quantile(test))\ntests/testthat/test-class-forecast-quantile.R:399:  expect_message(\ntests/testthat/test-class-forecast-quantile.R:400:    expect_warning(\ntests/testthat/test-class-forecast-quantile.R:401:      score(test),\ntests/testthat/test-class-forecast-quantile.R:402:      \"Computation for `ae_median` failed.\"\ntests/testthat/test-class-forecast-quantile.R:403:    ),\ntests/testthat/test-class-forecast-quantile.R:404:    \"interpolating median from the two innermost quantiles\"\ntests/testthat/test-class-forecast-quantile.R:405:  )\ntests/testthat/test-class-forecast-quantile.R:406:})\ntests/testthat/test-class-forecast-quantile.R:407:\ntests/testthat/test-class-forecast-quantile.R:408:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:409:# get_metrics.forecast_quantile() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-quantile.R:410:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:411:test_that(\"get_metrics.forecast_quantile() works as expected\", {\ntests/testthat/test-class-forecast-quantile.R:412:  expect_type(\ntests/testthat/test-class-forecast-quantile.R:413:    get_metrics(example_quantile), \"list\"\ntests/testthat/test-class-forecast-quantile.R:414:  )\ntests/testthat/test-class-forecast-quantile.R:415:})\ntests/testthat/test-class-forecast-quantile.R:416:\ntests/testthat/test-class-forecast-quantile.R:417:\ntests/testthat/test-class-forecast-quantile.R:418:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:419:# get_pit_histogram.forecast_quantile() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-quantile.R:420:# ==============================================================================\ntests/testthat/test-class-forecast-quantile.R:421:test_that(\"get_pit_histogram.forecast_quantile() works as expected\", {\ntests/testthat/test-class-forecast-quantile.R:422:  pit_quantile <- get_pit_histogram(example_quantile, by = \"model\")\ntests/testthat/test-class-forecast-quantile.R:423:\ntests/testthat/test-class-forecast-quantile.R:424:  expect_named(pit_quantile, c(\"model\", \"density\", \"bin\", \"mid\"))\ntests/testthat/test-class-forecast-quantile.R:425:  expect_s3_class(pit_quantile, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-quantile.R:426:\ntests/testthat/test-class-forecast-quantile.R:427:  # check printing works\ntests/testthat/test-class-forecast-quantile.R:428:  expect_output(print(pit_quantile))\ntests/testthat/test-class-forecast-quantile.R:429:})\ntests/testthat/test-class-forecast.R:1:# ==============================================================================\ntests/testthat/test-class-forecast.R:2:# as_forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:3:# ==============================================================================\ntests/testthat/test-class-forecast.R:4:# see tests for each forecast type for more specific tests.\ntests/testthat/test-class-forecast.R:5:\ntests/testthat/test-class-forecast.R:6:\ntests/testthat/test-class-forecast.R:7:# ==============================================================================\ntests/testthat/test-class-forecast.R:8:# is_forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:9:# ==============================================================================\ntests/testthat/test-class-forecast.R:10:\ntests/testthat/test-class-forecast.R:11:test_that(\"is_forecast() works as expected\", {\ntests/testthat/test-class-forecast.R:12:  expect_true(is_forecast(example_binary))\ntests/testthat/test-class-forecast.R:13:  expect_true(is_forecast(example_point))\ntests/testthat/test-class-forecast.R:14:  expect_true(is_forecast(example_quantile))\ntests/testthat/test-class-forecast.R:15:  expect_true(is_forecast(example_sample_continuous))\ntests/testthat/test-class-forecast.R:16:  expect_true(is_forecast(example_nominal))\ntests/testthat/test-class-forecast.R:17:\ntests/testthat/test-class-forecast.R:18:  expect_false(is_forecast(1:10))\ntests/testthat/test-class-forecast.R:19:  expect_false(is_forecast(data.table::as.data.table(example_point)))\ntests/testthat/test-class-forecast.R:20:})\ntests/testthat/test-class-forecast.R:21:\ntests/testthat/test-class-forecast.R:22:\ntests/testthat/test-class-forecast.R:23:# ==============================================================================\ntests/testthat/test-class-forecast.R:24:# assert_forecast() and assert_forecast_generic() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:25:# ==============================================================================\ntests/testthat/test-class-forecast.R:26:\ntests/testthat/test-class-forecast.R:27:test_that(\"assert_forecast() works as expected\", {\ntests/testthat/test-class-forecast.R:28:  # test that by default, `as_forecast()` errors\ntests/testthat/test-class-forecast.R:29:  expect_error(\ntests/testthat/test-class-forecast.R:30:    assert_forecast(data.frame(x = 1:10)),\ntests/testthat/test-class-forecast.R:31:    \"The input needs to be a valid forecast object.\"\ntests/testthat/test-class-forecast.R:32:  )\ntests/testthat/test-class-forecast.R:33:})\ntests/testthat/test-class-forecast.R:34:\ntests/testthat/test-class-forecast.R:35:test_that(\"assert_forecast_generic() works as expected with a data.frame\", {\ntests/testthat/test-class-forecast.R:36:  expect_error(\ntests/testthat/test-class-forecast.R:37:    assert_forecast_generic(example_quantile_df),\ntests/testthat/test-class-forecast.R:38:    \"Assertion on 'data' failed: Must be a data.table, not data.frame.\"\ntests/testthat/test-class-forecast.R:39:  )\ntests/testthat/test-class-forecast.R:40:})\ntests/testthat/test-class-forecast.R:41:\ntests/testthat/test-class-forecast.R:42:\ntests/testthat/test-class-forecast.R:43:# ==============================================================================\ntests/testthat/test-class-forecast.R:44:# new_forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:45:# ==============================================================================\ntests/testthat/test-class-forecast.R:46:\ntests/testthat/test-class-forecast.R:47:test_that(\"new_forecast() works as expected with a data.frame\", {\ntests/testthat/test-class-forecast.R:48:  expect_s3_class(\ntests/testthat/test-class-forecast.R:49:    new_forecast(example_quantile_df, \"quantile\"),\ntests/testthat/test-class-forecast.R:50:    c(\"forecast_quantile\", \"data.table\", \"data.frame\")\ntests/testthat/test-class-forecast.R:51:  )\ntests/testthat/test-class-forecast.R:52:})\ntests/testthat/test-class-forecast.R:53:\ntests/testthat/test-class-forecast.R:54:\ntests/testthat/test-class-forecast.R:55:# ==============================================================================\ntests/testthat/test-class-forecast.R:56:# [.forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:57:# ==============================================================================\ntests/testthat/test-class-forecast.R:58:\ntests/testthat/test-class-forecast.R:59:test_that(\"[.forecast() immediately invalidates on change when necessary\", {\ntests/testthat/test-class-forecast.R:60:  test <- na.omit(data.table::copy(example_quantile))\ntests/testthat/test-class-forecast.R:61:\ntests/testthat/test-class-forecast.R:62:  # For cols; various ways to drop.\ntests/testthat/test-class-forecast.R:63:  # We use local() to avoid actual deletion in this frame and having to recreate\ntests/testthat/test-class-forecast.R:64:  # the input multiple times\ntests/testthat/test-class-forecast.R:65:  expect_warning(\ntests/testthat/test-class-forecast.R:66:    local(test[, colnames(test) != \"observed\", with = FALSE]),\ntests/testthat/test-class-forecast.R:67:    \"Error in validating\"\ntests/testthat/test-class-forecast.R:68:  )\ntests/testthat/test-class-forecast.R:69:\ntests/testthat/test-class-forecast.R:70:  expect_warning(\ntests/testthat/test-class-forecast.R:71:    local({\ntests/testthat/test-class-forecast.R:72:      test[, \"observed\"] <- NULL\ntests/testthat/test-class-forecast.R:73:    }),\ntests/testthat/test-class-forecast.R:74:    \"Error in validating\"\ntests/testthat/test-class-forecast.R:75:  )\ntests/testthat/test-class-forecast.R:76:\ntests/testthat/test-class-forecast.R:77:  expect_warning(\ntests/testthat/test-class-forecast.R:78:    local({\ntests/testthat/test-class-forecast.R:79:      test$observed <- NULL\ntests/testthat/test-class-forecast.R:80:    }),\ntests/testthat/test-class-forecast.R:81:    \"Error in validating\"\ntests/testthat/test-class-forecast.R:82:  )\ntests/testthat/test-class-forecast.R:83:\ntests/testthat/test-class-forecast.R:84:  expect_warning(\ntests/testthat/test-class-forecast.R:85:    local({\ntests/testthat/test-class-forecast.R:86:      test[[\"observed\"]] <- NULL\ntests/testthat/test-class-forecast.R:87:    }),\ntests/testthat/test-class-forecast.R:88:    \"Error in validating\"\ntests/testthat/test-class-forecast.R:89:  )\ntests/testthat/test-class-forecast.R:90:\ntests/testthat/test-class-forecast.R:91:  # For rows\ntests/testthat/test-class-forecast.R:92:  expect_warning(\ntests/testthat/test-class-forecast.R:93:    local({\ntests/testthat/test-class-forecast.R:94:      test[2, ] <- test[1, ]\ntests/testthat/test-class-forecast.R:95:    })\ntests/testthat/test-class-forecast.R:96:  )\ntests/testthat/test-class-forecast.R:97:})\ntests/testthat/test-class-forecast.R:98:\ntests/testthat/test-class-forecast.R:99:test_that(\"[.forecast() doesn't warn on cases where the user likely didn't intend getting a forecast object\", {\ntests/testthat/test-class-forecast.R:100:  test <- as_forecast_quantile(na.omit(example_quantile))\ntests/testthat/test-class-forecast.R:101:\ntests/testthat/test-class-forecast.R:102:  expect_no_condition(test[, location])\ntests/testthat/test-class-forecast.R:103:})\ntests/testthat/test-class-forecast.R:104:\ntests/testthat/test-class-forecast.R:105:test_that(\"[.forecast() is compatible with data.table syntax\", {\ntests/testthat/test-class-forecast.R:106:  test <- as_forecast_quantile(na.omit(example_quantile))\ntests/testthat/test-class-forecast.R:107:\ntests/testthat/test-class-forecast.R:108:  expect_no_condition(\ntests/testthat/test-class-forecast.R:109:    test[location == \"DE\"]\ntests/testthat/test-class-forecast.R:110:  )\ntests/testthat/test-class-forecast.R:111:\ntests/testthat/test-class-forecast.R:112:  expect_no_condition(\ntests/testthat/test-class-forecast.R:113:    test[\ntests/testthat/test-class-forecast.R:114:      target_type == \"Cases\",\ntests/testthat/test-class-forecast.R:115:      .(location, target_end_date, observed, location_name, forecast_date, quantile_level, predicted, model)\ntests/testthat/test-class-forecast.R:116:    ]\ntests/testthat/test-class-forecast.R:117:  )\ntests/testthat/test-class-forecast.R:118:})\ntests/testthat/test-class-forecast.R:119:\ntests/testthat/test-class-forecast.R:120:\ntests/testthat/test-class-forecast.R:121:# ==============================================================================\ntests/testthat/test-class-forecast.R:122:# print.forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:123:# ==============================================================================\ntests/testthat/test-class-forecast.R:124:test_that(\"print() works on forecast_* objects\", {\ntests/testthat/test-class-forecast.R:125:  # Check print works on each forecast object\ntests/testthat/test-class-forecast.R:126:  test_dat <- list(\ntests/testthat/test-class-forecast.R:127:    example_binary, example_quantile,\ntests/testthat/test-class-forecast.R:128:    example_point, example_sample_continuous,\ntests/testthat/test-class-forecast.R:129:    example_sample_discrete\ntests/testthat/test-class-forecast.R:130:  )\ntests/testthat/test-class-forecast.R:131:  test_dat <- lapply(test_dat, na.omit)\ntests/testthat/test-class-forecast.R:132:  for (dat in test_dat) {\ntests/testthat/test-class-forecast.R:133:    forecast_type <- scoringutils:::get_forecast_type(dat) # nolint: undesirable_operator_linter\ntests/testthat/test-class-forecast.R:134:    forecast_unit <- get_forecast_unit(dat)\ntests/testthat/test-class-forecast.R:135:\ntests/testthat/test-class-forecast.R:136:    fn_name <- paste0(\"as_forecast_\", forecast_type)\ntests/testthat/test-class-forecast.R:137:    fn <- get(fn_name)\ntests/testthat/test-class-forecast.R:138:    dat <- suppressWarnings(suppressMessages(do.call(fn, list(dat))))\ntests/testthat/test-class-forecast.R:139:\ntests/testthat/test-class-forecast.R:140:    # Check Forecast type\ntests/testthat/test-class-forecast.R:141:    expect_snapshot(print(dat))\ntests/testthat/test-class-forecast.R:142:    expect_snapshot(print(dat))\ntests/testthat/test-class-forecast.R:143:    # Check Forecast unit\ntests/testthat/test-class-forecast.R:144:    expect_snapshot(print(dat))\ntests/testthat/test-class-forecast.R:145:    expect_snapshot(print(dat))\ntests/testthat/test-class-forecast.R:146:\ntests/testthat/test-class-forecast.R:147:    # Check print.data.table works.\ntests/testthat/test-class-forecast.R:148:    output_original <- suppressMessages(capture.output(print(dat)))\ntests/testthat/test-class-forecast.R:149:    output_test <- suppressMessages(capture.output(print(data.table(dat))))\ntests/testthat/test-class-forecast.R:150:    expect_contains(output_original, output_test)\ntests/testthat/test-class-forecast.R:151:  }\ntests/testthat/test-class-forecast.R:152:})\ntests/testthat/test-class-forecast.R:153:\ntests/testthat/test-class-forecast.R:154:test_that(\"print() throws the expected messages\", {\ntests/testthat/test-class-forecast.R:155:  test <- data.table::copy(example_point)\ntests/testthat/test-class-forecast.R:156:  class(test) <- c(\"point\", \"forecast\", \"data.table\", \"data.frame\")\ntests/testthat/test-class-forecast.R:157:\ntests/testthat/test-class-forecast.R:158:  # note that since introducing a length maximum for validation to be triggered,\ntests/testthat/test-class-forecast.R:159:  # we don't throw a warning automatically anymore\ntests/testthat/test-class-forecast.R:160:  suppressMessages(\ntests/testthat/test-class-forecast.R:161:    expect_message(\ntests/testthat/test-class-forecast.R:162:      capture.output(print(test)),\ntests/testthat/test-class-forecast.R:163:      \"Could not determine forecast type due to error in validation.\"\ntests/testthat/test-class-forecast.R:164:    )\ntests/testthat/test-class-forecast.R:165:  )\ntests/testthat/test-class-forecast.R:166:\ntests/testthat/test-class-forecast.R:167:  class(test) <- c(\"forecast_point\", \"forecast\")\ntests/testthat/test-class-forecast.R:168:  suppressMessages(\ntests/testthat/test-class-forecast.R:169:    expect_message(\ntests/testthat/test-class-forecast.R:170:      capture.output(print(test)),\ntests/testthat/test-class-forecast.R:171:      \"Could not determine forecast unit.\"\ntests/testthat/test-class-forecast.R:172:    )\ntests/testthat/test-class-forecast.R:173:  )\ntests/testthat/test-class-forecast.R:174:})\ntests/testthat/test-class-forecast.R:175:\ntests/testthat/test-class-forecast.R:176:\ntests/testthat/test-class-forecast.R:177:# ==============================================================================\ntests/testthat/test-class-forecast.R:178:# check_number_per_forecast() # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:179:# ==============================================================================\ntests/testthat/test-class-forecast.R:180:test_that(\"check_number_per_forecast works\", {\ntests/testthat/test-class-forecast.R:181:  expect_identical(\ntests/testthat/test-class-forecast.R:182:    capture.output(\ntests/testthat/test-class-forecast.R:183:      check_number_per_forecast(\ntests/testthat/test-class-forecast.R:184:        example_binary,\ntests/testthat/test-class-forecast.R:185:        forecast_unit = \"location_name\"\ntests/testthat/test-class-forecast.R:186:      )\ntests/testthat/test-class-forecast.R:187:    ),\ntests/testthat/test-class-forecast.R:188:    paste(\ntests/testthat/test-class-forecast.R:189:      \"[1] \\\"Some forecasts have different numbers of rows\",\ntests/testthat/test-class-forecast.R:190:      \"(e.g. quantiles or samples). scoringutils found: 224, 215.\",\ntests/testthat/test-class-forecast.R:191:      \"This may be a problem (it can potentially distort scores,\",\ntests/testthat/test-class-forecast.R:192:      \"making it more difficult to compare them),\",\ntests/testthat/test-class-forecast.R:193:      \"so make sure this is intended.\\\"\"\ntests/testthat/test-class-forecast.R:194:    )\ntests/testthat/test-class-forecast.R:195:  )\ntests/testthat/test-class-forecast.R:196:  expect_true(\ntests/testthat/test-class-forecast.R:197:    check_number_per_forecast(\ntests/testthat/test-class-forecast.R:198:      example_binary\ntests/testthat/test-class-forecast.R:199:    )\ntests/testthat/test-class-forecast.R:200:  )\ntests/testthat/test-class-forecast.R:201:})\ntests/testthat/test-class-forecast.R:202:\ntests/testthat/test-class-forecast.R:203:\ntests/testthat/test-class-forecast.R:204:# ==============================================================================\ntests/testthat/test-class-forecast.R:205:# Test removing `NA` values from the data # nolint: commented_code_linter\ntests/testthat/test-class-forecast.R:206:# ==============================================================================\ntests/testthat/test-class-forecast.R:207:test_that(\"removing NA rows from data works as expected\", {\ntests/testthat/test-class-forecast.R:208:  expect_identical(nrow(na.omit(example_quantile)), 20401L)\ntests/testthat/test-class-forecast.R:209:\ntests/testthat/test-class-forecast.R:210:  ex <- data.frame(observed = c(NA, 1:3), predicted = 1:4)\ntests/testthat/test-class-forecast.R:211:  expect_identical(nrow(na.omit(ex)), 3L)\ntests/testthat/test-class-forecast.R:212:\ntests/testthat/test-class-forecast.R:213:  ex$predicted <- c(1:3, NA)\ntests/testthat/test-class-forecast.R:214:  expect_identical(nrow(na.omit(ex)), 2L)\ntests/testthat/test-class-forecast.R:215:\ntests/testthat/test-class-forecast.R:216:  # test that attributes and classes are retained\ntests/testthat/test-class-forecast.R:217:  ex <- as_forecast_sample(na.omit(example_sample_discrete))\ntests/testthat/test-class-forecast.R:218:  expect_s3_class(\ntests/testthat/test-class-forecast.R:219:    na.omit(ex),\ntests/testthat/test-class-forecast.R:220:    c(\"forecast_sample\", \"forecast\", \"data.table\", \"data.frame\"),\ntests/testthat/test-class-forecast.R:221:    exact = TRUE\ntests/testthat/test-class-forecast.R:222:  )\ntests/testthat/test-class-forecast.R:223:\ntests/testthat/test-class-forecast.R:224:  attributes <- attributes(ex)\ntests/testthat/test-class-forecast.R:225:  expect_identical(\ntests/testthat/test-class-forecast.R:226:    attributes(na.omit(ex)),\ntests/testthat/test-class-forecast.R:227:    attributes\ntests/testthat/test-class-forecast.R:228:  )\ntests/testthat/test-class-forecast.R:229:})\ntests/testthat/test-class-forecast-ordinal.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:2:# as_forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-ordinal.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:4:test_that(\"as_forecast.forecast_ordinal() works as expected\", {\ntests/testthat/test-class-forecast-ordinal.R:5:  ex <- data.table::copy(example_ordinal) |>\ntests/testthat/test-class-forecast-ordinal.R:6:    na.omit()\ntests/testthat/test-class-forecast-ordinal.R:7:\ntests/testthat/test-class-forecast-ordinal.R:8:\ntests/testthat/test-class-forecast-ordinal.R:9:  expect_s3_class(\ntests/testthat/test-class-forecast-ordinal.R:10:    as_forecast_ordinal(ex),\ntests/testthat/test-class-forecast-ordinal.R:11:    c(\"forecast_ordinal\", \"forecast\", \"data.table\", \"data.frame\"),\ntests/testthat/test-class-forecast-ordinal.R:12:    exact = TRUE\ntests/testthat/test-class-forecast-ordinal.R:13:  )\ntests/testthat/test-class-forecast-ordinal.R:14:\ntests/testthat/test-class-forecast-ordinal.R:15:  setnames(ex, old = \"predicted_label\", new = \"label\")\ntests/testthat/test-class-forecast-ordinal.R:16:  expect_no_condition(\ntests/testthat/test-class-forecast-ordinal.R:17:    as_forecast_ordinal(ex, predicted_label = \"label\")\ntests/testthat/test-class-forecast-ordinal.R:18:  )\ntests/testthat/test-class-forecast-ordinal.R:19:})\ntests/testthat/test-class-forecast-ordinal.R:20:\ntests/testthat/test-class-forecast-ordinal.R:21:test_that(\"as_forecast.forecast_ordinal() breaks when rows with zero probability are missing\", {\ntests/testthat/test-class-forecast-ordinal.R:22:  ex_faulty <- as.data.table(example_ordinal)\ntests/testthat/test-class-forecast-ordinal.R:23:  ex_faulty <- ex_faulty[predicted != 0]\ntests/testthat/test-class-forecast-ordinal.R:24:  expect_warning(\ntests/testthat/test-class-forecast-ordinal.R:25:    expect_error(\ntests/testthat/test-class-forecast-ordinal.R:26:      as_forecast_ordinal(ex_faulty),\ntests/testthat/test-class-forecast-ordinal.R:27:      \"Found incomplete forecasts\"\ntests/testthat/test-class-forecast-ordinal.R:28:    ),\ntests/testthat/test-class-forecast-ordinal.R:29:    \"Some forecasts have different numbers of rows\"\ntests/testthat/test-class-forecast-ordinal.R:30:  )\ntests/testthat/test-class-forecast-ordinal.R:31:})\ntests/testthat/test-class-forecast-ordinal.R:32:\ntests/testthat/test-class-forecast-ordinal.R:33:test_that(\"assert_forecast.forecast_ordinal() fails if factors are not ordered\", {\ntests/testthat/test-class-forecast-ordinal.R:34:  ex_faulty <- na.omit(data.table::copy(example_nominal))\ntests/testthat/test-class-forecast-ordinal.R:35:  expect_error(\ntests/testthat/test-class-forecast-ordinal.R:36:    as_forecast_ordinal(ex_faulty),\ntests/testthat/test-class-forecast-ordinal.R:37:    \"Assertion on 'forecast\\\\$observed' failed: Must be an ordered factor, but is unordered.\"\ntests/testthat/test-class-forecast-ordinal.R:38:  )\ntests/testthat/test-class-forecast-ordinal.R:39:})\ntests/testthat/test-class-forecast-ordinal.R:40:\ntests/testthat/test-class-forecast-ordinal.R:41:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:42:# is_forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-ordinal.R:43:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:44:test_that(\"is_forecast_nominal() works as expected\", {\ntests/testthat/test-class-forecast-ordinal.R:45:  expect_true(is_forecast_ordinal(example_ordinal))\ntests/testthat/test-class-forecast-ordinal.R:46:  expect_false(is_forecast_ordinal(example_binary))\ntests/testthat/test-class-forecast-ordinal.R:47:  expect_false(is_forecast_ordinal(example_point))\ntests/testthat/test-class-forecast-ordinal.R:48:  expect_false(is_forecast_ordinal(example_quantile))\ntests/testthat/test-class-forecast-ordinal.R:49:  expect_false(is_forecast_ordinal(example_sample_continuous))\ntests/testthat/test-class-forecast-ordinal.R:50:  expect_false(is_forecast_ordinal(1:10))\ntests/testthat/test-class-forecast-ordinal.R:51:})\ntests/testthat/test-class-forecast-ordinal.R:52:\ntests/testthat/test-class-forecast-ordinal.R:53:\ntests/testthat/test-class-forecast-ordinal.R:54:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:55:# get_metrics.forecast_nominal() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-ordinal.R:56:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:57:\ntests/testthat/test-class-forecast-ordinal.R:58:test_that(\"get_metrics.forecast_nominal() works as expected\", {\ntests/testthat/test-class-forecast-ordinal.R:59:  expect_type(\ntests/testthat/test-class-forecast-ordinal.R:60:    get_metrics(example_ordinal), \"list\"\ntests/testthat/test-class-forecast-ordinal.R:61:  )\ntests/testthat/test-class-forecast-ordinal.R:62:})\ntests/testthat/test-class-forecast-ordinal.R:63:\ntests/testthat/test-class-forecast-ordinal.R:64:\ntests/testthat/test-class-forecast-ordinal.R:65:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:66:# Printing # nolint: commented_code_linter\ntests/testthat/test-class-forecast-ordinal.R:67:# ==============================================================================\ntests/testthat/test-class-forecast-ordinal.R:68:test_that(\"Printing works as expected\", {\ntests/testthat/test-class-forecast-ordinal.R:69:  suppressMessages(\ntests/testthat/test-class-forecast-ordinal.R:70:    expect_message(\ntests/testthat/test-class-forecast-ordinal.R:71:      expect_message(\ntests/testthat/test-class-forecast-ordinal.R:72:        capture.output(print(example_ordinal)),\ntests/testthat/test-class-forecast-ordinal.R:73:        \"Forecast type: ordinal\"\ntests/testthat/test-class-forecast-ordinal.R:74:      ),\ntests/testthat/test-class-forecast-ordinal.R:75:      \"Forecast unit:\"\ntests/testthat/test-class-forecast-ordinal.R:76:    )\ntests/testthat/test-class-forecast-ordinal.R:77:  )\ntests/testthat/test-class-forecast-ordinal.R:78:})\ntests/testthat/test-metrics-sample.R:1:test_that(\"Input handling\", {\ntests/testthat/test-metrics-sample.R:2:  observed <- rpois(30, lambda = 1:30)\ntests/testthat/test-metrics-sample.R:3:  predicted <- replicate(20, rpois(n = 30, lambda = 1:30))\ntests/testthat/test-metrics-sample.R:4:  expect_length(crps_sample(observed, predicted), 30)\ntests/testthat/test-metrics-sample.R:5:\ntests/testthat/test-metrics-sample.R:6:  # should error when wrong prediction type is given\ntests/testthat/test-metrics-sample.R:7:  predicted2 <- rpois(30, lambda = 1)\ntests/testthat/test-metrics-sample.R:8:  expect_error(crps_sample(observed, predicted2),\ntests/testthat/test-metrics-sample.R:9:    \"Assertion on 'predicted' failed: Must be of type 'matrix', not 'integer'\",\ntests/testthat/test-metrics-sample.R:10:    fixed = TRUE\ntests/testthat/test-metrics-sample.R:11:  )\ntests/testthat/test-metrics-sample.R:12:\ntests/testthat/test-metrics-sample.R:13:  # predictions have wrong number of rows\ntests/testthat/test-metrics-sample.R:14:  predicted3 <- replicate(20, rpois(n = 31, lambda = 1))\ntests/testthat/test-metrics-sample.R:15:  expect_error(\ntests/testthat/test-metrics-sample.R:16:    crps_sample(observed, predicted3),\ntests/testthat/test-metrics-sample.R:17:    \"Assertion on 'predicted' failed: Must have exactly 30 rows, but has 31 rows.\",\ntests/testthat/test-metrics-sample.R:18:    # \"Mismatch: 'observed' has length `30`, but 'predicted' has `31` rows.\",\ntests/testthat/test-metrics-sample.R:19:    fixed = TRUE\ntests/testthat/test-metrics-sample.R:20:  )\ntests/testthat/test-metrics-sample.R:21:\ntests/testthat/test-metrics-sample.R:22:  # error with missing argument\ntests/testthat/test-metrics-sample.R:23:  expect_error(crps_sample(predicted = predicted),\ntests/testthat/test-metrics-sample.R:24:    'argument \"observed\" is missing, with no default',\ntests/testthat/test-metrics-sample.R:25:    fixed = TRUE\ntests/testthat/test-metrics-sample.R:26:  )\ntests/testthat/test-metrics-sample.R:27:})\ntests/testthat/test-metrics-sample.R:28:\ntests/testthat/test-metrics-sample.R:29:test_that(\"crps works with separate results\", {\ntests/testthat/test-metrics-sample.R:30:  observed <- rpois(30, lambda = 1:30)\ntests/testthat/test-metrics-sample.R:31:  predicted <- replicate(20, rpois(n = 30, lambda = 1:30))\ntests/testthat/test-metrics-sample.R:32:  crps <- crps_sample(\ntests/testthat/test-metrics-sample.R:33:    observed = observed,\ntests/testthat/test-metrics-sample.R:34:    predicted = predicted,\ntests/testthat/test-metrics-sample.R:35:    separate_results = TRUE\ntests/testthat/test-metrics-sample.R:36:  )\ntests/testthat/test-metrics-sample.R:37:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:38:    crps$crps, crps$dispersion + crps$overprediction + crps$underprediction\ntests/testthat/test-metrics-sample.R:39:  )\ntests/testthat/test-metrics-sample.R:40:})\ntests/testthat/test-metrics-sample.R:41:\ntests/testthat/test-metrics-sample.R:42:test_that(\"crps is the sum of overprediction, underprediction, dispersion\", {\ntests/testthat/test-metrics-sample.R:43:  observed <- rpois(30, lambda = 1:30)\ntests/testthat/test-metrics-sample.R:44:  predicted <- replicate(20, rpois(n = 30, lambda = 1:30))\ntests/testthat/test-metrics-sample.R:45:  crps <- crps_sample(\ntests/testthat/test-metrics-sample.R:46:    observed = observed,\ntests/testthat/test-metrics-sample.R:47:    predicted = predicted\ntests/testthat/test-metrics-sample.R:48:  )\ntests/testthat/test-metrics-sample.R:49:\ntests/testthat/test-metrics-sample.R:50:  d <- dispersion_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:51:  o <- overprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:52:  u <- underprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:53:\ntests/testthat/test-metrics-sample.R:54:  expect_equal(crps, d + o + u) # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:55:\ntests/testthat/test-metrics-sample.R:56:  observed <- rnorm(30, mean = 1:30)\ntests/testthat/test-metrics-sample.R:57:  predicted <- replicate(20, rnorm(n = 30, mean = 1:30))\ntests/testthat/test-metrics-sample.R:58:  crps <- crps_sample(\ntests/testthat/test-metrics-sample.R:59:    observed = observed,\ntests/testthat/test-metrics-sample.R:60:    predicted = predicted\ntests/testthat/test-metrics-sample.R:61:  )\ntests/testthat/test-metrics-sample.R:62:\ntests/testthat/test-metrics-sample.R:63:  d <- dispersion_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:64:  o <- overprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:65:  u <- underprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:66:\ntests/testthat/test-metrics-sample.R:67:  expect_equal(crps, d + o + u) # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:68:})\ntests/testthat/test-metrics-sample.R:69:\ntests/testthat/test-metrics-sample.R:70:\ntests/testthat/test-metrics-sample.R:71:test_that(\"crps_sample() components correspond to WIS components\", {\ntests/testthat/test-metrics-sample.R:72:  set.seed(123)\ntests/testthat/test-metrics-sample.R:73:  nreplicates <- 15\ntests/testthat/test-metrics-sample.R:74:  nsamples <- 2000\ntests/testthat/test-metrics-sample.R:75:\ntests/testthat/test-metrics-sample.R:76:  observed <- rnorm(nreplicates, mean = seq_len(nreplicates))\ntests/testthat/test-metrics-sample.R:77:  predicted <- replicate(\ntests/testthat/test-metrics-sample.R:78:    nsamples, rnorm(n = nreplicates, mean = seq_len(nreplicates))\ntests/testthat/test-metrics-sample.R:79:  )\ntests/testthat/test-metrics-sample.R:80:  crps <- crps_sample(\ntests/testthat/test-metrics-sample.R:81:    observed = observed,\ntests/testthat/test-metrics-sample.R:82:    predicted = predicted\ntests/testthat/test-metrics-sample.R:83:  )\ntests/testthat/test-metrics-sample.R:84:\ntests/testthat/test-metrics-sample.R:85:  dcrps <- dispersion_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:86:  ocrps <- overprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:87:  ucrps <- underprediction_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:88:\ntests/testthat/test-metrics-sample.R:89:  levels <- seq(0.01, 0.99, by = 0.01)\ntests/testthat/test-metrics-sample.R:90:  quantiles <- t(apply(predicted, 1, quantile, probs = levels))\ntests/testthat/test-metrics-sample.R:91:\ntests/testthat/test-metrics-sample.R:92:  dwis <- dispersion_quantile(observed, quantiles, levels)\ntests/testthat/test-metrics-sample.R:93:  owis <- overprediction_quantile(observed, quantiles, levels)\ntests/testthat/test-metrics-sample.R:94:  uwis <- underprediction_quantile(observed, quantiles, levels)\ntests/testthat/test-metrics-sample.R:95:\ntests/testthat/test-metrics-sample.R:96:  expect_true(all(abs(c(dcrps - dwis, ocrps - owis, ucrps - uwis)) < 0.01))\ntests/testthat/test-metrics-sample.R:97:})\ntests/testthat/test-metrics-sample.R:98:\ntests/testthat/test-metrics-sample.R:99:test_that(\"crps_sample() works with a single observation\", {\ntests/testthat/test-metrics-sample.R:100:  crps <- expect_no_condition(\ntests/testthat/test-metrics-sample.R:101:    crps_sample(\ntests/testthat/test-metrics-sample.R:102:      observed = 2.5, predicted = 1.5:10.5, separate_results = TRUE\ntests/testthat/test-metrics-sample.R:103:    )\ntests/testthat/test-metrics-sample.R:104:  )\ntests/testthat/test-metrics-sample.R:105:  expect_length(crps, 4)\ntests/testthat/test-metrics-sample.R:106:  expect_equal(unique(lengths(crps)), 1) # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:107:})\ntests/testthat/test-metrics-sample.R:108:\ntests/testthat/test-metrics-sample.R:109:test_that(\"bias_sample() throws an error when missing observed\", {\ntests/testthat/test-metrics-sample.R:110:  observed <- rpois(10, lambda = 1:10)\ntests/testthat/test-metrics-sample.R:111:  predicted <- replicate(50, rpois(n = 10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:112:\ntests/testthat/test-metrics-sample.R:113:  expect_error(\ntests/testthat/test-metrics-sample.R:114:    bias_sample(predicted = predicted),\ntests/testthat/test-metrics-sample.R:115:    'argument \"observed\" is missing, with no default'\ntests/testthat/test-metrics-sample.R:116:  )\ntests/testthat/test-metrics-sample.R:117:})\ntests/testthat/test-metrics-sample.R:118:\ntests/testthat/test-metrics-sample.R:119:test_that(\"bias_sample() throws an error when missing 'predicted'\", {\ntests/testthat/test-metrics-sample.R:120:  observed <- rpois(10, lambda = 1:10)\ntests/testthat/test-metrics-sample.R:121:  predicted <- replicate(50, rpois(n = 10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:122:\ntests/testthat/test-metrics-sample.R:123:  expect_error(\ntests/testthat/test-metrics-sample.R:124:    bias_sample(observed = observed),\ntests/testthat/test-metrics-sample.R:125:    'argument \"predicted\" is missing, with no default'\ntests/testthat/test-metrics-sample.R:126:  )\ntests/testthat/test-metrics-sample.R:127:})\ntests/testthat/test-metrics-sample.R:128:\ntests/testthat/test-metrics-sample.R:129:test_that(\"bias_sample() works for integer observed and predicted\", {\ntests/testthat/test-metrics-sample.R:130:  observed <- rpois(10, lambda = 1:10)\ntests/testthat/test-metrics-sample.R:131:  predicted <- replicate(10, rpois(10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:132:  output <- bias_sample(\ntests/testthat/test-metrics-sample.R:133:    observed = observed,\ntests/testthat/test-metrics-sample.R:134:    predicted = predicted\ntests/testthat/test-metrics-sample.R:135:  )\ntests/testthat/test-metrics-sample.R:136:  expect_length(\ntests/testthat/test-metrics-sample.R:137:    output,\ntests/testthat/test-metrics-sample.R:138:    length(observed)\ntests/testthat/test-metrics-sample.R:139:  )\ntests/testthat/test-metrics-sample.R:140:  expect_type(\ntests/testthat/test-metrics-sample.R:141:    output,\ntests/testthat/test-metrics-sample.R:142:    \"double\"\ntests/testthat/test-metrics-sample.R:143:  )\ntests/testthat/test-metrics-sample.R:144:})\ntests/testthat/test-metrics-sample.R:145:\ntests/testthat/test-metrics-sample.R:146:test_that(\"bias_sample() works for continuous observed values and predicted\", {\ntests/testthat/test-metrics-sample.R:147:  observed <- rnorm(10)\ntests/testthat/test-metrics-sample.R:148:  predicted <- replicate(10, rnorm(10))\ntests/testthat/test-metrics-sample.R:149:  output <- bias_sample(\ntests/testthat/test-metrics-sample.R:150:    observed = observed,\ntests/testthat/test-metrics-sample.R:151:    predicted = predicted\ntests/testthat/test-metrics-sample.R:152:  )\ntests/testthat/test-metrics-sample.R:153:  expect_length(\ntests/testthat/test-metrics-sample.R:154:    output,\ntests/testthat/test-metrics-sample.R:155:    length(observed)\ntests/testthat/test-metrics-sample.R:156:  )\ntests/testthat/test-metrics-sample.R:157:  expect_type(\ntests/testthat/test-metrics-sample.R:158:    output,\ntests/testthat/test-metrics-sample.R:159:    \"double\"\ntests/testthat/test-metrics-sample.R:160:  )\ntests/testthat/test-metrics-sample.R:161:})\ntests/testthat/test-metrics-sample.R:162:\ntests/testthat/test-metrics-sample.R:163:test_that(\"bias_sample() works as expected\", {\ntests/testthat/test-metrics-sample.R:164:  observed <- rpois(30, lambda = 1:30)\ntests/testthat/test-metrics-sample.R:165:  predicted <- replicate(200, rpois(n = 30, lambda = 1:30))\ntests/testthat/test-metrics-sample.R:166:  expect_true(all(bias_sample(observed, predicted) == bias_sample(observed, predicted)))\ntests/testthat/test-metrics-sample.R:167:\ntests/testthat/test-metrics-sample.R:168:  ## continuous forecasts\ntests/testthat/test-metrics-sample.R:169:  observed <- rnorm(30, mean = 1:30)\ntests/testthat/test-metrics-sample.R:170:  predicted <- replicate(200, rnorm(30, mean = 1:30))\ntests/testthat/test-metrics-sample.R:171:\ntests/testthat/test-metrics-sample.R:172:  scoringutils2 <- bias_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:173:  scoringutils <- bias_sample(observed, predicted)\ntests/testthat/test-metrics-sample.R:174:\ntests/testthat/test-metrics-sample.R:175:  expect_equal(scoringutils, scoringutils2) # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:176:})\ntests/testthat/test-metrics-sample.R:177:\ntests/testthat/test-metrics-sample.R:178:\ntests/testthat/test-metrics-sample.R:179:test_that(\"bias_sample() approx equals bias_quantile() for many samples\", {\ntests/testthat/test-metrics-sample.R:180:  set.seed(123)\ntests/testthat/test-metrics-sample.R:181:\ntests/testthat/test-metrics-sample.R:182:  # Generate true value\ntests/testthat/test-metrics-sample.R:183:  observed <- 3\ntests/testthat/test-metrics-sample.R:184:\ntests/testthat/test-metrics-sample.R:185:  # Generate many sample predictions\ntests/testthat/test-metrics-sample.R:186:  predicted <- sample(rnorm(1000, mean = observed, sd = 2), 1000)\ntests/testthat/test-metrics-sample.R:187:\ntests/testthat/test-metrics-sample.R:188:  # Get sample based bias\ntests/testthat/test-metrics-sample.R:189:  bias_sample_result <- bias_sample(\ntests/testthat/test-metrics-sample.R:190:    observed, matrix(predicted, nrow = 1)\ntests/testthat/test-metrics-sample.R:191:  )\ntests/testthat/test-metrics-sample.R:192:\ntests/testthat/test-metrics-sample.R:193:  # Convert predictions to quantiles\ntests/testthat/test-metrics-sample.R:194:  quantiles <- seq(0, 1, length.out = 100)\ntests/testthat/test-metrics-sample.R:195:  quantile_preds <- quantile(predicted, probs = quantiles)\ntests/testthat/test-metrics-sample.R:196:\ntests/testthat/test-metrics-sample.R:197:  # Get quantile based bias\ntests/testthat/test-metrics-sample.R:198:  bias_quantile_result <- suppressMessages(\ntests/testthat/test-metrics-sample.R:199:    bias_quantile(observed, quantile_preds, quantiles)\ntests/testthat/test-metrics-sample.R:200:  )\ntests/testthat/test-metrics-sample.R:201:\ntests/testthat/test-metrics-sample.R:202:  # Difference should be small\ntests/testthat/test-metrics-sample.R:203:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:204:    bias_quantile_result, bias_sample_result, tolerance = 0.1\ntests/testthat/test-metrics-sample.R:205:  )\ntests/testthat/test-metrics-sample.R:206:})\ntests/testthat/test-metrics-sample.R:207:\ntests/testthat/test-metrics-sample.R:208:\ntests/testthat/test-metrics-sample.R:209:# `ae_median_sample` ===========================================================\ntests/testthat/test-metrics-sample.R:210:test_that(\"ae_median_sample works\", {\ntests/testthat/test-metrics-sample.R:211:  observed <- rnorm(30, mean = 1:30)\ntests/testthat/test-metrics-sample.R:212:  predicted_values <- rnorm(30, mean = 1:30)\ntests/testthat/test-metrics-sample.R:213:  scoringutils <- ae_median_sample(observed, matrix(predicted_values))\ntests/testthat/test-metrics-sample.R:214:  ae <- abs(observed - predicted_values)\ntests/testthat/test-metrics-sample.R:215:  expect_equal(ae, scoringutils) # nolint: expect_identical_linter # nolint: expect_identical_linter\ntests/testthat/test-metrics-sample.R:216:})\ntests/testthat/test-metrics-sample.R:217:\ntests/testthat/test-metrics-sample.R:218:# `mad_sample()` ===============================================================\ntests/testthat/test-metrics-sample.R:219:test_that(\"function throws an error when missing 'predicted'\", {\ntests/testthat/test-metrics-sample.R:220:  predicted <- replicate(50, rpois(n = 10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:221:\ntests/testthat/test-metrics-sample.R:222:  expect_error(\ntests/testthat/test-metrics-sample.R:223:    mad_sample()\ntests/testthat/test-metrics-sample.R:224:  )\ntests/testthat/test-metrics-sample.R:225:})\ntests/testthat/test-metrics-sample.R:226:\ntests/testthat/test-metrics-sample.R:227:\ntests/testthat/test-metrics-sample.R:228:# ============================================================================ #\ntests/testthat/test-metrics-sample.R:229:# pit_histogram_sample() # nolint: commented_code_linter\ntests/testthat/test-metrics-sample.R:230:# ============================================================================ #\ntests/testthat/test-metrics-sample.R:231:\ntests/testthat/test-metrics-sample.R:232:test_that(\"pit_histogram_sample() function throws an error when missing args\", {\ntests/testthat/test-metrics-sample.R:233:  observed <- rpois(10, lambda = 1:10)\ntests/testthat/test-metrics-sample.R:234:  predicted <- replicate(50, rpois(n = 10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:235:\ntests/testthat/test-metrics-sample.R:236:  expect_error(\ntests/testthat/test-metrics-sample.R:237:    pit_histogram_sample(predicted = predicted),\ntests/testthat/test-metrics-sample.R:238:    'argument \"observed\" is missing, with no default'\ntests/testthat/test-metrics-sample.R:239:  )\ntests/testthat/test-metrics-sample.R:240:\ntests/testthat/test-metrics-sample.R:241:  expect_error(\ntests/testthat/test-metrics-sample.R:242:    pit_histogram_sample(observed = observed),\ntests/testthat/test-metrics-sample.R:243:    'argument \"predicted\" is missing, with no default'\ntests/testthat/test-metrics-sample.R:244:  )\ntests/testthat/test-metrics-sample.R:245:\ntests/testthat/test-metrics-sample.R:246:  expect_error(\ntests/testthat/test-metrics-sample.R:247:    pit_histogram_sample(predicted = predicted, observed = observed),\ntests/testthat/test-metrics-sample.R:248:    'argument \"quantiles\" is missing, with no default'\ntests/testthat/test-metrics-sample.R:249:  )\ntests/testthat/test-metrics-sample.R:250:\ntests/testthat/test-metrics-sample.R:251:  expect_error(\ntests/testthat/test-metrics-sample.R:252:    pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:253:      predicted = predicted, observed = observed,\ntests/testthat/test-metrics-sample.R:254:      quantiles = seq(0, 1, by = 0.1), integers = \"random\"\ntests/testthat/test-metrics-sample.R:255:    ),\ntests/testthat/test-metrics-sample.R:256:    \"Assertion on 'n_replicates with `integers` =  random' failed:\"\ntests/testthat/test-metrics-sample.R:257:  )\ntests/testthat/test-metrics-sample.R:258:})\ntests/testthat/test-metrics-sample.R:259:\ntests/testthat/test-metrics-sample.R:260:test_that(\"pit_histogram_sample() function works for integer observed and predicted\", {\ntests/testthat/test-metrics-sample.R:261:  observed <- rpois(10, lambda = 1:10)\ntests/testthat/test-metrics-sample.R:262:  predicted <- replicate(10, rpois(10, lambda = 1:10))\ntests/testthat/test-metrics-sample.R:263:  output <- pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:264:    observed = observed,\ntests/testthat/test-metrics-sample.R:265:    predicted = predicted,\ntests/testthat/test-metrics-sample.R:266:    quantiles = seq(0, 1, by = 0.1)\ntests/testthat/test-metrics-sample.R:267:  )\ntests/testthat/test-metrics-sample.R:268:  expect_length(\ntests/testthat/test-metrics-sample.R:269:    output,\ntests/testthat/test-metrics-sample.R:270:    10\ntests/testthat/test-metrics-sample.R:271:  )\ntests/testthat/test-metrics-sample.R:272:\ntests/testthat/test-metrics-sample.R:273:  checkmate::expect_class(output, \"numeric\")\ntests/testthat/test-metrics-sample.R:274:\ntests/testthat/test-metrics-sample.R:275:  output2 <- pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:276:    observed = observed,\ntests/testthat/test-metrics-sample.R:277:    predicted = predicted,\ntests/testthat/test-metrics-sample.R:278:    quantiles = seq(0, 1, by = 0.1),\ntests/testthat/test-metrics-sample.R:279:    integers = \"random\",\ntests/testthat/test-metrics-sample.R:280:    n_replicates = 56\ntests/testthat/test-metrics-sample.R:281:  )\ntests/testthat/test-metrics-sample.R:282:})\ntests/testthat/test-metrics-sample.R:283:\ntests/testthat/test-metrics-sample.R:284:test_that(\"pit_histogram_sample() function works for continuous observed and predicted\", {\ntests/testthat/test-metrics-sample.R:285:  observed <- rnorm(10)\ntests/testthat/test-metrics-sample.R:286:  predicted <- replicate(10, rnorm(10))\ntests/testthat/test-metrics-sample.R:287:  output <- pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:288:    observed = observed,\ntests/testthat/test-metrics-sample.R:289:    predicted = predicted,\ntests/testthat/test-metrics-sample.R:290:    quantiles = seq(0, 1, by = 0.1)\ntests/testthat/test-metrics-sample.R:291:  )\ntests/testthat/test-metrics-sample.R:292:  expect_length(\ntests/testthat/test-metrics-sample.R:293:    output,\ntests/testthat/test-metrics-sample.R:294:    10\ntests/testthat/test-metrics-sample.R:295:  )\ntests/testthat/test-metrics-sample.R:296:})\ntests/testthat/test-metrics-sample.R:297:\ntests/testthat/test-metrics-sample.R:298:test_that(\"pit_histogram_sample() works with a single observvation\", {\ntests/testthat/test-metrics-sample.R:299:  output <- expect_no_condition(\ntests/testthat/test-metrics-sample.R:300:    pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:301:      observed = 2.5, predicted = 1.5:10.5, quantiles = seq(0, 1, by = 0.1)\ntests/testthat/test-metrics-sample.R:302:    )\ntests/testthat/test-metrics-sample.R:303:  )\ntests/testthat/test-metrics-sample.R:304:  expect_length(output, 10)\ntests/testthat/test-metrics-sample.R:305:\ntests/testthat/test-metrics-sample.R:306:  # test discrete case\ntests/testthat/test-metrics-sample.R:307:  output2 <- expect_no_condition(\ntests/testthat/test-metrics-sample.R:308:    pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:309:      observed = 3, predicted = 1:10, quantiles = seq(0, 1, by = 0.1)\ntests/testthat/test-metrics-sample.R:310:    )\ntests/testthat/test-metrics-sample.R:311:  )\ntests/testthat/test-metrics-sample.R:312:  expect_length(output2, 10)\ntests/testthat/test-metrics-sample.R:313:})\ntests/testthat/test-metrics-sample.R:314:\ntests/testthat/test-metrics-sample.R:315:test_that(\"pit_histogram_sample() throws an error if inputs are wrong\", {\ntests/testthat/test-metrics-sample.R:316:  observed <- 1.5:20.5\ntests/testthat/test-metrics-sample.R:317:  predicted <- replicate(100, 1.5:20.5)\ntests/testthat/test-metrics-sample.R:318:\ntests/testthat/test-metrics-sample.R:319:  # expect an error if predicted cannot be coerced to a matrix\ntests/testthat/test-metrics-sample.R:320:  expect_error(\ntests/testthat/test-metrics-sample.R:321:    pit_histogram_sample(observed, function(x) {}),\ntests/testthat/test-metrics-sample.R:322:    \"Assertion on 'predicted' failed: Must be of type 'matrix'\"\ntests/testthat/test-metrics-sample.R:323:  )\ntests/testthat/test-metrics-sample.R:324:\ntests/testthat/test-metrics-sample.R:325:  # expect an error if the number of rows in predicted does not match the length of observed\ntests/testthat/test-metrics-sample.R:326:  expect_error(\ntests/testthat/test-metrics-sample.R:327:    pit_histogram_sample(observed, predicted[1:10, ]),\ntests/testthat/test-metrics-sample.R:328:    \"Assertion on 'predicted' failed: Must have exactly 20 rows, but has 10 rows.\"\ntests/testthat/test-metrics-sample.R:329:  )\ntests/testthat/test-metrics-sample.R:330:\ntests/testthat/test-metrics-sample.R:331:  expect_warning(\ntests/testthat/test-metrics-sample.R:332:    pit_histogram_sample(\ntests/testthat/test-metrics-sample.R:333:      observed, predicted,\ntests/testthat/test-metrics-sample.R:334:      quantiles = seq(0, 1, by = 0.1), n_replicates = 10\ntests/testthat/test-metrics-sample.R:335:    ),\ntests/testthat/test-metrics-sample.R:336:    \"`n_replicates` is ignored when `integers` is not `random`\"\ntests/testthat/test-metrics-sample.R:337:  )\ntests/testthat/test-metrics-sample.R:338:})\ntests/testthat/test-get-duplicate-forecasts.R:1:# ==============================================================================\ntests/testthat/test-get-duplicate-forecasts.R:2:# get_duplicate_forecasts() # nolint: commented_code_linter\ntests/testthat/test-get-duplicate-forecasts.R:3:# ==============================================================================\ntests/testthat/test-get-duplicate-forecasts.R:4:test_that(\"get_duplicate_forecasts() works as expected for quantile\", {\ntests/testthat/test-get-duplicate-forecasts.R:5:  expect_no_condition(get_duplicate_forecasts(\ntests/testthat/test-get-duplicate-forecasts.R:6:    example_quantile,\ntests/testthat/test-get-duplicate-forecasts.R:7:    forecast_unit =\ntests/testthat/test-get-duplicate-forecasts.R:8:      c(\ntests/testthat/test-get-duplicate-forecasts.R:9:        \"location\", \"target_end_date\", \"target_type\", \"location_name\",\ntests/testthat/test-get-duplicate-forecasts.R:10:        \"forecast_date\", \"model\"\ntests/testthat/test-get-duplicate-forecasts.R:11:      )\ntests/testthat/test-get-duplicate-forecasts.R:12:  ))\ntests/testthat/test-get-duplicate-forecasts.R:13:\ntests/testthat/test-get-duplicate-forecasts.R:14:  expect_identical(nrow(get_duplicate_forecasts(example_quantile)), 0L)\ntests/testthat/test-get-duplicate-forecasts.R:15:  expect_identical(\ntests/testthat/test-get-duplicate-forecasts.R:16:    nrow(\ntests/testthat/test-get-duplicate-forecasts.R:17:      get_duplicate_forecasts(rbind(example_quantile, example_quantile[1000:1010]))\ntests/testthat/test-get-duplicate-forecasts.R:18:    ),\ntests/testthat/test-get-duplicate-forecasts.R:19:    22L\ntests/testthat/test-get-duplicate-forecasts.R:20:  )\ntests/testthat/test-get-duplicate-forecasts.R:21:})\ntests/testthat/test-get-duplicate-forecasts.R:22:\ntests/testthat/test-get-duplicate-forecasts.R:23:test_that(\"get_duplicate_forecasts() works as expected for sample\", {\ntests/testthat/test-get-duplicate-forecasts.R:24:  expect_identical(nrow(get_duplicate_forecasts(example_sample_continuous)), 0L)\ntests/testthat/test-get-duplicate-forecasts.R:25:  expect_identical(\ntests/testthat/test-get-duplicate-forecasts.R:26:    nrow(\ntests/testthat/test-get-duplicate-forecasts.R:27:      get_duplicate_forecasts(rbind(example_sample_continuous, example_sample_continuous[1040:1050]))\ntests/testthat/test-get-duplicate-forecasts.R:28:    ),\ntests/testthat/test-get-duplicate-forecasts.R:29:    22L\ntests/testthat/test-get-duplicate-forecasts.R:30:  )\ntests/testthat/test-get-duplicate-forecasts.R:31:})\ntests/testthat/test-get-duplicate-forecasts.R:32:\ntests/testthat/test-get-duplicate-forecasts.R:33:\ntests/testthat/test-get-duplicate-forecasts.R:34:test_that(\"get_duplicate_forecasts() works as expected for binary\", {\ntests/testthat/test-get-duplicate-forecasts.R:35:  expect_identical(nrow(get_duplicate_forecasts(example_binary)), 0L)\ntests/testthat/test-get-duplicate-forecasts.R:36:  expect_identical(\ntests/testthat/test-get-duplicate-forecasts.R:37:    nrow(\ntests/testthat/test-get-duplicate-forecasts.R:38:      get_duplicate_forecasts(rbind(example_binary, example_binary[1000:1010]))\ntests/testthat/test-get-duplicate-forecasts.R:39:    ),\ntests/testthat/test-get-duplicate-forecasts.R:40:    22L\ntests/testthat/test-get-duplicate-forecasts.R:41:  )\ntests/testthat/test-get-duplicate-forecasts.R:42:})\ntests/testthat/test-get-duplicate-forecasts.R:43:\ntests/testthat/test-get-duplicate-forecasts.R:44:test_that(\"get_duplicate_forecasts() works as expected for point\", {\ntests/testthat/test-get-duplicate-forecasts.R:45:  expect_identical(nrow(get_duplicate_forecasts(example_binary)), 0L)\ntests/testthat/test-get-duplicate-forecasts.R:46:  expect_identical(\ntests/testthat/test-get-duplicate-forecasts.R:47:    nrow(\ntests/testthat/test-get-duplicate-forecasts.R:48:      get_duplicate_forecasts(rbind(example_point, example_point[1010:1020]))\ntests/testthat/test-get-duplicate-forecasts.R:49:    ),\ntests/testthat/test-get-duplicate-forecasts.R:50:    22L\ntests/testthat/test-get-duplicate-forecasts.R:51:  )\ntests/testthat/test-get-duplicate-forecasts.R:52:\ntests/testthat/test-get-duplicate-forecasts.R:53:  expect_s3_class(\ntests/testthat/test-get-duplicate-forecasts.R:54:    get_duplicate_forecasts(as.data.frame(example_point)),\ntests/testthat/test-get-duplicate-forecasts.R:55:    c(\"data.table\", \"data.frame\"),\ntests/testthat/test-get-duplicate-forecasts.R:56:    exact = TRUE\ntests/testthat/test-get-duplicate-forecasts.R:57:  )\ntests/testthat/test-get-duplicate-forecasts.R:58:})\ntests/testthat/test-get-duplicate-forecasts.R:59:\ntests/testthat/test-get-duplicate-forecasts.R:60:test_that(\"get_duplicate_forecasts() returns the expected class\", {\ntests/testthat/test-get-duplicate-forecasts.R:61:  expect_s3_class(\ntests/testthat/test-get-duplicate-forecasts.R:62:    get_duplicate_forecasts(example_point),\ntests/testthat/test-get-duplicate-forecasts.R:63:    c(\"data.table\", \"data.frame\")\ntests/testthat/test-get-duplicate-forecasts.R:64:  )\ntests/testthat/test-get-duplicate-forecasts.R:65:})\ntests/testthat/test-get-duplicate-forecasts.R:66:\ntests/testthat/test-get-duplicate-forecasts.R:67:test_that(\"get_duplicate_forecasts() works as expected with a data.frame\", {\ntests/testthat/test-get-duplicate-forecasts.R:68:  duplicates <- get_duplicate_forecasts(\ntests/testthat/test-get-duplicate-forecasts.R:69:    rbind(example_quantile_df, example_quantile_df[101:110, ])\ntests/testthat/test-get-duplicate-forecasts.R:70:  )\ntests/testthat/test-get-duplicate-forecasts.R:71:  expect_identical(nrow(duplicates), 20L)\ntests/testthat/test-get-duplicate-forecasts.R:72:})\ntests/testthat/test-get-duplicate-forecasts.R:73:\ntests/testthat/test-get-duplicate-forecasts.R:74:test_that(\"get_duplicate_forecasts() shows counts correctly\", {\ntests/testthat/test-get-duplicate-forecasts.R:75:  duplicates <- get_duplicate_forecasts(\ntests/testthat/test-get-duplicate-forecasts.R:76:    rbind(example_quantile, example_quantile[101:110, ]),\ntests/testthat/test-get-duplicate-forecasts.R:77:    counts = TRUE\ntests/testthat/test-get-duplicate-forecasts.R:78:  )\ntests/testthat/test-get-duplicate-forecasts.R:79:  expect_identical(nrow(duplicates), 2L)\ntests/testthat/test-get-duplicate-forecasts.R:80:  expect_identical(unique(duplicates$n_duplicates), 10L)\ntests/testthat/test-get-duplicate-forecasts.R:81:})\ntests/testthat/test-get-duplicate-forecasts.R:82:\ntests/testthat/test-get-duplicate-forecasts.R:83:\ntests/testthat/test-get-duplicate-forecasts.R:84:# ==============================================================================\ntests/testthat/test-get-duplicate-forecasts.R:85:# check_duplicates() # nolint: commented_code_linter\ntests/testthat/test-get-duplicate-forecasts.R:86:# ==============================================================================\ntests/testthat/test-get-duplicate-forecasts.R:87:test_that(\"check_duplicates works\", {\ntests/testthat/test-get-duplicate-forecasts.R:88:  example_bin <- rbind(example_binary[1000:1002, ], example_binary[1000:1002, ])\ntests/testthat/test-get-duplicate-forecasts.R:89:  expect_identical(\ntests/testthat/test-get-duplicate-forecasts.R:90:    capture.output(\ntests/testthat/test-get-duplicate-forecasts.R:91:      check_duplicates(example_bin)\ntests/testthat/test-get-duplicate-forecasts.R:92:    ),\ntests/testthat/test-get-duplicate-forecasts.R:93:    paste(\ntests/testthat/test-get-duplicate-forecasts.R:94:      \"[1] \\\"There are instances with more than one forecast for the same\",\ntests/testthat/test-get-duplicate-forecasts.R:95:      \"target. This can't be right and needs to be resolved.\",\ntests/testthat/test-get-duplicate-forecasts.R:96:      \"Maybe you need to check the unit of a single forecast and add\",\ntests/testthat/test-get-duplicate-forecasts.R:97:      \"missing columns? Use the function get_duplicate_forecasts() to\",\ntests/testthat/test-get-duplicate-forecasts.R:98:      \"identify duplicate rows\\\"\"\ntests/testthat/test-get-duplicate-forecasts.R:99:    )\ntests/testthat/test-get-duplicate-forecasts.R:100:  )\ntests/testthat/test-get-duplicate-forecasts.R:101:  expect_true(\ntests/testthat/test-get-duplicate-forecasts.R:102:    check_duplicates(example_binary)\ntests/testthat/test-get-duplicate-forecasts.R:103:  )\ntests/testthat/test-get-duplicate-forecasts.R:104:})\ntests/testthat/test-get-duplicate-forecasts.R:105:\ntests/testthat/test-get-duplicate-forecasts.R:106:\ntests/testthat/test-get-duplicate-forecasts.R:107:test_that(\"check_duplicates() works\", {\ntests/testthat/test-get-duplicate-forecasts.R:108:  bad <- rbind(\ntests/testthat/test-get-duplicate-forecasts.R:109:    example_quantile[1000:1010],\ntests/testthat/test-get-duplicate-forecasts.R:110:    example_quantile[1000:1010]\ntests/testthat/test-get-duplicate-forecasts.R:111:  )\ntests/testthat/test-get-duplicate-forecasts.R:112:\ntests/testthat/test-get-duplicate-forecasts.R:113:  expect_match(\ntests/testthat/test-get-duplicate-forecasts.R:114:    check_duplicates(bad),\ntests/testthat/test-get-duplicate-forecasts.R:115:    \"There are instances with more than one forecast.*get_duplicate_forecasts\"\ntests/testthat/test-get-duplicate-forecasts.R:116:  )\ntests/testthat/test-get-duplicate-forecasts.R:117:})\ntests/testthat/setup.R:1:data.table::setDTthreads(2) # restricts number of cores used on CRAN\ntests/testthat/setup.R:2:\ntests/testthat/setup.R:3:metrics_no_cov <- get_metrics(\ntests/testthat/setup.R:4:  example_quantile,\ntests/testthat/setup.R:5:  exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\ntests/testthat/setup.R:6:)\ntests/testthat/setup.R:7:metrics_no_cov_no_ae <- get_metrics(\ntests/testthat/setup.R:8:  example_quantile,\ntests/testthat/setup.R:9:  exclude = c(\ntests/testthat/setup.R:10:    \"interval_coverage_50\", \"interval_coverage_90\",\ntests/testthat/setup.R:11:    \"ae_median\"\ntests/testthat/setup.R:12:  )\ntests/testthat/setup.R:13:)\ntests/testthat/setup.R:14:\ntests/testthat/setup.R:15:example_quantile_df <- as.data.frame(na.omit(example_quantile))\ntests/testthat/setup.R:16:checkmate::assert_number(length(class(example_quantile_df)))\ntests/testthat/setup.R:17:\ntests/testthat/setup.R:18:\ntests/testthat/setup.R:19:# pre-computed scores\ntests/testthat/setup.R:20:scores_quantile <- score(example_quantile)\ntests/testthat/setup.R:21:scores_sample_continuous <- score(example_sample_continuous)\ntests/testthat/setup.R:22:scores_sample_discrete <- score(example_sample_discrete)\ntests/testthat/setup.R:23:scores_point <- score(example_point)\ntests/testthat/setup.R:24:scores_binary <- score(example_binary)\ntests/testthat/setup.R:25:scores_nominal <- score(example_nominal)\ntests/testthat/test-metrics-point.R:1:# covidHubUtils-tests on absolute error ========================================\ntests/testthat/test-metrics-point.R:2:# test are adapted from the package\ntests/testthat/test-metrics-point.R:3:# covidHubUtils, https://github.com/reichlab/covidHubUtils/\ntests/testthat/test-metrics-point.R:4:y <- c(1, -15, 22)\ntests/testthat/test-metrics-point.R:5:forecast_quantiles_matrix <- rbind(\ntests/testthat/test-metrics-point.R:6:  c(-1, 0, 1, 2, 3),\ntests/testthat/test-metrics-point.R:7:  c(-2, 1, 2, 2, 4),\ntests/testthat/test-metrics-point.R:8:  c(-2, 0, 3, 3, 4)\ntests/testthat/test-metrics-point.R:9:)\ntests/testthat/test-metrics-point.R:10:forecast_quantile_probs <- c(0.1, 0.25, 0.5, 0.75, 0.9)\ntests/testthat/test-metrics-point.R:11:\ntests/testthat/test-metrics-point.R:12:target_end_dates <- as.Date(\"2020-01-01\") + c(7, 14, 7)\ntests/testthat/test-metrics-point.R:13:horizons <- c(\"1\", \"2\", \"1\")\ntests/testthat/test-metrics-point.R:14:locations <- c(\"01\", \"01\", \"02\")\ntests/testthat/test-metrics-point.R:15:target_variables <- rep(\"inc death\", length(y))\ntests/testthat/test-metrics-point.R:16:\ntests/testthat/test-metrics-point.R:17:test_that(\"abs error is correct within score, point forecast only\", {\ntests/testthat/test-metrics-point.R:18:  forecast_target_end_dates <-\ntests/testthat/test-metrics-point.R:19:    rep(target_end_dates, times = 1)\ntests/testthat/test-metrics-point.R:20:  forecast_horizons <- rep(horizons, times = 1)\ntests/testthat/test-metrics-point.R:21:  forecast_locations <- rep(locations, times = 1)\ntests/testthat/test-metrics-point.R:22:  forecast_target_variables <-\ntests/testthat/test-metrics-point.R:23:    rep(target_variables, times = 1)\ntests/testthat/test-metrics-point.R:24:\ntests/testthat/test-metrics-point.R:25:  point_forecast <- c(5, 6, 7)\ntests/testthat/test-metrics-point.R:26:\ntests/testthat/test-metrics-point.R:27:  test_truth <- data.frame(\ntests/testthat/test-metrics-point.R:28:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-point.R:29:    target_variable = target_variables,\ntests/testthat/test-metrics-point.R:30:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-point.R:31:    location = locations,\ntests/testthat/test-metrics-point.R:32:    value = y,\ntests/testthat/test-metrics-point.R:33:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:34:  )\ntests/testthat/test-metrics-point.R:35:\ntests/testthat/test-metrics-point.R:36:\ntests/testthat/test-metrics-point.R:37:  n_forecasts <- length(point_forecast)\ntests/testthat/test-metrics-point.R:38:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-point.R:39:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-point.R:40:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-point.R:41:    location = forecast_locations,\ntests/testthat/test-metrics-point.R:42:    horizon = forecast_horizons,\ntests/testthat/test-metrics-point.R:43:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-point.R:44:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-point.R:45:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-point.R:46:    type = rep(\"point\", 3),\ntests/testthat/test-metrics-point.R:47:    quantile = NA,\ntests/testthat/test-metrics-point.R:48:    value = point_forecast,\ntests/testthat/test-metrics-point.R:49:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:50:  )\ntests/testthat/test-metrics-point.R:51:\ntests/testthat/test-metrics-point.R:52:  # bring in scoringutils format\ntests/testthat/test-metrics-point.R:53:  truth_scoringutils <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-point.R:54:  fc_scoringutils <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-point.R:55:  data.table::setnames(truth_scoringutils, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-point.R:56:  data.table::setnames(fc_scoringutils, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-point.R:57:  truth_scoringutils[, model := NULL]\ntests/testthat/test-metrics-point.R:58:\ntests/testthat/test-metrics-point.R:59:  data_scoringutils <- merge(\ntests/testthat/test-metrics-point.R:60:    fc_scoringutils,\ntests/testthat/test-metrics-point.R:61:    truth_scoringutils\ntests/testthat/test-metrics-point.R:62:  )[, quantile := NULL] |>\ntests/testthat/test-metrics-point.R:63:    as_forecast_point()\ntests/testthat/test-metrics-point.R:64:\ntests/testthat/test-metrics-point.R:65:  eval <- scoringutils::score(data_scoringutils)\ntests/testthat/test-metrics-point.R:66:\ntests/testthat/test-metrics-point.R:67:  expected <- abs(y - point_forecast)\ntests/testthat/test-metrics-point.R:68:  expect_equal(eval$ae_point, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-point.R:69:})\ntests/testthat/test-metrics-point.R:70:\ntests/testthat/test-metrics-point.R:71:test_that(\"abs error is correct, point and median forecasts different\", {\ntests/testthat/test-metrics-point.R:72:  forecast_quantiles_matrix <- forecast_quantiles_matrix[, 3, drop = FALSE]\ntests/testthat/test-metrics-point.R:73:  forecast_quantile_probs <- forecast_quantile_probs[3]\ntests/testthat/test-metrics-point.R:74:\ntests/testthat/test-metrics-point.R:75:  forecast_target_end_dates <-\ntests/testthat/test-metrics-point.R:76:    rep(target_end_dates, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:77:  forecast_horizons <- rep(horizons, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:78:  forecast_locations <- rep(locations, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:79:  forecast_target_variables <-\ntests/testthat/test-metrics-point.R:80:    rep(target_variables, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:81:  forecast_quantile_probs <- rep(forecast_quantile_probs, each = length(y))\ntests/testthat/test-metrics-point.R:82:  forecast_quantiles <- forecast_quantiles_matrix\ntests/testthat/test-metrics-point.R:83:  dim(forecast_quantiles) <- prod(dim(forecast_quantiles))\ntests/testthat/test-metrics-point.R:84:\ntests/testthat/test-metrics-point.R:85:  point_forecast <- c(5, 6, 7)\ntests/testthat/test-metrics-point.R:86:\ntests/testthat/test-metrics-point.R:87:  test_truth <- data.frame(\ntests/testthat/test-metrics-point.R:88:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-point.R:89:    target_variable = target_variables,\ntests/testthat/test-metrics-point.R:90:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-point.R:91:    location = locations,\ntests/testthat/test-metrics-point.R:92:    value = y,\ntests/testthat/test-metrics-point.R:93:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:94:  )\ntests/testthat/test-metrics-point.R:95:\ntests/testthat/test-metrics-point.R:96:  n_forecasts <- length(point_forecast) + length(forecast_quantiles)\ntests/testthat/test-metrics-point.R:97:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-point.R:98:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-point.R:99:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-point.R:100:    location = forecast_locations,\ntests/testthat/test-metrics-point.R:101:    horizon = forecast_horizons,\ntests/testthat/test-metrics-point.R:102:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-point.R:103:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-point.R:104:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-point.R:105:    type = c(rep(\"point\", length(point_forecast)), rep(\"quantile\", length(forecast_quantiles))),\ntests/testthat/test-metrics-point.R:106:    quantile = c(rep(NA, length(point_forecast)), forecast_quantile_probs),\ntests/testthat/test-metrics-point.R:107:    value = c(point_forecast, forecast_quantiles),\ntests/testthat/test-metrics-point.R:108:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:109:  )\ntests/testthat/test-metrics-point.R:110:\ntests/testthat/test-metrics-point.R:111:  # bring in scoringutils format\ntests/testthat/test-metrics-point.R:112:  truth_scoringutils <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-point.R:113:  fc_scoringutils <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-point.R:114:  data.table::setnames(truth_scoringutils, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-point.R:115:  data.table::setnames(fc_scoringutils, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-point.R:116:  truth_scoringutils[, model := NULL]\ntests/testthat/test-metrics-point.R:117:\ntests/testthat/test-metrics-point.R:118:  data_scoringutils <- merge(\ntests/testthat/test-metrics-point.R:119:    fc_scoringutils,\ntests/testthat/test-metrics-point.R:120:    truth_scoringutils\ntests/testthat/test-metrics-point.R:121:  )[, quantile := NULL] |>\ntests/testthat/test-metrics-point.R:122:    as_forecast_point()\ntests/testthat/test-metrics-point.R:123:\ntests/testthat/test-metrics-point.R:124:  eval <- scoringutils::score(data_scoringutils)\ntests/testthat/test-metrics-point.R:125:\ntests/testthat/test-metrics-point.R:126:  expected <- abs(y - point_forecast)\ntests/testthat/test-metrics-point.R:127:  # expect_equal(actual$abs_error, expected) # nolint: commented_code_linter\ntests/testthat/test-metrics-point.R:128:  expect_equal(eval[type == \"point\"]$ae_point, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-point.R:129:})\ntests/testthat/test-metrics-point.R:130:\ntests/testthat/test-metrics-point.R:131:test_that(\"abs error is correct, point and median forecasts same\", {\ntests/testthat/test-metrics-point.R:132:  forecast_quantiles_matrix <- forecast_quantiles_matrix[, 3, drop = FALSE]\ntests/testthat/test-metrics-point.R:133:  forecast_quantile_probs <- forecast_quantile_probs[3]\ntests/testthat/test-metrics-point.R:134:\ntests/testthat/test-metrics-point.R:135:  forecast_target_end_dates <-\ntests/testthat/test-metrics-point.R:136:    rep(target_end_dates, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:137:  forecast_horizons <- rep(horizons, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:138:  forecast_locations <- rep(locations, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:139:  forecast_target_variables <-\ntests/testthat/test-metrics-point.R:140:    rep(target_variables, times = 1 + ncol(forecast_quantiles_matrix))\ntests/testthat/test-metrics-point.R:141:  forecast_quantile_probs <- rep(forecast_quantile_probs, each = length(y))\ntests/testthat/test-metrics-point.R:142:  forecast_quantiles <- forecast_quantiles_matrix\ntests/testthat/test-metrics-point.R:143:  dim(forecast_quantiles) <- prod(dim(forecast_quantiles))\ntests/testthat/test-metrics-point.R:144:\ntests/testthat/test-metrics-point.R:145:  point_forecast <- c(1, 2, 3)\ntests/testthat/test-metrics-point.R:146:\ntests/testthat/test-metrics-point.R:147:  test_truth <- data.frame(\ntests/testthat/test-metrics-point.R:148:    model = rep(\"truth_source\", length(y)),\ntests/testthat/test-metrics-point.R:149:    target_variable = target_variables,\ntests/testthat/test-metrics-point.R:150:    target_end_date = target_end_dates,\ntests/testthat/test-metrics-point.R:151:    location = locations,\ntests/testthat/test-metrics-point.R:152:    value = y,\ntests/testthat/test-metrics-point.R:153:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:154:  )\ntests/testthat/test-metrics-point.R:155:\ntests/testthat/test-metrics-point.R:156:  n_forecasts <- length(point_forecast) + length(forecast_quantiles)\ntests/testthat/test-metrics-point.R:157:  test_forecasts <- data.frame(\ntests/testthat/test-metrics-point.R:158:    model = rep(\"m1\", n_forecasts),\ntests/testthat/test-metrics-point.R:159:    forecast_date = rep(as.Date(\"2020-01-01\"), n_forecasts),\ntests/testthat/test-metrics-point.R:160:    location = forecast_locations,\ntests/testthat/test-metrics-point.R:161:    horizon = forecast_horizons,\ntests/testthat/test-metrics-point.R:162:    temporal_resolution = rep(\"wk\", n_forecasts),\ntests/testthat/test-metrics-point.R:163:    target_variable = forecast_target_variables,\ntests/testthat/test-metrics-point.R:164:    target_end_date = forecast_target_end_dates,\ntests/testthat/test-metrics-point.R:165:    type = c(rep(\"point\", length(point_forecast)), rep(\"quantile\", length(forecast_quantiles))),\ntests/testthat/test-metrics-point.R:166:    quantile_level = c(rep(NA, length(point_forecast)), forecast_quantile_probs),\ntests/testthat/test-metrics-point.R:167:    value = c(point_forecast, forecast_quantiles),\ntests/testthat/test-metrics-point.R:168:    stringsAsFactors = FALSE\ntests/testthat/test-metrics-point.R:169:  )\ntests/testthat/test-metrics-point.R:170:\ntests/testthat/test-metrics-point.R:171:  # bring in scoringutils format\ntests/testthat/test-metrics-point.R:172:  truth_scoringutils <- data.table::as.data.table(test_truth)\ntests/testthat/test-metrics-point.R:173:  fc_scoringutils <- data.table::as.data.table(test_forecasts)\ntests/testthat/test-metrics-point.R:174:  data.table::setnames(truth_scoringutils, old = \"value\", new = \"observed\")\ntests/testthat/test-metrics-point.R:175:  data.table::setnames(fc_scoringutils, old = \"value\", new = \"predicted\")\ntests/testthat/test-metrics-point.R:176:  truth_scoringutils[, model := NULL]\ntests/testthat/test-metrics-point.R:177:\ntests/testthat/test-metrics-point.R:178:  data_scoringutils <- merge(\ntests/testthat/test-metrics-point.R:179:    fc_scoringutils,\ntests/testthat/test-metrics-point.R:180:    truth_scoringutils\ntests/testthat/test-metrics-point.R:181:  )\ntests/testthat/test-metrics-point.R:182:\ntests/testthat/test-metrics-point.R:183:  data_forecast_point <- as_forecast_point(\ntests/testthat/test-metrics-point.R:184:    data_scoringutils[type == \"point\"][, quantile_level := NULL]\ntests/testthat/test-metrics-point.R:185:  )\ntests/testthat/test-metrics-point.R:186:\ntests/testthat/test-metrics-point.R:187:  eval <- score(forecast = data_forecast_point)\ntests/testthat/test-metrics-point.R:188:  eval <- summarise_scores(eval,\ntests/testthat/test-metrics-point.R:189:    by = c(\ntests/testthat/test-metrics-point.R:190:      \"location\", \"target_end_date\",\ntests/testthat/test-metrics-point.R:191:      \"horizon\"\ntests/testthat/test-metrics-point.R:192:    ),\ntests/testthat/test-metrics-point.R:193:    na.rm = TRUE\ntests/testthat/test-metrics-point.R:194:  )\ntests/testthat/test-metrics-point.R:195:\ntests/testthat/test-metrics-point.R:196:  expected <- abs(y - point_forecast)\ntests/testthat/test-metrics-point.R:197:  expect_equal(eval$ae_point, expected) # nolint: expect_identical_linter\ntests/testthat/test-metrics-point.R:198:})\ntests/testthat/test-forecast-unit.R:1:# ============================================================================ #\ntests/testthat/test-forecast-unit.R:2:# `set_forecast_unit()` # nolint: commented_code_linter\ntests/testthat/test-forecast-unit.R:3:# ============================================================================ #\ntests/testthat/test-forecast-unit.R:4:\ntests/testthat/test-forecast-unit.R:5:test_that(\"function set_forecast_unit() works\", {\ntests/testthat/test-forecast-unit.R:6:  # some columns in the example data have duplicated information. So we can remove\ntests/testthat/test-forecast-unit.R:7:  # these and see whether the result stays the same.\ntests/testthat/test-forecast-unit.R:8:  scores1 <- scores_quantile[order(location, target_end_date, target_type, horizon, model), ]\ntests/testthat/test-forecast-unit.R:9:\ntests/testthat/test-forecast-unit.R:10:  # test that if setting the forecast unit results in an invalid object,\ntests/testthat/test-forecast-unit.R:11:  # a warning occurs.\ntests/testthat/test-forecast-unit.R:12:  expect_warning(\ntests/testthat/test-forecast-unit.R:13:    set_forecast_unit(example_quantile, \"model\"),\ntests/testthat/test-forecast-unit.R:14:    \"Assertion on 'data' failed: There are instances with more\"\ntests/testthat/test-forecast-unit.R:15:  )\ntests/testthat/test-forecast-unit.R:16:\ntests/testthat/test-forecast-unit.R:17:  ex2 <- set_forecast_unit(\ntests/testthat/test-forecast-unit.R:18:    example_quantile,\ntests/testthat/test-forecast-unit.R:19:    c(\"location\", \"target_end_date\", \"target_type\", \"horizon\", \"model\")\ntests/testthat/test-forecast-unit.R:20:  )\ntests/testthat/test-forecast-unit.R:21:  scores2 <- score(na.omit(ex2))\ntests/testthat/test-forecast-unit.R:22:  scores2 <- scores2[order(location, target_end_date, target_type, horizon, model), ]\ntests/testthat/test-forecast-unit.R:23:\ntests/testthat/test-forecast-unit.R:24:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-forecast-unit.R:25:    scores1$interval_score, scores2$interval_score\ntests/testthat/test-forecast-unit.R:26:  )\ntests/testthat/test-forecast-unit.R:27:})\ntests/testthat/test-forecast-unit.R:28:\ntests/testthat/test-forecast-unit.R:29:test_that(\"set_forecast_unit() works on input that's not a data.table\", {\ntests/testthat/test-forecast-unit.R:30:  df <- data.frame(\ntests/testthat/test-forecast-unit.R:31:    a = 1:2,\ntests/testthat/test-forecast-unit.R:32:    b = 2:3,\ntests/testthat/test-forecast-unit.R:33:    c = 3:4\ntests/testthat/test-forecast-unit.R:34:  )\ntests/testthat/test-forecast-unit.R:35:  expect_named(\ntests/testthat/test-forecast-unit.R:36:    set_forecast_unit(df, c(\"a\", \"b\")),\ntests/testthat/test-forecast-unit.R:37:    c(\"a\", \"b\")\ntests/testthat/test-forecast-unit.R:38:  )\ntests/testthat/test-forecast-unit.R:39:\ntests/testthat/test-forecast-unit.R:40:  expect_named(\ntests/testthat/test-forecast-unit.R:41:    set_forecast_unit(as.matrix(df), \"a\"),\ntests/testthat/test-forecast-unit.R:42:    \"a\"\ntests/testthat/test-forecast-unit.R:43:  )\ntests/testthat/test-forecast-unit.R:44:\ntests/testthat/test-forecast-unit.R:45:  expect_s3_class(\ntests/testthat/test-forecast-unit.R:46:    set_forecast_unit(df, c(\"a\", \"b\")),\ntests/testthat/test-forecast-unit.R:47:    c(\"data.table\", \"data.frame\"),\ntests/testthat/test-forecast-unit.R:48:    exact = TRUE\ntests/testthat/test-forecast-unit.R:49:  )\ntests/testthat/test-forecast-unit.R:50:})\ntests/testthat/test-forecast-unit.R:51:\ntests/testthat/test-forecast-unit.R:52:test_that(\"set_forecast_unit() revalidates a forecast object\", {\ntests/testthat/test-forecast-unit.R:53:  obj <- as_forecast_quantile(na.omit(example_quantile))\ntests/testthat/test-forecast-unit.R:54:  expect_no_condition(\ntests/testthat/test-forecast-unit.R:55:    set_forecast_unit(obj, c(\"location\", \"target_end_date\", \"target_type\", \"model\", \"horizon\"))\ntests/testthat/test-forecast-unit.R:56:  )\ntests/testthat/test-forecast-unit.R:57:})\ntests/testthat/test-forecast-unit.R:58:\ntests/testthat/test-forecast-unit.R:59:\ntests/testthat/test-forecast-unit.R:60:test_that(\"function set_forecast_unit() errors when column is not there\", {\ntests/testthat/test-forecast-unit.R:61:  expect_error(\ntests/testthat/test-forecast-unit.R:62:    set_forecast_unit(\ntests/testthat/test-forecast-unit.R:63:      example_quantile,\ntests/testthat/test-forecast-unit.R:64:      c(\"location\", \"target_end_date\", \"target_type\", \"horizon\", \"model\", \"test1\", \"test2\")\ntests/testthat/test-forecast-unit.R:65:    ),\ntests/testthat/test-forecast-unit.R:66:    \"Assertion on 'forecast_unit' failed: Must be a subset of \"\ntests/testthat/test-forecast-unit.R:67:  )\ntests/testthat/test-forecast-unit.R:68:})\ntests/testthat/test-forecast-unit.R:69:\ntests/testthat/test-forecast-unit.R:70:test_that(\"function get_forecast_unit() and set_forecast_unit() work together\", {\ntests/testthat/test-forecast-unit.R:71:  fu_set <- c(\"location\", \"target_end_date\", \"target_type\", \"horizon\", \"model\")\ntests/testthat/test-forecast-unit.R:72:  ex <- set_forecast_unit(example_binary, fu_set)\ntests/testthat/test-forecast-unit.R:73:  fu_get <- get_forecast_unit(ex)\ntests/testthat/test-forecast-unit.R:74:  expect_identical(fu_set, fu_get)\ntests/testthat/test-forecast-unit.R:75:})\ntests/testthat/test-forecast-unit.R:76:\ntests/testthat/test-forecast-unit.R:77:test_that(\"output class of set_forecast_unit() is as expected\", {\ntests/testthat/test-forecast-unit.R:78:  ex <- as_forecast_binary(na.omit(example_binary))\ntests/testthat/test-forecast-unit.R:79:  expect_s3_class(\ntests/testthat/test-forecast-unit.R:80:    set_forecast_unit(\ntests/testthat/test-forecast-unit.R:81:      ex, c(\"location\", \"target_end_date\", \"target_type\", \"horizon\", \"model\")\ntests/testthat/test-forecast-unit.R:82:    ),\ntests/testthat/test-forecast-unit.R:83:    class(ex)\ntests/testthat/test-forecast-unit.R:84:  )\ntests/testthat/test-forecast-unit.R:85:})\ntests/testthat/test-forecast-unit.R:86:\ntests/testthat/test-forecast-unit.R:87:\ntests/testthat/test-forecast-unit.R:88:# ==============================================================================\ntests/testthat/test-forecast-unit.R:89:# `get_forecast_unit()` # nolint: commented_code_linter\ntests/testthat/test-forecast-unit.R:90:# ==============================================================================\ntests/testthat/test-forecast-unit.R:91:test_that(\"get_forecast_unit() works as expected\", {\ntests/testthat/test-forecast-unit.R:92:  fc <- c(\ntests/testthat/test-forecast-unit.R:93:    \"location\", \"target_end_date\", \"target_type\", \"location_name\",\ntests/testthat/test-forecast-unit.R:94:    \"forecast_date\", \"model\", \"horizon\"\ntests/testthat/test-forecast-unit.R:95:  )\ntests/testthat/test-forecast-unit.R:96:\ntests/testthat/test-forecast-unit.R:97:  expect_identical(get_forecast_unit(example_quantile), fc)\ntests/testthat/test-forecast-unit.R:98:  expect_identical(get_forecast_unit(scores_quantile), fc)\ntests/testthat/test-forecast-unit.R:99:\ntests/testthat/test-forecast-unit.R:100:  # test with data.frame\ntests/testthat/test-forecast-unit.R:101:  expect_identical(get_forecast_unit(as.data.frame(example_quantile)), fc)\ntests/testthat/test-forecast-unit.R:102:})\ntests/testthat/test-get-protected-columns.R:1:# ==============================================================================\ntests/testthat/test-get-protected-columns.R:2:# `get_protected_columns()` # nolint: commented_code_linter\ntests/testthat/test-get-protected-columns.R:3:# ==============================================================================\ntests/testthat/test-get-protected-columns.R:4:test_that(\"get_protected_columns() works as expected\", {\ntests/testthat/test-get-protected-columns.R:5:  expect_identical(\ntests/testthat/test-get-protected-columns.R:6:    get_protected_columns(),\ntests/testthat/test-get-protected-columns.R:7:    c(\ntests/testthat/test-get-protected-columns.R:8:      \".mv_group_id\",\ntests/testthat/test-get-protected-columns.R:9:      \"predicted\", \"observed\", \"sample_id\",\ntests/testthat/test-get-protected-columns.R:10:      \"quantile_level\", \"upper\", \"lower\", \"pit_value\",\ntests/testthat/test-get-protected-columns.R:11:      \"interval_range\", \"boundary\", \"predicted_label\", \"interval_coverage\",\ntests/testthat/test-get-protected-columns.R:12:      \"interval_coverage_deviation\", \"quantile_coverage\",\ntests/testthat/test-get-protected-columns.R:13:      \"quantile_coverage_deviation\"\ntests/testthat/test-get-protected-columns.R:14:    )\ntests/testthat/test-get-protected-columns.R:15:  )\ntests/testthat/test-get-protected-columns.R:16:})\ntests/testthat/test-get-protected-columns.R:17:\ntests/testthat/test-get-protected-columns.R:18:test_that(\"get_protected_columns() returns the correct result\", {\ntests/testthat/test-get-protected-columns.R:19:  data <- example_quantile\ntests/testthat/test-get-protected-columns.R:20:  manual <- protected_columns <- c(\ntests/testthat/test-get-protected-columns.R:21:    \".mv_group_id\",\ntests/testthat/test-get-protected-columns.R:22:    \"predicted\", \"observed\", \"sample_id\", \"quantile_level\", \"upper\", \"lower\",\ntests/testthat/test-get-protected-columns.R:23:    \"pit_value\",\ntests/testthat/test-get-protected-columns.R:24:    \"range\", \"boundary\",\ntests/testthat/test-get-protected-columns.R:25:    grep(\"coverage_\", names(data), fixed = TRUE, value = TRUE)\ntests/testthat/test-get-protected-columns.R:26:  )\ntests/testthat/test-get-protected-columns.R:27:  manual <- intersect(manual, colnames(example_quantile))\ntests/testthat/test-get-protected-columns.R:28:  auto <- get_protected_columns(data)\ntests/testthat/test-get-protected-columns.R:29:  expect_identical(sort(manual), sort(auto))\ntests/testthat/test-get-protected-columns.R:30:\ntests/testthat/test-get-protected-columns.R:31:\ntests/testthat/test-get-protected-columns.R:32:  data <- example_binary\ntests/testthat/test-get-protected-columns.R:33:  manual <- protected_columns <- c(\ntests/testthat/test-get-protected-columns.R:34:    \"predicted\", \"observed\", \"sample_id\", \"quantile_level\", \"upper\", \"lower\",\ntests/testthat/test-get-protected-columns.R:35:    \"pit_value\",\ntests/testthat/test-get-protected-columns.R:36:    \"range\", \"boundary\",\ntests/testthat/test-get-protected-columns.R:37:    grep(\"coverage_\", names(data), fixed = TRUE, value = TRUE)\ntests/testthat/test-get-protected-columns.R:38:  )\ntests/testthat/test-get-protected-columns.R:39:  manual <- intersect(manual, colnames(example_binary))\ntests/testthat/test-get-protected-columns.R:40:  auto <- get_protected_columns(data)\ntests/testthat/test-get-protected-columns.R:41:  expect_identical(sort(manual), sort(auto))\ntests/testthat/test-get-protected-columns.R:42:\ntests/testthat/test-get-protected-columns.R:43:  data <- example_sample_continuous\ntests/testthat/test-get-protected-columns.R:44:  manual <- protected_columns <- c(\ntests/testthat/test-get-protected-columns.R:45:    \"predicted\", \"observed\", \"sample_id\", \"quantile_level\", \"upper\", \"lower\",\ntests/testthat/test-get-protected-columns.R:46:    \"pit_value\",\ntests/testthat/test-get-protected-columns.R:47:    \"range\", \"boundary\",\ntests/testthat/test-get-protected-columns.R:48:    grep(\"coverage_\", names(data), fixed = TRUE, value = TRUE)\ntests/testthat/test-get-protected-columns.R:49:  )\ntests/testthat/test-get-protected-columns.R:50:  manual <- intersect(manual, colnames(example_sample_continuous))\ntests/testthat/test-get-protected-columns.R:51:  auto <- get_protected_columns(data)\ntests/testthat/test-get-protected-columns.R:52:  expect_identical(sort(manual), sort(auto))\ntests/testthat/test-get-protected-columns.R:53:})\ntests/testthat/test-metrics-binary.R:1:observed <- factor(rbinom(10, size = 1, prob = 0.5))\ntests/testthat/test-metrics-binary.R:2:predicted <- c(0.425, 0.55, 0.541, 0.52, 0.13, 0.469, 0.86, 0.22, 0.74, 0.9)\ntests/testthat/test-metrics-binary.R:3:df <- data.table(\ntests/testthat/test-metrics-binary.R:4:  observed = observed,\ntests/testthat/test-metrics-binary.R:5:  predicted = predicted,\ntests/testthat/test-metrics-binary.R:6:  model = \"m1\",\ntests/testthat/test-metrics-binary.R:7:  id = 1:10\ntests/testthat/test-metrics-binary.R:8:)\ntests/testthat/test-metrics-binary.R:9:\ntests/testthat/test-metrics-binary.R:10:observed_point <- rnorm(10)\ntests/testthat/test-metrics-binary.R:11:predicted_point <- rnorm(10)\ntests/testthat/test-metrics-binary.R:12:\ntests/testthat/test-metrics-binary.R:13:# ==============================================================================\ntests/testthat/test-metrics-binary.R:14:# Test Input Checks - this also checks point inputs where functions are similar\ntests/testthat/test-metrics-binary.R:15:# ==============================================================================\ntests/testthat/test-metrics-binary.R:16:test_that(\"correct input works\", {\ntests/testthat/test-metrics-binary.R:17:  expect_no_condition(assert_input_binary(observed, predicted))\ntests/testthat/test-metrics-binary.R:18:  expect_no_condition(assert_input_point(observed_point, predicted_point))\ntests/testthat/test-metrics-binary.R:19:\ntests/testthat/test-metrics-binary.R:20:  # observed is a single number and does not have the same length as predicted\ntests/testthat/test-metrics-binary.R:21:  expect_no_condition(\ntests/testthat/test-metrics-binary.R:22:    assert_input_binary(factor(1, levels = c(0, 1)), predicted)\ntests/testthat/test-metrics-binary.R:23:  )\ntests/testthat/test-metrics-binary.R:24:  expect_no_condition(\ntests/testthat/test-metrics-binary.R:25:    assert_input_point(1, predicted_point)\ntests/testthat/test-metrics-binary.R:26:  )\ntests/testthat/test-metrics-binary.R:27:\ntests/testthat/test-metrics-binary.R:28:  # predicted is a single number and does not have the same length as observed\ntests/testthat/test-metrics-binary.R:29:  expect_no_condition(assert_input_binary(observed, predicted = 0.2))\ntests/testthat/test-metrics-binary.R:30:  expect_no_condition(assert_input_point(observed_point, predicted = 0.2))\ntests/testthat/test-metrics-binary.R:31:\ntests/testthat/test-metrics-binary.R:32:  # predicted is a matrix with nrow equal to observed\ntests/testthat/test-metrics-binary.R:33:  expect_no_condition(assert_input_binary(observed, matrix(predicted)))\ntests/testthat/test-metrics-binary.R:34:  expect_no_condition(assert_input_point(observed_point, matrix(predicted_point)))\ntests/testthat/test-metrics-binary.R:35:})\ntests/testthat/test-metrics-binary.R:36:\ntests/testthat/test-metrics-binary.R:37:# test input handling\ntests/testthat/test-metrics-binary.R:38:test_that(\"function throws an error for wrong input formats\", {\ntests/testthat/test-metrics-binary.R:39:  # observed value not as expected\ntests/testthat/test-metrics-binary.R:40:  expect_error(\ntests/testthat/test-metrics-binary.R:41:    assert_input_binary(observed = rnorm(10), predicted = predicted),\ntests/testthat/test-metrics-binary.R:42:    \"Assertion on 'observed' failed: Must be of type 'factor', not 'double'.\"\ntests/testthat/test-metrics-binary.R:43:  )\ntests/testthat/test-metrics-binary.R:44:  expect_error(\ntests/testthat/test-metrics-binary.R:45:    assert_input_binary(1:10, predicted),\ntests/testthat/test-metrics-binary.R:46:    \"Assertion on 'observed' failed: Must be of type 'factor', not 'integer'.\"\ntests/testthat/test-metrics-binary.R:47:  )\ntests/testthat/test-metrics-binary.R:48:  expect_error(\ntests/testthat/test-metrics-binary.R:49:    assert_input_binary(observed = observed, predicted = as.list(predicted)),\ntests/testthat/test-metrics-binary.R:50:    \"Assertion on 'predicted' failed: Must be of type 'numeric', not 'list'.\"\ntests/testthat/test-metrics-binary.R:51:  )\ntests/testthat/test-metrics-binary.R:52:  expect_error(\ntests/testthat/test-metrics-binary.R:53:    assert_input_point(observed = factor(rnorm(10)), predicted = predicted),\ntests/testthat/test-metrics-binary.R:54:    \"Assertion on 'observed' failed: Must be of type 'numeric', not 'factor'.\"\ntests/testthat/test-metrics-binary.R:55:  )\ntests/testthat/test-metrics-binary.R:56:  expect_error(\ntests/testthat/test-metrics-binary.R:57:    assert_input_point(observed = observed_point, list(predicted_point)),\ntests/testthat/test-metrics-binary.R:58:    \"Assertion on 'predicted' failed: Must be of type 'numeric', not 'list'.\"\ntests/testthat/test-metrics-binary.R:59:  )\ntests/testthat/test-metrics-binary.R:60:\ntests/testthat/test-metrics-binary.R:61:  # observed value has not 2 levels\ntests/testthat/test-metrics-binary.R:62:  expect_error(\ntests/testthat/test-metrics-binary.R:63:    assert_input_binary(factor(1:10), predicted),\ntests/testthat/test-metrics-binary.R:64:    \"Assertion on 'observed' failed: Must have exactly 2 levels.\"\ntests/testthat/test-metrics-binary.R:65:  )\ntests/testthat/test-metrics-binary.R:66:\ntests/testthat/test-metrics-binary.R:67:  # wrong length\ntests/testthat/test-metrics-binary.R:68:  expect_error(\ntests/testthat/test-metrics-binary.R:69:    assert_input_binary(observed = observed, predicted = runif(15, min = 0, max = 1)),\ntests/testthat/test-metrics-binary.R:70:    \"`observed` and `predicted` must either be of length 1 or of equal length.\",\ntests/testthat/test-metrics-binary.R:71:    fixed = TRUE\ntests/testthat/test-metrics-binary.R:72:  )\ntests/testthat/test-metrics-binary.R:73:  expect_error(\ntests/testthat/test-metrics-binary.R:74:    assert_input_point(observed_point, runif(15, min = 0, max = 1)),\ntests/testthat/test-metrics-binary.R:75:    \"`observed` and `predicted` must either be of length 1 or of equal length\",\ntests/testthat/test-metrics-binary.R:76:    fixed = TRUE\ntests/testthat/test-metrics-binary.R:77:  )\ntests/testthat/test-metrics-binary.R:78:\ntests/testthat/test-metrics-binary.R:79:  # predicted > 1 # nolint: commented_code_linter\ntests/testthat/test-metrics-binary.R:80:  expect_error(\ntests/testthat/test-metrics-binary.R:81:    assert_input_binary(observed, predicted + 1),\ntests/testthat/test-metrics-binary.R:82:    \"Assertion on 'predicted' failed: Element 1 is not <= 1.\"\ntests/testthat/test-metrics-binary.R:83:  )\ntests/testthat/test-metrics-binary.R:84:\ntests/testthat/test-metrics-binary.R:85:  # predicted < 0 # nolint: commented_code_linter\ntests/testthat/test-metrics-binary.R:86:  expect_error(\ntests/testthat/test-metrics-binary.R:87:    assert_input_binary(observed, predicted - 1),\ntests/testthat/test-metrics-binary.R:88:    \"Assertion on 'predicted' failed: Element 1 is not >= 0.\"\ntests/testthat/test-metrics-binary.R:89:  )\ntests/testthat/test-metrics-binary.R:90:\ntests/testthat/test-metrics-binary.R:91:  # predicted is a matrix with one row\ntests/testthat/test-metrics-binary.R:92:  expect_error(\ntests/testthat/test-metrics-binary.R:93:    assert_input_binary(observed, predicted = matrix(0.2)),\ntests/testthat/test-metrics-binary.R:94:    \"Assertion failed.*check_vector.*check_matrix\"\ntests/testthat/test-metrics-binary.R:95:  )\ntests/testthat/test-metrics-binary.R:96:  expect_error(\ntests/testthat/test-metrics-binary.R:97:    assert_input_point(observed_point, predicted = matrix(0.2)),\ntests/testthat/test-metrics-binary.R:98:    \"Assertion failed.*check_vector.*check_matrix\"\ntests/testthat/test-metrics-binary.R:99:  )\ntests/testthat/test-metrics-binary.R:100:\ntests/testthat/test-metrics-binary.R:101:  # predicted is a matrix with 2 rows\ntests/testthat/test-metrics-binary.R:102:  expect_error(\ntests/testthat/test-metrics-binary.R:103:    assert_input_binary(observed, matrix(rep(predicted, 2), ncol = 2)),\ntests/testthat/test-metrics-binary.R:104:    \"Assertion failed.*check_vector.*check_matrix\"\ntests/testthat/test-metrics-binary.R:105:  )\ntests/testthat/test-metrics-binary.R:106:})\ntests/testthat/test-metrics-binary.R:107:\ntests/testthat/test-metrics-binary.R:108:\ntests/testthat/test-metrics-binary.R:109:# ==============================================================================\ntests/testthat/test-metrics-binary.R:110:# Test Binary Metrics\ntests/testthat/test-metrics-binary.R:111:# ==============================================================================\ntests/testthat/test-metrics-binary.R:112:\ntests/testthat/test-metrics-binary.R:113:test_that(\"function throws an error when missing observed or predicted\", {\ntests/testthat/test-metrics-binary.R:114:  expect_error(\ntests/testthat/test-metrics-binary.R:115:    brier_score(predicted = predicted),\ntests/testthat/test-metrics-binary.R:116:    'argument \"observed\" is missing, with no default'\ntests/testthat/test-metrics-binary.R:117:  )\ntests/testthat/test-metrics-binary.R:118:\ntests/testthat/test-metrics-binary.R:119:  expect_error(\ntests/testthat/test-metrics-binary.R:120:    brier_score(observed = observed),\ntests/testthat/test-metrics-binary.R:121:    'argument \"predicted\" is missing, with no default'\ntests/testthat/test-metrics-binary.R:122:  )\ntests/testthat/test-metrics-binary.R:123:})\ntests/testthat/test-metrics-binary.R:124:\ntests/testthat/test-metrics-binary.R:125:test_that(\"Brier score works with different inputs\", {\ntests/testthat/test-metrics-binary.R:126:  # observed is a single number and does not have the same length as predicted\ntests/testthat/test-metrics-binary.R:127:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:128:    brier_score(factor(1, levels = c(0, 1)), predicted),\ntests/testthat/test-metrics-binary.R:129:    (1 - predicted)^2\ntests/testthat/test-metrics-binary.R:130:  )\ntests/testthat/test-metrics-binary.R:131:\ntests/testthat/test-metrics-binary.R:132:  # predicted is a single number and does not have the same length as observed\ntests/testthat/test-metrics-binary.R:133:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:134:    brier_score(observed, predicted = 0.2),\ntests/testthat/test-metrics-binary.R:135:    ifelse(observed == 1, (1 - 0.2)^2, (0.2)^2)\ntests/testthat/test-metrics-binary.R:136:  )\ntests/testthat/test-metrics-binary.R:137:\ntests/testthat/test-metrics-binary.R:138:  # predicted is a matrix with 1 row\ntests/testthat/test-metrics-binary.R:139:  expect_error(\ntests/testthat/test-metrics-binary.R:140:    brier_score(observed, predicted = matrix(0.2)),\ntests/testthat/test-metrics-binary.R:141:    \"Assertion failed.*check_vector.*check_matrix\"\ntests/testthat/test-metrics-binary.R:142:  )\ntests/testthat/test-metrics-binary.R:143:\ntests/testthat/test-metrics-binary.R:144:  # predicted is an array\ntests/testthat/test-metrics-binary.R:145:  expect_error(\ntests/testthat/test-metrics-binary.R:146:    brier_score(observed, predicted = array(0.2)),\ntests/testthat/test-metrics-binary.R:147:    \"Assertion failed.*check_vector.*check_matrix\"\ntests/testthat/test-metrics-binary.R:148:  )\ntests/testthat/test-metrics-binary.R:149:})\ntests/testthat/test-metrics-binary.R:150:\ntests/testthat/test-metrics-binary.R:151:\ntests/testthat/test-metrics-binary.R:152:test_that(\"Binary metrics work within and outside of `score()`\", {\ntests/testthat/test-metrics-binary.R:153:  result <- score(as_forecast_binary(df))\ntests/testthat/test-metrics-binary.R:154:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:155:    brier_score(observed, predicted),\ntests/testthat/test-metrics-binary.R:156:    result$brier_score\ntests/testthat/test-metrics-binary.R:157:  )\ntests/testthat/test-metrics-binary.R:158:\ntests/testthat/test-metrics-binary.R:159:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:160:    logs_binary(observed, predicted),\ntests/testthat/test-metrics-binary.R:161:    result$log_score\ntests/testthat/test-metrics-binary.R:162:  )\ntests/testthat/test-metrics-binary.R:163:})\ntests/testthat/test-metrics-binary.R:164:\ntests/testthat/test-metrics-binary.R:165:test_that(\"`logs_binary()` works as expected\", {\ntests/testthat/test-metrics-binary.R:166:  # check against the function Metrics::ll\ntests/testthat/test-metrics-binary.R:167:  obs2 <- as.numeric(as.character(observed))\ntests/testthat/test-metrics-binary.R:168:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:169:    logs_binary(observed, predicted),\ntests/testthat/test-metrics-binary.R:170:    Metrics::ll(obs2, predicted)\ntests/testthat/test-metrics-binary.R:171:  )\ntests/testthat/test-metrics-binary.R:172:\ntests/testthat/test-metrics-binary.R:173:  # check this works for a single observed value\ntests/testthat/test-metrics-binary.R:174:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:175:    logs_binary(observed[1], predicted),\ntests/testthat/test-metrics-binary.R:176:    Metrics::ll(obs2[1], predicted)\ntests/testthat/test-metrics-binary.R:177:  )\ntests/testthat/test-metrics-binary.R:178:\ntests/testthat/test-metrics-binary.R:179:  # check this works for a single predicted value\ntests/testthat/test-metrics-binary.R:180:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-binary.R:181:    logs_binary(observed, predicted[1]),\ntests/testthat/test-metrics-binary.R:182:    Metrics::ll(obs2, predicted[1])\ntests/testthat/test-metrics-binary.R:183:  )\ntests/testthat/test-metrics-binary.R:184:})\ntests/testthat/test-metrics-ordinal.R:1:factor_levels <- c(\"one\", \"two\", \"three\")\ntests/testthat/test-metrics-ordinal.R:2:predicted_label <- factor(c(\"one\", \"two\", \"three\"), levels = factor_levels, ordered = TRUE)\ntests/testthat/test-metrics-ordinal.R:3:observed <- factor(c(\"one\", \"two\", \"two\"), levels = factor_levels, ordered = TRUE)\ntests/testthat/test-metrics-ordinal.R:4:predicted <- matrix(\ntests/testthat/test-metrics-ordinal.R:5:  c(\ntests/testthat/test-metrics-ordinal.R:6:    0.8, 0.1, 0.4,\ntests/testthat/test-metrics-ordinal.R:7:    0.1, 0.2, 0.4,\ntests/testthat/test-metrics-ordinal.R:8:    0.1, 0.7, 0.2\ntests/testthat/test-metrics-ordinal.R:9:  ),\ntests/testthat/test-metrics-ordinal.R:10:  nrow = 3\ntests/testthat/test-metrics-ordinal.R:11:)\ntests/testthat/test-metrics-ordinal.R:12:\ntests/testthat/test-metrics-ordinal.R:13:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:14:# Input handling ===============================================================\ntests/testthat/test-metrics-ordinal.R:15:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:16:test_that(\"Input checking for ordinal forecasts works\", {\ntests/testthat/test-metrics-ordinal.R:17:  # everything correct\ntests/testthat/test-metrics-ordinal.R:18:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:19:    assert_input_ordinal(observed, predicted, predicted_label)\ntests/testthat/test-metrics-ordinal.R:20:  )\ntests/testthat/test-metrics-ordinal.R:21:\ntests/testthat/test-metrics-ordinal.R:22:  # works with a single observations\ntests/testthat/test-metrics-ordinal.R:23:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:24:    assert_input_ordinal(observed[1], predicted[1, ], predicted_label)\ntests/testthat/test-metrics-ordinal.R:25:  )\ntests/testthat/test-metrics-ordinal.R:26:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:27:    assert_input_ordinal(observed[1], matrix(predicted[1, ], nrow = 1), predicted_label)\ntests/testthat/test-metrics-ordinal.R:28:  )\ntests/testthat/test-metrics-ordinal.R:29:\ntests/testthat/test-metrics-ordinal.R:30:  # observed and predicted_label have different level lengths\ntests/testthat/test-metrics-ordinal.R:31:  observed_wrong <- factor(observed, levels = c(\"one\", \"two\"), ordered = TRUE)\ntests/testthat/test-metrics-ordinal.R:32:  expect_error(\ntests/testthat/test-metrics-ordinal.R:33:    assert_input_ordinal(observed_wrong, predicted, predicted_label),\ntests/testthat/test-metrics-ordinal.R:34:    \"Assertion on 'predicted_label' failed: Must have length 2, but has length 3.\"\ntests/testthat/test-metrics-ordinal.R:35:  )\ntests/testthat/test-metrics-ordinal.R:36:\ntests/testthat/test-metrics-ordinal.R:37:  # observed and predicted_label have different levels, resulting in an `NA` in predicted_label\ntests/testthat/test-metrics-ordinal.R:38:  predicted_label_wrong <- factor(predicted_label, levels = c(\"one\", \"two\", \"four\"))\ntests/testthat/test-metrics-ordinal.R:39:  expect_error(\ntests/testthat/test-metrics-ordinal.R:40:    assert_input_ordinal(observed, predicted, predicted_label_wrong),\ntests/testthat/test-metrics-ordinal.R:41:    \"Assertion on 'predicted_label' failed: Contains missing values\"\ntests/testthat/test-metrics-ordinal.R:42:  )\ntests/testthat/test-metrics-ordinal.R:43:\ntests/testthat/test-metrics-ordinal.R:44:  # 6 observations, but only 3 forecasts\ntests/testthat/test-metrics-ordinal.R:45:  observed_wrong <- factor(\ntests/testthat/test-metrics-ordinal.R:46:    c(\"one\", \"two\", \"one\", \"one\", \"two\", \"three\"),\ntests/testthat/test-metrics-ordinal.R:47:    levels = c(\"one\", \"two\", \"three\"),\ntests/testthat/test-metrics-ordinal.R:48:    ordered = TRUE\ntests/testthat/test-metrics-ordinal.R:49:  )\ntests/testthat/test-metrics-ordinal.R:50:  expect_error(\ntests/testthat/test-metrics-ordinal.R:51:    assert_input_ordinal(observed_wrong, predicted, predicted_label),\ntests/testthat/test-metrics-ordinal.R:52:    \"Assertion on 'predicted' failed: Must have exactly 6 rows, but has 3 rows.\"\ntests/testthat/test-metrics-ordinal.R:53:  )\ntests/testthat/test-metrics-ordinal.R:54:\ntests/testthat/test-metrics-ordinal.R:55:  # observed value or predicted_label is not factor\ntests/testthat/test-metrics-ordinal.R:56:  expect_error(\ntests/testthat/test-metrics-ordinal.R:57:    assert_input_ordinal(as.numeric(observed), predicted, predicted_label),\ntests/testthat/test-metrics-ordinal.R:58:    \"Assertion on 'observed' failed: Must be of type 'factor', not 'double'.\"\ntests/testthat/test-metrics-ordinal.R:59:  )\ntests/testthat/test-metrics-ordinal.R:60:  expect_error(\ntests/testthat/test-metrics-ordinal.R:61:    assert_input_ordinal(observed, predicted, as.character(predicted_label)),\ntests/testthat/test-metrics-ordinal.R:62:    \"Assertion on 'predicted_label' failed: Must be of type 'factor', not 'character'.\"\ntests/testthat/test-metrics-ordinal.R:63:  )\ntests/testthat/test-metrics-ordinal.R:64:\ntests/testthat/test-metrics-ordinal.R:65:  # a single observation\ntests/testthat/test-metrics-ordinal.R:66:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:67:    assert_input_ordinal(observed[1], predicted[1, ], predicted_label)\ntests/testthat/test-metrics-ordinal.R:68:  )\ntests/testthat/test-metrics-ordinal.R:69:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:70:    assert_input_ordinal(observed[1], as.numeric(predicted[1, ]), predicted_label)\ntests/testthat/test-metrics-ordinal.R:71:  )\ntests/testthat/test-metrics-ordinal.R:72:\ntests/testthat/test-metrics-ordinal.R:73:  # wrong dimensions\ntests/testthat/test-metrics-ordinal.R:74:  expect_error(\ntests/testthat/test-metrics-ordinal.R:75:    assert_input_ordinal(observed[1], predicted, predicted_label),\ntests/testthat/test-metrics-ordinal.R:76:    \"One of the following must apply:\"\ntests/testthat/test-metrics-ordinal.R:77:  )\ntests/testthat/test-metrics-ordinal.R:78:\ntests/testthat/test-metrics-ordinal.R:79:  # NA values in observed are permitted\ntests/testthat/test-metrics-ordinal.R:80:  observed2 <- factor(c(\"one\", \"two\", \"missing\"), levels = c(\"one\", \"two\", \"three\"), ordered = TRUE)\ntests/testthat/test-metrics-ordinal.R:81:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:82:    assert_input_ordinal(observed2, predicted, predicted_label)\ntests/testthat/test-metrics-ordinal.R:83:  )\ntests/testthat/test-metrics-ordinal.R:84:\ntests/testthat/test-metrics-ordinal.R:85:  # NA values in predicted are permitted and treated as zeros\ntests/testthat/test-metrics-ordinal.R:86:  # (as long as probabilities still sum to one)\ntests/testthat/test-metrics-ordinal.R:87:  predicted2 <- predicted\ntests/testthat/test-metrics-ordinal.R:88:  predicted2[2, 2] <- NA\ntests/testthat/test-metrics-ordinal.R:89:  expect_error(\ntests/testthat/test-metrics-ordinal.R:90:    assert_input_ordinal(observed, predicted2, predicted_label),\ntests/testthat/test-metrics-ordinal.R:91:    \"Probabilities belonging to a single forecast must sum to one\"\ntests/testthat/test-metrics-ordinal.R:92:  )\ntests/testthat/test-metrics-ordinal.R:93:  predicted2[2, 1] <- 0.3\ntests/testthat/test-metrics-ordinal.R:94:  expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:95:    assert_input_ordinal(observed, predicted2, predicted_label)\ntests/testthat/test-metrics-ordinal.R:96:  )\ntests/testthat/test-metrics-ordinal.R:97:})\ntests/testthat/test-metrics-ordinal.R:98:\ntests/testthat/test-metrics-ordinal.R:99:\ntests/testthat/test-metrics-ordinal.R:100:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:101:# logs ordinal =============================================================== #\ntests/testthat/test-metrics-ordinal.R:102:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:103:test_that(\"logs_categorical() works as expected with ordered factors\", {\ntests/testthat/test-metrics-ordinal.R:104:  res <- expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:105:    logs_categorical(observed, predicted, predicted_label)\ntests/testthat/test-metrics-ordinal.R:106:  )\ntests/testthat/test-metrics-ordinal.R:107:  res_manual <- -log(c(predicted[1, 1], predicted[2, 2], predicted[3, 2]))\ntests/testthat/test-metrics-ordinal.R:108:  expect_equal(res, res_manual) # nolint: expect_identical_linter\ntests/testthat/test-metrics-ordinal.R:109:})\ntests/testthat/test-metrics-ordinal.R:110:\ntests/testthat/test-metrics-ordinal.R:111:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:112:# rps ordinal =============================================================== #\ntests/testthat/test-metrics-ordinal.R:113:# ============================================================================ #\ntests/testthat/test-metrics-ordinal.R:114:result <- c(0.05, 0.5, 0.2)\ntests/testthat/test-metrics-ordinal.R:115:test_that(\"rps_ordinal() works as expected\", {\ntests/testthat/test-metrics-ordinal.R:116:  res <- expect_no_condition(\ntests/testthat/test-metrics-ordinal.R:117:    rps_ordinal(observed, predicted, predicted_label)\ntests/testthat/test-metrics-ordinal.R:118:  )\ntests/testthat/test-metrics-ordinal.R:119:\ntests/testthat/test-metrics-ordinal.R:120:  expect_equal(res, result) # nolint: expect_identical_linter\ntests/testthat/test-metrics-ordinal.R:121:\ntests/testthat/test-metrics-ordinal.R:122:  # works with changed order of levels\ntests/testthat/test-metrics-ordinal.R:123:  predicted_label2 <- factor(c(\"three\", \"one\", \"two\"), levels = factor_levels, ordered = TRUE)\ntests/testthat/test-metrics-ordinal.R:124:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-ordinal.R:125:    rps_ordinal(observed, predicted, predicted_label2),\ntests/testthat/test-metrics-ordinal.R:126:    scoringRules::rps_probs(as.numeric(observed), predicted[, c(3, 1, 2)])\ntests/testthat/test-metrics-ordinal.R:127:  )\ntests/testthat/test-metrics-ordinal.R:128:})\ntests/testthat/test-metrics-ordinal.R:129:\ntests/testthat/test-metrics-ordinal.R:130:test_that(\"rps_ordinal() works with a single observation\", {\ntests/testthat/test-metrics-ordinal.R:131:  expect_equal( # nolint: expect_identical_linter\ntests/testthat/test-metrics-ordinal.R:132:    rps_ordinal(observed[1], predicted[1, ], predicted_label),\ntests/testthat/test-metrics-ordinal.R:133:    result[1]\ntests/testthat/test-metrics-ordinal.R:134:  )\ntests/testthat/test-metrics-ordinal.R:135:})\ntests/testthat/test-get-coverage.R:1:# ==============================================================================\ntests/testthat/test-get-coverage.R:2:# `get_coverage()` # nolint: commented_code_linter\ntests/testthat/test-get-coverage.R:3:# ==============================================================================\ntests/testthat/test-get-coverage.R:4:ex_coverage <- example_quantile[model == \"EuroCOVIDhub-ensemble\"]\ntests/testthat/test-get-coverage.R:5:\ntests/testthat/test-get-coverage.R:6:test_that(\"get_coverage() works as expected\", {\ntests/testthat/test-get-coverage.R:7:  cov <- example_quantile |>\ntests/testthat/test-get-coverage.R:8:    get_coverage(by = get_forecast_unit(example_quantile))\ntests/testthat/test-get-coverage.R:9:\ntests/testthat/test-get-coverage.R:10:  expect_identical(\ntests/testthat/test-get-coverage.R:11:    sort(colnames(cov)),\ntests/testthat/test-get-coverage.R:12:    sort(c(get_forecast_unit(example_quantile), c(\ntests/testthat/test-get-coverage.R:13:      \"interval_range\", \"quantile_level\", \"interval_coverage\", \"interval_coverage_deviation\",\ntests/testthat/test-get-coverage.R:14:      \"quantile_coverage\", \"quantile_coverage_deviation\"\ntests/testthat/test-get-coverage.R:15:    )))\ntests/testthat/test-get-coverage.R:16:  )\ntests/testthat/test-get-coverage.R:17:\ntests/testthat/test-get-coverage.R:18:  expect_identical(nrow(cov), nrow(na.omit(example_quantile)))\ntests/testthat/test-get-coverage.R:19:\ntests/testthat/test-get-coverage.R:20:  expect_s3_class(\ntests/testthat/test-get-coverage.R:21:    cov,\ntests/testthat/test-get-coverage.R:22:    c(\"data.table\", \"data.frame\"),\ntests/testthat/test-get-coverage.R:23:    exact = TRUE\ntests/testthat/test-get-coverage.R:24:  )\ntests/testthat/test-get-coverage.R:25:})\ntests/testthat/test-get-coverage.R:26:\ntests/testthat/test-get-coverage.R:27:test_that(\"get_coverage() outputs an object of class c('data.table', 'data.frame'\", {\ntests/testthat/test-get-coverage.R:28:  cov <- get_coverage(example_quantile)\ntests/testthat/test-get-coverage.R:29:  expect_s3_class(cov, c(\"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-get-coverage.R:30:})\ntests/testthat/test-get-coverage.R:31:\ntests/testthat/test-get-coverage.R:32:test_that(\"get_coverage() can deal with non-symmetric prediction intervals\", {\ntests/testthat/test-get-coverage.R:33:  # the expected result is that `get_coverage()` just works. However,\ntests/testthat/test-get-coverage.R:34:  # all interval coverages with missing values should just be `NA`\ntests/testthat/test-get-coverage.R:35:  test <- data.table::copy(example_quantile)\ntests/testthat/test-get-coverage.R:36:  test <- test[!quantile_level %in% c(0.2, 0.3, 0.5)]\ntests/testthat/test-get-coverage.R:37:\ntests/testthat/test-get-coverage.R:38:  cov <- expect_no_condition(get_coverage(test))\ntests/testthat/test-get-coverage.R:39:\ntests/testthat/test-get-coverage.R:40:  prediction_intervals <- get_range_from_quantile(c(0.2, 0.3, 0.5))\ntests/testthat/test-get-coverage.R:41:\ntests/testthat/test-get-coverage.R:42:  missing <- cov[interval_range %in% prediction_intervals]\ntests/testthat/test-get-coverage.R:43:  not_missing <- cov[!interval_range %in% prediction_intervals]\ntests/testthat/test-get-coverage.R:44:\ntests/testthat/test-get-coverage.R:45:  expect_true(all(is.na(missing$interval_coverage)))\ntests/testthat/test-get-coverage.R:46:  expect_false(anyNA(not_missing))\ntests/testthat/test-get-coverage.R:47:\ntests/testthat/test-get-coverage.R:48:  # test for a version where values are not missing, but just `NA`\ntests/testthat/test-get-coverage.R:49:  # since `get_coverage()` calls `na.omit`, the result should be the same.\ntests/testthat/test-get-coverage.R:50:  test <- data.table::copy(example_quantile)\ntests/testthat/test-get-coverage.R:51:  test <- test[quantile_level %in% c(0.2, 0.3, 0.5), predicted := NA]\ntests/testthat/test-get-coverage.R:52:  cov2 <- get_coverage(test)\ntests/testthat/test-get-coverage.R:53:  expect_identical(cov, cov2)\ntests/testthat/test-get-coverage.R:54:})\ntests/testthat/test-get-coverage.R:55:\ntests/testthat/test-get-coverage.R:56:\ntests/testthat/test-get-coverage.R:57:# ==============================================================================\ntests/testthat/test-get-coverage.R:58:# plot_interval_coverage() # nolint: commented_code_linter\ntests/testthat/test-get-coverage.R:59:# ==============================================================================\ntests/testthat/test-get-coverage.R:60:test_that(\"plot_interval_coverage() works as expected\", {\ntests/testthat/test-get-coverage.R:61:  coverage <- example_quantile |>\ntests/testthat/test-get-coverage.R:62:    na.omit() |>\ntests/testthat/test-get-coverage.R:63:    as_forecast_quantile() |>\ntests/testthat/test-get-coverage.R:64:    get_coverage(by = \"model\")\ntests/testthat/test-get-coverage.R:65:  p <- plot_interval_coverage(coverage)\ntests/testthat/test-get-coverage.R:66:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-get-coverage.R:67:  skip_on_cran()\ntests/testthat/test-get-coverage.R:68:  suppressWarnings(vdiffr::expect_doppelganger(\"plot_interval_coverage\", p))\ntests/testthat/test-get-coverage.R:69:\ntests/testthat/test-get-coverage.R:70:  # make sure that plot_interval_coverage() doesn't drop column names\ntests/testthat/test-get-coverage.R:71:  expect_true(all(c(\ntests/testthat/test-get-coverage.R:72:    \"interval_coverage\", \"interval_coverage_deviation\",\ntests/testthat/test-get-coverage.R:73:    \"quantile_coverage\", \"quantile_coverage_deviation\"\ntests/testthat/test-get-coverage.R:74:  ) %in%\ntests/testthat/test-get-coverage.R:75:    names(coverage)))\ntests/testthat/test-get-coverage.R:76:})\ntests/testthat/test-get-coverage.R:77:\ntests/testthat/test-get-coverage.R:78:\ntests/testthat/test-get-coverage.R:79:# ==============================================================================\ntests/testthat/test-get-coverage.R:80:# plot_quantile_coverage() # nolint: commented_code_linter\ntests/testthat/test-get-coverage.R:81:# ==============================================================================\ntests/testthat/test-get-coverage.R:82:test_that(\"plot_quantile_coverage() works as expected\", {\ntests/testthat/test-get-coverage.R:83:  coverage <- example_quantile |>\ntests/testthat/test-get-coverage.R:84:    na.omit() |>\ntests/testthat/test-get-coverage.R:85:    as_forecast_quantile() |>\ntests/testthat/test-get-coverage.R:86:    get_coverage(by = c(\"model\", \"quantile_level\"))\ntests/testthat/test-get-coverage.R:87:\ntests/testthat/test-get-coverage.R:88:  p <- plot_quantile_coverage(coverage)\ntests/testthat/test-get-coverage.R:89:  expect_s3_class(p, \"ggplot\")\ntests/testthat/test-get-coverage.R:90:  skip_on_cran()\ntests/testthat/test-get-coverage.R:91:  suppressWarnings(vdiffr::expect_doppelganger(\"plot_quantile_coverage\", p))\ntests/testthat/test-get-coverage.R:92:})\ntests/testthat/test-class-forecast-point.R:1:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:2:# as_forecast_point() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-point.R:3:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:4:\ntests/testthat/test-class-forecast-point.R:5:test_that(\"as_forecast_point() works\", {\ntests/testthat/test-class-forecast-point.R:6:  expect_no_condition(\ntests/testthat/test-class-forecast-point.R:7:    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))\ntests/testthat/test-class-forecast-point.R:8:  )\ntests/testthat/test-class-forecast-point.R:9:})\ntests/testthat/test-class-forecast-point.R:10:\ntests/testthat/test-class-forecast-point.R:11:\ntests/testthat/test-class-forecast-point.R:12:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:13:# is_forecast_point() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-point.R:14:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:15:test_that(\"is_forecast_point() works as expected\", {\ntests/testthat/test-class-forecast-point.R:16:  expect_true(is_forecast_point(example_point))\ntests/testthat/test-class-forecast-point.R:17:  expect_false(is_forecast_point(example_binary))\ntests/testthat/test-class-forecast-point.R:18:  expect_false(is_forecast_point(example_quantile))\ntests/testthat/test-class-forecast-point.R:19:  expect_false(is_forecast_point(example_sample_continuous))\ntests/testthat/test-class-forecast-point.R:20:  expect_false(is_forecast_point(example_nominal))\ntests/testthat/test-class-forecast-point.R:21:})\ntests/testthat/test-class-forecast-point.R:22:\ntests/testthat/test-class-forecast-point.R:23:\ntests/testthat/test-class-forecast-point.R:24:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:25:# assert_forecast.forecast_point() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-point.R:26:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:27:\ntests/testthat/test-class-forecast-point.R:28:test_that(\"assert_forecast.forecast_point() works as expected\", {\ntests/testthat/test-class-forecast-point.R:29:  test <- na.omit(data.table::as.data.table(example_point))\ntests/testthat/test-class-forecast-point.R:30:  test <- as_forecast_point(test)\ntests/testthat/test-class-forecast-point.R:31:\ntests/testthat/test-class-forecast-point.R:32:  # expect an error if column is changed to character after initial validation.\ntests/testthat/test-class-forecast-point.R:33:  expect_warning(\ntests/testthat/test-class-forecast-point.R:34:    test[, \"predicted\" := as.character(predicted)],\ntests/testthat/test-class-forecast-point.R:35:    \"Input looks like a point forecast, but found the following issue\"\ntests/testthat/test-class-forecast-point.R:36:  )\ntests/testthat/test-class-forecast-point.R:37:  expect_error(\ntests/testthat/test-class-forecast-point.R:38:    assert_forecast(test),\ntests/testthat/test-class-forecast-point.R:39:    \"Input looks like a point forecast, but found the following issue\"\ntests/testthat/test-class-forecast-point.R:40:  )\ntests/testthat/test-class-forecast-point.R:41:})\ntests/testthat/test-class-forecast-point.R:42:\ntests/testthat/test-class-forecast-point.R:43:test_that(\"assert_forecast.forecast_point() complains if the forecast type is wrong\", {\ntests/testthat/test-class-forecast-point.R:44:  expect_error(\ntests/testthat/test-class-forecast-point.R:45:    assert_forecast(na.omit(example_point), forecast_type = \"quantile\"),\ntests/testthat/test-class-forecast-point.R:46:    \"Forecast type determined by scoringutils based on input:\"\ntests/testthat/test-class-forecast-point.R:47:  )\ntests/testthat/test-class-forecast-point.R:48:})\ntests/testthat/test-class-forecast-point.R:49:\ntests/testthat/test-class-forecast-point.R:50:\ntests/testthat/test-class-forecast-point.R:51:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:52:# score.forecast_point() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-point.R:53:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:54:test_that(\"function produces output for a point case\", {\ntests/testthat/test-class-forecast-point.R:55:  expect_named(\ntests/testthat/test-class-forecast-point.R:56:    scores_binary,\ntests/testthat/test-class-forecast-point.R:57:    c(get_forecast_unit(example_binary), names(get_metrics(example_binary)))\ntests/testthat/test-class-forecast-point.R:58:  )\ntests/testthat/test-class-forecast-point.R:59:\ntests/testthat/test-class-forecast-point.R:60:  eval <- summarise_scores(scores_point, by = c(\"model\", \"target_type\"))\ntests/testthat/test-class-forecast-point.R:61:\ntests/testthat/test-class-forecast-point.R:62:  expect_gt(\ntests/testthat/test-class-forecast-point.R:63:    nrow(eval), 1\ntests/testthat/test-class-forecast-point.R:64:  )\ntests/testthat/test-class-forecast-point.R:65:  expect_identical(\ntests/testthat/test-class-forecast-point.R:66:    colnames(eval),\ntests/testthat/test-class-forecast-point.R:67:    c(\"model\", \"target_type\", names(get_metrics(example_point)))\ntests/testthat/test-class-forecast-point.R:68:  )\ntests/testthat/test-class-forecast-point.R:69:\ntests/testthat/test-class-forecast-point.R:70:  expect_s3_class(eval, c(\"scores\", \"data.table\", \"data.frame\"), exact = TRUE)\ntests/testthat/test-class-forecast-point.R:71:})\ntests/testthat/test-class-forecast-point.R:72:\ntests/testthat/test-class-forecast-point.R:73:test_that(\"Changing metrics names works\", {\ntests/testthat/test-class-forecast-point.R:74:  metrics_test <- get_metrics(example_point)\ntests/testthat/test-class-forecast-point.R:75:  names(metrics_test)[1] <- \"just_testing\"\ntests/testthat/test-class-forecast-point.R:76:  eval <- suppressMessages(score(as_forecast_point(example_point),\ntests/testthat/test-class-forecast-point.R:77:    metrics = metrics_test\ntests/testthat/test-class-forecast-point.R:78:  ))\ntests/testthat/test-class-forecast-point.R:79:  eval_summarised <- summarise_scores(eval, by = \"model\")\ntests/testthat/test-class-forecast-point.R:80:  expect_identical(\ntests/testthat/test-class-forecast-point.R:81:    colnames(eval_summarised),\ntests/testthat/test-class-forecast-point.R:82:    c(\"model\", \"just_testing\", names(get_metrics(example_point))[-1])\ntests/testthat/test-class-forecast-point.R:83:  )\ntests/testthat/test-class-forecast-point.R:84:})\ntests/testthat/test-class-forecast-point.R:85:\ntests/testthat/test-class-forecast-point.R:86:test_that(\"score.forecast_point() errors with only NA values\", {\ntests/testthat/test-class-forecast-point.R:87:  # [.forecast()` will warn even before score()\ntests/testthat/test-class-forecast-point.R:88:  only_nas <- suppressWarnings(\ntests/testthat/test-class-forecast-point.R:89:    copy(example_point)[, predicted := NA_real_]\ntests/testthat/test-class-forecast-point.R:90:  )\ntests/testthat/test-class-forecast-point.R:91:  expect_error(\ntests/testthat/test-class-forecast-point.R:92:    score(only_nas),\ntests/testthat/test-class-forecast-point.R:93:    \"After removing rows with NA values in the data, no forecasts are left.\"\ntests/testthat/test-class-forecast-point.R:94:  )\ntests/testthat/test-class-forecast-point.R:95:})\ntests/testthat/test-class-forecast-point.R:96:\ntests/testthat/test-class-forecast-point.R:97:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:98:# get_metrics.forecast_point() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-point.R:99:# ==============================================================================\ntests/testthat/test-class-forecast-point.R:100:test_that(\"get_metrics.forecast_point() works as expected\", {\ntests/testthat/test-class-forecast-point.R:101:  expect_type(\ntests/testthat/test-class-forecast-point.R:102:    get_metrics(example_point), \"list\"\ntests/testthat/test-class-forecast-point.R:103:  )\ntests/testthat/test-class-forecast-point.R:104:\ntests/testthat/test-class-forecast-point.R:105:  expect_identical(\ntests/testthat/test-class-forecast-point.R:106:    get_metrics.scores(scores_point),\ntests/testthat/test-class-forecast-point.R:107:    c(\"ae_point\", \"se_point\", \"ape\")\ntests/testthat/test-class-forecast-point.R:108:  )\ntests/testthat/test-class-forecast-point.R:109:})\ntests/testthat/test-get-forecast-type.R:1:# ==============================================================================\ntests/testthat/test-get-forecast-type.R:2:# `get_forecast_type` # nolint: commented_code_linter\ntests/testthat/test-get-forecast-type.R:3:# ==============================================================================\ntests/testthat/test-get-forecast-type.R:4:test_that(\"get_forecast_type() works as expected\", {\ntests/testthat/test-get-forecast-type.R:5:  expect_identical(get_forecast_type(example_quantile), \"quantile\")\ntests/testthat/test-get-forecast-type.R:6:  expect_identical(get_forecast_type(example_sample_continuous), \"sample\")\ntests/testthat/test-get-forecast-type.R:7:  expect_identical(get_forecast_type(example_sample_discrete), \"sample\")\ntests/testthat/test-get-forecast-type.R:8:  expect_identical(get_forecast_type(example_binary), \"binary\")\ntests/testthat/test-get-forecast-type.R:9:  expect_identical(get_forecast_type(example_point), \"point\")\ntests/testthat/test-get-forecast-type.R:10:  expect_identical(get_forecast_type(example_nominal), \"nominal\")\ntests/testthat/test-get-forecast-type.R:11:\ntests/testthat/test-get-forecast-type.R:12:  expect_error(\ntests/testthat/test-get-forecast-type.R:13:    get_forecast_type(data.frame(x = 1:10)),\ntests/testthat/test-get-forecast-type.R:14:    \"Input is not a valid forecast object\",\ntests/testthat/test-get-forecast-type.R:15:    fixed = TRUE\ntests/testthat/test-get-forecast-type.R:16:  )\ntests/testthat/test-get-forecast-type.R:17:\ntests/testthat/test-get-forecast-type.R:18:  test <- test <- data.table::copy(example_quantile)\ntests/testthat/test-get-forecast-type.R:19:  class(test) <- c(\"forecast\", \"data.table\", \"data.frame\")\ntests/testthat/test-get-forecast-type.R:20:  expect_error(\ntests/testthat/test-get-forecast-type.R:21:    get_forecast_type(test),\ntests/testthat/test-get-forecast-type.R:22:    \"Input is not a valid forecast object\"\ntests/testthat/test-get-forecast-type.R:23:  )\ntests/testthat/test-get-forecast-type.R:24:\ntests/testthat/test-get-forecast-type.R:25:  # get_forecast_type() should still work even if a new class is added\ntests/testthat/test-get-forecast-type.R:26:  testclassobject <- data.table::copy(example_quantile)\ntests/testthat/test-get-forecast-type.R:27:  class(testclassobject) <- c(\"something\", class(testclassobject))\ntests/testthat/test-get-forecast-type.R:28:  expect_identical(get_forecast_type(testclassobject), \"quantile\")\ntests/testthat/test-get-forecast-type.R:29:})\ntests/testthat/test-get-forecast-type.R:30:\ntests/testthat/test-get-forecast-type.R:31:\ntests/testthat/test-get-forecast-type.R:32:# ==============================================================================\ntests/testthat/test-get-forecast-type.R:33:# `get_type()` # nolint: commented_code_linter\ntests/testthat/test-get-forecast-type.R:34:# ==============================================================================\ntests/testthat/test-get-forecast-type.R:35:test_that(\"get_type() works as expected with vectors\", {\ntests/testthat/test-get-forecast-type.R:36:  expect_identical(get_type(1:3), \"integer\")\ntests/testthat/test-get-forecast-type.R:37:  expect_identical(get_type(factor(1:2)), \"classification\")\ntests/testthat/test-get-forecast-type.R:38:  expect_identical(get_type(c(1.0, 2)), \"integer\")\ntests/testthat/test-get-forecast-type.R:39:  expect_identical(get_type(c(1.0, 2.3)), \"continuous\")\ntests/testthat/test-get-forecast-type.R:40:  expect_error(\ntests/testthat/test-get-forecast-type.R:41:    get_type(c(\"a\", \"b\")),\ntests/testthat/test-get-forecast-type.R:42:    \"Assertion on 'as.vector(x)' failed: Must be of type 'numeric', not 'character'.\",\ntests/testthat/test-get-forecast-type.R:43:    fixed = TRUE\ntests/testthat/test-get-forecast-type.R:44:  )\ntests/testthat/test-get-forecast-type.R:45:})\ntests/testthat/test-get-forecast-type.R:46:\ntests/testthat/test-get-forecast-type.R:47:test_that(\"get_type() works as expected with matrices\", {\ntests/testthat/test-get-forecast-type.R:48:  expect_identical(get_type(matrix(1:4, nrow = 2)), \"integer\")\ntests/testthat/test-get-forecast-type.R:49:  expect_identical(get_type(matrix(c(1.0, 2:4))), \"integer\")\ntests/testthat/test-get-forecast-type.R:50:  expect_identical(get_type(matrix(c(1.0, 2.3, 3, 4))), \"continuous\")\ntests/testthat/test-get-forecast-type.R:51:\ntests/testthat/test-get-forecast-type.R:52:  # matrix of factors doesn't work\ntests/testthat/test-get-forecast-type.R:53:  expect_error(\ntests/testthat/test-get-forecast-type.R:54:    get_type(matrix(factor(1:4), nrow = 2)),\ntests/testthat/test-get-forecast-type.R:55:    \"Assertion on 'as.vector(x)' failed: Must be of type 'numeric', not 'character'.\",\ntests/testthat/test-get-forecast-type.R:56:    fixed = TRUE\ntests/testthat/test-get-forecast-type.R:57:  )\ntests/testthat/test-get-forecast-type.R:58:\ntests/testthat/test-get-forecast-type.R:59:  expect_error(\ntests/testthat/test-get-forecast-type.R:60:    get_type(matrix(c(\"a\", \"b\", \"c\", \"d\"))),\ntests/testthat/test-get-forecast-type.R:61:    \"Assertion on 'as.vector(x)' failed: Must be of type 'numeric', not 'character'.\",\ntests/testthat/test-get-forecast-type.R:62:    fixed = TRUE\ntests/testthat/test-get-forecast-type.R:63:  )\ntests/testthat/test-get-forecast-type.R:64:})\ntests/testthat/test-get-forecast-type.R:65:\ntests/testthat/test-get-forecast-type.R:66:\ntests/testthat/test-get-forecast-type.R:67:test_that(\"new `get_type()` is equal to old `prediction_type()\", {\ntests/testthat/test-get-forecast-type.R:68:  get_prediction_type <- function(data) {\ntests/testthat/test-get-forecast-type.R:69:    if (is.data.frame(data)) {\ntests/testthat/test-get-forecast-type.R:70:      data <- data$predicted\ntests/testthat/test-get-forecast-type.R:71:    }\ntests/testthat/test-get-forecast-type.R:72:    if (\ntests/testthat/test-get-forecast-type.R:73:      isTRUE(all.equal(as.vector(data), as.integer(data))) &&\ntests/testthat/test-get-forecast-type.R:74:        !all(is.na(as.integer(data)))\ntests/testthat/test-get-forecast-type.R:75:    ) {\ntests/testthat/test-get-forecast-type.R:76:      return(\"integer\")\ntests/testthat/test-get-forecast-type.R:77:    } else if (suppressWarnings(!all(is.na(as.numeric(data))))) {\ntests/testthat/test-get-forecast-type.R:78:      return(\"continuous\")\ntests/testthat/test-get-forecast-type.R:79:    } else {\ntests/testthat/test-get-forecast-type.R:80:      stop(\"Input is not numeric and cannot be coerced to numeric\", call. = FALSE)\ntests/testthat/test-get-forecast-type.R:81:    }\ntests/testthat/test-get-forecast-type.R:82:  }\ntests/testthat/test-get-forecast-type.R:83:\ntests/testthat/test-get-forecast-type.R:84:  check_data <- list(\ntests/testthat/test-get-forecast-type.R:85:    1:2,\ntests/testthat/test-get-forecast-type.R:86:    # factor(1:2) # old function would classify as \"continuous\" # nolint: commented_code_linter\ntests/testthat/test-get-forecast-type.R:87:    c(1.0, 2),\ntests/testthat/test-get-forecast-type.R:88:    c(1.0, 2.3),\ntests/testthat/test-get-forecast-type.R:89:    matrix(1:4, nrow = 2),\ntests/testthat/test-get-forecast-type.R:90:    matrix(c(1.0, 2:4)),\ntests/testthat/test-get-forecast-type.R:91:    matrix(c(1.0, 2.3, 3, 4))\ntests/testthat/test-get-forecast-type.R:92:  )\ntests/testthat/test-get-forecast-type.R:93:\ntests/testthat/test-get-forecast-type.R:94:  for (i in seq_along(check_data)) {\ntests/testthat/test-get-forecast-type.R:95:    expect_identical(\ntests/testthat/test-get-forecast-type.R:96:      get_prediction_type(check_data[[i]]),\ntests/testthat/test-get-forecast-type.R:97:      get_type(check_data[[i]])\ntests/testthat/test-get-forecast-type.R:98:    )\ntests/testthat/test-get-forecast-type.R:99:  }\ntests/testthat/test-get-forecast-type.R:100:})\ntests/testthat/test-get-forecast-type.R:101:\ntests/testthat/test-get-forecast-type.R:102:test_that(\"get_type() handles `NA` values\", {\ntests/testthat/test-get-forecast-type.R:103:  expect_identical(get_type(c(1, NA, 3)), \"integer\")\ntests/testthat/test-get-forecast-type.R:104:  expect_identical(get_type(c(1, NA, 3.2)), \"continuous\")\ntests/testthat/test-get-forecast-type.R:105:  expect_error(get_type(NA), \"Can't get type: all values of are \\\"NA\\\"\")\ntests/testthat/test-get-forecast-type.R:106:})\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:3:<defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:6:      fill: none;\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:7:      stroke: #000000;\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:11:    }\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:12:  ]]></style>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:13:</defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:15:<defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:18:  </clipPath>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:19:</defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:22:</g>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:23:<defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:24:  <clipPath id='cpMTI3Ljk5fDcxNC41MnwyMi43OHw0NjkuODE='>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:25:    <rect x='127.99' y='22.78' width='586.53' height='447.02' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:26:  </clipPath>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:27:</defs>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:28:<g clip-path='url(#cpMTI3Ljk5fDcxNC41MnwyMi43OHw0NjkuODE=)'>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:29:<rect x='127.99' y='246.29' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #E0E8F2;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:30:<rect x='127.99' y='358.05' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFDAD4;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:31:<rect x='127.99' y='22.78' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #D6E0ED;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:32:<rect x='421.26' y='246.29' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFE5E1;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:33:<rect x='421.26' y='358.05' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:34:<rect x='421.26' y='134.54' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F5F7FB;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:35:<rect x='421.26' y='22.78' width='293.26' height='111.76' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #FAFBFD;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:36:<text x='274.62' y='305.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.06</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:37:<text x='274.62' y='417.71' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='15.29px' lengthAdjust='spacingAndGlyphs'>0.1</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:38:<text x='274.62' y='82.45' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.08</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:39:<text x='567.89' y='305.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.07</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:40:<text x='567.89' y='417.71' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.34</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:41:<text x='567.89' y='194.20' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.02</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:42:<text x='567.89' y='82.45' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.01</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:43:</g>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:44:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:45:<polyline points='127.99,469.81 127.99,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:46:<text x='120.32' y='416.96' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:47:<text x='120.32' y='305.20' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:48:<text x='120.32' y='193.45' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:49:<text x='120.32' y='81.69' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:50:<polyline points='125.25,413.93 127.99,413.93 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:51:<polyline points='125.25,302.17 127.99,302.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:52:<polyline points='125.25,190.42 127.99,190.42 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:53:<polyline points='125.25,78.66 127.99,78.66 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:54:<polyline points='127.99,469.81 714.52,469.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:55:<polyline points='274.62,472.55 274.62,469.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:56:<polyline points='567.89,472.55 567.89,469.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:57:<text transform='translate(280.68,477.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:58:<text transform='translate(573.94,477.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:59:<text x='421.26' y='515.68' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='55.04px' lengthAdjust='spacingAndGlyphs'>target_type</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:60:<text transform='translate(13.05,246.29) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:61:<text x='365.22' y='553.50' style='font-size: 11.00px; font-family: sans;' textLength='20.18px' lengthAdjust='spacingAndGlyphs'>bias</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:62:<image width='86.40' height='17.28' x='390.89' y='534.40' preserveAspectRatio='none' xlink:href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAABCAYAAABkOJMpAAAAgklEQVQ4jbVRSRKAIAxL//8/z37AN8RDcArIJuCppNnqaMd5EWYwAGaAQQ/HWgqnb2mlca/jN+e5iPamhXCpM7olQPUXc/22uAekyGQSIMLs8SVdhx/Onunu6Fa8s7ph746urxktfcW3M+uPzJVvzzgO9QOs/ud0snnjo8luLnVlnhv1hRP8wmytawAAAABJRU5ErkJggg=='/>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:63:<polyline points='407.43,548.22 407.43,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:64:<polyline points='427.94,548.22 427.94,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:65:<polyline points='448.44,548.22 448.44,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:66:<polyline points='468.94,548.22 468.94,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:67:<polyline points='407.43,537.85 407.43,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:68:<polyline points='427.94,537.85 427.94,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:69:<polyline points='448.44,537.85 448.44,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:70:<polyline points='468.94,537.85 468.94,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:71:<text x='407.43' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.0</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:72:<text x='427.94' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.1</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:73:<text x='448.44' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.2</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:74:<text x='468.94' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.3</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:75:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='80.00px' lengthAdjust='spacingAndGlyphs'>plot_heatmap</text>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:76:</g>\ntests/testthat/_snaps/plot_heatmap/plot-heatmap.svg:77:</svg>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:3:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:6:      fill: none;\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:7:      stroke: #000000;\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:11:    }\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:12:  ]]></style>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:13:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:15:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:18:  </clipPath>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:19:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:22:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:23:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:24:  <clipPath id='cpMTI3Ljk5fDQwNi44NnwzOS40M3w0NTIuNjg='>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:25:    <rect x='127.99' y='39.43' width='278.86' height='413.24' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:26:  </clipPath>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:27:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:28:<g clip-path='url(#cpMTI3Ljk5fDQwNi44NnwzOS40M3w0NTIuNjg=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:29:<rect x='130.62' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:30:<rect x='153.48' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:31:<rect x='176.34' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:32:<rect x='199.19' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:33:<rect x='222.05' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:34:<rect x='244.91' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:35:<rect x='267.77' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:36:<rect x='290.62' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:37:<rect x='313.48' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:38:<rect x='336.34' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:39:<rect x='359.20' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:40:<rect x='382.06' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:41:<rect x='130.62' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:42:<rect x='153.48' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:43:<rect x='176.34' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:44:<rect x='199.19' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:45:<rect x='222.05' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:46:<rect x='244.91' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:47:<rect x='267.77' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:48:<rect x='290.62' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:49:<rect x='313.48' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:50:<rect x='336.34' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:51:<rect x='359.20' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:52:<rect x='382.06' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:53:<rect x='130.62' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:54:<rect x='153.48' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:55:<rect x='176.34' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:56:<rect x='199.19' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:57:<rect x='222.05' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:58:<rect x='244.91' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:59:<rect x='267.77' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:60:<rect x='290.62' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:61:<rect x='313.48' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:62:<rect x='336.34' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:63:<rect x='359.20' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:64:<rect x='382.06' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:65:<rect x='130.62' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:66:<rect x='153.48' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:67:<rect x='176.34' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:68:<rect x='199.19' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:69:<rect x='222.05' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:70:<rect x='244.91' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:71:<rect x='267.77' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:72:<rect x='290.62' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:73:<rect x='313.48' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:74:<rect x='336.34' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:75:<rect x='359.20' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:76:<rect x='382.06' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:77:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:78:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:79:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:80:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:81:  <clipPath id='cpNDM1LjY2fDcxNC41MnwzOS40M3w0NTIuNjg='>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:82:    <rect x='435.66' y='39.43' width='278.86' height='413.24' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:83:  </clipPath>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:84:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:85:<g clip-path='url(#cpNDM1LjY2fDcxNC41MnwzOS40M3w0NTIuNjg=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:86:<rect x='438.28' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:87:<rect x='461.14' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:88:<rect x='484.00' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:89:<rect x='506.86' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:90:<rect x='529.72' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:91:<rect x='552.57' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:92:<rect x='575.43' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:93:<rect x='598.29' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:94:<rect x='621.15' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:95:<rect x='644.00' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:96:<rect x='666.86' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:97:<rect x='689.72' y='345.92' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:98:<rect x='438.28' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:99:<rect x='461.14' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:100:<rect x='484.00' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:101:<rect x='506.86' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:102:<rect x='529.72' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:103:<rect x='552.57' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:104:<rect x='575.43' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:105:<rect x='598.29' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:106:<rect x='621.15' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:107:<rect x='644.00' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:108:<rect x='666.86' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:109:<rect x='689.72' y='247.53' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:110:<rect x='438.28' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:111:<rect x='461.14' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:112:<rect x='484.00' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:113:<rect x='506.86' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:114:<rect x='529.72' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:115:<rect x='552.57' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:116:<rect x='575.43' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:117:<rect x='598.29' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:118:<rect x='621.15' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:119:<rect x='644.00' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:120:<rect x='666.86' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:121:<rect x='689.72' y='149.14' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:122:<rect x='438.28' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #BCCBDD;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:123:<rect x='461.14' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:124:<rect x='484.00' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:125:<rect x='506.86' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:126:<rect x='529.72' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #588BB9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:127:<rect x='552.57' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #6894BE;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:128:<rect x='575.43' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #779DC4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:129:<rect x='598.29' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #6894BE;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:130:<rect x='621.15' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #588BB9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:131:<rect x='644.00' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:132:<rect x='666.86' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #4682B4;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:133:<rect x='689.72' y='50.75' width='22.17' height='95.44' style='stroke-width: 0.43; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #85A6C9;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:134:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:135:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:136:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:137:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:138:  <clipPath id='cpMTI3Ljk5fDQwNi44NnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:139:    <rect x='127.99' y='22.78' width='278.86' height='16.65' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:140:  </clipPath>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:141:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:142:<g clip-path='url(#cpMTI3Ljk5fDQwNi44NnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:143:<text x='267.42' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:144:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:145:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:146:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:147:<defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:148:  <clipPath id='cpNDM1LjY2fDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:149:    <rect x='435.66' y='22.78' width='278.86' height='16.65' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:150:  </clipPath>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:151:</defs>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:152:<g clip-path='url(#cpNDM1LjY2fDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:153:<text x='575.09' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:154:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:155:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:156:<polyline points='127.99,452.68 406.86,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:157:<polyline points='141.71,455.42 141.71,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:158:<polyline points='164.56,455.42 164.56,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:159:<polyline points='187.42,455.42 187.42,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:160:<polyline points='210.28,455.42 210.28,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:161:<polyline points='233.14,455.42 233.14,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:162:<polyline points='255.99,455.42 255.99,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:163:<polyline points='278.85,455.42 278.85,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:164:<polyline points='301.71,455.42 301.71,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:165:<polyline points='324.57,455.42 324.57,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:166:<polyline points='347.43,455.42 347.43,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:167:<polyline points='370.28,455.42 370.28,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:168:<polyline points='393.14,455.42 393.14,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:169:<text transform='translate(147.76,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-08</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:170:<text transform='translate(170.62,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-15</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:171:<text transform='translate(193.48,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-22</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:172:<text transform='translate(216.34,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-29</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:173:<text transform='translate(239.19,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-05</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:174:<text transform='translate(262.05,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-12</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:175:<text transform='translate(284.91,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-19</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:176:<text transform='translate(307.77,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-26</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:177:<text transform='translate(330.62,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-03</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:178:<text transform='translate(353.48,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-10</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:179:<text transform='translate(376.34,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-17</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:180:<text transform='translate(399.20,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-24</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:181:<polyline points='435.66,452.68 714.52,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:182:<polyline points='449.37,455.42 449.37,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:183:<polyline points='472.23,455.42 472.23,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:184:<polyline points='495.09,455.42 495.09,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:185:<polyline points='517.94,455.42 517.94,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:186:<polyline points='540.80,455.42 540.80,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:187:<polyline points='563.66,455.42 563.66,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:188:<polyline points='586.52,455.42 586.52,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:189:<polyline points='609.37,455.42 609.37,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:190:<polyline points='632.23,455.42 632.23,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:191:<polyline points='655.09,455.42 655.09,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:192:<polyline points='677.95,455.42 677.95,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:193:<polyline points='700.81,455.42 700.81,452.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:194:<text transform='translate(455.43,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-08</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:195:<text transform='translate(478.28,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-15</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:196:<text transform='translate(501.14,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-22</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:197:<text transform='translate(524.00,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-05-29</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:198:<text transform='translate(546.86,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-05</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:199:<text transform='translate(569.72,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-12</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:200:<text transform='translate(592.57,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-19</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:201:<text transform='translate(615.43,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-06-26</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:202:<text transform='translate(638.29,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-03</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:203:<text transform='translate(661.15,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-10</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:204:<text transform='translate(684.00,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-17</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:205:<text transform='translate(706.86,460.35) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='45.02px' lengthAdjust='spacingAndGlyphs'>2021-07-24</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:206:<polyline points='127.99,452.68 127.99,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:207:<text x='120.32' y='396.67' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:208:<text x='120.32' y='298.28' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:209:<text x='120.32' y='199.89' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:210:<text x='120.32' y='101.50' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:211:<polyline points='125.25,393.64 127.99,393.64 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:212:<polyline points='125.25,295.25 127.99,295.25 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:213:<polyline points='125.25,196.86 127.99,196.86 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:214:<polyline points='125.25,98.47 127.99,98.47 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:215:<text x='421.26' y='515.68' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='80.13px' lengthAdjust='spacingAndGlyphs'>target_end_date</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:216:<text transform='translate(13.05,246.06) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:217:<text x='360.64' y='553.50' style='font-size: 11.00px; font-family: sans;' textLength='29.36px' lengthAdjust='spacingAndGlyphs'>Count</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:218:<image width='86.40' height='17.28' x='395.47' y='534.40' preserveAspectRatio='none' xlink:href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAABCAYAAABkOJMpAAAAkElEQVQ4jZVTOQKAMAjD//+2H4hDLQKGQ4cOgUAIeK21ABERiGA/AtnfCeABbJ7HYGKHi8DhmHK1n89jmGp18Udrgr39CNfWVwyBE7xg2MDHD1Z4kfpTaJvsTveR1We76/xIe/L6k5km91j5+F+rv43RvZictpblMaz0m/9j3b2Us9uZGDbkZXNmOmKOm7vh3RuSXIwyeLayAAAAAElFTkSuQmCC'/>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:219:<polyline points='395.62,548.22 395.62,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:220:<polyline points='417.15,548.22 417.15,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:221:<polyline points='438.67,548.22 438.67,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:222:<polyline points='460.20,548.22 460.20,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:223:<polyline points='481.73,548.22 481.73,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:224:<polyline points='395.62,537.85 395.62,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:225:<polyline points='417.15,537.85 417.15,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:226:<polyline points='438.67,537.85 438.67,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:227:<polyline points='460.20,537.85 460.20,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:228:<polyline points='481.73,537.85 481.73,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:229:<text x='395.62' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:230:<text x='417.15' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>3</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:231:<text x='438.67' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>6</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:232:<text x='460.20' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>9</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:233:<text x='481.73' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>12</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:234:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='141.64px' lengthAdjust='spacingAndGlyphs'>plot_available_forecasts</text>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:235:</g>\ntests/testthat/_snaps/get-forecast-counts/plot-available-forecasts.svg:236:</svg>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:3:<defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:6:      fill: none;\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:7:      stroke: #000000;\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:11:    }\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:12:  ]]></style>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:13:</defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:15:<defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:18:  </clipPath>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:19:</defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:22:</g>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:23:<defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:24:  <clipPath id='cpNDAuNDN8NzE0LjUyfDIyLjc4fDUwMy4xNw=='>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:25:    <rect x='40.43' y='22.78' width='674.09' height='480.39' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:26:  </clipPath>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:27:</defs>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:28:<g clip-path='url(#cpNDAuNDN8NzE0LjUyfDIyLjc4fDUwMy4xNw==)'>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:29:<polygon points='40.43,503.17 40.43,22.78 714.52,22.78 ' style='stroke-width: 1.07; stroke: #FFFFFF; stroke-linecap: butt; fill: #9ACD32; fill-opacity: 0.051;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:30:[Omitted long matching line]\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:31:<polyline points='40.43,503.17 107.84,461.89 175.25,411.23 242.66,364.31 310.06,323.03 377.47,264.86 444.88,201.05 512.29,131.62 579.70,97.84 647.11,65.94 680.82,58.44 701.04,54.68 ' style='stroke-width: 1.07; stroke: #F8766D; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:32:<polyline points='40.43,501.30 107.84,431.87 175.25,383.08 242.66,317.40 310.06,253.60 377.47,199.18 444.88,182.29 512.29,141.00 579.70,110.98 647.11,69.70 680.82,50.93 701.04,37.80 ' style='stroke-width: 1.07; stroke: #7CAE00; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:33:<polyline points='40.43,495.67 107.84,454.39 175.25,409.35 242.66,368.06 310.06,319.28 377.47,281.74 444.88,244.21 512.29,206.68 579.70,135.38 647.11,82.83 680.82,45.30 701.04,30.29 ' style='stroke-width: 1.07; stroke: #00BFC4; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:34:<polyline points='40.43,501.23 107.84,458.44 175.25,423.43 242.66,392.32 310.06,349.53 377.47,289.24 444.88,244.50 512.29,197.82 579.70,151.15 647.11,96.69 680.82,83.08 701.04,65.57 ' style='stroke-width: 1.07; stroke: #C77CFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:35:</g>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:36:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:37:<polyline points='40.43,503.17 40.43,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:38:<text x='32.76' y='506.20' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:39:<text x='32.76' y='386.11' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>25</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:40:<text x='32.76' y='266.01' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>50</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:41:<text x='32.76' y='145.91' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>75</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:42:<text x='32.76' y='25.81' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='14.68px' lengthAdjust='spacingAndGlyphs'>100</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:43:<polyline points='37.69,503.17 40.43,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:44:<polyline points='37.69,383.08 40.43,383.08 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:45:<polyline points='37.69,262.98 40.43,262.98 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:46:<polyline points='37.69,142.88 40.43,142.88 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:47:<polyline points='37.69,22.78 40.43,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:48:<polyline points='40.43,503.17 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:49:<polyline points='40.43,505.91 40.43,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:50:<polyline points='208.95,505.91 208.95,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:51:<polyline points='377.47,505.91 377.47,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:52:<polyline points='546.00,505.91 546.00,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:53:<polyline points='714.52,505.91 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:54:<text x='40.43' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:55:<text x='208.95' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>25</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:56:<text x='377.47' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>50</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:57:<text x='546.00' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>75</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:58:<text x='714.52' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='14.68px' lengthAdjust='spacingAndGlyphs'>100</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:59:<text x='377.47' y='529.04' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='127.19px' lengthAdjust='spacingAndGlyphs'>Nominal interval coverage</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:60:<text transform='translate(13.05,262.98) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='103.34px' lengthAdjust='spacingAndGlyphs'>% Obs inside interval</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:61:<text x='125.49' y='560.19' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:62:<line x1='162.67' y1='556.40' x2='176.49' y2='556.40' style='stroke-width: 1.07; stroke: #F8766D; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:63:<line x1='287.77' y1='556.40' x2='301.60' y2='556.40' style='stroke-width: 1.07; stroke: #7CAE00; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:64:<line x1='418.26' y1='556.40' x2='432.08' y2='556.40' style='stroke-width: 1.07; stroke: #00BFC4; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:65:<line x1='522.81' y1='556.40' x2='536.64' y2='556.40' style='stroke-width: 1.07; stroke: #C77CFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:66:<text x='183.70' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:67:<text x='308.80' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:68:<text x='439.29' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:69:<text x='543.84' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:70:<text x='40.43' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='132.83px' lengthAdjust='spacingAndGlyphs'>plot_interval_coverage</text>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:71:</g>\ntests/testthat/_snaps/get-coverage/plot-interval-coverage.svg:72:</svg>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:3:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:6:      fill: none;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:7:      stroke: #000000;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:11:    }\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:12:  ]]></style>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:13:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:15:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:18:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:19:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:22:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:23:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:24:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwzOS40M3w0NDguMDE='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:25:    <rect x='127.99' y='39.43' width='290.52' height='408.57' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:26:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:27:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:28:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwzOS40M3w0NDguMDE=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:29:<rect x='201.17' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:30:<rect x='347.53' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:31:<rect x='127.99' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:32:<rect x='127.99' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:33:<rect x='201.17' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:34:<rect x='347.53' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:35:<rect x='347.53' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:36:<rect x='127.99' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:37:<rect x='201.17' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:38:<text x='236.66' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:39:<text x='383.02' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:40:<text x='163.48' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:41:<text x='163.48' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:42:<text x='236.66' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='27.53px' lengthAdjust='spacingAndGlyphs'>0.298</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:43:<text x='383.02' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:44:<text x='383.02' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='27.53px' lengthAdjust='spacingAndGlyphs'>0.298</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:45:<text x='163.48' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:46:<text x='236.66' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:47:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:48:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:49:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:50:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:51:  <clipPath id='cpNDI0LjAwfDcxNC41MnwzOS40M3w0NDguMDE='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:52:    <rect x='424.00' y='39.43' width='290.52' height='408.57' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:53:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:54:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:55:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwzOS40M3w0NDguMDE=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:56:<rect x='497.18' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:57:<rect x='570.36' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:58:<rect x='643.54' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:59:<rect x='424.00' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:60:<rect x='424.00' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:61:<rect x='497.18' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:62:<rect x='570.36' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:63:<rect x='643.54' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:64:<rect x='497.18' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:65:<rect x='643.54' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:66:<rect x='424.00' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:67:<rect x='570.36' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:68:<rect x='643.54' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:69:<rect x='570.36' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:70:<rect x='424.00' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #7CCD7C;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:71:<rect x='497.18' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:72:<text x='532.67' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:73:<text x='605.85' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:74:<text x='679.03' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:75:<text x='459.49' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:76:<text x='459.49' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:77:<text x='532.67' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:78:<text x='605.85' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:79:<text x='679.03' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:80:<text x='532.67' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='27.53px' lengthAdjust='spacingAndGlyphs'>0.007</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:81:<text x='679.03' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:82:<text x='459.49' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:83:<text x='605.85' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:84:<text x='679.03' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:85:<text x='605.85' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='27.53px' lengthAdjust='spacingAndGlyphs'>0.007</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:86:<text x='459.49' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='37.01px' lengthAdjust='spacingAndGlyphs'>&lt; 0.001</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:87:<text x='532.67' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:88:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:89:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:90:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:91:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:92:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:93:    <rect x='127.99' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:94:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:95:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:96:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:97:<text x='273.25' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:98:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:99:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:100:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:101:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:102:  <clipPath id='cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:103:    <rect x='424.00' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:104:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:105:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:106:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:107:<text x='569.26' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:108:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:109:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:110:<polyline points='127.99,448.01 418.52,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:111:<polyline points='163.48,450.75 163.48,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:112:<polyline points='236.66,450.75 236.66,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:113:<polyline points='309.84,450.75 309.84,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:114:<polyline points='383.02,450.75 383.02,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:115:<text transform='translate(169.54,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:116:<text transform='translate(242.72,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:117:<text transform='translate(315.90,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:118:<text transform='translate(389.08,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:119:<polyline points='424.00,448.01 714.52,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:120:<polyline points='459.49,450.75 459.49,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:121:<polyline points='532.67,450.75 532.67,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:122:<polyline points='605.85,450.75 605.85,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:123:<polyline points='679.03,450.75 679.03,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:124:<text transform='translate(465.54,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:125:<text transform='translate(538.72,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:126:<text transform='translate(611.90,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:127:<text transform='translate(685.08,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:128:<polyline points='127.99,448.01 127.99,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:129:<text x='120.32' y='401.12' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:130:<text x='120.32' y='298.21' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:131:<text x='120.32' y='195.29' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:132:<text x='120.32' y='92.38' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:133:<polyline points='125.25,398.09 127.99,398.09 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:134:<polyline points='125.25,295.18 127.99,295.18 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:135:<polyline points='125.25,192.26 127.99,192.26 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:136:<polyline points='125.25,89.35 127.99,89.35 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:137:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='184.20px' lengthAdjust='spacingAndGlyphs'>plot_pairwise_comparison_pval</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:138:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison-pval.svg:139:</svg>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:3:<defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:6:      fill: none;\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:7:      stroke: #000000;\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:11:    }\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:12:  ]]></style>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:13:</defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:15:<defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:18:  </clipPath>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:19:</defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:22:</g>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:23:<defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:24:  <clipPath id='cpNDAuNDN8NzE0LjUyfDIyLjc4fDUwMy4xNw=='>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:25:    <rect x='40.43' y='22.78' width='674.09' height='480.39' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:26:  </clipPath>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:27:</defs>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:28:<g clip-path='url(#cpNDAuNDN8NzE0LjUyfDIyLjc4fDUwMy4xNw==)'>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:29:<polygon points='40.43,503.17 377.47,503.17 377.47,262.98 377.47,262.98 377.47,22.78 714.52,22.78 ' style='stroke-width: 1.07; stroke: #FFFFFF; stroke-linecap: butt; fill: #9ACD32; fill-opacity: 0.051;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:30:[Omitted long matching line]\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:31:<polyline points='47.17,488.16 57.28,488.16 74.13,482.53 107.84,463.77 141.54,439.37 175.25,383.08 208.95,326.78 242.66,277.99 276.36,251.72 310.06,221.70 343.77,187.92 377.47,167.28 411.18,146.63 444.88,131.62 478.59,114.73 512.29,97.84 546.00,88.46 579.70,82.83 613.41,67.82 647.11,58.44 680.82,45.30 697.67,43.43 707.78,39.67 ' style='stroke-width: 1.07; stroke: #F8766D; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:32:<polyline points='47.17,495.67 57.28,488.16 74.13,482.53 107.84,465.64 141.54,454.39 175.25,435.62 208.95,424.36 242.66,375.57 276.36,339.92 310.06,308.02 343.77,279.87 377.47,247.97 411.18,214.19 444.88,187.92 478.59,154.14 512.29,135.38 546.00,120.36 579.70,116.61 613.41,92.22 647.11,73.45 680.82,49.05 697.67,35.92 707.78,30.29 ' style='stroke-width: 1.07; stroke: #7CAE00; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:33:<polyline points='47.17,499.42 57.28,495.67 74.13,473.15 107.84,443.13 141.54,405.60 175.25,386.83 208.95,371.82 242.66,364.31 276.36,334.29 310.06,323.03 343.77,300.51 377.47,262.98 411.18,251.72 444.88,229.20 478.59,206.68 512.29,184.16 546.00,157.89 579.70,127.87 613.41,109.10 647.11,82.83 680.82,52.81 697.67,37.80 707.78,26.54 ' style='stroke-width: 1.07; stroke: #00BFC4; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:34:<polyline points='47.17,491.51 57.28,479.84 74.13,474.00 107.84,454.55 141.54,433.16 175.25,403.98 208.95,376.76 242.66,349.53 276.36,328.13 310.06,312.57 343.77,293.13 377.47,265.90 411.18,248.39 444.88,234.78 478.59,217.27 512.29,195.88 546.00,164.76 579.70,145.31 613.41,127.81 647.11,102.52 680.82,67.52 697.67,59.74 707.78,53.90 ' style='stroke-width: 1.07; stroke: #C77CFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:35:</g>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:36:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:37:<polyline points='40.43,503.17 40.43,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:38:<text x='32.76' y='506.20' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:39:<text x='32.76' y='386.11' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>25</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:40:<text x='32.76' y='266.01' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>50</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:41:<text x='32.76' y='145.91' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='9.79px' lengthAdjust='spacingAndGlyphs'>75</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:42:<text x='32.76' y='25.81' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='14.68px' lengthAdjust='spacingAndGlyphs'>100</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:43:<polyline points='37.69,503.17 40.43,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:44:<polyline points='37.69,383.08 40.43,383.08 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:45:<polyline points='37.69,262.98 40.43,262.98 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:46:<polyline points='37.69,142.88 40.43,142.88 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:47:<polyline points='37.69,22.78 40.43,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:48:<polyline points='40.43,503.17 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:49:<polyline points='40.43,505.91 40.43,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:50:<polyline points='208.95,505.91 208.95,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:51:<polyline points='377.47,505.91 377.47,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:52:<polyline points='546.00,505.91 546.00,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:53:<polyline points='714.52,505.91 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:54:<text x='40.43' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.00</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:55:<text x='208.95' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.25</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:56:<text x='377.47' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.50</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:57:<text x='546.00' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.75</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:58:<text x='714.52' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>1.00</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:59:<text x='377.47' y='529.04' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='66.65px' lengthAdjust='spacingAndGlyphs'>Quantile level</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:60:<text transform='translate(13.05,262.98) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='132.09px' lengthAdjust='spacingAndGlyphs'>% Obs below quantile level</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:61:<text x='125.49' y='560.19' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:62:<line x1='162.67' y1='556.40' x2='176.49' y2='556.40' style='stroke-width: 1.07; stroke: #F8766D; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:63:<line x1='287.77' y1='556.40' x2='301.60' y2='556.40' style='stroke-width: 1.07; stroke: #7CAE00; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:64:<line x1='418.26' y1='556.40' x2='432.08' y2='556.40' style='stroke-width: 1.07; stroke: #00BFC4; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:65:<line x1='522.81' y1='556.40' x2='536.64' y2='556.40' style='stroke-width: 1.07; stroke: #C77CFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:66:<text x='183.70' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:67:<text x='308.80' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:68:<text x='439.29' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:69:<text x='543.84' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:70:<text x='40.43' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='136.52px' lengthAdjust='spacingAndGlyphs'>plot_quantile_coverage</text>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:71:</g>\ntests/testthat/_snaps/get-coverage/plot-quantile-coverage.svg:72:</svg>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:3:<defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:6:      fill: none;\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:7:      stroke: #000000;\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:11:    }\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:12:  ]]></style>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:13:</defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:15:<defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:18:  </clipPath>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:19:</defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:22:</g>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:23:<defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:24:  <clipPath id='cpMTA5LjkwfDcxNC41MnwyMi43OHw0MTMuNTQ='>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:25:    <rect x='109.90' y='22.78' width='604.62' height='390.75' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:26:  </clipPath>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:27:</defs>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:28:<g clip-path='url(#cpMTA5LjkwfDcxNC41MnwyMi43OHw0MTMuNTQ=)'>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:29:<rect x='640.93' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:30:<rect x='565.07' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FC887A;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:31:<rect x='565.07' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:32:<rect x='489.21' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFDCD6;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:33:<rect x='489.21' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FAFBFD;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:34:<rect x='489.21' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:35:<rect x='413.35' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFC5BC;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:36:<rect x='413.35' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFD7D0;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:37:<rect x='413.35' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFECE9;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:38:<rect x='413.35' y='218.90' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:39:<rect x='337.49' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFF1EF;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:40:<rect x='337.49' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFE3DE;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:41:<rect x='337.49' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #C2D1E5;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:42:<rect x='337.49' y='218.90' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFF1EF;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:43:<rect x='337.49' y='169.87' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:44:<rect x='261.63' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #DAE3EF;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:45:<rect x='261.63' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #E5EBF4;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:46:<rect x='261.63' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #DAE3EF;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:47:<rect x='261.63' y='218.90' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #EFF3F8;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:48:<rect x='261.63' y='169.87' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFFEFE;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:49:<rect x='261.63' y='120.84' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:50:<rect x='185.76' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #B7CAE0;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:51:<rect x='185.76' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #C7D5E7;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:52:<rect x='185.76' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #C0D0E4;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:53:<rect x='185.76' y='218.90' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #EFF3F8;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:54:<rect x='185.76' y='169.87' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFF2F0;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:55:<rect x='185.76' y='120.84' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFD1C9;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:56:<rect x='185.76' y='71.81' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:57:<rect x='109.90' y='365.98' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8173;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:58:<rect x='109.90' y='316.95' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FD8D7F;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:59:<rect x='109.90' y='267.92' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFD4CD;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:60:<rect x='109.90' y='218.90' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFBBB1;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:61:<rect x='109.90' y='169.87' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FFF2F0;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:62:<rect x='109.90' y='120.84' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #D3DEEC;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:63:<rect x='109.90' y='71.81' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #B7CAE0;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:64:<rect x='109.90' y='22.78' width='73.59' height='47.56' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FA8072;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:65:<text x='677.73' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:66:<text x='601.87' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.94</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:67:<text x='601.87' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:68:<text x='526.00' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.28</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:69:<text x='526.00' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.03</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:70:<text x='526.00' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:71:<text x='450.14' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.46</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:72:<text x='450.14' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.32</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:73:<text x='450.14' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.15</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:74:<text x='450.14' y='246.46' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:75:<text x='374.28' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.11</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:76:<text x='374.28' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.22</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:77:<text x='374.28' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.35</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:78:<text x='374.28' y='246.46' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.11</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:79:<text x='374.28' y='197.43' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:80:<text x='298.42' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.21</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:81:<text x='298.42' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.15</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:82:<text x='298.42' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.21</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:83:<text x='298.42' y='246.46' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.09</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:84:<text x='298.42' y='197.43' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.01</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:85:<text x='298.42' y='148.40' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:86:<text x='222.56' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.41</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:87:<text x='222.56' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.32</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:88:<text x='222.56' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.36</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:89:<text x='222.56' y='246.46' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.09</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:90:<text x='222.56' y='197.43' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='15.29px' lengthAdjust='spacingAndGlyphs'>0.1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:91:<text x='222.56' y='148.40' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.37</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:92:<text x='222.56' y='99.38' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:93:<text x='146.70' y='393.54' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.99</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:94:<text x='146.70' y='344.52' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='15.29px' lengthAdjust='spacingAndGlyphs'>0.9</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:95:<text x='146.70' y='295.49' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.34</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:96:<text x='146.70' y='246.46' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.54</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:97:<text x='146.70' y='197.43' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='15.29px' lengthAdjust='spacingAndGlyphs'>0.1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:98:<text x='146.70' y='148.40' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.25</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:99:<text x='146.70' y='99.38' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='25.07px' lengthAdjust='spacingAndGlyphs'>-0.41</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:100:<text x='146.70' y='50.35' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:101:</g>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:102:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:103:<polyline points='109.90,413.54 109.90,22.78 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:104:<text x='102.23' y='392.79' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='12.71px' lengthAdjust='spacingAndGlyphs'>wis</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:105:<text x='102.23' y='343.76' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='55.28px' lengthAdjust='spacingAndGlyphs'>overprediction</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:106:<text x='102.23' y='294.73' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='60.67px' lengthAdjust='spacingAndGlyphs'>underprediction</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:107:<text x='102.23' y='245.70' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='40.12px' lengthAdjust='spacingAndGlyphs'>dispersion</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:108:<text x='102.23' y='196.67' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='16.15px' lengthAdjust='spacingAndGlyphs'>bias</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:109:<text x='102.23' y='147.65' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='84.16px' lengthAdjust='spacingAndGlyphs'>interval_coverage_50</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:110:<text x='102.23' y='98.62' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='84.16px' lengthAdjust='spacingAndGlyphs'>interval_coverage_90</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:111:<text x='102.23' y='49.59' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='43.55px' lengthAdjust='spacingAndGlyphs'>ae_median</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:112:<polyline points='107.16,389.76 109.90,389.76 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:113:<polyline points='107.16,340.73 109.90,340.73 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:114:<polyline points='107.16,291.70 109.90,291.70 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:115:<polyline points='107.16,242.67 109.90,242.67 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:116:<polyline points='107.16,193.65 109.90,193.65 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:117:<polyline points='107.16,144.62 109.90,144.62 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:118:<polyline points='107.16,95.59 109.90,95.59 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:119:<polyline points='107.16,46.56 109.90,46.56 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:120:<polyline points='109.90,413.54 714.52,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:121:<polyline points='146.70,416.28 146.70,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:122:<polyline points='222.56,416.28 222.56,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:123:<polyline points='298.42,416.28 298.42,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:124:<polyline points='374.28,416.28 374.28,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:125:<polyline points='450.14,416.28 450.14,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:126:<polyline points='526.00,416.28 526.00,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:127:<polyline points='601.87,416.28 601.87,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:128:<polyline points='677.73,416.28 677.73,413.54 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:129:<text transform='translate(152.75,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='43.55px' lengthAdjust='spacingAndGlyphs'>ae_median</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:130:<text transform='translate(228.61,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='84.16px' lengthAdjust='spacingAndGlyphs'>interval_coverage_90</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:131:<text transform='translate(304.47,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='84.16px' lengthAdjust='spacingAndGlyphs'>interval_coverage_50</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:132:<text transform='translate(380.34,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='16.15px' lengthAdjust='spacingAndGlyphs'>bias</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:133:<text transform='translate(456.20,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='40.12px' lengthAdjust='spacingAndGlyphs'>dispersion</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:134:<text transform='translate(532.06,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='60.67px' lengthAdjust='spacingAndGlyphs'>underprediction</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:135:<text transform='translate(607.92,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='55.28px' lengthAdjust='spacingAndGlyphs'>overprediction</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:136:<text transform='translate(683.78,421.21) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='12.71px' lengthAdjust='spacingAndGlyphs'>wis</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:137:<text x='339.37' y='553.50' style='font-size: 11.00px; font-family: sans;' textLength='53.80px' lengthAdjust='spacingAndGlyphs'>Correlation</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:138:<image width='86.40' height='17.28' x='398.65' y='534.40' preserveAspectRatio='none' xlink:href='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAABCAYAAABkOJMpAAAAi0lEQVQ4jc2Q0Q0CMQxDn/cfiB2Ygk3MR9pcK3pXgkDiq5GTPDvV7f6wAElIAPGOWshqWtNbnfMC5W4szVpjjOzOyHr2YOG3Z895WNyyZvf7qzle/4UhB3ZAbcDxmqPuvdXcaa8wl55XjHHuLNu7uQv+pf8o7H503z95/Zh3yT407/wM3uRx+n2n/wR2mBP8oZBbpQAAAABJRU5ErkJggg=='/>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:139:<polyline points='423.84,548.22 423.84,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:140:<polyline points='454.37,548.22 454.37,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:141:<polyline points='484.91,548.22 484.91,551.68 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:142:<polyline points='423.84,537.85 423.84,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:143:<polyline points='454.37,537.85 454.37,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:144:<polyline points='484.91,537.85 484.91,534.40 ' style='stroke-width: 0.38; stroke: #FFFFFF; stroke-linecap: butt;' />\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:145:<text x='423.84' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.0</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:146:<text x='454.37' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>0.5</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:147:<text x='484.91' y='563.21' text-anchor='middle' style='font-size: 8.80px; font-family: sans;' textLength='12.23px' lengthAdjust='spacingAndGlyphs'>1.0</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:148:<text x='109.90' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='97.60px' lengthAdjust='spacingAndGlyphs'>plot__correlation</text>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:149:</g>\ntests/testthat/_snaps/get-correlations/plot-correlation.svg:150:</svg>\ntests/testthat/_snaps/helper-quantile-interval-range.md:1:# quantile_to_range works - scalar and vector case\ntests/testthat/_snaps/helper-quantile-interval-range.md:2:\ntests/testthat/_snaps/helper-quantile-interval-range.md:3:    Code\ntests/testthat/_snaps/helper-quantile-interval-range.md:4:      out1\ntests/testthat/_snaps/helper-quantile-interval-range.md:5:    Output\ntests/testthat/_snaps/helper-quantile-interval-range.md:6:      Key: <forecast_id, observed, interval_range>\ntests/testthat/_snaps/helper-quantile-interval-range.md:7:         forecast_id observed interval_range lower upper\ntests/testthat/_snaps/helper-quantile-interval-range.md:8:               <int>    <num>          <num> <int> <int>\ntests/testthat/_snaps/helper-quantile-interval-range.md:9:      1:           1        5              0     5     5\ntests/testthat/_snaps/helper-quantile-interval-range.md:10:      2:           1        5             20     4     6\ntests/testthat/_snaps/helper-quantile-interval-range.md:11:      3:           1        5             40     3     7\ntests/testthat/_snaps/helper-quantile-interval-range.md:12:      4:           1        5             60     2     8\ntests/testthat/_snaps/helper-quantile-interval-range.md:13:      5:           1        5             80     1     9\ntests/testthat/_snaps/helper-quantile-interval-range.md:14:\ntests/testthat/_snaps/helper-quantile-interval-range.md:15:---\ntests/testthat/_snaps/helper-quantile-interval-range.md:16:\ntests/testthat/_snaps/helper-quantile-interval-range.md:17:    Code\ntests/testthat/_snaps/helper-quantile-interval-range.md:18:      out3\ntests/testthat/_snaps/helper-quantile-interval-range.md:19:    Output\ntests/testthat/_snaps/helper-quantile-interval-range.md:20:      Key: <forecast_id, observed, interval_range>\ntests/testthat/_snaps/helper-quantile-interval-range.md:21:         forecast_id observed interval_range lower upper\ntests/testthat/_snaps/helper-quantile-interval-range.md:22:               <int>    <num>          <num> <int> <int>\ntests/testthat/_snaps/helper-quantile-interval-range.md:23:      1:           1        5              0     5     5\ntests/testthat/_snaps/helper-quantile-interval-range.md:24:      2:           1        5             20     4     6\ntests/testthat/_snaps/helper-quantile-interval-range.md:25:      3:           1        5             40     3     7\ntests/testthat/_snaps/helper-quantile-interval-range.md:26:      4:           1        5             60     2     8\ntests/testthat/_snaps/helper-quantile-interval-range.md:27:      5:           1        5             80     1    NA\ntests/testthat/_snaps/helper-quantile-interval-range.md:28:\ntests/testthat/_snaps/helper-quantile-interval-range.md:29:---\ntests/testthat/_snaps/helper-quantile-interval-range.md:30:\ntests/testthat/_snaps/helper-quantile-interval-range.md:31:    Code\ntests/testthat/_snaps/helper-quantile-interval-range.md:32:      out4\ntests/testthat/_snaps/helper-quantile-interval-range.md:33:    Output\ntests/testthat/_snaps/helper-quantile-interval-range.md:34:      Key: <forecast_id, observed, interval_range>\ntests/testthat/_snaps/helper-quantile-interval-range.md:35:         forecast_id observed interval_range lower upper\ntests/testthat/_snaps/helper-quantile-interval-range.md:36:               <int>    <num>          <num> <int> <int>\ntests/testthat/_snaps/helper-quantile-interval-range.md:37:      1:           1        5              0     5     5\ntests/testthat/_snaps/helper-quantile-interval-range.md:38:      2:           1        5             20     4     6\ntests/testthat/_snaps/helper-quantile-interval-range.md:39:      3:           1        5             40     3     7\ntests/testthat/_snaps/helper-quantile-interval-range.md:40:      4:           1        5             60     2     8\ntests/testthat/_snaps/helper-quantile-interval-range.md:41:      5:           1        5             80     1    NA\ntests/testthat/_snaps/helper-quantile-interval-range.md:42:      6:           1        5             90    NA     9\ntests/testthat/_snaps/helper-quantile-interval-range.md:43:\ntests/testthat/_snaps/helper-quantile-interval-range.md:44:# quantile_to_range works - matrix case\ntests/testthat/_snaps/helper-quantile-interval-range.md:45:\ntests/testthat/_snaps/helper-quantile-interval-range.md:46:    Code\ntests/testthat/_snaps/helper-quantile-interval-range.md:47:      out1\ntests/testthat/_snaps/helper-quantile-interval-range.md:48:    Output\ntests/testthat/_snaps/helper-quantile-interval-range.md:49:      Key: <forecast_id, observed, interval_range>\ntests/testthat/_snaps/helper-quantile-interval-range.md:50:          forecast_id observed interval_range lower upper\ntests/testthat/_snaps/helper-quantile-interval-range.md:51:                <int>    <num>          <num> <int> <int>\ntests/testthat/_snaps/helper-quantile-interval-range.md:52:       1:           1       21              0    21    21\ntests/testthat/_snaps/helper-quantile-interval-range.md:53:       2:           1       21             20    16    26\ntests/testthat/_snaps/helper-quantile-interval-range.md:54:       3:           1       21             40    11    31\ntests/testthat/_snaps/helper-quantile-interval-range.md:55:       4:           1       21             60     6    36\ntests/testthat/_snaps/helper-quantile-interval-range.md:56:       5:           1       21             80     1    41\ntests/testthat/_snaps/helper-quantile-interval-range.md:57:       6:           2       22              0    22    22\ntests/testthat/_snaps/helper-quantile-interval-range.md:58:       7:           2       22             20    17    27\ntests/testthat/_snaps/helper-quantile-interval-range.md:59:       8:           2       22             40    12    32\ntests/testthat/_snaps/helper-quantile-interval-range.md:60:       9:           2       22             60     7    37\ntests/testthat/_snaps/helper-quantile-interval-range.md:61:      10:           2       22             80     2    42\ntests/testthat/_snaps/helper-quantile-interval-range.md:62:      11:           3       23              0    23    23\ntests/testthat/_snaps/helper-quantile-interval-range.md:63:      12:           3       23             20    18    28\ntests/testthat/_snaps/helper-quantile-interval-range.md:64:      13:           3       23             40    13    33\ntests/testthat/_snaps/helper-quantile-interval-range.md:65:      14:           3       23             60     8    38\ntests/testthat/_snaps/helper-quantile-interval-range.md:66:      15:           3       23             80     3    43\ntests/testthat/_snaps/helper-quantile-interval-range.md:67:      16:           4       24              0    24    24\ntests/testthat/_snaps/helper-quantile-interval-range.md:68:      17:           4       24             20    19    29\ntests/testthat/_snaps/helper-quantile-interval-range.md:69:      18:           4       24             40    14    34\ntests/testthat/_snaps/helper-quantile-interval-range.md:70:      19:           4       24             60     9    39\ntests/testthat/_snaps/helper-quantile-interval-range.md:71:      20:           4       24             80     4    44\ntests/testthat/_snaps/helper-quantile-interval-range.md:72:      21:           5       25              0    25    25\ntests/testthat/_snaps/helper-quantile-interval-range.md:73:      22:           5       25             20    20    30\ntests/testthat/_snaps/helper-quantile-interval-range.md:74:      23:           5       25             40    15    35\ntests/testthat/_snaps/helper-quantile-interval-range.md:75:      24:           5       25             60    10    40\ntests/testthat/_snaps/helper-quantile-interval-range.md:76:      25:           5       25             80     5    45\ntests/testthat/_snaps/helper-quantile-interval-range.md:77:          forecast_id observed interval_range lower upper\ntests/testthat/_snaps/helper-quantile-interval-range.md:78:                <int>    <num>          <num> <int> <int>\ntests/testthat/_snaps/helper-quantile-interval-range.md:79:\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:3:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:6:      fill: none;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:7:      stroke: #000000;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:11:    }\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:12:  ]]></style>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:13:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:15:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:18:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:19:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:22:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:23:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:24:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwzOS40M3w0NDguMDE='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:25:    <rect x='127.99' y='39.43' width='290.52' height='408.57' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:26:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:27:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:28:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwzOS40M3w0NDguMDE=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:29:<rect x='201.17' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F9D6D1;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:30:<rect x='347.53' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F9D6D1;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:31:<rect x='127.99' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:32:<rect x='127.99' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #CAD5E3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:33:<rect x='201.17' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:34:<rect x='347.53' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:35:<rect x='347.53' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:36:<rect x='127.99' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #CAD5E3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:37:<rect x='201.17' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:38:<text x='236.66' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.37</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:39:<text x='383.02' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.59</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:40:<text x='163.48' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:41:<text x='163.48' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.63</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:42:<text x='236.66' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.86</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:43:<text x='383.02' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:44:<text x='383.02' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.16</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:45:<text x='163.48' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.73</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:46:<text x='236.66' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:47:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:48:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:49:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:50:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:51:  <clipPath id='cpNDI0LjAwfDcxNC41MnwzOS40M3w0NDguMDE='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:52:    <rect x='424.00' y='39.43' width='290.52' height='408.57' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:53:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:54:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:55:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwzOS40M3w0NDguMDE=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:56:<rect x='497.18' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FDBAB0;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:57:<rect x='570.36' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FDBAB0;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:58:<rect x='643.54' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #FDBAB0;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:59:<rect x='424.00' y='348.18' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:60:<rect x='424.00' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #A1B8D3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:61:<rect x='497.18' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #CAD5E3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:62:<rect x='570.36' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:63:<rect x='643.54' y='39.43' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:64:<rect x='497.18' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #CAD5E3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:65:<rect x='643.54' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:66:<rect x='424.00' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #A1B8D3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:67:<rect x='570.36' y='142.35' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:68:<rect x='643.54' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F9D6D1;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:69:<rect x='570.36' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F9D6D1;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:70:<rect x='424.00' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #A1B8D3;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:71:<rect x='497.18' y='245.26' width='70.98' height='99.83' style='stroke-width: 0.43; stroke: #FFFFFF; stroke-linecap: butt; stroke-linejoin: miter; fill: #F2F2F2;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:72:<text x='532.67' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>2.38</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:73:<text x='605.85' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>3.03</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:74:<text x='679.03' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>3.85</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:75:<text x='459.49' y='401.88' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:76:<text x='459.49' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.26</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:77:<text x='532.67' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.62</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:78:<text x='605.85' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.79</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:79:<text x='679.03' y='93.13' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:80:<text x='532.67' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.74</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:81:<text x='679.03' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.27</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:82:<text x='459.49' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.33</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:83:<text x='605.85' y='196.05' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:84:<text x='679.03' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.61</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:85:<text x='605.85' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>1.34</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:86:<text x='459.49' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='21.41px' lengthAdjust='spacingAndGlyphs'>0.42</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:87:<text x='532.67' y='298.96' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='6.12px' lengthAdjust='spacingAndGlyphs'>1</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:88:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:89:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:90:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:91:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:92:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:93:    <rect x='127.99' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:94:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:95:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:96:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:97:<text x='273.25' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:98:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:99:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:100:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:101:<defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:102:  <clipPath id='cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:103:    <rect x='424.00' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:104:  </clipPath>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:105:</defs>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:106:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:107:<text x='569.26' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:108:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:109:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:110:<polyline points='127.99,448.01 418.52,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:111:<polyline points='163.48,450.75 163.48,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:112:<polyline points='236.66,450.75 236.66,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:113:<polyline points='309.84,450.75 309.84,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:114:<polyline points='383.02,450.75 383.02,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:115:<text transform='translate(169.54,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:116:<text transform='translate(242.72,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:117:<text transform='translate(315.90,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:118:<text transform='translate(389.08,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:119:<polyline points='424.00,448.01 714.52,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:120:<polyline points='459.49,450.75 459.49,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:121:<polyline points='532.67,450.75 532.67,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:122:<polyline points='605.85,450.75 605.85,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:123:<polyline points='679.03,450.75 679.03,448.01 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:124:<text transform='translate(465.54,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:125:<text transform='translate(538.72,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:126:<text transform='translate(611.90,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:127:<text transform='translate(685.08,455.68) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #8B2323; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:128:<polyline points='127.99,448.01 127.99,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:129:<text x='120.32' y='401.12' text-anchor='end' style='font-size: 8.80px; fill: #36648B; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:130:<text x='120.32' y='298.21' text-anchor='end' style='font-size: 8.80px; fill: #36648B; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:131:<text x='120.32' y='195.29' text-anchor='end' style='font-size: 8.80px; fill: #36648B; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:132:<text x='120.32' y='92.38' text-anchor='end' style='font-size: 8.80px; fill: #36648B; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:133:<polyline points='125.25,398.09 127.99,398.09 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:134:<polyline points='125.25,295.18 127.99,295.18 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:135:<polyline points='125.25,192.26 127.99,192.26 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:136:<polyline points='125.25,89.35 127.99,89.35 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:137:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='152.63px' lengthAdjust='spacingAndGlyphs'>plot_pairwise_comparison</text>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:138:</g>\ntests/testthat/_snaps/pairwise_comparison/plot-pairwise-comparison.svg:139:</svg>\ntests/testthat/_snaps/class-forecast.md:1:# print() works on forecast_* objects\ntests/testthat/_snaps/class-forecast.md:2:\ntests/testthat/_snaps/class-forecast.md:3:    Code\ntests/testthat/_snaps/class-forecast.md:4:      print(dat)\ntests/testthat/_snaps/class-forecast.md:5:    Message\ntests/testthat/_snaps/class-forecast.md:6:      Forecast type: binary\ntests/testthat/_snaps/class-forecast.md:7:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:8:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:9:      and horizon\ntests/testthat/_snaps/class-forecast.md:10:    Output\ntests/testthat/_snaps/class-forecast.md:11:      \ntests/testthat/_snaps/class-forecast.md:12:           location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:13:             <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:14:        1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:15:        2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:16:        3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:17:        4:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:18:        5:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:19:       ---                                                                 \ntests/testthat/_snaps/class-forecast.md:20:      883:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:21:      884:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:22:      885:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:23:      886:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:24:      887:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:25:                           model horizon predicted observed\ntests/testthat/_snaps/class-forecast.md:26:                          <char>   <num>     <num>   <fctr>\ntests/testthat/_snaps/class-forecast.md:27:        1: EuroCOVIDhub-ensemble       1     0.375        0\ntests/testthat/_snaps/class-forecast.md:28:        2: EuroCOVIDhub-baseline       1     0.475        0\ntests/testthat/_snaps/class-forecast.md:29:        3:  epiforecasts-EpiNow2       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:30:        4: EuroCOVIDhub-ensemble       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:31:        5: EuroCOVIDhub-baseline       1     0.500        1\ntests/testthat/_snaps/class-forecast.md:32:       ---                                                 \ntests/testthat/_snaps/class-forecast.md:33:      883: EuroCOVIDhub-baseline       2     0.250        0\ntests/testthat/_snaps/class-forecast.md:34:      884:       UMass-MechBayes       3     0.475        0\ntests/testthat/_snaps/class-forecast.md:35:      885:       UMass-MechBayes       2     0.450        0\ntests/testthat/_snaps/class-forecast.md:36:      886:  epiforecasts-EpiNow2       3     0.375        0\ntests/testthat/_snaps/class-forecast.md:37:      887:  epiforecasts-EpiNow2       2     0.300        0\ntests/testthat/_snaps/class-forecast.md:38:\ntests/testthat/_snaps/class-forecast.md:39:---\ntests/testthat/_snaps/class-forecast.md:40:\ntests/testthat/_snaps/class-forecast.md:41:    Code\ntests/testthat/_snaps/class-forecast.md:42:      print(dat)\ntests/testthat/_snaps/class-forecast.md:43:    Message\ntests/testthat/_snaps/class-forecast.md:44:      Forecast type: binary\ntests/testthat/_snaps/class-forecast.md:45:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:46:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:47:      and horizon\ntests/testthat/_snaps/class-forecast.md:48:    Output\ntests/testthat/_snaps/class-forecast.md:49:      \ntests/testthat/_snaps/class-forecast.md:50:           location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:51:             <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:52:        1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:53:        2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:54:        3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:55:        4:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:56:        5:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:57:       ---                                                                 \ntests/testthat/_snaps/class-forecast.md:58:      883:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:59:      884:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:60:      885:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:61:      886:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:62:      887:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:63:                           model horizon predicted observed\ntests/testthat/_snaps/class-forecast.md:64:                          <char>   <num>     <num>   <fctr>\ntests/testthat/_snaps/class-forecast.md:65:        1: EuroCOVIDhub-ensemble       1     0.375        0\ntests/testthat/_snaps/class-forecast.md:66:        2: EuroCOVIDhub-baseline       1     0.475        0\ntests/testthat/_snaps/class-forecast.md:67:        3:  epiforecasts-EpiNow2       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:68:        4: EuroCOVIDhub-ensemble       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:69:        5: EuroCOVIDhub-baseline       1     0.500        1\ntests/testthat/_snaps/class-forecast.md:70:       ---                                                 \ntests/testthat/_snaps/class-forecast.md:71:      883: EuroCOVIDhub-baseline       2     0.250        0\ntests/testthat/_snaps/class-forecast.md:72:      884:       UMass-MechBayes       3     0.475        0\ntests/testthat/_snaps/class-forecast.md:73:      885:       UMass-MechBayes       2     0.450        0\ntests/testthat/_snaps/class-forecast.md:74:      886:  epiforecasts-EpiNow2       3     0.375        0\ntests/testthat/_snaps/class-forecast.md:75:      887:  epiforecasts-EpiNow2       2     0.300        0\ntests/testthat/_snaps/class-forecast.md:76:\ntests/testthat/_snaps/class-forecast.md:77:---\ntests/testthat/_snaps/class-forecast.md:78:\ntests/testthat/_snaps/class-forecast.md:79:    Code\ntests/testthat/_snaps/class-forecast.md:80:      print(dat)\ntests/testthat/_snaps/class-forecast.md:81:    Message\ntests/testthat/_snaps/class-forecast.md:82:      Forecast type: binary\ntests/testthat/_snaps/class-forecast.md:83:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:84:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:85:      and horizon\ntests/testthat/_snaps/class-forecast.md:86:    Output\ntests/testthat/_snaps/class-forecast.md:87:      \ntests/testthat/_snaps/class-forecast.md:88:           location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:89:             <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:90:        1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:91:        2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:92:        3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:93:        4:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:94:        5:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:95:       ---                                                                 \ntests/testthat/_snaps/class-forecast.md:96:      883:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:97:      884:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:98:      885:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:99:      886:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:100:      887:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:101:                           model horizon predicted observed\ntests/testthat/_snaps/class-forecast.md:102:                          <char>   <num>     <num>   <fctr>\ntests/testthat/_snaps/class-forecast.md:103:        1: EuroCOVIDhub-ensemble       1     0.375        0\ntests/testthat/_snaps/class-forecast.md:104:        2: EuroCOVIDhub-baseline       1     0.475        0\ntests/testthat/_snaps/class-forecast.md:105:        3:  epiforecasts-EpiNow2       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:106:        4: EuroCOVIDhub-ensemble       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:107:        5: EuroCOVIDhub-baseline       1     0.500        1\ntests/testthat/_snaps/class-forecast.md:108:       ---                                                 \ntests/testthat/_snaps/class-forecast.md:109:      883: EuroCOVIDhub-baseline       2     0.250        0\ntests/testthat/_snaps/class-forecast.md:110:      884:       UMass-MechBayes       3     0.475        0\ntests/testthat/_snaps/class-forecast.md:111:      885:       UMass-MechBayes       2     0.450        0\ntests/testthat/_snaps/class-forecast.md:112:      886:  epiforecasts-EpiNow2       3     0.375        0\ntests/testthat/_snaps/class-forecast.md:113:      887:  epiforecasts-EpiNow2       2     0.300        0\ntests/testthat/_snaps/class-forecast.md:114:\ntests/testthat/_snaps/class-forecast.md:115:---\ntests/testthat/_snaps/class-forecast.md:116:\ntests/testthat/_snaps/class-forecast.md:117:    Code\ntests/testthat/_snaps/class-forecast.md:118:      print(dat)\ntests/testthat/_snaps/class-forecast.md:119:    Message\ntests/testthat/_snaps/class-forecast.md:120:      Forecast type: binary\ntests/testthat/_snaps/class-forecast.md:121:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:122:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:123:      and horizon\ntests/testthat/_snaps/class-forecast.md:124:    Output\ntests/testthat/_snaps/class-forecast.md:125:      \ntests/testthat/_snaps/class-forecast.md:126:           location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:127:             <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:128:        1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:129:        2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:130:        3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:131:        4:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:132:        5:       DE       Germany      2021-05-08      Deaths    2021-05-03\ntests/testthat/_snaps/class-forecast.md:133:       ---                                                                 \ntests/testthat/_snaps/class-forecast.md:134:      883:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:135:      884:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:136:      885:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:137:      886:       IT         Italy      2021-07-24      Deaths    2021-07-05\ntests/testthat/_snaps/class-forecast.md:138:      887:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:139:                           model horizon predicted observed\ntests/testthat/_snaps/class-forecast.md:140:                          <char>   <num>     <num>   <fctr>\ntests/testthat/_snaps/class-forecast.md:141:        1: EuroCOVIDhub-ensemble       1     0.375        0\ntests/testthat/_snaps/class-forecast.md:142:        2: EuroCOVIDhub-baseline       1     0.475        0\ntests/testthat/_snaps/class-forecast.md:143:        3:  epiforecasts-EpiNow2       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:144:        4: EuroCOVIDhub-ensemble       1     0.425        0\ntests/testthat/_snaps/class-forecast.md:145:        5: EuroCOVIDhub-baseline       1     0.500        1\ntests/testthat/_snaps/class-forecast.md:146:       ---                                                 \ntests/testthat/_snaps/class-forecast.md:147:      883: EuroCOVIDhub-baseline       2     0.250        0\ntests/testthat/_snaps/class-forecast.md:148:      884:       UMass-MechBayes       3     0.475        0\ntests/testthat/_snaps/class-forecast.md:149:      885:       UMass-MechBayes       2     0.450        0\ntests/testthat/_snaps/class-forecast.md:150:      886:  epiforecasts-EpiNow2       3     0.375        0\ntests/testthat/_snaps/class-forecast.md:151:      887:  epiforecasts-EpiNow2       2     0.300        0\ntests/testthat/_snaps/class-forecast.md:152:\ntests/testthat/_snaps/class-forecast.md:153:---\ntests/testthat/_snaps/class-forecast.md:154:\ntests/testthat/_snaps/class-forecast.md:155:    Code\ntests/testthat/_snaps/class-forecast.md:156:      print(dat)\ntests/testthat/_snaps/class-forecast.md:157:    Message\ntests/testthat/_snaps/class-forecast.md:158:      Forecast type: quantile\ntests/testthat/_snaps/class-forecast.md:159:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:160:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:161:      and horizon\ntests/testthat/_snaps/class-forecast.md:162:    Output\ntests/testthat/_snaps/class-forecast.md:163:      \ntests/testthat/_snaps/class-forecast.md:164:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:165:             location target_end_date target_type observed location_name\ntests/testthat/_snaps/class-forecast.md:166:               <char>          <Date>      <char>    <num>        <char>\ntests/testthat/_snaps/class-forecast.md:167:          1:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:168:          2:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:169:          3:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:170:          4:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:171:          5:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:172:         ---                                                            \ntests/testthat/_snaps/class-forecast.md:173:      20397:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:174:      20398:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:175:      20399:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:176:      20400:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:177:      20401:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:178:             forecast_date quantile_level predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:179:                    <Date>          <num>     <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:180:          1:    2021-05-03          0.010     82466 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:181:          2:    2021-05-03          0.025     86669 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:182:          3:    2021-05-03          0.050     90285 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:183:          4:    2021-05-03          0.100     95341 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:184:          5:    2021-05-03          0.150     99171 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:185:         ---                                                                     \ntests/testthat/_snaps/class-forecast.md:186:      20397:    2021-07-12          0.850       352  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:187:      20398:    2021-07-12          0.900       397  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:188:      20399:    2021-07-12          0.950       499  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:189:      20400:    2021-07-12          0.975       611  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:190:      20401:    2021-07-12          0.990       719  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:191:\ntests/testthat/_snaps/class-forecast.md:192:---\ntests/testthat/_snaps/class-forecast.md:193:\ntests/testthat/_snaps/class-forecast.md:194:    Code\ntests/testthat/_snaps/class-forecast.md:195:      print(dat)\ntests/testthat/_snaps/class-forecast.md:196:    Message\ntests/testthat/_snaps/class-forecast.md:197:      Forecast type: quantile\ntests/testthat/_snaps/class-forecast.md:198:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:199:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:200:      and horizon\ntests/testthat/_snaps/class-forecast.md:201:    Output\ntests/testthat/_snaps/class-forecast.md:202:      \ntests/testthat/_snaps/class-forecast.md:203:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:204:             location target_end_date target_type observed location_name\ntests/testthat/_snaps/class-forecast.md:205:               <char>          <Date>      <char>    <num>        <char>\ntests/testthat/_snaps/class-forecast.md:206:          1:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:207:          2:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:208:          3:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:209:          4:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:210:          5:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:211:         ---                                                            \ntests/testthat/_snaps/class-forecast.md:212:      20397:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:213:      20398:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:214:      20399:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:215:      20400:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:216:      20401:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:217:             forecast_date quantile_level predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:218:                    <Date>          <num>     <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:219:          1:    2021-05-03          0.010     82466 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:220:          2:    2021-05-03          0.025     86669 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:221:          3:    2021-05-03          0.050     90285 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:222:          4:    2021-05-03          0.100     95341 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:223:          5:    2021-05-03          0.150     99171 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:224:         ---                                                                     \ntests/testthat/_snaps/class-forecast.md:225:      20397:    2021-07-12          0.850       352  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:226:      20398:    2021-07-12          0.900       397  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:227:      20399:    2021-07-12          0.950       499  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:228:      20400:    2021-07-12          0.975       611  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:229:      20401:    2021-07-12          0.990       719  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:230:\ntests/testthat/_snaps/class-forecast.md:231:---\ntests/testthat/_snaps/class-forecast.md:232:\ntests/testthat/_snaps/class-forecast.md:233:    Code\ntests/testthat/_snaps/class-forecast.md:234:      print(dat)\ntests/testthat/_snaps/class-forecast.md:235:    Message\ntests/testthat/_snaps/class-forecast.md:236:      Forecast type: quantile\ntests/testthat/_snaps/class-forecast.md:237:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:238:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:239:      and horizon\ntests/testthat/_snaps/class-forecast.md:240:    Output\ntests/testthat/_snaps/class-forecast.md:241:      \ntests/testthat/_snaps/class-forecast.md:242:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:243:             location target_end_date target_type observed location_name\ntests/testthat/_snaps/class-forecast.md:244:               <char>          <Date>      <char>    <num>        <char>\ntests/testthat/_snaps/class-forecast.md:245:          1:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:246:          2:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:247:          3:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:248:          4:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:249:          5:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:250:         ---                                                            \ntests/testthat/_snaps/class-forecast.md:251:      20397:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:252:      20398:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:253:      20399:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:254:      20400:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:255:      20401:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:256:             forecast_date quantile_level predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:257:                    <Date>          <num>     <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:258:          1:    2021-05-03          0.010     82466 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:259:          2:    2021-05-03          0.025     86669 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:260:          3:    2021-05-03          0.050     90285 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:261:          4:    2021-05-03          0.100     95341 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:262:          5:    2021-05-03          0.150     99171 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:263:         ---                                                                     \ntests/testthat/_snaps/class-forecast.md:264:      20397:    2021-07-12          0.850       352  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:265:      20398:    2021-07-12          0.900       397  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:266:      20399:    2021-07-12          0.950       499  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:267:      20400:    2021-07-12          0.975       611  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:268:      20401:    2021-07-12          0.990       719  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:269:\ntests/testthat/_snaps/class-forecast.md:270:---\ntests/testthat/_snaps/class-forecast.md:271:\ntests/testthat/_snaps/class-forecast.md:272:    Code\ntests/testthat/_snaps/class-forecast.md:273:      print(dat)\ntests/testthat/_snaps/class-forecast.md:274:    Message\ntests/testthat/_snaps/class-forecast.md:275:      Forecast type: quantile\ntests/testthat/_snaps/class-forecast.md:276:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:277:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:278:      and horizon\ntests/testthat/_snaps/class-forecast.md:279:    Output\ntests/testthat/_snaps/class-forecast.md:280:      \ntests/testthat/_snaps/class-forecast.md:281:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:282:             location target_end_date target_type observed location_name\ntests/testthat/_snaps/class-forecast.md:283:               <char>          <Date>      <char>    <num>        <char>\ntests/testthat/_snaps/class-forecast.md:284:          1:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:285:          2:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:286:          3:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:287:          4:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:288:          5:       DE      2021-05-08       Cases   106987       Germany\ntests/testthat/_snaps/class-forecast.md:289:         ---                                                            \ntests/testthat/_snaps/class-forecast.md:290:      20397:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:291:      20398:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:292:      20399:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:293:      20400:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:294:      20401:       IT      2021-07-24      Deaths       78         Italy\ntests/testthat/_snaps/class-forecast.md:295:             forecast_date quantile_level predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:296:                    <Date>          <num>     <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:297:          1:    2021-05-03          0.010     82466 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:298:          2:    2021-05-03          0.025     86669 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:299:          3:    2021-05-03          0.050     90285 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:300:          4:    2021-05-03          0.100     95341 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:301:          5:    2021-05-03          0.150     99171 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:302:         ---                                                                     \ntests/testthat/_snaps/class-forecast.md:303:      20397:    2021-07-12          0.850       352  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:304:      20398:    2021-07-12          0.900       397  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:305:      20399:    2021-07-12          0.950       499  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:306:      20400:    2021-07-12          0.975       611  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:307:      20401:    2021-07-12          0.990       719  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:308:\ntests/testthat/_snaps/class-forecast.md:309:---\ntests/testthat/_snaps/class-forecast.md:310:\ntests/testthat/_snaps/class-forecast.md:311:    Code\ntests/testthat/_snaps/class-forecast.md:312:      print(dat)\ntests/testthat/_snaps/class-forecast.md:313:    Message\ntests/testthat/_snaps/class-forecast.md:314:      Forecast type: point\ntests/testthat/_snaps/class-forecast.md:315:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:316:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:317:      and horizon\ntests/testthat/_snaps/class-forecast.md:318:    Output\ntests/testthat/_snaps/class-forecast.md:319:      \ntests/testthat/_snaps/class-forecast.md:320:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:321:           location target_end_date target_type observed location_name forecast_date\ntests/testthat/_snaps/class-forecast.md:322:             <char>          <Date>      <char>    <num>        <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:323:        1:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:324:        2:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:325:        3:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:326:        4:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:327:        5:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:328:       ---                                                                          \ntests/testthat/_snaps/class-forecast.md:329:      883:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:330:      884:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:331:      885:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:332:      886:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:333:      887:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:334:           predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:335:               <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:336:        1:    119258 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:337:        2:    132607 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:338:        3:    151179  epiforecasts-EpiNow2       1\ntests/testthat/_snaps/class-forecast.md:339:        4:      1568 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:340:        5:      1597 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:341:       ---                                        \ntests/testthat/_snaps/class-forecast.md:342:      883:       131 EuroCOVIDhub-baseline       2\ntests/testthat/_snaps/class-forecast.md:343:      884:        79       UMass-MechBayes       3\ntests/testthat/_snaps/class-forecast.md:344:      885:       124       UMass-MechBayes       2\ntests/testthat/_snaps/class-forecast.md:345:      886:       104  epiforecasts-EpiNow2       3\ntests/testthat/_snaps/class-forecast.md:346:      887:       186  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:347:\ntests/testthat/_snaps/class-forecast.md:348:---\ntests/testthat/_snaps/class-forecast.md:349:\ntests/testthat/_snaps/class-forecast.md:350:    Code\ntests/testthat/_snaps/class-forecast.md:351:      print(dat)\ntests/testthat/_snaps/class-forecast.md:352:    Message\ntests/testthat/_snaps/class-forecast.md:353:      Forecast type: point\ntests/testthat/_snaps/class-forecast.md:354:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:355:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:356:      and horizon\ntests/testthat/_snaps/class-forecast.md:357:    Output\ntests/testthat/_snaps/class-forecast.md:358:      \ntests/testthat/_snaps/class-forecast.md:359:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:360:           location target_end_date target_type observed location_name forecast_date\ntests/testthat/_snaps/class-forecast.md:361:             <char>          <Date>      <char>    <num>        <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:362:        1:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:363:        2:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:364:        3:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:365:        4:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:366:        5:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:367:       ---                                                                          \ntests/testthat/_snaps/class-forecast.md:368:      883:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:369:      884:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:370:      885:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:371:      886:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:372:      887:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:373:           predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:374:               <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:375:        1:    119258 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:376:        2:    132607 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:377:        3:    151179  epiforecasts-EpiNow2       1\ntests/testthat/_snaps/class-forecast.md:378:        4:      1568 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:379:        5:      1597 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:380:       ---                                        \ntests/testthat/_snaps/class-forecast.md:381:      883:       131 EuroCOVIDhub-baseline       2\ntests/testthat/_snaps/class-forecast.md:382:      884:        79       UMass-MechBayes       3\ntests/testthat/_snaps/class-forecast.md:383:      885:       124       UMass-MechBayes       2\ntests/testthat/_snaps/class-forecast.md:384:      886:       104  epiforecasts-EpiNow2       3\ntests/testthat/_snaps/class-forecast.md:385:      887:       186  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:386:\ntests/testthat/_snaps/class-forecast.md:387:---\ntests/testthat/_snaps/class-forecast.md:388:\ntests/testthat/_snaps/class-forecast.md:389:    Code\ntests/testthat/_snaps/class-forecast.md:390:      print(dat)\ntests/testthat/_snaps/class-forecast.md:391:    Message\ntests/testthat/_snaps/class-forecast.md:392:      Forecast type: point\ntests/testthat/_snaps/class-forecast.md:393:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:394:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:395:      and horizon\ntests/testthat/_snaps/class-forecast.md:396:    Output\ntests/testthat/_snaps/class-forecast.md:397:      \ntests/testthat/_snaps/class-forecast.md:398:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:399:           location target_end_date target_type observed location_name forecast_date\ntests/testthat/_snaps/class-forecast.md:400:             <char>          <Date>      <char>    <num>        <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:401:        1:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:402:        2:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:403:        3:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:404:        4:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:405:        5:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:406:       ---                                                                          \ntests/testthat/_snaps/class-forecast.md:407:      883:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:408:      884:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:409:      885:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:410:      886:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:411:      887:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:412:           predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:413:               <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:414:        1:    119258 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:415:        2:    132607 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:416:        3:    151179  epiforecasts-EpiNow2       1\ntests/testthat/_snaps/class-forecast.md:417:        4:      1568 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:418:        5:      1597 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:419:       ---                                        \ntests/testthat/_snaps/class-forecast.md:420:      883:       131 EuroCOVIDhub-baseline       2\ntests/testthat/_snaps/class-forecast.md:421:      884:        79       UMass-MechBayes       3\ntests/testthat/_snaps/class-forecast.md:422:      885:       124       UMass-MechBayes       2\ntests/testthat/_snaps/class-forecast.md:423:      886:       104  epiforecasts-EpiNow2       3\ntests/testthat/_snaps/class-forecast.md:424:      887:       186  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:425:\ntests/testthat/_snaps/class-forecast.md:426:---\ntests/testthat/_snaps/class-forecast.md:427:\ntests/testthat/_snaps/class-forecast.md:428:    Code\ntests/testthat/_snaps/class-forecast.md:429:      print(dat)\ntests/testthat/_snaps/class-forecast.md:430:    Message\ntests/testthat/_snaps/class-forecast.md:431:      Forecast type: point\ntests/testthat/_snaps/class-forecast.md:432:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:433:      location, target_end_date, target_type, location_name, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:434:      and horizon\ntests/testthat/_snaps/class-forecast.md:435:    Output\ntests/testthat/_snaps/class-forecast.md:436:      \ntests/testthat/_snaps/class-forecast.md:437:      Key: <location, target_end_date, target_type>\ntests/testthat/_snaps/class-forecast.md:438:           location target_end_date target_type observed location_name forecast_date\ntests/testthat/_snaps/class-forecast.md:439:             <char>          <Date>      <char>    <num>        <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:440:        1:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:441:        2:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:442:        3:       DE      2021-05-08       Cases   106987       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:443:        4:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:444:        5:       DE      2021-05-08      Deaths     1582       Germany    2021-05-03\ntests/testthat/_snaps/class-forecast.md:445:       ---                                                                          \ntests/testthat/_snaps/class-forecast.md:446:      883:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:447:      884:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:448:      885:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:449:      886:       IT      2021-07-24      Deaths       78         Italy    2021-07-05\ntests/testthat/_snaps/class-forecast.md:450:      887:       IT      2021-07-24      Deaths       78         Italy    2021-07-12\ntests/testthat/_snaps/class-forecast.md:451:           predicted                 model horizon\ntests/testthat/_snaps/class-forecast.md:452:               <int>                <char>   <num>\ntests/testthat/_snaps/class-forecast.md:453:        1:    119258 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:454:        2:    132607 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:455:        3:    151179  epiforecasts-EpiNow2       1\ntests/testthat/_snaps/class-forecast.md:456:        4:      1568 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast.md:457:        5:      1597 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast.md:458:       ---                                        \ntests/testthat/_snaps/class-forecast.md:459:      883:       131 EuroCOVIDhub-baseline       2\ntests/testthat/_snaps/class-forecast.md:460:      884:        79       UMass-MechBayes       3\ntests/testthat/_snaps/class-forecast.md:461:      885:       124       UMass-MechBayes       2\ntests/testthat/_snaps/class-forecast.md:462:      886:       104  epiforecasts-EpiNow2       3\ntests/testthat/_snaps/class-forecast.md:463:      887:       186  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast.md:464:\ntests/testthat/_snaps/class-forecast.md:465:---\ntests/testthat/_snaps/class-forecast.md:466:\ntests/testthat/_snaps/class-forecast.md:467:    Code\ntests/testthat/_snaps/class-forecast.md:468:      print(dat)\ntests/testthat/_snaps/class-forecast.md:469:    Message\ntests/testthat/_snaps/class-forecast.md:470:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:471:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:472:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:473:      and horizon\ntests/testthat/_snaps/class-forecast.md:474:    Output\ntests/testthat/_snaps/class-forecast.md:475:      \ntests/testthat/_snaps/class-forecast.md:476:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:477:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:478:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:479:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:480:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:481:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:482:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:483:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:484:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:485:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:486:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:487:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:488:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:489:                             model horizon    predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:490:                            <char>   <num>        <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:491:          1: EuroCOVIDhub-ensemble       1 102672.00034         1   106987\ntests/testthat/_snaps/class-forecast.md:492:          2: EuroCOVIDhub-ensemble       1 164763.08492         2   106987\ntests/testthat/_snaps/class-forecast.md:493:          3: EuroCOVIDhub-ensemble       1 153042.63536         3   106987\ntests/testthat/_snaps/class-forecast.md:494:          4: EuroCOVIDhub-ensemble       1 119544.25389         4   106987\ntests/testthat/_snaps/class-forecast.md:495:          5: EuroCOVIDhub-ensemble       1  81230.71875         5   106987\ntests/testthat/_snaps/class-forecast.md:496:         ---                                                              \ntests/testthat/_snaps/class-forecast.md:497:      35476:  epiforecasts-EpiNow2       2    159.84534        36       78\ntests/testthat/_snaps/class-forecast.md:498:      35477:  epiforecasts-EpiNow2       2    128.21214        37       78\ntests/testthat/_snaps/class-forecast.md:499:      35478:  epiforecasts-EpiNow2       2    190.52560        38       78\ntests/testthat/_snaps/class-forecast.md:500:      35479:  epiforecasts-EpiNow2       2    141.06659        39       78\ntests/testthat/_snaps/class-forecast.md:501:      35480:  epiforecasts-EpiNow2       2     24.43419        40       78\ntests/testthat/_snaps/class-forecast.md:502:\ntests/testthat/_snaps/class-forecast.md:503:---\ntests/testthat/_snaps/class-forecast.md:504:\ntests/testthat/_snaps/class-forecast.md:505:    Code\ntests/testthat/_snaps/class-forecast.md:506:      print(dat)\ntests/testthat/_snaps/class-forecast.md:507:    Message\ntests/testthat/_snaps/class-forecast.md:508:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:509:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:510:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:511:      and horizon\ntests/testthat/_snaps/class-forecast.md:512:    Output\ntests/testthat/_snaps/class-forecast.md:513:      \ntests/testthat/_snaps/class-forecast.md:514:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:515:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:516:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:517:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:518:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:519:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:520:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:521:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:522:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:523:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:524:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:525:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:526:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:527:                             model horizon    predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:528:                            <char>   <num>        <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:529:          1: EuroCOVIDhub-ensemble       1 102672.00034         1   106987\ntests/testthat/_snaps/class-forecast.md:530:          2: EuroCOVIDhub-ensemble       1 164763.08492         2   106987\ntests/testthat/_snaps/class-forecast.md:531:          3: EuroCOVIDhub-ensemble       1 153042.63536         3   106987\ntests/testthat/_snaps/class-forecast.md:532:          4: EuroCOVIDhub-ensemble       1 119544.25389         4   106987\ntests/testthat/_snaps/class-forecast.md:533:          5: EuroCOVIDhub-ensemble       1  81230.71875         5   106987\ntests/testthat/_snaps/class-forecast.md:534:         ---                                                              \ntests/testthat/_snaps/class-forecast.md:535:      35476:  epiforecasts-EpiNow2       2    159.84534        36       78\ntests/testthat/_snaps/class-forecast.md:536:      35477:  epiforecasts-EpiNow2       2    128.21214        37       78\ntests/testthat/_snaps/class-forecast.md:537:      35478:  epiforecasts-EpiNow2       2    190.52560        38       78\ntests/testthat/_snaps/class-forecast.md:538:      35479:  epiforecasts-EpiNow2       2    141.06659        39       78\ntests/testthat/_snaps/class-forecast.md:539:      35480:  epiforecasts-EpiNow2       2     24.43419        40       78\ntests/testthat/_snaps/class-forecast.md:540:\ntests/testthat/_snaps/class-forecast.md:541:---\ntests/testthat/_snaps/class-forecast.md:542:\ntests/testthat/_snaps/class-forecast.md:543:    Code\ntests/testthat/_snaps/class-forecast.md:544:      print(dat)\ntests/testthat/_snaps/class-forecast.md:545:    Message\ntests/testthat/_snaps/class-forecast.md:546:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:547:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:548:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:549:      and horizon\ntests/testthat/_snaps/class-forecast.md:550:    Output\ntests/testthat/_snaps/class-forecast.md:551:      \ntests/testthat/_snaps/class-forecast.md:552:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:553:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:554:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:555:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:556:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:557:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:558:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:559:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:560:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:561:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:562:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:563:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:564:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:565:                             model horizon    predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:566:                            <char>   <num>        <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:567:          1: EuroCOVIDhub-ensemble       1 102672.00034         1   106987\ntests/testthat/_snaps/class-forecast.md:568:          2: EuroCOVIDhub-ensemble       1 164763.08492         2   106987\ntests/testthat/_snaps/class-forecast.md:569:          3: EuroCOVIDhub-ensemble       1 153042.63536         3   106987\ntests/testthat/_snaps/class-forecast.md:570:          4: EuroCOVIDhub-ensemble       1 119544.25389         4   106987\ntests/testthat/_snaps/class-forecast.md:571:          5: EuroCOVIDhub-ensemble       1  81230.71875         5   106987\ntests/testthat/_snaps/class-forecast.md:572:         ---                                                              \ntests/testthat/_snaps/class-forecast.md:573:      35476:  epiforecasts-EpiNow2       2    159.84534        36       78\ntests/testthat/_snaps/class-forecast.md:574:      35477:  epiforecasts-EpiNow2       2    128.21214        37       78\ntests/testthat/_snaps/class-forecast.md:575:      35478:  epiforecasts-EpiNow2       2    190.52560        38       78\ntests/testthat/_snaps/class-forecast.md:576:      35479:  epiforecasts-EpiNow2       2    141.06659        39       78\ntests/testthat/_snaps/class-forecast.md:577:      35480:  epiforecasts-EpiNow2       2     24.43419        40       78\ntests/testthat/_snaps/class-forecast.md:578:\ntests/testthat/_snaps/class-forecast.md:579:---\ntests/testthat/_snaps/class-forecast.md:580:\ntests/testthat/_snaps/class-forecast.md:581:    Code\ntests/testthat/_snaps/class-forecast.md:582:      print(dat)\ntests/testthat/_snaps/class-forecast.md:583:    Message\ntests/testthat/_snaps/class-forecast.md:584:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:585:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:586:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:587:      and horizon\ntests/testthat/_snaps/class-forecast.md:588:    Output\ntests/testthat/_snaps/class-forecast.md:589:      \ntests/testthat/_snaps/class-forecast.md:590:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:591:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:592:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:593:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:594:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:595:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:596:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:597:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:598:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:599:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:600:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:601:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:602:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:603:                             model horizon    predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:604:                            <char>   <num>        <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:605:          1: EuroCOVIDhub-ensemble       1 102672.00034         1   106987\ntests/testthat/_snaps/class-forecast.md:606:          2: EuroCOVIDhub-ensemble       1 164763.08492         2   106987\ntests/testthat/_snaps/class-forecast.md:607:          3: EuroCOVIDhub-ensemble       1 153042.63536         3   106987\ntests/testthat/_snaps/class-forecast.md:608:          4: EuroCOVIDhub-ensemble       1 119544.25389         4   106987\ntests/testthat/_snaps/class-forecast.md:609:          5: EuroCOVIDhub-ensemble       1  81230.71875         5   106987\ntests/testthat/_snaps/class-forecast.md:610:         ---                                                              \ntests/testthat/_snaps/class-forecast.md:611:      35476:  epiforecasts-EpiNow2       2    159.84534        36       78\ntests/testthat/_snaps/class-forecast.md:612:      35477:  epiforecasts-EpiNow2       2    128.21214        37       78\ntests/testthat/_snaps/class-forecast.md:613:      35478:  epiforecasts-EpiNow2       2    190.52560        38       78\ntests/testthat/_snaps/class-forecast.md:614:      35479:  epiforecasts-EpiNow2       2    141.06659        39       78\ntests/testthat/_snaps/class-forecast.md:615:      35480:  epiforecasts-EpiNow2       2     24.43419        40       78\ntests/testthat/_snaps/class-forecast.md:616:\ntests/testthat/_snaps/class-forecast.md:617:---\ntests/testthat/_snaps/class-forecast.md:618:\ntests/testthat/_snaps/class-forecast.md:619:    Code\ntests/testthat/_snaps/class-forecast.md:620:      print(dat)\ntests/testthat/_snaps/class-forecast.md:621:    Message\ntests/testthat/_snaps/class-forecast.md:622:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:623:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:624:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:625:      and horizon\ntests/testthat/_snaps/class-forecast.md:626:    Output\ntests/testthat/_snaps/class-forecast.md:627:      \ntests/testthat/_snaps/class-forecast.md:628:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:629:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:630:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:631:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:632:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:633:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:634:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:635:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:636:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:637:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:638:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:639:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:640:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:641:                             model horizon predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:642:                            <char>   <num>     <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:643:          1: EuroCOVIDhub-ensemble       1    102672         1   106987\ntests/testthat/_snaps/class-forecast.md:644:          2: EuroCOVIDhub-ensemble       1    164763         2   106987\ntests/testthat/_snaps/class-forecast.md:645:          3: EuroCOVIDhub-ensemble       1    153043         3   106987\ntests/testthat/_snaps/class-forecast.md:646:          4: EuroCOVIDhub-ensemble       1    119544         4   106987\ntests/testthat/_snaps/class-forecast.md:647:          5: EuroCOVIDhub-ensemble       1     81231         5   106987\ntests/testthat/_snaps/class-forecast.md:648:         ---                                                           \ntests/testthat/_snaps/class-forecast.md:649:      35476:  epiforecasts-EpiNow2       2       160        36       78\ntests/testthat/_snaps/class-forecast.md:650:      35477:  epiforecasts-EpiNow2       2       128        37       78\ntests/testthat/_snaps/class-forecast.md:651:      35478:  epiforecasts-EpiNow2       2       191        38       78\ntests/testthat/_snaps/class-forecast.md:652:      35479:  epiforecasts-EpiNow2       2       141        39       78\ntests/testthat/_snaps/class-forecast.md:653:      35480:  epiforecasts-EpiNow2       2        24        40       78\ntests/testthat/_snaps/class-forecast.md:654:\ntests/testthat/_snaps/class-forecast.md:655:---\ntests/testthat/_snaps/class-forecast.md:656:\ntests/testthat/_snaps/class-forecast.md:657:    Code\ntests/testthat/_snaps/class-forecast.md:658:      print(dat)\ntests/testthat/_snaps/class-forecast.md:659:    Message\ntests/testthat/_snaps/class-forecast.md:660:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:661:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:662:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:663:      and horizon\ntests/testthat/_snaps/class-forecast.md:664:    Output\ntests/testthat/_snaps/class-forecast.md:665:      \ntests/testthat/_snaps/class-forecast.md:666:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:667:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:668:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:669:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:670:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:671:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:672:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:673:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:674:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:675:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:676:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:677:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:678:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:679:                             model horizon predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:680:                            <char>   <num>     <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:681:          1: EuroCOVIDhub-ensemble       1    102672         1   106987\ntests/testthat/_snaps/class-forecast.md:682:          2: EuroCOVIDhub-ensemble       1    164763         2   106987\ntests/testthat/_snaps/class-forecast.md:683:          3: EuroCOVIDhub-ensemble       1    153043         3   106987\ntests/testthat/_snaps/class-forecast.md:684:          4: EuroCOVIDhub-ensemble       1    119544         4   106987\ntests/testthat/_snaps/class-forecast.md:685:          5: EuroCOVIDhub-ensemble       1     81231         5   106987\ntests/testthat/_snaps/class-forecast.md:686:         ---                                                           \ntests/testthat/_snaps/class-forecast.md:687:      35476:  epiforecasts-EpiNow2       2       160        36       78\ntests/testthat/_snaps/class-forecast.md:688:      35477:  epiforecasts-EpiNow2       2       128        37       78\ntests/testthat/_snaps/class-forecast.md:689:      35478:  epiforecasts-EpiNow2       2       191        38       78\ntests/testthat/_snaps/class-forecast.md:690:      35479:  epiforecasts-EpiNow2       2       141        39       78\ntests/testthat/_snaps/class-forecast.md:691:      35480:  epiforecasts-EpiNow2       2        24        40       78\ntests/testthat/_snaps/class-forecast.md:692:\ntests/testthat/_snaps/class-forecast.md:693:---\ntests/testthat/_snaps/class-forecast.md:694:\ntests/testthat/_snaps/class-forecast.md:695:    Code\ntests/testthat/_snaps/class-forecast.md:696:      print(dat)\ntests/testthat/_snaps/class-forecast.md:697:    Message\ntests/testthat/_snaps/class-forecast.md:698:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:699:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:700:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:701:      and horizon\ntests/testthat/_snaps/class-forecast.md:702:    Output\ntests/testthat/_snaps/class-forecast.md:703:      \ntests/testthat/_snaps/class-forecast.md:704:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:705:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:706:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:707:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:708:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:709:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:710:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:711:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:712:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:713:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:714:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:715:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:716:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:717:                             model horizon predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:718:                            <char>   <num>     <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:719:          1: EuroCOVIDhub-ensemble       1    102672         1   106987\ntests/testthat/_snaps/class-forecast.md:720:          2: EuroCOVIDhub-ensemble       1    164763         2   106987\ntests/testthat/_snaps/class-forecast.md:721:          3: EuroCOVIDhub-ensemble       1    153043         3   106987\ntests/testthat/_snaps/class-forecast.md:722:          4: EuroCOVIDhub-ensemble       1    119544         4   106987\ntests/testthat/_snaps/class-forecast.md:723:          5: EuroCOVIDhub-ensemble       1     81231         5   106987\ntests/testthat/_snaps/class-forecast.md:724:         ---                                                           \ntests/testthat/_snaps/class-forecast.md:725:      35476:  epiforecasts-EpiNow2       2       160        36       78\ntests/testthat/_snaps/class-forecast.md:726:      35477:  epiforecasts-EpiNow2       2       128        37       78\ntests/testthat/_snaps/class-forecast.md:727:      35478:  epiforecasts-EpiNow2       2       191        38       78\ntests/testthat/_snaps/class-forecast.md:728:      35479:  epiforecasts-EpiNow2       2       141        39       78\ntests/testthat/_snaps/class-forecast.md:729:      35480:  epiforecasts-EpiNow2       2        24        40       78\ntests/testthat/_snaps/class-forecast.md:730:\ntests/testthat/_snaps/class-forecast.md:731:---\ntests/testthat/_snaps/class-forecast.md:732:\ntests/testthat/_snaps/class-forecast.md:733:    Code\ntests/testthat/_snaps/class-forecast.md:734:      print(dat)\ntests/testthat/_snaps/class-forecast.md:735:    Message\ntests/testthat/_snaps/class-forecast.md:736:      Forecast type: sample\ntests/testthat/_snaps/class-forecast.md:737:      Forecast unit:\ntests/testthat/_snaps/class-forecast.md:738:      location, location_name, target_end_date, target_type, forecast_date, model,\ntests/testthat/_snaps/class-forecast.md:739:      and horizon\ntests/testthat/_snaps/class-forecast.md:740:    Output\ntests/testthat/_snaps/class-forecast.md:741:      \ntests/testthat/_snaps/class-forecast.md:742:             location location_name target_end_date target_type forecast_date\ntests/testthat/_snaps/class-forecast.md:743:               <char>        <char>          <Date>      <char>        <Date>\ntests/testthat/_snaps/class-forecast.md:744:          1:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:745:          2:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:746:          3:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:747:          4:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:748:          5:       DE       Germany      2021-05-08       Cases    2021-05-03\ntests/testthat/_snaps/class-forecast.md:749:         ---                                                                 \ntests/testthat/_snaps/class-forecast.md:750:      35476:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:751:      35477:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:752:      35478:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:753:      35479:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:754:      35480:       IT         Italy      2021-07-24      Deaths    2021-07-12\ntests/testthat/_snaps/class-forecast.md:755:                             model horizon predicted sample_id observed\ntests/testthat/_snaps/class-forecast.md:756:                            <char>   <num>     <num>     <int>    <num>\ntests/testthat/_snaps/class-forecast.md:757:          1: EuroCOVIDhub-ensemble       1    102672         1   106987\ntests/testthat/_snaps/class-forecast.md:758:          2: EuroCOVIDhub-ensemble       1    164763         2   106987\ntests/testthat/_snaps/class-forecast.md:759:          3: EuroCOVIDhub-ensemble       1    153043         3   106987\ntests/testthat/_snaps/class-forecast.md:760:          4: EuroCOVIDhub-ensemble       1    119544         4   106987\ntests/testthat/_snaps/class-forecast.md:761:          5: EuroCOVIDhub-ensemble       1     81231         5   106987\ntests/testthat/_snaps/class-forecast.md:762:         ---                                                           \ntests/testthat/_snaps/class-forecast.md:763:      35476:  epiforecasts-EpiNow2       2       160        36       78\ntests/testthat/_snaps/class-forecast.md:764:      35477:  epiforecasts-EpiNow2       2       128        37       78\ntests/testthat/_snaps/class-forecast.md:765:      35478:  epiforecasts-EpiNow2       2       191        38       78\ntests/testthat/_snaps/class-forecast.md:766:      35479:  epiforecasts-EpiNow2       2       141        39       78\ntests/testthat/_snaps/class-forecast.md:767:      35480:  epiforecasts-EpiNow2       2        24        40       78\ntests/testthat/_snaps/class-forecast.md:768:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:1:# as_forecast_multivariate_sample() creates expected structure\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:2:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:3:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:4:      print(result)\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:5:    Message\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:6:      Forecast type: sample_multivariate\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:7:      Forecast unit:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:8:      location, model, target_type, target_end_date, and horizon\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:9:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:10:      \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:11:                predicted sample_id observed location                 model\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:12:                    <num>     <int>    <num>   <char>                <char>\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:13:          1: 102672.00034         1   106987       DE EuroCOVIDhub-ensemble\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:14:          2: 164763.08492         2   106987       DE EuroCOVIDhub-ensemble\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:15:          3: 153042.63536         3   106987       DE EuroCOVIDhub-ensemble\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:16:          4: 119544.25389         4   106987       DE EuroCOVIDhub-ensemble\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:17:          5:  81230.71875         5   106987       DE EuroCOVIDhub-ensemble\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:18:         ---                                                               \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:19:      35476:    159.84534        36       78       IT  epiforecasts-EpiNow2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:20:      35477:    128.21214        37       78       IT  epiforecasts-EpiNow2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:21:      35478:    190.52560        38       78       IT  epiforecasts-EpiNow2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:22:      35479:    141.06659        39       78       IT  epiforecasts-EpiNow2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:23:      35480:     24.43419        40       78       IT  epiforecasts-EpiNow2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:24:             target_type target_end_date horizon .mv_group_id\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:25:                  <char>          <Date>   <num>        <int>\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:26:          1:       Cases      2021-05-08       1            1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:27:          2:       Cases      2021-05-08       1            1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:28:          3:       Cases      2021-05-08       1            1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:29:          4:       Cases      2021-05-08       1            1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:30:          5:       Cases      2021-05-08       1            1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:31:         ---                                                 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:32:      35476:      Deaths      2021-07-24       2          224\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:33:      35477:      Deaths      2021-07-24       2          224\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:34:      35478:      Deaths      2021-07-24       2          224\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:35:      35479:      Deaths      2021-07-24       2          224\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:36:      35480:      Deaths      2021-07-24       2          224\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:37:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:38:---\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:39:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:40:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:41:      cat(\"Class:\", class(result), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:42:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:43:      Class: forecast_sample_multivariate forecast data.table data.frame \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:44:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:45:      cat(\"Forecast type:\", scoringutils:::get_forecast_type(result), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:46:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:47:      Forecast type: sample_multivariate \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:48:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:49:      cat(\"Forecast unit:\", toString(get_forecast_unit(result)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:50:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:51:      Forecast unit: location, model, target_type, target_end_date, horizon \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:52:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:53:      cat(\"Number of rows:\", nrow(result), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:54:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:55:      Number of rows: 35480 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:56:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:57:      cat(\"Number of columns:\", ncol(result), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:58:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:59:      Number of columns: 9 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:60:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:61:      cat(\"Column names:\", toString(names(result)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:62:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:63:      Column names: predicted, sample_id, observed, location, model, target_type, target_end_date, horizon, .mv_group_id \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:64:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:65:      cat(\"Number of unique groups:\", length(unique(result$.mv_group_id)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:66:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:67:      Number of unique groups: 224 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:68:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:69:# score.forecast_sample_multivariate() creates expected output structure\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:70:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:71:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:72:      print(scores)\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:73:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:74:           target_end_date target_type forecast_date                 model horizon\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:75:                    <Date>      <char>        <Date>                <char>   <num>\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:76:        1:      2021-05-08       Cases    2021-05-03 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:77:        2:      2021-05-08       Cases    2021-05-03 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:78:        3:      2021-05-08       Cases    2021-05-03  epiforecasts-EpiNow2       1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:79:        4:      2021-05-08      Deaths    2021-05-03 EuroCOVIDhub-ensemble       1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:80:        5:      2021-05-08      Deaths    2021-05-03 EuroCOVIDhub-baseline       1\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:81:       ---                                                                        \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:82:      220:      2021-07-24      Deaths    2021-07-12 EuroCOVIDhub-baseline       2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:83:      221:      2021-07-24      Deaths    2021-07-05       UMass-MechBayes       3\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:84:      222:      2021-07-24      Deaths    2021-07-12       UMass-MechBayes       2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:85:      223:      2021-07-24      Deaths    2021-07-05  epiforecasts-EpiNow2       3\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:86:      224:      2021-07-24      Deaths    2021-07-12  epiforecasts-EpiNow2       2\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:87:           energy_score .mv_group_id\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:88:                  <num>        <int>\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:89:        1:   23454.2838           37\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:90:        2:   34263.4665           38\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:91:        3:   67609.0941           39\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:92:        4:     138.9681           40\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:93:        5:     401.5740           41\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:94:       ---                          \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:95:      220:     275.4460          256\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:96:      221:     142.7219          257\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:97:      222:      96.7978          258\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:98:      223:     142.3382          259\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:99:      224:     137.3695          260\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:100:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:101:---\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:102:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:103:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:104:      cat(\"Class:\", class(scores), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:105:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:106:      Class: scores data.table data.frame \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:107:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:108:      cat(\"Number of rows:\", nrow(scores), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:109:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:110:      Number of rows: 224 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:111:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:112:      cat(\"Number of columns:\", ncol(scores), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:113:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:114:      Number of columns: 7 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:115:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:116:      cat(\"Column names:\", toString(names(scores)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:117:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:118:      Column names: target_end_date, target_type, forecast_date, model, horizon, energy_score, .mv_group_id \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:119:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:120:      cat(\"Energy score range:\", paste(range(scores$energy_score, na.rm = TRUE),\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:121:      collapse = \" to \"), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:122:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:123:      Energy score range: 37.8373892350605 to 433525.521054322 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:124:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:125:      cat(\"Number of non-NA energy scores:\", sum(!is.na(scores$energy_score)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:126:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:127:      Number of non-NA energy scores: 224 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:128:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:129:      cat(\"Sample of energy scores:\", toString(head(scores$energy_score, 5)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:130:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:131:      Sample of energy scores: 23454.2837522622, 34263.4664789642, 67609.0941230609, 138.968094149042, 401.574009570395 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:132:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:133:---\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:134:\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:135:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:136:      cat(\"=== Specific Metrics Test ===\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:137:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:138:      === Specific Metrics Test ===\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:139:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:140:      cat(\"Class:\", class(scores_specific), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:141:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:142:      Class: scores data.table data.frame \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:143:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:144:      cat(\"Number of rows:\", nrow(scores_specific), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:145:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:146:      Number of rows: 224 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:147:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:148:      cat(\"Number of columns:\", ncol(scores_specific), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:149:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:150:      Number of columns: 7 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:151:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:152:      cat(\"Column names:\", toString(names(scores_specific)), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:153:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:154:      Column names: target_end_date, target_type, forecast_date, model, horizon, energy_score, .mv_group_id \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:155:    Code\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:156:      cat(\"Energy score range:\", paste(range(scores_specific$energy_score, na.rm = TRUE),\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:157:      collapse = \" to \"), \"\\n\")\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:158:    Output\ntests/testthat/_snaps/class-forecast-multivariate-sample.md:159:      Energy score range: 37.8373892350605 to 433525.521054322 \ntests/testthat/_snaps/class-forecast-multivariate-sample.md:160:\ntests/testthat/_snaps/plot_wis/plot-wis.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:3:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/plot_wis/plot-wis.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/plot_wis/plot-wis.svg:6:      fill: none;\ntests/testthat/_snaps/plot_wis/plot-wis.svg:7:      stroke: #000000;\ntests/testthat/_snaps/plot_wis/plot-wis.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/plot_wis/plot-wis.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/plot_wis/plot-wis.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/plot_wis/plot-wis.svg:11:    }\ntests/testthat/_snaps/plot_wis/plot-wis.svg:12:  ]]></style>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:13:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:15:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:18:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:19:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:22:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:23:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:24:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwzOS40M3w1MDMuMTc='>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:25:    <rect x='127.99' y='39.43' width='290.52' height='463.74' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:26:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:27:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:28:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwzOS40M3w1MDMuMTc=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:29:<rect x='257.49' y='276.83' width='147.82' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:30:<rect x='274.60' y='387.24' width='130.71' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:31:<rect x='254.35' y='56.00' width='150.96' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:32:<rect x='195.12' y='276.83' width='62.37' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:33:<rect x='179.24' y='387.24' width='95.37' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:34:<rect x='213.01' y='56.00' width='41.34' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:35:<rect x='141.20' y='276.83' width='53.92' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:36:<rect x='141.20' y='387.24' width='38.04' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:37:<rect x='141.20' y='56.00' width='71.82' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:38:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:39:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:40:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:41:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:42:  <clipPath id='cpNDI0LjAwfDcxNC41MnwzOS40M3w1MDMuMTc='>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:43:    <rect x='424.00' y='39.43' width='290.52' height='463.74' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:44:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:45:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:46:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwzOS40M3w1MDMuMTc=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:47:<rect x='655.80' y='276.83' width='45.51' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:48:<rect x='592.13' y='387.24' width='109.19' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:49:<rect x='656.28' y='166.41' width='45.04' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:50:<rect x='626.44' y='56.00' width='74.87' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:51:<rect x='629.64' y='276.83' width='26.16' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:52:<rect x='588.65' y='387.24' width='3.48' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:53:<rect x='572.00' y='166.41' width='84.28' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:54:<rect x='563.45' y='56.00' width='62.99' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:55:<rect x='437.20' y='276.83' width='192.44' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:56:<rect x='437.20' y='387.24' width='151.45' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:57:<rect x='437.20' y='166.41' width='134.80' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:58:<rect x='437.20' y='56.00' width='126.25' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:59:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:60:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:61:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:62:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:63:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:64:    <rect x='127.99' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:65:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:66:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:67:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:68:<text x='273.25' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:69:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:70:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:71:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:72:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:73:  <clipPath id='cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:74:    <rect x='424.00' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:75:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:76:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:77:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:78:<text x='569.26' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:79:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:80:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:81:<polyline points='127.99,503.17 418.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:82:<polyline points='141.20,505.91 141.20,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:83:<polyline points='207.23,505.91 207.23,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:84:<polyline points='273.25,505.91 273.25,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:85:<polyline points='339.28,505.91 339.28,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:86:<polyline points='405.31,505.91 405.31,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:87:<text x='141.20' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:88:<text x='207.23' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.25</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:89:<text x='273.25' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.50</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:90:<text x='339.28' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.75</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:91:<text x='405.31' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>1.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:92:<polyline points='424.00,503.17 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:93:<polyline points='437.20,505.91 437.20,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:94:<polyline points='503.23,505.91 503.23,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:95:<polyline points='569.26,505.91 569.26,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:96:<polyline points='635.29,505.91 635.29,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:97:<polyline points='701.31,505.91 701.31,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:98:<text x='437.20' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:99:<text x='503.23' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.25</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:100:<text x='569.26' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.50</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:101:<text x='635.29' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.75</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:102:<text x='701.31' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>1.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:103:<polyline points='127.99,503.17 127.99,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:104:<text x='120.32' y='439.95' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:105:<text x='120.32' y='329.54' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:106:<text x='120.32' y='219.13' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:107:<text x='120.32' y='108.71' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:108:<polyline points='125.25,436.93 127.99,436.93 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:109:<polyline points='125.25,326.51 127.99,326.51 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:110:<polyline points='125.25,216.10 127.99,216.10 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:111:<polyline points='125.25,105.68 127.99,105.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:112:<text x='421.26' y='529.04' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='86.21px' lengthAdjust='spacingAndGlyphs'>WIS contributions</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:113:<text transform='translate(13.05,271.30) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:114:<text x='261.73' y='560.19' style='font-size: 11.00px; font-family: sans;' textLength='78.27px' lengthAdjust='spacingAndGlyphs'>WIS component</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:115:<rect x='346.19' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:116:<rect x='429.71' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:117:<rect x='518.61' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis.svg:118:<text x='368.24' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='55.28px' lengthAdjust='spacingAndGlyphs'>overprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:119:<text x='451.76' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='60.67px' lengthAdjust='spacingAndGlyphs'>underprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:120:<text x='540.66' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='40.12px' lengthAdjust='spacingAndGlyphs'>dispersion</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:121:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='47.69px' lengthAdjust='spacingAndGlyphs'>plot_wis</text>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:122:</g>\ntests/testthat/_snaps/plot_wis/plot-wis.svg:123:</svg>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:3:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:6:      fill: none;\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:7:      stroke: #000000;\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:11:    }\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:12:  ]]></style>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:13:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:15:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:18:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:19:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:22:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:23:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:24:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwzOS40M3w1MDMuMTc='>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:25:    <rect x='127.99' y='39.43' width='290.52' height='463.74' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:26:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:27:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:28:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwzOS40M3w1MDMuMTc=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:29:<rect x='214.46' y='276.83' width='93.12' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:30:<rect x='274.60' y='387.24' width='130.71' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:31:<rect x='223.95' y='56.00' width='110.41' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:32:<rect x='175.17' y='276.83' width='39.29' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:33:<rect x='179.24' y='387.24' width='95.37' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:34:<rect x='193.72' y='56.00' width='30.23' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:35:<rect x='141.20' y='276.83' width='33.97' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:36:<rect x='141.20' y='387.24' width='38.04' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:37:<rect x='141.20' y='56.00' width='52.52' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:38:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:39:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:40:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:41:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:42:  <clipPath id='cpNDI0LjAwfDcxNC41MnwzOS40M3w1MDMuMTc='>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:43:    <rect x='424.00' y='39.43' width='290.52' height='463.74' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:44:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:45:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:46:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwzOS40M3w1MDMuMTc=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:47:<rect x='437.52' y='276.83' width='0.066' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:48:<rect x='438.07' y='387.24' width='0.61' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:49:<rect x='437.61' y='166.41' width='0.083' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:50:<rect x='437.64' y='56.00' width='0.18' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:51:<rect x='437.48' y='276.83' width='0.038' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:52:<rect x='438.05' y='387.24' width='0.019' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:53:<rect x='437.45' y='166.41' width='0.16' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:54:<rect x='437.50' y='56.00' width='0.15' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:55:<rect x='437.20' y='276.83' width='0.28' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:56:<rect x='437.20' y='387.24' width='0.85' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:57:<rect x='437.20' y='166.41' width='0.25' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:58:<rect x='437.20' y='56.00' width='0.30' height='99.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:59:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:60:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:61:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:62:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:63:  <clipPath id='cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:64:    <rect x='127.99' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:65:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:66:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:67:<g clip-path='url(#cpMTI3Ljk5fDQxOC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:68:<text x='273.25' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:69:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:70:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:71:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:72:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:73:  <clipPath id='cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:74:    <rect x='424.00' y='22.78' width='290.52' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:75:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:76:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:77:<g clip-path='url(#cpNDI0LjAwfDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:78:<text x='569.26' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:79:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:80:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:81:<polyline points='127.99,503.17 418.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:82:<polyline points='141.20,505.91 141.20,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:83:<polyline points='233.92,505.91 233.92,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:84:<polyline points='326.65,505.91 326.65,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:85:<text x='141.20' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:86:<text x='233.92' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='24.47px' lengthAdjust='spacingAndGlyphs'>10000</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:87:<text x='326.65' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='24.47px' lengthAdjust='spacingAndGlyphs'>20000</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:88:<polyline points='424.00,503.17 714.52,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:89:<polyline points='437.20,505.91 437.20,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:90:<polyline points='529.93,505.91 529.93,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:91:<polyline points='622.65,505.91 622.65,503.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:92:<text x='437.20' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='4.89px' lengthAdjust='spacingAndGlyphs'>0</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:93:<text x='529.93' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='24.47px' lengthAdjust='spacingAndGlyphs'>10000</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:94:<text x='622.65' y='516.90' text-anchor='middle' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='24.47px' lengthAdjust='spacingAndGlyphs'>20000</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:95:<polyline points='127.99,503.17 127.99,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:96:<text x='120.32' y='439.95' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:97:<text x='120.32' y='329.54' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:98:<text x='120.32' y='219.13' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:99:<text x='120.32' y='108.71' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:100:<polyline points='125.25,436.93 127.99,436.93 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:101:<polyline points='125.25,326.51 127.99,326.51 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:102:<polyline points='125.25,216.10 127.99,216.10 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:103:<polyline points='125.25,105.68 127.99,105.68 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:104:<text x='421.26' y='529.04' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='86.21px' lengthAdjust='spacingAndGlyphs'>WIS contributions</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:105:<text transform='translate(13.05,271.30) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:106:<text x='261.73' y='560.19' style='font-size: 11.00px; font-family: sans;' textLength='78.27px' lengthAdjust='spacingAndGlyphs'>WIS component</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:107:<rect x='346.19' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:108:<rect x='429.71' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:109:<rect x='518.61' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:110:<text x='368.24' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='55.28px' lengthAdjust='spacingAndGlyphs'>overprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:111:<text x='451.76' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='60.67px' lengthAdjust='spacingAndGlyphs'>underprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:112:<text x='540.66' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='40.12px' lengthAdjust='spacingAndGlyphs'>dispersion</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:113:<text x='127.99' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='119.62px' lengthAdjust='spacingAndGlyphs'>plot_wis_no_relative</text>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:114:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-no-relative.svg:115:</svg>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:1:<?xml version='1.0' encoding='UTF-8' ?>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:2:<svg xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink' class='svglite' data-engine-version='2.0' width='720.00pt' height='576.00pt' viewBox='0 0 720.00 576.00'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:3:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:4:  <style type='text/css'><![CDATA[\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:5:    .svglite line, .svglite polyline, .svglite polygon, .svglite path, .svglite rect, .svglite circle {\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:6:      fill: none;\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:7:      stroke: #000000;\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:8:      stroke-linecap: round;\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:9:      stroke-linejoin: round;\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:10:      stroke-miterlimit: 10.00;\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:11:    }\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:12:  ]]></style>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:13:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:14:<rect width='100%' height='100%' style='stroke: none; fill: #FFFFFF;'/>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:15:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:16:  <clipPath id='cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA='>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:17:    <rect x='0.00' y='0.00' width='720.00' height='576.00' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:18:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:19:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:20:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:21:<rect x='0.00' y='0.00' width='720.00' height='576.00' style='stroke-width: 1.07; stroke: none; fill: #FFFFFF;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:22:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:23:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:24:  <clipPath id='cpNDIuODd8MzczLjAzfDM5LjQzfDQwOC44MQ=='>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:25:    <rect x='42.87' y='39.43' width='330.15' height='369.38' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:26:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:27:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:28:<g clip-path='url(#cpNDIuODd8MzczLjAzfDM5LjQzfDQwOC44MQ==)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:29:<rect x='133.27' y='56.22' width='70.75' height='187.95' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:30:<rect x='54.66' y='56.22' width='70.75' height='166.18' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:31:<rect x='290.49' y='56.22' width='70.75' height='191.93' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:32:<rect x='133.27' y='244.17' width='70.75' height='79.29' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:33:<rect x='54.66' y='222.40' width='70.75' height='121.25' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:34:<rect x='290.49' y='248.16' width='70.75' height='52.56' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:35:<rect x='133.27' y='323.46' width='70.75' height='68.56' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:36:<rect x='54.66' y='343.66' width='70.75' height='48.37' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:37:<rect x='290.49' y='300.71' width='70.75' height='91.31' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:38:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:39:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:40:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:41:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:42:  <clipPath id='cpMzg0LjM3fDcxNC41MnwzOS40M3w0MDguODE='>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:43:    <rect x='384.37' y='39.43' width='330.15' height='369.38' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:44:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:45:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:46:<g clip-path='url(#cpMzg0LjM3fDcxNC41MnwzOS40M3w0MDguODE=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:47:<rect x='474.77' y='56.22' width='70.75' height='57.87' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:48:<rect x='396.16' y='56.22' width='70.75' height='138.82' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:49:<rect x='553.37' y='56.22' width='70.75' height='57.26' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:50:<rect x='631.98' y='56.22' width='70.75' height='95.20' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:51:<rect x='474.77' y='114.09' width='70.75' height='33.26' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:52:<rect x='396.16' y='195.05' width='70.75' height='4.42' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:53:<rect x='553.37' y='113.49' width='70.75' height='107.15' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:54:<rect x='631.98' y='151.42' width='70.75' height='80.08' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:55:<rect x='474.77' y='147.35' width='70.75' height='244.67' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:56:<rect x='396.16' y='199.47' width='70.75' height='192.55' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:57:<rect x='553.37' y='220.64' width='70.75' height='171.38' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:58:<rect x='631.98' y='231.50' width='70.75' height='160.52' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:59:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:60:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:61:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:62:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:63:  <clipPath id='cpNDIuODd8MzczLjAzfDIyLjc4fDM5LjQz'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:64:    <rect x='42.87' y='22.78' width='330.15' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:65:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:66:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:67:<g clip-path='url(#cpNDIuODd8MzczLjAzfDIyLjc4fDM5LjQz)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:68:<text x='207.95' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='24.95px' lengthAdjust='spacingAndGlyphs'>Cases</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:69:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:70:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:71:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:72:<defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:73:  <clipPath id='cpMzg0LjM3fDcxNC41MnwyMi43OHwzOS40Mw=='>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:74:    <rect x='384.37' y='22.78' width='330.15' height='16.65' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:75:  </clipPath>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:76:</defs>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:77:<g clip-path='url(#cpMzg0LjM3fDcxNC41MnwyMi43OHwzOS40Mw==)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:78:<text x='549.44' y='34.14' text-anchor='middle' style='font-size: 8.80px; fill: #1A1A1A; font-family: sans;' textLength='27.89px' lengthAdjust='spacingAndGlyphs'>Deaths</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:79:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:80:<g clip-path='url(#cpMC4wMHw3MjAuMDB8MC4wMHw1NzYuMDA=)'>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:81:<polyline points='42.87,408.81 373.03,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:82:<polyline points='90.04,411.55 90.04,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:83:<polyline points='168.65,411.55 168.65,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:84:<polyline points='247.25,411.55 247.25,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:85:<polyline points='325.86,411.55 325.86,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:86:<text transform='translate(96.09,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:87:<text transform='translate(174.70,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:88:<text transform='translate(253.31,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:89:<text transform='translate(331.92,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:90:<polyline points='384.37,408.81 714.52,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:91:<polyline points='431.53,411.55 431.53,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:92:<polyline points='510.14,411.55 510.14,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:93:<polyline points='588.75,411.55 588.75,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:94:<polyline points='667.36,411.55 667.36,408.81 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:95:<text transform='translate(437.59,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='96.87px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-baseline</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:96:<text transform='translate(516.20,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='102.25px' lengthAdjust='spacingAndGlyphs'>EuroCOVIDhub-ensemble</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:97:<text transform='translate(594.80,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='76.32px' lengthAdjust='spacingAndGlyphs'>UMass-MechBayes</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:98:<text transform='translate(673.41,416.48) rotate(-90)' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='85.61px' lengthAdjust='spacingAndGlyphs'>epiforecasts-EpiNow2</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:99:<polyline points='42.87,408.81 42.87,39.43 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:100:<text x='35.20' y='395.05' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:101:<text x='35.20' y='311.10' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.25</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:102:<text x='35.20' y='227.15' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.50</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:103:<text x='35.20' y='143.20' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>0.75</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:104:<text x='35.20' y='59.25' text-anchor='end' style='font-size: 8.80px; fill: #4D4D4D; font-family: sans;' textLength='17.13px' lengthAdjust='spacingAndGlyphs'>1.00</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:105:<polyline points='40.13,392.02 42.87,392.02 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:106:<polyline points='40.13,308.07 42.87,308.07 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:107:<polyline points='40.13,224.12 42.87,224.12 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:108:<polyline points='40.13,140.17 42.87,140.17 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:109:<polyline points='40.13,56.22 42.87,56.22 ' style='stroke-width: 1.07; stroke: #CCCCCC; stroke-linecap: butt;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:110:<text x='378.70' y='529.04' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='29.96px' lengthAdjust='spacingAndGlyphs'>model</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:111:<text transform='translate(13.05,224.12) rotate(-90)' text-anchor='middle' style='font-size: 11.00px; font-family: sans;' textLength='86.21px' lengthAdjust='spacingAndGlyphs'>WIS contributions</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:112:<text x='219.17' y='560.19' style='font-size: 11.00px; font-family: sans;' textLength='78.27px' lengthAdjust='spacingAndGlyphs'>WIS component</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:113:<rect x='303.63' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #DF536B;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:114:<rect x='387.15' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #61D04F;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:115:<rect x='476.05' y='548.47' width='15.86' height='15.86' style='stroke-width: 1.07; stroke: none; stroke-linecap: butt; stroke-linejoin: miter; fill: #2297E6;' />\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:116:<text x='325.68' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='55.28px' lengthAdjust='spacingAndGlyphs'>overprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:117:<text x='409.20' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='60.67px' lengthAdjust='spacingAndGlyphs'>underprediction</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:118:<text x='498.11' y='559.43' style='font-size: 8.80px; font-family: sans;' textLength='40.12px' lengthAdjust='spacingAndGlyphs'>dispersion</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:119:<text x='42.87' y='14.56' style='font-size: 13.20px; font-family: sans;' textLength='71.91px' lengthAdjust='spacingAndGlyphs'>plot_wis_flip</text>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:120:</g>\ntests/testthat/_snaps/plot_wis/plot-wis-flip.svg:121:</svg>","numLines":7741}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EpzRKrDsHqGNzuojxTprZz","type":"message","role":"assistant","content":[{"type":"text","text":"There are no existing tests for documentation structure in this project. Let me look more carefully at what the fix entails and what could be tested. Let me check the `.Rd` files to understand the current state of the documentation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1001,"cache_read_input_tokens":52136,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1001},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d2ff8582-72dd-495e-a86b-5c3609ea7573"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EpzRKrDsHqGNzuojxTprZz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YLuWKt7vVmsB7wsNSY8pZm","name":"Glob","input":{"pattern":"man/as_forecast_quantile*.Rd","path":"/Users/nikos/github-synced/scoringutils-pipeline"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1001,"cache_read_input_tokens":52136,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1001},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"5c745f60-743c-466c-a252-03eb8286740e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YLuWKt7vVmsB7wsNSY8pZm","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_quantile.Rd"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"ebfc659d-8a91-47e2-b375-b04d803fdc06","tool_use_result":{"filenames":["/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_quantile.Rd"],"durationMs":313,"numFiles":1,"truncated":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EpzRKrDsHqGNzuojxTprZz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017C3v7LprxQZFjL3WR54nhw","name":"Glob","input":{"pattern":"man/as_forecast_point*.Rd","path":"/Users/nikos/github-synced/scoringutils-pipeline"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1001,"cache_read_input_tokens":52136,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1001},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6856f4dd-9c76-4d3b-b6a5-80ce7d863a7a"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017C3v7LprxQZFjL3WR54nhw","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_point.Rd"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2003d935-c48b-4e53-bf92-43e8d91d47b6","tool_use_result":{"filenames":["/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_point.Rd"],"durationMs":279,"numFiles":1,"truncated":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EpzRKrDsHqGNzuojxTprZz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JCWDDJsAT68yAZNepF9oyK","name":"Glob","input":{"pattern":"man/get_pit_histogram*.Rd","path":"/Users/nikos/github-synced/scoringutils-pipeline"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1001,"cache_read_input_tokens":52136,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1001},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"b620d6b7-89e1-4fe8-806b-303fc14e6f25"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JCWDDJsAT68yAZNepF9oyK","type":"tool_result","content":"/Users/nikos/github-synced/scoringutils-pipeline/man/get_pit_histogram.Rd"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"18b809a4-a691-428c-8536-a93dca2e4e53","tool_use_result":{"filenames":["/Users/nikos/github-synced/scoringutils-pipeline/man/get_pit_histogram.Rd"],"durationMs":276,"numFiles":1,"truncated":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0149GHZb3HmRe4UTNXaRkPwM","type":"message","role":"assistant","content":[{"type":"text","text":"Currently there's only one `.Rd` file per function (the shared rdname). After the fix, there should be separate `.Rd` files for methods with different arguments. Let me read the existing `.Rd` files to understand the current lumped documentation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":458,"cache_read_input_tokens":53137,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":458},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"dd0209b9-1716-4cb5-88db-57b96a92aadc"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0149GHZb3HmRe4UTNXaRkPwM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016aufLcwhqoiXKsHcyqVXst","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_quantile.Rd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":458,"cache_read_input_tokens":53137,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":458},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7f6766cb-a7a5-4ed8-8938-b1cd999da8a4"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016aufLcwhqoiXKsHcyqVXst","type":"tool_result","content":"     1→% Generated by roxygen2: do not edit by hand\n     2→% Please edit documentation in R/class-forecast-quantile.R,\n     3→%   R/class-forecast-sample.R\n     4→\\name{as_forecast_quantile}\n     5→\\alias{as_forecast_quantile}\n     6→\\alias{as_forecast_quantile.default}\n     7→\\alias{as_forecast_quantile.forecast_sample}\n     8→\\title{Create a \\code{forecast} object for quantile-based forecasts}\n     9→\\usage{\n    10→as_forecast_quantile(data, ...)\n    11→\n    12→\\method{as_forecast_quantile}{default}(\n    13→  data,\n    14→  forecast_unit = NULL,\n    15→  observed = NULL,\n    16→  predicted = NULL,\n    17→  quantile_level = NULL,\n    18→  ...\n    19→)\n    20→\n    21→\\method{as_forecast_quantile}{forecast_sample}(\n    22→  data,\n    23→  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),\n    24→  type = 7,\n    25→  ...\n    26→)\n    27→}\n    28→\\arguments{\n    29→\\item{data}{A data.frame (or similar) with predicted and observed values.\n    30→See the details section of for additional information\n    31→on the required input format.}\n    32→\n    33→\\item{...}{Unused}\n    34→\n    35→\\item{forecast_unit}{(optional) Name of the columns in \\code{data} (after\n    36→any renaming of columns) that denote the unit of a\n    37→single forecast. See \\code{\\link[=get_forecast_unit]{get_forecast_unit()}} for details.\n    38→If \\code{NULL} (the default), all columns that are not required columns are\n    39→assumed to form the unit of a single forecast. If specified, all columns\n    40→that are not part of the forecast unit (or required columns) will be removed.}\n    41→\n    42→\\item{observed}{(optional) Name of the column in \\code{data} that contains the\n    43→observed values. This column will be renamed to \"observed\".}\n    44→\n    45→\\item{predicted}{(optional) Name of the column in \\code{data} that contains the\n    46→predicted values. This column will be renamed to \"predicted\".}\n    47→\n    48→\\item{quantile_level}{(optional) Name of the column in \\code{data} that contains\n    49→the quantile level of the predicted values. This column will be renamed to\n    50→\"quantile_level\". Only applicable to quantile-based forecasts.}\n    51→\n    52→\\item{probs}{A numeric vector of quantile levels for which\n    53→quantiles will be computed. Corresponds to the \\code{probs} argument in\n    54→\\code{\\link[=quantile]{quantile()}}.}\n    55→\n    56→\\item{type}{Type argument passed down to the quantile function. For more\n    57→information, see \\code{\\link[=quantile]{quantile()}}.}\n    58→}\n    59→\\value{\n    60→A \\code{forecast} object of class \\code{forecast_quantile}\n    61→}\n    62→\\description{\n    63→Process and validate a data.frame (or similar) or similar with forecasts\n    64→and observations. If the input passes all input checks, those functions will\n    65→be converted to a \\code{forecast} object. A forecast object is a \\code{data.table} with\n    66→a class \\code{forecast} and an additional class that depends on the forecast type.\n    67→\n    68→The arguments \\code{observed}, \\code{predicted}, etc. make it possible to rename\n    69→existing columns of the input data to match the required columns for a\n    70→forecast object. Using the argument \\code{forecast_unit}, you can specify\n    71→the columns that uniquely identify a single forecast (and thereby removing\n    72→other, unneeded columns. See section \"Forecast Unit\" below for details).\n    73→}\n    74→\\section{Target format}{\n    75→The input for all further scoring needs to be a data.frame or similar with\n    76→the following columns:\n    77→\\itemize{\n    78→\\item \\code{observed}: Column of type \\code{numeric} with observed values.\n    79→\\item \\code{predicted}: Column of type \\code{numeric} with predicted values. Predicted\n    80→values represent quantiles of the predictive distribution.\n    81→\\item \\code{quantile_level}: Column of type \\code{numeric}, denoting the quantile level of\n    82→the corresponding predicted value.\n    83→Quantile levels must be between 0 and 1.\n    84→}\n    85→\n    86→For convenience, we recommend an additional column \\code{model} holding the name\n    87→of the forecaster or model that produced a prediction, but this is not\n    88→strictly necessary.\n    89→\n    90→See the \\link{example_quantile} data set for an example.\n    91→}\n    92→\n    93→\\section{Converting from \\code{forecast_sample} to \\code{forecast_quantile}}{\n    94→When creating a \\code{forecast_quantile} object from a \\code{forecast_sample} object,\n    95→the quantiles are estimated by computing empircal quantiles from the samples\n    96→via \\code{\\link[=quantile]{quantile()}}. Note that empirical quantiles are a biased estimator for\n    97→the true quantiles in particular in the tails of the distribution and\n    98→when the number of available samples is low.\n    99→}\n   100→\n   101→\\section{Forecast unit}{\n   102→In order to score forecasts, \\code{scoringutils} needs to know which of the rows\n   103→of the data belong together and jointly form a single forecast. This is\n   104→easy e.g. for point forecast, where there is one row per forecast. For\n   105→quantile or sample-based forecasts, however, there are multiple rows that\n   106→belong to a single forecast. (For a multivariate forecast, several univariate\n   107→forecasts are pooled together to form a joint forecast. In the multivariate\n   108→case, \"forecast unit\" still refers to the forecast unit of the univariate\n   109→forecasts that are pooled together to form the multivariate forecast.)\n   110→\n   111→The \\emph{forecast unit} or \\emph{unit of a single forecast} is then described by the\n   112→combination of columns that uniquely identify a single forecast.\n   113→For example, we could have forecasts made by different models in various\n   114→locations at different time points, each for several weeks into the future.\n   115→The forecast unit could then be described as\n   116→\\code{forecast_unit = c(\"model\", \"location\", \"forecast_date\", \"forecast_horizon\")}.\n   117→\\code{scoringutils} automatically tries to determine the unit of a single\n   118→forecast. It uses all existing columns for this, which means that no columns\n   119→must be present that are unrelated to the forecast unit. As a very simplistic\n   120→example, if you had an additional row, \"even\", that is one if the row number\n   121→is even and zero otherwise, then this would mess up scoring as \\code{scoringutils}\n   122→then thinks that this column was relevant in defining the forecast unit.\n   123→\n   124→In order to avoid issues, we recommend setting the forecast unit explicitly,\n   125→using the \\code{forecast_unit} argument. This will simply drop unneeded columns,\n   126→while making sure that all necessary, 'protected columns' like \"predicted\"\n   127→or \"observed\" are retained.\n   128→}\n   129→\n   130→\\examples{\n   131→as_forecast_quantile(\n   132→  example_quantile,\n   133→  predicted = \"predicted\",\n   134→  forecast_unit = c(\"model\", \"target_type\", \"target_end_date\",\n   135→                    \"horizon\", \"location\")\n   136→)\n   137→}\n   138→\\seealso{\n   139→Other functions to create forecast objects: \n   140→\\code{\\link{as_forecast_binary}()},\n   141→\\code{\\link{as_forecast_multivariate_sample}()},\n   142→\\code{\\link{as_forecast_nominal}()},\n   143→\\code{\\link{as_forecast_ordinal}()},\n   144→\\code{\\link{as_forecast_point}()},\n   145→\\code{\\link{as_forecast_sample}()}\n   146→}\n   147→\\concept{functions to create forecast objects}\n   148→\\keyword{as_forecast}\n   149→\\keyword{transform}\n   150→"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"19f49a66-6cb8-48a2-abb1-6f0eee185a99","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_quantile.Rd","content":"% Generated by roxygen2: do not edit by hand\n% Please edit documentation in R/class-forecast-quantile.R,\n%   R/class-forecast-sample.R\n\\name{as_forecast_quantile}\n\\alias{as_forecast_quantile}\n\\alias{as_forecast_quantile.default}\n\\alias{as_forecast_quantile.forecast_sample}\n\\title{Create a \\code{forecast} object for quantile-based forecasts}\n\\usage{\nas_forecast_quantile(data, ...)\n\n\\method{as_forecast_quantile}{default}(\n  data,\n  forecast_unit = NULL,\n  observed = NULL,\n  predicted = NULL,\n  quantile_level = NULL,\n  ...\n)\n\n\\method{as_forecast_quantile}{forecast_sample}(\n  data,\n  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),\n  type = 7,\n  ...\n)\n}\n\\arguments{\n\\item{data}{A data.frame (or similar) with predicted and observed values.\nSee the details section of for additional information\non the required input format.}\n\n\\item{...}{Unused}\n\n\\item{forecast_unit}{(optional) Name of the columns in \\code{data} (after\nany renaming of columns) that denote the unit of a\nsingle forecast. See \\code{\\link[=get_forecast_unit]{get_forecast_unit()}} for details.\nIf \\code{NULL} (the default), all columns that are not required columns are\nassumed to form the unit of a single forecast. If specified, all columns\nthat are not part of the forecast unit (or required columns) will be removed.}\n\n\\item{observed}{(optional) Name of the column in \\code{data} that contains the\nobserved values. This column will be renamed to \"observed\".}\n\n\\item{predicted}{(optional) Name of the column in \\code{data} that contains the\npredicted values. This column will be renamed to \"predicted\".}\n\n\\item{quantile_level}{(optional) Name of the column in \\code{data} that contains\nthe quantile level of the predicted values. This column will be renamed to\n\"quantile_level\". Only applicable to quantile-based forecasts.}\n\n\\item{probs}{A numeric vector of quantile levels for which\nquantiles will be computed. Corresponds to the \\code{probs} argument in\n\\code{\\link[=quantile]{quantile()}}.}\n\n\\item{type}{Type argument passed down to the quantile function. For more\ninformation, see \\code{\\link[=quantile]{quantile()}}.}\n}\n\\value{\nA \\code{forecast} object of class \\code{forecast_quantile}\n}\n\\description{\nProcess and validate a data.frame (or similar) or similar with forecasts\nand observations. If the input passes all input checks, those functions will\nbe converted to a \\code{forecast} object. A forecast object is a \\code{data.table} with\na class \\code{forecast} and an additional class that depends on the forecast type.\n\nThe arguments \\code{observed}, \\code{predicted}, etc. make it possible to rename\nexisting columns of the input data to match the required columns for a\nforecast object. Using the argument \\code{forecast_unit}, you can specify\nthe columns that uniquely identify a single forecast (and thereby removing\nother, unneeded columns. See section \"Forecast Unit\" below for details).\n}\n\\section{Target format}{\nThe input for all further scoring needs to be a data.frame or similar with\nthe following columns:\n\\itemize{\n\\item \\code{observed}: Column of type \\code{numeric} with observed values.\n\\item \\code{predicted}: Column of type \\code{numeric} with predicted values. Predicted\nvalues represent quantiles of the predictive distribution.\n\\item \\code{quantile_level}: Column of type \\code{numeric}, denoting the quantile level of\nthe corresponding predicted value.\nQuantile levels must be between 0 and 1.\n}\n\nFor convenience, we recommend an additional column \\code{model} holding the name\nof the forecaster or model that produced a prediction, but this is not\nstrictly necessary.\n\nSee the \\link{example_quantile} data set for an example.\n}\n\n\\section{Converting from \\code{forecast_sample} to \\code{forecast_quantile}}{\nWhen creating a \\code{forecast_quantile} object from a \\code{forecast_sample} object,\nthe quantiles are estimated by computing empircal quantiles from the samples\nvia \\code{\\link[=quantile]{quantile()}}. Note that empirical quantiles are a biased estimator for\nthe true quantiles in particular in the tails of the distribution and\nwhen the number of available samples is low.\n}\n\n\\section{Forecast unit}{\nIn order to score forecasts, \\code{scoringutils} needs to know which of the rows\nof the data belong together and jointly form a single forecast. This is\neasy e.g. for point forecast, where there is one row per forecast. For\nquantile or sample-based forecasts, however, there are multiple rows that\nbelong to a single forecast. (For a multivariate forecast, several univariate\nforecasts are pooled together to form a joint forecast. In the multivariate\ncase, \"forecast unit\" still refers to the forecast unit of the univariate\nforecasts that are pooled together to form the multivariate forecast.)\n\nThe \\emph{forecast unit} or \\emph{unit of a single forecast} is then described by the\ncombination of columns that uniquely identify a single forecast.\nFor example, we could have forecasts made by different models in various\nlocations at different time points, each for several weeks into the future.\nThe forecast unit could then be described as\n\\code{forecast_unit = c(\"model\", \"location\", \"forecast_date\", \"forecast_horizon\")}.\n\\code{scoringutils} automatically tries to determine the unit of a single\nforecast. It uses all existing columns for this, which means that no columns\nmust be present that are unrelated to the forecast unit. As a very simplistic\nexample, if you had an additional row, \"even\", that is one if the row number\nis even and zero otherwise, then this would mess up scoring as \\code{scoringutils}\nthen thinks that this column was relevant in defining the forecast unit.\n\nIn order to avoid issues, we recommend setting the forecast unit explicitly,\nusing the \\code{forecast_unit} argument. This will simply drop unneeded columns,\nwhile making sure that all necessary, 'protected columns' like \"predicted\"\nor \"observed\" are retained.\n}\n\n\\examples{\nas_forecast_quantile(\n  example_quantile,\n  predicted = \"predicted\",\n  forecast_unit = c(\"model\", \"target_type\", \"target_end_date\",\n                    \"horizon\", \"location\")\n)\n}\n\\seealso{\nOther functions to create forecast objects: \n\\code{\\link{as_forecast_binary}()},\n\\code{\\link{as_forecast_multivariate_sample}()},\n\\code{\\link{as_forecast_nominal}()},\n\\code{\\link{as_forecast_ordinal}()},\n\\code{\\link{as_forecast_point}()},\n\\code{\\link{as_forecast_sample}()}\n}\n\\concept{functions to create forecast objects}\n\\keyword{as_forecast}\n\\keyword{transform}\n","numLines":150,"startLine":1,"totalLines":150}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0149GHZb3HmRe4UTNXaRkPwM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GPVvWzdXJP89wZMuFrV4HC","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_point.Rd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":458,"cache_read_input_tokens":53137,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":458},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6810cd56-93f4-421b-88e9-6f89fd4a6911"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GPVvWzdXJP89wZMuFrV4HC","type":"tool_result","content":"     1→% Generated by roxygen2: do not edit by hand\n     2→% Please edit documentation in R/class-forecast-point.R,\n     3→%   R/class-forecast-quantile.R\n     4→\\name{as_forecast_point}\n     5→\\alias{as_forecast_point}\n     6→\\alias{as_forecast_point.default}\n     7→\\alias{as_forecast_point.forecast_quantile}\n     8→\\title{Create a \\code{forecast} object for point forecasts}\n     9→\\usage{\n    10→as_forecast_point(data, ...)\n    11→\n    12→\\method{as_forecast_point}{default}(\n    13→  data,\n    14→  forecast_unit = NULL,\n    15→  observed = NULL,\n    16→  predicted = NULL,\n    17→  ...\n    18→)\n    19→\n    20→\\method{as_forecast_point}{forecast_quantile}(data, ...)\n    21→}\n    22→\\arguments{\n    23→\\item{data}{A data.frame (or similar) with predicted and observed values.\n    24→See the details section of for additional information\n    25→on the required input format.}\n    26→\n    27→\\item{...}{Unused}\n    28→\n    29→\\item{forecast_unit}{(optional) Name of the columns in \\code{data} (after\n    30→any renaming of columns) that denote the unit of a\n    31→single forecast. See \\code{\\link[=get_forecast_unit]{get_forecast_unit()}} for details.\n    32→If \\code{NULL} (the default), all columns that are not required columns are\n    33→assumed to form the unit of a single forecast. If specified, all columns\n    34→that are not part of the forecast unit (or required columns) will be removed.}\n    35→\n    36→\\item{observed}{(optional) Name of the column in \\code{data} that contains the\n    37→observed values. This column will be renamed to \"observed\".}\n    38→\n    39→\\item{predicted}{(optional) Name of the column in \\code{data} that contains the\n    40→predicted values. This column will be renamed to \"predicted\".}\n    41→}\n    42→\\value{\n    43→A \\code{forecast} object of class \\code{forecast_point}\n    44→}\n    45→\\description{\n    46→When converting a \\code{forecast_quantile} object into a \\code{forecast_point} object,\n    47→the 0.5 quantile is extracted and returned as the point forecast.\n    48→}\n    49→\\section{Target format}{\n    50→The input for all further scoring needs to be a data.frame or similar with\n    51→the following columns:\n    52→\\itemize{\n    53→\\item \\code{observed}: Column of type \\code{numeric} with observed values.\n    54→\\item \\code{predicted}: Column of type \\code{numeric} with predicted values.\n    55→}\n    56→\n    57→For convenience, we recommend an additional column \\code{model} holding the name\n    58→of the forecaster or model that produced a prediction, but this is not\n    59→strictly necessary.\n    60→\n    61→See the \\link{example_point} data set for an example.\n    62→}\n    63→\n    64→\\seealso{\n    65→Other functions to create forecast objects: \n    66→\\code{\\link{as_forecast_binary}()},\n    67→\\code{\\link{as_forecast_multivariate_sample}()},\n    68→\\code{\\link{as_forecast_nominal}()},\n    69→\\code{\\link{as_forecast_ordinal}()},\n    70→\\code{\\link{as_forecast_quantile}()},\n    71→\\code{\\link{as_forecast_sample}()}\n    72→}\n    73→\\concept{functions to create forecast objects}\n    74→\\keyword{as_forecast}\n    75→\\keyword{transform}\n    76→"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a6f49850-6400-4a0c-95e9-0464878a49c8","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/man/as_forecast_point.Rd","content":"% Generated by roxygen2: do not edit by hand\n% Please edit documentation in R/class-forecast-point.R,\n%   R/class-forecast-quantile.R\n\\name{as_forecast_point}\n\\alias{as_forecast_point}\n\\alias{as_forecast_point.default}\n\\alias{as_forecast_point.forecast_quantile}\n\\title{Create a \\code{forecast} object for point forecasts}\n\\usage{\nas_forecast_point(data, ...)\n\n\\method{as_forecast_point}{default}(\n  data,\n  forecast_unit = NULL,\n  observed = NULL,\n  predicted = NULL,\n  ...\n)\n\n\\method{as_forecast_point}{forecast_quantile}(data, ...)\n}\n\\arguments{\n\\item{data}{A data.frame (or similar) with predicted and observed values.\nSee the details section of for additional information\non the required input format.}\n\n\\item{...}{Unused}\n\n\\item{forecast_unit}{(optional) Name of the columns in \\code{data} (after\nany renaming of columns) that denote the unit of a\nsingle forecast. See \\code{\\link[=get_forecast_unit]{get_forecast_unit()}} for details.\nIf \\code{NULL} (the default), all columns that are not required columns are\nassumed to form the unit of a single forecast. If specified, all columns\nthat are not part of the forecast unit (or required columns) will be removed.}\n\n\\item{observed}{(optional) Name of the column in \\code{data} that contains the\nobserved values. This column will be renamed to \"observed\".}\n\n\\item{predicted}{(optional) Name of the column in \\code{data} that contains the\npredicted values. This column will be renamed to \"predicted\".}\n}\n\\value{\nA \\code{forecast} object of class \\code{forecast_point}\n}\n\\description{\nWhen converting a \\code{forecast_quantile} object into a \\code{forecast_point} object,\nthe 0.5 quantile is extracted and returned as the point forecast.\n}\n\\section{Target format}{\nThe input for all further scoring needs to be a data.frame or similar with\nthe following columns:\n\\itemize{\n\\item \\code{observed}: Column of type \\code{numeric} with observed values.\n\\item \\code{predicted}: Column of type \\code{numeric} with predicted values.\n}\n\nFor convenience, we recommend an additional column \\code{model} holding the name\nof the forecaster or model that produced a prediction, but this is not\nstrictly necessary.\n\nSee the \\link{example_point} data set for an example.\n}\n\n\\seealso{\nOther functions to create forecast objects: \n\\code{\\link{as_forecast_binary}()},\n\\code{\\link{as_forecast_multivariate_sample}()},\n\\code{\\link{as_forecast_nominal}()},\n\\code{\\link{as_forecast_ordinal}()},\n\\code{\\link{as_forecast_quantile}()},\n\\code{\\link{as_forecast_sample}()}\n}\n\\concept{functions to create forecast objects}\n\\keyword{as_forecast}\n\\keyword{transform}\n","numLines":76,"startLine":1,"totalLines":76}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0149GHZb3HmRe4UTNXaRkPwM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019Eu4xPYwddRS5K69agPovF","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/man/get_pit_histogram.Rd"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":458,"cache_read_input_tokens":53137,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":458},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"764db41e-bd43-4642-ab1e-213c7c82b336"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019Eu4xPYwddRS5K69agPovF","type":"tool_result","content":"     1→% Generated by roxygen2: do not edit by hand\n     2→% Please edit documentation in R/class-forecast-quantile.R,\n     3→%   R/class-forecast-sample.R, R/get-pit-histogram.R\n     4→\\name{get_pit_histogram.forecast_quantile}\n     5→\\alias{get_pit_histogram.forecast_quantile}\n     6→\\alias{get_pit_histogram.forecast_sample}\n     7→\\alias{get_pit_histogram}\n     8→\\alias{get_pit_histogram.default}\n     9→\\title{Probability integral transformation histogram}\n    10→\\usage{\n    11→\\method{get_pit_histogram}{forecast_quantile}(forecast, num_bins = NULL, breaks = NULL, by, ...)\n    12→\n    13→\\method{get_pit_histogram}{forecast_sample}(\n    14→  forecast,\n    15→  num_bins = 10,\n    16→  breaks = NULL,\n    17→  by,\n    18→  integers = c(\"nonrandom\", \"random\", \"ignore\"),\n    19→  n_replicates = NULL,\n    20→  ...\n    21→)\n    22→\n    23→get_pit_histogram(forecast, num_bins, breaks, by, ...)\n    24→\n    25→\\method{get_pit_histogram}{default}(forecast, num_bins, breaks, by, ...)\n    26→}\n    27→\\arguments{\n    28→\\item{forecast}{A forecast object (a validated data.table with predicted and\n    29→observed values).}\n    30→\n    31→\\item{num_bins}{The number of bins in the PIT histogram. For sample-based\n    32→forecasts, the default is 10 bins. For quantile-based forecasts, the\n    33→default is one bin for each available quantile.\n    34→You can control the number of bins by supplying a number. This is fine for\n    35→sample-based pit histograms, but may fail for quantile-based formats. In\n    36→this case it is preferred to supply explicit breaks points using the\n    37→\\code{breaks} argument.}\n    38→\n    39→\\item{breaks}{Numeric vector with the break points for the bins in the\n    40→PIT histogram. This is preferred when creating a PIT histogram based on\n    41→quantile-based data. Default is \\code{NULL} and breaks will be determined by\n    42→\\code{num_bins}. If \\code{breaks} is used, \\code{num_bins} will be ignored.\n    43→0 and 1 will always be added as left and right bounds, respectively.}\n    44→\n    45→\\item{by}{Character vector with the columns according to which the\n    46→PIT values shall be grouped. If you e.g. have the columns 'model' and\n    47→'location' in the input data and want to have a PIT histogram for\n    48→every model and location, specify \\code{by = c(\"model\", \"location\")}.}\n    49→\n    50→\\item{...}{Currently unused. You \\emph{cannot} pass additional arguments to scoring\n    51→functions via \\code{...}. See the \\emph{Customising metrics} section below for\n    52→details on how to use \\code{\\link[purrr:partial]{purrr::partial()}} to pass arguments to individual\n    53→metrics.}\n    54→\n    55→\\item{integers}{How to handle integer forecasts (count data). This is based\n    56→on methods described Czado et al. (2007). If \"nonrandom\" (default) the\n    57→function will use the non-randomised PIT method. If \"random\", will use the\n    58→randomised PIT method. If \"ignore\", will treat integer forecasts as if they\n    59→were continuous.}\n    60→\n    61→\\item{n_replicates}{The number of draws for the randomised PIT for discrete\n    62→predictions. Will be ignored if forecasts are continuous or \\code{integers} is\n    63→not set to \\code{random}.}\n    64→}\n    65→\\value{\n    66→A data.table with density values for each bin in the PIT histogram.\n    67→}\n    68→\\description{\n    69→Generate a Probability Integral Transformation (PIT) histogram for\n    70→validated forecast objects.\n    71→\n    72→See the examples for how to plot the result of this function.\n    73→}\n    74→\\examples{\n    75→library(\"ggplot2\")\n    76→\n    77→result <- get_pit_histogram(example_sample_continuous, by = \"model\")\n    78→ggplot(result,  aes(x = mid, y = density)) +\n    79→  geom_col() +\n    80→  facet_wrap(. ~ model) +\n    81→  labs(x = \"Quantile\", y = \"Density\")\n    82→\n    83→# example with quantile data\n    84→result <- get_pit_histogram(example_quantile, by = \"model\")\n    85→ggplot(result,  aes(x = mid, y = density)) +\n    86→  geom_col() +\n    87→  facet_wrap(. ~ model) +\n    88→  labs(x = \"Quantile\", y = \"Density\")\n    89→}\n    90→\\references{\n    91→Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe,\n    92→Rosalind M. Eggo, W. John Edmunds (2019) Assessing the performance of\n    93→real-time epidemic forecasts: A case study of Ebola in the Western Area\n    94→region of Sierra Leone, 2014-15, \\doi{10.1371/journal.pcbi.1006785}\n    95→}\n    96→\\seealso{\n    97→\\code{\\link[=pit_histogram_sample]{pit_histogram_sample()}}\n    98→}\n    99→\\keyword{scoring}\n   100→"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f81a8a05-7a7e-486b-b9ec-751564f68c1f","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/man/get_pit_histogram.Rd","content":"% Generated by roxygen2: do not edit by hand\n% Please edit documentation in R/class-forecast-quantile.R,\n%   R/class-forecast-sample.R, R/get-pit-histogram.R\n\\name{get_pit_histogram.forecast_quantile}\n\\alias{get_pit_histogram.forecast_quantile}\n\\alias{get_pit_histogram.forecast_sample}\n\\alias{get_pit_histogram}\n\\alias{get_pit_histogram.default}\n\\title{Probability integral transformation histogram}\n\\usage{\n\\method{get_pit_histogram}{forecast_quantile}(forecast, num_bins = NULL, breaks = NULL, by, ...)\n\n\\method{get_pit_histogram}{forecast_sample}(\n  forecast,\n  num_bins = 10,\n  breaks = NULL,\n  by,\n  integers = c(\"nonrandom\", \"random\", \"ignore\"),\n  n_replicates = NULL,\n  ...\n)\n\nget_pit_histogram(forecast, num_bins, breaks, by, ...)\n\n\\method{get_pit_histogram}{default}(forecast, num_bins, breaks, by, ...)\n}\n\\arguments{\n\\item{forecast}{A forecast object (a validated data.table with predicted and\nobserved values).}\n\n\\item{num_bins}{The number of bins in the PIT histogram. For sample-based\nforecasts, the default is 10 bins. For quantile-based forecasts, the\ndefault is one bin for each available quantile.\nYou can control the number of bins by supplying a number. This is fine for\nsample-based pit histograms, but may fail for quantile-based formats. In\nthis case it is preferred to supply explicit breaks points using the\n\\code{breaks} argument.}\n\n\\item{breaks}{Numeric vector with the break points for the bins in the\nPIT histogram. This is preferred when creating a PIT histogram based on\nquantile-based data. Default is \\code{NULL} and breaks will be determined by\n\\code{num_bins}. If \\code{breaks} is used, \\code{num_bins} will be ignored.\n0 and 1 will always be added as left and right bounds, respectively.}\n\n\\item{by}{Character vector with the columns according to which the\nPIT values shall be grouped. If you e.g. have the columns 'model' and\n'location' in the input data and want to have a PIT histogram for\nevery model and location, specify \\code{by = c(\"model\", \"location\")}.}\n\n\\item{...}{Currently unused. You \\emph{cannot} pass additional arguments to scoring\nfunctions via \\code{...}. See the \\emph{Customising metrics} section below for\ndetails on how to use \\code{\\link[purrr:partial]{purrr::partial()}} to pass arguments to individual\nmetrics.}\n\n\\item{integers}{How to handle integer forecasts (count data). This is based\non methods described Czado et al. (2007). If \"nonrandom\" (default) the\nfunction will use the non-randomised PIT method. If \"random\", will use the\nrandomised PIT method. If \"ignore\", will treat integer forecasts as if they\nwere continuous.}\n\n\\item{n_replicates}{The number of draws for the randomised PIT for discrete\npredictions. Will be ignored if forecasts are continuous or \\code{integers} is\nnot set to \\code{random}.}\n}\n\\value{\nA data.table with density values for each bin in the PIT histogram.\n}\n\\description{\nGenerate a Probability Integral Transformation (PIT) histogram for\nvalidated forecast objects.\n\nSee the examples for how to plot the result of this function.\n}\n\\examples{\nlibrary(\"ggplot2\")\n\nresult <- get_pit_histogram(example_sample_continuous, by = \"model\")\nggplot(result,  aes(x = mid, y = density)) +\n  geom_col() +\n  facet_wrap(. ~ model) +\n  labs(x = \"Quantile\", y = \"Density\")\n\n# example with quantile data\nresult <- get_pit_histogram(example_quantile, by = \"model\")\nggplot(result,  aes(x = mid, y = density)) +\n  geom_col() +\n  facet_wrap(. ~ model) +\n  labs(x = \"Quantile\", y = \"Density\")\n}\n\\references{\nSebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe,\nRosalind M. Eggo, W. John Edmunds (2019) Assessing the performance of\nreal-time epidemic forecasts: A case study of Ebola in the Western Area\nregion of Sierra Leone, 2014-15, \\doi{10.1371/journal.pcbi.1006785}\n}\n\\seealso{\n\\code{\\link[=pit_histogram_sample]{pit_histogram_sample()}}\n}\n\\keyword{scoring}\n","numLines":100,"startLine":1,"totalLines":100}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Mb9jn6Ty1DJ2eu85HRZF5o","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a complete picture. This is a **documentation-only** issue — modifying `@rdname` tags so S3 methods with different parameters get separate help pages. The fix involves:\n\n1. Removing `@rdname as_forecast_quantile` from `as_forecast_quantile.forecast_sample`\n2. Removing `@rdname as_forecast_point` from `as_forecast_point.forecast_quantile`\n3. Removing `@rdname get_pit_histogram` from `get_pit_histogram.forecast_sample`\n4. Giving each its own documentation page with proper title and description\n\nFor testing, while this is documentation, we can design tests that verify:\n1. The man pages exist as separate files after `roxygenise()`\n2. The parameter documentation is correct on each page (no confusion between methods)\n3. The functions themselves still work correctly with their specific parameters (regression tests)\n\nLet me check what existing tests exist for these specific methods to understand what regression tests already cover."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5232,"cache_read_input_tokens":53595,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5232},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2f83c846-b73d-45f4-9f36-702cc43f9680"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Mb9jn6Ty1DJ2eu85HRZF5o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YEzMuDuV36RX8CckL7xjfT","name":"Grep","input":{"pattern":"as_forecast_quantile.*forecast_sample|as_forecast_quantile\\.forecast_sample","path":"/Users/nikos/github-synced/scoringutils-pipeline/tests","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5232,"cache_read_input_tokens":53595,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5232},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"169bbda0-cf6d-4068-bc70-c65d77f2cab1"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YEzMuDuV36RX8CckL7xjfT","type":"tool_result","content":"No matches found"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"8459939d-6c2a-4a32-82d8-0112d82bc32e","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"","numLines":0}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Mb9jn6Ty1DJ2eu85HRZF5o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01G2uaYzDPstoabdaJajpRfY","name":"Grep","input":{"pattern":"as_forecast_point.*forecast_quantile|as_forecast_point\\.forecast_quantile","path":"/Users/nikos/github-synced/scoringutils-pipeline/tests","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5232,"cache_read_input_tokens":53595,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5232},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"68b52555-14f6-4f5b-811a-45828f31d5fc"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01G2uaYzDPstoabdaJajpRfY","type":"tool_result","content":"tests/testthat/test-class-forecast-point.R:7:    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"0ebfb7fb-a022-4ff9-a5df-d3b091c26855","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"tests/testthat/test-class-forecast-point.R:7:    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))","numLines":1}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Mb9jn6Ty1DJ2eu85HRZF5o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ekp6PvzxcK2Rqz8zx7aCdF","name":"Grep","input":{"pattern":"get_pit_histogram.*forecast_sample","path":"/Users/nikos/github-synced/scoringutils-pipeline/tests","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5232,"cache_read_input_tokens":53595,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5232},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"37637d38-08bc-4a19-85eb-f1d84d95d31f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ekp6PvzxcK2Rqz8zx7aCdF","type":"tool_result","content":"tests/testthat/test-class-forecast-sample.R:60:# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:62:test_that(\"get_pit_histogram.forecast_sample() works as expected\", {"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2909f2cc-0a8e-4dbb-8372-9934285d7cf0","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"tests/testthat/test-class-forecast-sample.R:60:# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\ntests/testthat/test-class-forecast-sample.R:62:test_that(\"get_pit_histogram.forecast_sample() works as expected\", {","numLines":2}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011HCmXut71bvd9hvYPucrMU","type":"message","role":"assistant","content":[{"type":"text","text":"Let me read the relevant test sections more fully."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":767,"cache_read_input_tokens":58827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":767},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"68e4ae35-e609-4e94-8faf-a3a0fa20844e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011HCmXut71bvd9hvYPucrMU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NGZqRK3ThZyZYKQp6P871e","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R","offset":90,"limit":80}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":767,"cache_read_input_tokens":58827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":767},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2bbf041e-5476-4f5a-9ccb-c362b839831e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NGZqRK3ThZyZYKQp6P871e","type":"tool_result","content":"    90→})\n    91→\n    92→test_that(\"as_forecast_quantile() works with a data.frame\", {\n    93→  expect_no_condition(as_forecast_quantile(example_quantile_df))\n    94→})\n    95→\n    96→test_that(\"as_forecast_quantiles works\", {\n    97→  samples <- data.frame(\n    98→    date = as.Date(\"2020-01-01\") + 1:10,\n    99→    model = \"model1\",\n   100→    observed = 1:10,\n   101→    predicted = c(rep(0, 10), 2:11, 3:12, 4:13, rep(100, 10)),\n   102→    sample_id = rep(1:5, each = 10),\n   103→    stringsAsFactors = FALSE\n   104→  ) |>\n   105→    as_forecast_sample()\n   106→\n   107→  quantile <- data.frame(\n   108→    date = rep(as.Date(\"2020-01-01\") + 1:10, each = 2),\n   109→    model = \"model1\",\n   110→    observed = rep(1:10, each = 2),\n   111→    quantile_level = c(0.25, 0.75),\n   112→    predicted = rep(2:11, each = 2) + c(0, 2),\n   113→    stringsAsFactors = FALSE\n   114→  )\n   115→\n   116→  expect_no_condition(\n   117→    as_forecast_quantile(samples, probs = c(0.25, 0.75))\n   118→  )\n   119→\n   120→  wrongclass <- as_forecast_sample(samples)\n   121→  class(wrongclass) <- c(\"forecast_point\", \"data.table\", \"data.frame\")\n   122→  expect_error(\n   123→    as_forecast_quantile(wrongclass, quantile_level = c(0.25, 0.75)),\n   124→    \"Assertion on 'quantile_level' failed: Must be of type\"\n   125→  )\n   126→\n   127→\n   128→  quantile2 <- as_forecast_quantile(\n   129→    as_forecast_sample(samples),\n   130→    probs = c(0.25, 0.75)\n   131→  )\n   132→\n   133→  expect_identical(quantile, as.data.frame(quantile2))\n   134→\n   135→  # Verify that `type` is correctly scoped in as_forecast_quantile(), as it is\n   136→  # also an argument.\n   137→  # If it's not scoped well, the call to `as_forecast_quantile()` will fail.\n   138→  samples$type <- \"test\"\n   139→\n   140→  quantile3 <- as_forecast_quantile(\n   141→    as_forecast_sample(samples),\n   142→    probs = c(0.25, 0.75)\n   143→  )\n   144→  quantile3$type <- NULL\n   145→\n   146→  expect_identical(\n   147→    quantile2,\n   148→    quantile3\n   149→  )\n   150→})\n   151→\n   152→test_that(\"as_forecast_quantiles issue 557 fix\", {\n   153→  out <- example_sample_discrete |>\n   154→    na.omit() |>\n   155→    as_forecast_quantile(\n   156→      probs = c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)\n   157→    ) |>\n   158→    score()\n   159→\n   160→  expect_false(anyNA(out$interval_coverage_deviation))\n   161→})\n   162→\n   163→test_that(\"as_forecast_quantile doesn't modify column names in place\", {\n   164→  quantile_data <- data.table(\n   165→    my_quantile = c(0.25, 0.5),\n   166→    forecast_value = c(1, 2),\n   167→    observed_value = c(5, 5)\n   168→  )\n   169→  pre <- names(quantile_data)"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"16e29d84-0d57-4f72-8626-c920e273dc97","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-quantile.R","content":"})\n\ntest_that(\"as_forecast_quantile() works with a data.frame\", {\n  expect_no_condition(as_forecast_quantile(example_quantile_df))\n})\n\ntest_that(\"as_forecast_quantiles works\", {\n  samples <- data.frame(\n    date = as.Date(\"2020-01-01\") + 1:10,\n    model = \"model1\",\n    observed = 1:10,\n    predicted = c(rep(0, 10), 2:11, 3:12, 4:13, rep(100, 10)),\n    sample_id = rep(1:5, each = 10),\n    stringsAsFactors = FALSE\n  ) |>\n    as_forecast_sample()\n\n  quantile <- data.frame(\n    date = rep(as.Date(\"2020-01-01\") + 1:10, each = 2),\n    model = \"model1\",\n    observed = rep(1:10, each = 2),\n    quantile_level = c(0.25, 0.75),\n    predicted = rep(2:11, each = 2) + c(0, 2),\n    stringsAsFactors = FALSE\n  )\n\n  expect_no_condition(\n    as_forecast_quantile(samples, probs = c(0.25, 0.75))\n  )\n\n  wrongclass <- as_forecast_sample(samples)\n  class(wrongclass) <- c(\"forecast_point\", \"data.table\", \"data.frame\")\n  expect_error(\n    as_forecast_quantile(wrongclass, quantile_level = c(0.25, 0.75)),\n    \"Assertion on 'quantile_level' failed: Must be of type\"\n  )\n\n\n  quantile2 <- as_forecast_quantile(\n    as_forecast_sample(samples),\n    probs = c(0.25, 0.75)\n  )\n\n  expect_identical(quantile, as.data.frame(quantile2))\n\n  # Verify that `type` is correctly scoped in as_forecast_quantile(), as it is\n  # also an argument.\n  # If it's not scoped well, the call to `as_forecast_quantile()` will fail.\n  samples$type <- \"test\"\n\n  quantile3 <- as_forecast_quantile(\n    as_forecast_sample(samples),\n    probs = c(0.25, 0.75)\n  )\n  quantile3$type <- NULL\n\n  expect_identical(\n    quantile2,\n    quantile3\n  )\n})\n\ntest_that(\"as_forecast_quantiles issue 557 fix\", {\n  out <- example_sample_discrete |>\n    na.omit() |>\n    as_forecast_quantile(\n      probs = c(0.01, 0.025, seq(0.05, 0.95, 0.05), 0.975, 0.99)\n    ) |>\n    score()\n\n  expect_false(anyNA(out$interval_coverage_deviation))\n})\n\ntest_that(\"as_forecast_quantile doesn't modify column names in place\", {\n  quantile_data <- data.table(\n    my_quantile = c(0.25, 0.5),\n    forecast_value = c(1, 2),\n    observed_value = c(5, 5)\n  )\n  pre <- names(quantile_data)","numLines":80,"startLine":90,"totalLines":430}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011HCmXut71bvd9hvYPucrMU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013JrHpeBuiW6dzrDcyUffFm","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R","limit":30}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":767,"cache_read_input_tokens":58827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":767},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"f1823b78-2ef3-427b-8692-39a5612c4ea3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013JrHpeBuiW6dzrDcyUffFm","type":"tool_result","content":"     1→# ==============================================================================\n     2→# as_forecast_point() # nolint: commented_code_linter\n     3→# ==============================================================================\n     4→\n     5→test_that(\"as_forecast_point() works\", {\n     6→  expect_no_condition(\n     7→    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))\n     8→  )\n     9→})\n    10→\n    11→\n    12→# ==============================================================================\n    13→# is_forecast_point() # nolint: commented_code_linter\n    14→# ==============================================================================\n    15→test_that(\"is_forecast_point() works as expected\", {\n    16→  expect_true(is_forecast_point(example_point))\n    17→  expect_false(is_forecast_point(example_binary))\n    18→  expect_false(is_forecast_point(example_quantile))\n    19→  expect_false(is_forecast_point(example_sample_continuous))\n    20→  expect_false(is_forecast_point(example_nominal))\n    21→})\n    22→\n    23→\n    24→# ==============================================================================\n    25→# assert_forecast.forecast_point() # nolint: commented_code_linter\n    26→# ==============================================================================\n    27→\n    28→test_that(\"assert_forecast.forecast_point() works as expected\", {\n    29→  test <- na.omit(data.table::as.data.table(example_point))\n    30→  test <- as_forecast_point(test)"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"22933d41-ebe8-417f-a561-4e1b578151a1","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-point.R","content":"# ==============================================================================\n# as_forecast_point() # nolint: commented_code_linter\n# ==============================================================================\n\ntest_that(\"as_forecast_point() works\", {\n  expect_no_condition(\n    as_forecast_point(as_forecast_quantile(na.omit(example_quantile)))\n  )\n})\n\n\n# ==============================================================================\n# is_forecast_point() # nolint: commented_code_linter\n# ==============================================================================\ntest_that(\"is_forecast_point() works as expected\", {\n  expect_true(is_forecast_point(example_point))\n  expect_false(is_forecast_point(example_binary))\n  expect_false(is_forecast_point(example_quantile))\n  expect_false(is_forecast_point(example_sample_continuous))\n  expect_false(is_forecast_point(example_nominal))\n})\n\n\n# ==============================================================================\n# assert_forecast.forecast_point() # nolint: commented_code_linter\n# ==============================================================================\n\ntest_that(\"assert_forecast.forecast_point() works as expected\", {\n  test <- na.omit(data.table::as.data.table(example_point))\n  test <- as_forecast_point(test)","numLines":30,"startLine":1,"totalLines":110}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011HCmXut71bvd9hvYPucrMU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UDF4Lwp7wnvEdVWaUHmrPC","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R","offset":55,"limit":30}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":767,"cache_read_input_tokens":58827,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":767},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"957dc03a-622b-4a0e-9117-a61086ae9350"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UDF4Lwp7wnvEdVWaUHmrPC","type":"tool_result","content":"    55→  )\n    56→})\n    57→\n    58→\n    59→# ==============================================================================\n    60→# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\n    61→# ==============================================================================\n    62→test_that(\"get_pit_histogram.forecast_sample() works as expected\", {\n    63→  pit_continuous <- get_pit_histogram(example_sample_continuous, by = c(\"model\", \"target_type\"))\n    64→  pit_integer <- get_pit_histogram(example_sample_discrete, by = c(\"model\", \"location\"))\n    65→\n    66→  expect_named(pit_continuous, c(\"model\", \"target_type\", \"density\", \"bin\", \"mid\"))\n    67→  expect_named(pit_integer, c(\"model\", \"location\", \"density\", \"bin\", \"mid\"))\n    68→\n    69→  # check printing works\n    70→  expect_output(print(pit_continuous))\n    71→  expect_output(print(pit_integer))\n    72→\n    73→  # check class is correct\n    74→  expect_s3_class(pit_continuous, c(\"data.table\", \"data.frame\"), exact = TRUE)\n    75→  expect_s3_class(pit_integer, c(\"data.table\", \"data.frame\"), exact = TRUE)\n    76→})\n    77→"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"d11fe932-4946-42cc-bae1-f1f72f2df19f","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/test-class-forecast-sample.R","content":"  )\n})\n\n\n# ==============================================================================\n# get_pit_histogram.forecast_sample() # nolint: commented_code_linter\n# ==============================================================================\ntest_that(\"get_pit_histogram.forecast_sample() works as expected\", {\n  pit_continuous <- get_pit_histogram(example_sample_continuous, by = c(\"model\", \"target_type\"))\n  pit_integer <- get_pit_histogram(example_sample_discrete, by = c(\"model\", \"location\"))\n\n  expect_named(pit_continuous, c(\"model\", \"target_type\", \"density\", \"bin\", \"mid\"))\n  expect_named(pit_integer, c(\"model\", \"location\", \"density\", \"bin\", \"mid\"))\n\n  # check printing works\n  expect_output(print(pit_continuous))\n  expect_output(print(pit_integer))\n\n  # check class is correct\n  expect_s3_class(pit_continuous, c(\"data.table\", \"data.frame\"), exact = TRUE)\n  expect_s3_class(pit_integer, c(\"data.table\", \"data.frame\"), exact = TRUE)\n})\n","numLines":23,"startLine":55,"totalLines":77}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_014aRJNWNa1y24qYfHL895kC","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a complete understanding. Let me also check if there's an existing issue file for #793."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2206,"cache_read_input_tokens":59594,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2206},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7ae98b22-f8da-4e03-abcc-59bf579adf3f"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_014aRJNWNa1y24qYfHL895kC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CerVYCVCFMAd7SgsxTkmsw","name":"Glob","input":{"pattern":".ralph/issues/793*"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2206,"cache_read_input_tokens":59594,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2206},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"333e311b-f23b-4205-a92b-43822583b6b6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CerVYCVCFMAd7SgsxTkmsw","type":"tool_result","content":"No files found"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"3f1b0454-0ebd-47f7-bf42-997becea658e","tool_use_result":{"filenames":[],"durationMs":289,"numFiles":0,"truncated":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01LV1YCjJXAQpYN3DqdvMSwr","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me check the setup.R to understand what example data is available."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":277,"cache_read_input_tokens":61800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":277},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7cc2bc60-f847-40b1-98b1-2dae2936d424"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01LV1YCjJXAQpYN3DqdvMSwr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YQsZ56v2CpUuTwsdnw2Y24","name":"Read","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":277,"cache_read_input_tokens":61800,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":277},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"80fbd66a-fdca-4edd-8b95-c339c35854f9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YQsZ56v2CpUuTwsdnw2Y24","type":"tool_result","content":"     1→data.table::setDTthreads(2) # restricts number of cores used on CRAN\n     2→\n     3→metrics_no_cov <- get_metrics(\n     4→  example_quantile,\n     5→  exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\n     6→)\n     7→metrics_no_cov_no_ae <- get_metrics(\n     8→  example_quantile,\n     9→  exclude = c(\n    10→    \"interval_coverage_50\", \"interval_coverage_90\",\n    11→    \"ae_median\"\n    12→  )\n    13→)\n    14→\n    15→example_quantile_df <- as.data.frame(na.omit(example_quantile))\n    16→checkmate::assert_number(length(class(example_quantile_df)))\n    17→\n    18→\n    19→# pre-computed scores\n    20→scores_quantile <- score(example_quantile)\n    21→scores_sample_continuous <- score(example_sample_continuous)\n    22→scores_sample_discrete <- score(example_sample_discrete)\n    23→scores_point <- score(example_point)\n    24→scores_binary <- score(example_binary)\n    25→scores_nominal <- score(example_nominal)\n    26→"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"667c0f99-c191-4e32-bd14-c1c39e437b15","tool_use_result":{"type":"text","file":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/tests/testthat/setup.R","content":"data.table::setDTthreads(2) # restricts number of cores used on CRAN\n\nmetrics_no_cov <- get_metrics(\n  example_quantile,\n  exclude = c(\"interval_coverage_50\", \"interval_coverage_90\")\n)\nmetrics_no_cov_no_ae <- get_metrics(\n  example_quantile,\n  exclude = c(\n    \"interval_coverage_50\", \"interval_coverage_90\",\n    \"ae_median\"\n  )\n)\n\nexample_quantile_df <- as.data.frame(na.omit(example_quantile))\ncheckmate::assert_number(length(class(example_quantile_df)))\n\n\n# pre-computed scores\nscores_quantile <- score(example_quantile)\nscores_sample_continuous <- score(example_sample_continuous)\nscores_sample_discrete <- score(example_sample_discrete)\nscores_point <- score(example_point)\nscores_binary <- score(example_binary)\nscores_nominal <- score(example_nominal)\n","numLines":26,"startLine":1,"totalLines":26}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01T8YZS1WcuYtAMJehoeJttg","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have all the information I need. Let me design the test cases. Since this is a documentation-only change (roxygen `@rdname` tags), the tests should verify:\n\n1. That the `.Rd` files are generated correctly (separate pages exist)\n2. That the functions still work correctly with their method-specific parameters after the change (regression)\n3. That `R CMD check` passes (documentation matches actual function signatures)\n\nHowever, the project doesn't have any infrastructure for testing documentation structure (no `.Rd` file parsing tests). The most practical tests are:\n\n1. **Regression tests** ensuring each method works with its specific parameters\n2. **Negative tests** ensuring parameters from one method don't bleed into another (e.g., `as_forecast_quantile.forecast_sample` should NOT accept `quantile_level`)\n\nLet me now write the test specs."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":436,"cache_read_input_tokens":62077,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":436},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a0fc9625-e0e9-467d-af90-8847f470bfaf"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01T8YZS1WcuYtAMJehoeJttg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FfVQJJTVXupVEcnMwHRZL2","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"in_progress","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":436,"cache_read_input_tokens":62077,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":436},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"8ce98d16-fc53-429a-8af5-ec9b58144120"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FfVQJJTVXupVEcnMwHRZL2","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"9957e047-fb5d-4741-917b-4a2102e583a6","tool_use_result":{"oldTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"in_progress","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"pending","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"in_progress","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_014Uzc5oMQCjWMWqZAjm9dNe","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ud2uP5fUWhc9uE1fCSmZpW","name":"Write","input":{"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/issues/793-document-methods-different-args.md","content":"# Issue #793: How should we document methods that have different arguments than the default method?\n\n## Source\n\n- **GitHub**: https://github.com/epiforecasts/scoringutils/issues/793\n- **Action Summary**: Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description.\n- **Status Note**: Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list.\n\n## Test Specifications\n\n**Designed**: 2026-02-13\n**Test file**: `tests/testthat/test-class-forecast-quantile.R` (existing) and `tests/testthat/test-class-forecast-sample.R` (existing) and `tests/testthat/test-class-forecast-point.R` (existing)\n**Testing patterns observed**: testthat with data.table fixtures. Example datasets (`example_quantile`, `example_sample_continuous`, `example_sample_discrete`, `example_point`) pre-loaded. `setup.R` creates pre-computed scores. Tests use `expect_no_condition()`, `expect_error()`, `expect_identical()`, etc.\n\n### Test 1: test_that(\"as_forecast_quantile.forecast_sample() accepts probs and type args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_sample` method works correctly with its method-specific `probs` and `type` arguments, which differ from the `.default` method's `forecast_unit`, `observed`, `predicted`, `quantile_level` args.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- Use `example_sample_continuous` (already available as a `forecast_sample` object)\n**Action**:\n- Call `as_forecast_quantile(example_sample_continuous, probs = c(0.1, 0.5, 0.9), type = 7)`\n**Expected**:\n- Returns a `forecast_quantile` object (check with `is_forecast_quantile()`)\n- The resulting object has exactly the quantile levels 0.1, 0.5, 0.9 (check `unique(result$quantile_level)`)\n- No warnings or errors emitted (`expect_no_condition()`)\n**Fails now because**:\n- This test should PASS with current code. It serves as a regression test ensuring the `.forecast_sample` method's parameter interface remains intact after the `@rdname` change. The current code works; the issue is only about documentation structure.\n\n### Test 2: test_that(\"as_forecast_point.forecast_quantile() extracts median without extra args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_quantile` method works with only `data` and `...` (no `forecast_unit`, `observed`, `predicted` args from `.default`).\n**File**: `tests/testthat/test-class-forecast-point.R`\n**Setup**:\n- Use `na.omit(example_quantile)` piped through `as_forecast_quantile()`\n**Action**:\n- Call `as_forecast_point(quantile_forecast)` with no extra arguments\n**Expected**:\n- Returns a `forecast_point` object (check with `is_forecast_point()`)\n- The `predicted` column contains the median values (0.5 quantile) from the input\n- The result has no `quantile_level` or `sample_id` column\n- No warnings or errors emitted (`expect_no_condition()`)\n**Fails now because**:\n- This test should PASS with current code. It is a regression test confirming that the `.forecast_quantile` method's minimal interface (no extra column-renaming args) continues working after the `@rdname` separation.\n\n### Test 3: test_that(\"get_pit_histogram.forecast_sample() accepts integers and n_replicates args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_sample` method works with its extra `integers` and `n_replicates` parameters, which don't exist on the `.forecast_quantile` method.\n**File**: `tests/testthat/test-class-forecast-sample.R`\n**Setup**:\n- Use `example_sample_discrete` (integer-valued sample forecast)\n**Action**:\n- Call `get_pit_histogram(example_sample_discrete, by = \"model\", integers = \"random\", n_replicates = 50)`\n**Expected**:\n- Returns a data.table with columns `model`, `density`, `bin`, `mid`\n- No errors or unexpected warnings\n- The `density` values are non-negative\n**Fails now because**:\n- This test should PASS with current code. It is a regression test ensuring the `.forecast_sample`-specific `integers` and `n_replicates` parameters remain functional after the `@rdname` split.\n\n### Test 4: test_that(\"get_pit_histogram.forecast_quantile() does not accept integers arg\", { ... })\n\n**Reproduces**: Confirms that the `.forecast_quantile` method does NOT accept the `integers` parameter (which belongs only to `.forecast_sample`). This validates the parameter separation that the documentation fix aims to clarify.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- Use `example_quantile` (a `forecast_quantile` object)\n**Action**:\n- Call `get_pit_histogram(example_quantile, by = \"model\", integers = \"random\")`\n**Expected**:\n- Either raises a warning about unused arguments or silently ignores the `integers` argument (since it's passed through `...`). The key point is that `integers` is NOT a formal parameter of `get_pit_histogram.forecast_quantile()`.\n- Verify via `expect_true(!\"integers\" %in% names(formals(scoringutils:::get_pit_histogram.forecast_quantile)))` that `integers` is not a formal arg of the quantile method.\n**Fails now because**:\n- This test should PASS with current code. It validates the existing parameter separation at the code level, which the documentation change aims to make visible to users.\n\n### Test 5: test_that(\"separate .Rd files exist for methods with different args after roxygenise\", { ... })\n\n**Reproduces**: The core documentation bug — after the fix, three additional `.Rd` files should exist for the methods with differing parameter signatures.\n**File**: `tests/testthat/test-class-forecast-quantile.R` (or a new `test-documentation.R` if preferred)\n**Setup**:\n- Check the `man/` directory for `.Rd` files\n**Action**:\n- Check that `man/as_forecast_quantile.forecast_sample.Rd` exists (or an equivalent separate page)\n- Check that `man/as_forecast_point.forecast_quantile.Rd` exists (or an equivalent separate page)\n- Check that `man/get_pit_histogram.forecast_sample.Rd` exists (or an equivalent separate page)\n**Expected**:\n- All three `.Rd` files exist as separate documentation pages\n- `expect_true(file.exists(\"man/as_forecast_quantile.forecast_sample.Rd\"))` (or whatever naming convention the implementer chooses)\n**Fails now because**:\n- Currently all three methods share their generic's `.Rd` file. `as_forecast_quantile.forecast_sample` is documented in `man/as_forecast_quantile.Rd`, `as_forecast_point.forecast_quantile` in `man/as_forecast_point.Rd`, and `get_pit_histogram.forecast_sample` in `man/get_pit_histogram.Rd`. No separate `.Rd` files exist for these specific methods.\n\n**Note**: This test may not follow typical project conventions (no existing documentation-structure tests exist in the test suite). The implementer should decide whether this test is worth including or if `R CMD check` provides sufficient validation that documentation is correct. The `.Rd` file names will depend on the implementer's choice of `@rdname` or `@name` tags.\n\n### Test 6: test_that(\"formals differ between as_forecast_quantile methods\", { ... })\n\n**Reproduces**: Programmatically validates that the `.default` and `.forecast_sample` methods have different formal arguments, justifying separate documentation pages.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- None needed beyond access to the functions\n**Action**:\n- Get formal argument names for `scoringutils:::as_forecast_quantile.default` and `scoringutils:::as_forecast_quantile.forecast_sample`\n- Compare them\n**Expected**:\n- `expect_true(\"probs\" %in% names(formals(scoringutils:::as_forecast_quantile.forecast_sample)))` — the sample method has `probs`\n- `expect_false(\"probs\" %in% names(formals(scoringutils:::as_forecast_quantile.default)))` — the default method does NOT have `probs`\n- `expect_true(\"quantile_level\" %in% names(formals(scoringutils:::as_forecast_quantile.default)))` — the default method has `quantile_level`\n- `expect_false(\"quantile_level\" %in% names(formals(scoringutils:::as_forecast_quantile.forecast_sample)))` — the sample method does NOT have `quantile_level`\n**Fails now because**:\n- This test should PASS with current code — the formals already differ. It is a regression test ensuring the parameter signatures remain distinct, which is the entire reason for separating documentation pages.\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":449,"cache_read_input_tokens":62513,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":449},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"ded70806-7bb3-4358-9ca2-c7d33ab33636"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ud2uP5fUWhc9uE1fCSmZpW","type":"tool_result","content":"File created successfully at: /Users/nikos/github-synced/scoringutils-pipeline/.ralph/issues/793-document-methods-different-args.md"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e1984a7a-a5c0-4a38-8552-8f68c40c246b","tool_use_result":{"type":"create","filePath":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/issues/793-document-methods-different-args.md","content":"# Issue #793: How should we document methods that have different arguments than the default method?\n\n## Source\n\n- **GitHub**: https://github.com/epiforecasts/scoringutils/issues/793\n- **Action Summary**: Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description.\n- **Status Note**: Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list.\n\n## Test Specifications\n\n**Designed**: 2026-02-13\n**Test file**: `tests/testthat/test-class-forecast-quantile.R` (existing) and `tests/testthat/test-class-forecast-sample.R` (existing) and `tests/testthat/test-class-forecast-point.R` (existing)\n**Testing patterns observed**: testthat with data.table fixtures. Example datasets (`example_quantile`, `example_sample_continuous`, `example_sample_discrete`, `example_point`) pre-loaded. `setup.R` creates pre-computed scores. Tests use `expect_no_condition()`, `expect_error()`, `expect_identical()`, etc.\n\n### Test 1: test_that(\"as_forecast_quantile.forecast_sample() accepts probs and type args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_sample` method works correctly with its method-specific `probs` and `type` arguments, which differ from the `.default` method's `forecast_unit`, `observed`, `predicted`, `quantile_level` args.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- Use `example_sample_continuous` (already available as a `forecast_sample` object)\n**Action**:\n- Call `as_forecast_quantile(example_sample_continuous, probs = c(0.1, 0.5, 0.9), type = 7)`\n**Expected**:\n- Returns a `forecast_quantile` object (check with `is_forecast_quantile()`)\n- The resulting object has exactly the quantile levels 0.1, 0.5, 0.9 (check `unique(result$quantile_level)`)\n- No warnings or errors emitted (`expect_no_condition()`)\n**Fails now because**:\n- This test should PASS with current code. It serves as a regression test ensuring the `.forecast_sample` method's parameter interface remains intact after the `@rdname` change. The current code works; the issue is only about documentation structure.\n\n### Test 2: test_that(\"as_forecast_point.forecast_quantile() extracts median without extra args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_quantile` method works with only `data` and `...` (no `forecast_unit`, `observed`, `predicted` args from `.default`).\n**File**: `tests/testthat/test-class-forecast-point.R`\n**Setup**:\n- Use `na.omit(example_quantile)` piped through `as_forecast_quantile()`\n**Action**:\n- Call `as_forecast_point(quantile_forecast)` with no extra arguments\n**Expected**:\n- Returns a `forecast_point` object (check with `is_forecast_point()`)\n- The `predicted` column contains the median values (0.5 quantile) from the input\n- The result has no `quantile_level` or `sample_id` column\n- No warnings or errors emitted (`expect_no_condition()`)\n**Fails now because**:\n- This test should PASS with current code. It is a regression test confirming that the `.forecast_quantile` method's minimal interface (no extra column-renaming args) continues working after the `@rdname` separation.\n\n### Test 3: test_that(\"get_pit_histogram.forecast_sample() accepts integers and n_replicates args\", { ... })\n\n**Reproduces**: Verifies the `.forecast_sample` method works with its extra `integers` and `n_replicates` parameters, which don't exist on the `.forecast_quantile` method.\n**File**: `tests/testthat/test-class-forecast-sample.R`\n**Setup**:\n- Use `example_sample_discrete` (integer-valued sample forecast)\n**Action**:\n- Call `get_pit_histogram(example_sample_discrete, by = \"model\", integers = \"random\", n_replicates = 50)`\n**Expected**:\n- Returns a data.table with columns `model`, `density`, `bin`, `mid`\n- No errors or unexpected warnings\n- The `density` values are non-negative\n**Fails now because**:\n- This test should PASS with current code. It is a regression test ensuring the `.forecast_sample`-specific `integers` and `n_replicates` parameters remain functional after the `@rdname` split.\n\n### Test 4: test_that(\"get_pit_histogram.forecast_quantile() does not accept integers arg\", { ... })\n\n**Reproduces**: Confirms that the `.forecast_quantile` method does NOT accept the `integers` parameter (which belongs only to `.forecast_sample`). This validates the parameter separation that the documentation fix aims to clarify.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- Use `example_quantile` (a `forecast_quantile` object)\n**Action**:\n- Call `get_pit_histogram(example_quantile, by = \"model\", integers = \"random\")`\n**Expected**:\n- Either raises a warning about unused arguments or silently ignores the `integers` argument (since it's passed through `...`). The key point is that `integers` is NOT a formal parameter of `get_pit_histogram.forecast_quantile()`.\n- Verify via `expect_true(!\"integers\" %in% names(formals(scoringutils:::get_pit_histogram.forecast_quantile)))` that `integers` is not a formal arg of the quantile method.\n**Fails now because**:\n- This test should PASS with current code. It validates the existing parameter separation at the code level, which the documentation change aims to make visible to users.\n\n### Test 5: test_that(\"separate .Rd files exist for methods with different args after roxygenise\", { ... })\n\n**Reproduces**: The core documentation bug — after the fix, three additional `.Rd` files should exist for the methods with differing parameter signatures.\n**File**: `tests/testthat/test-class-forecast-quantile.R` (or a new `test-documentation.R` if preferred)\n**Setup**:\n- Check the `man/` directory for `.Rd` files\n**Action**:\n- Check that `man/as_forecast_quantile.forecast_sample.Rd` exists (or an equivalent separate page)\n- Check that `man/as_forecast_point.forecast_quantile.Rd` exists (or an equivalent separate page)\n- Check that `man/get_pit_histogram.forecast_sample.Rd` exists (or an equivalent separate page)\n**Expected**:\n- All three `.Rd` files exist as separate documentation pages\n- `expect_true(file.exists(\"man/as_forecast_quantile.forecast_sample.Rd\"))` (or whatever naming convention the implementer chooses)\n**Fails now because**:\n- Currently all three methods share their generic's `.Rd` file. `as_forecast_quantile.forecast_sample` is documented in `man/as_forecast_quantile.Rd`, `as_forecast_point.forecast_quantile` in `man/as_forecast_point.Rd`, and `get_pit_histogram.forecast_sample` in `man/get_pit_histogram.Rd`. No separate `.Rd` files exist for these specific methods.\n\n**Note**: This test may not follow typical project conventions (no existing documentation-structure tests exist in the test suite). The implementer should decide whether this test is worth including or if `R CMD check` provides sufficient validation that documentation is correct. The `.Rd` file names will depend on the implementer's choice of `@rdname` or `@name` tags.\n\n### Test 6: test_that(\"formals differ between as_forecast_quantile methods\", { ... })\n\n**Reproduces**: Programmatically validates that the `.default` and `.forecast_sample` methods have different formal arguments, justifying separate documentation pages.\n**File**: `tests/testthat/test-class-forecast-quantile.R`\n**Setup**:\n- None needed beyond access to the functions\n**Action**:\n- Get formal argument names for `scoringutils:::as_forecast_quantile.default` and `scoringutils:::as_forecast_quantile.forecast_sample`\n- Compare them\n**Expected**:\n- `expect_true(\"probs\" %in% names(formals(scoringutils:::as_forecast_quantile.forecast_sample)))` — the sample method has `probs`\n- `expect_false(\"probs\" %in% names(formals(scoringutils:::as_forecast_quantile.default)))` — the default method does NOT have `probs`\n- `expect_true(\"quantile_level\" %in% names(formals(scoringutils:::as_forecast_quantile.default)))` — the default method has `quantile_level`\n- `expect_false(\"quantile_level\" %in% names(formals(scoringutils:::as_forecast_quantile.forecast_sample)))` — the sample method does NOT have `quantile_level`\n**Fails now because**:\n- This test should PASS with current code — the formals already differ. It is a regression test ensuring the parameter signatures remain distinct, which is the entire reason for separating documentation pages.\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01K2qfWvtVjjSpgB6CATLTDo","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the triage table."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2577,"cache_read_input_tokens":62962,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2577},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"822f9bd5-f0be-431a-9f24-f8af161c997e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01K2qfWvtVjjSpgB6CATLTDo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Jx8J657fS5awVocF6rg41e","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"completed","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"in_progress","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2577,"cache_read_input_tokens":62962,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2577},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"6e750ef2-8afc-450f-a09c-bede98346c93"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Jx8J657fS5awVocF6rg41e","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"b206119e-14e4-4ea4-b90b-118616951b80","tool_use_result":{"oldTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"in_progress","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"pending","activeForm":"Updating triage table"}],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"completed","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"in_progress","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WVrD7pDsYdGKweVMPG8JWN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Dy4Pe6JTNoKa6T3g8ysMHR","name":"Edit","input":{"replace_all":false,"file_path":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md","old_string":"| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |","new_string":"| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [x] | [ ] | — | [ ] |"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":263,"cache_read_input_tokens":65539,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":263},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"a91c8b81-bb6d-4db3-8e93-52eed328a840"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Dy4Pe6JTNoKa6T3g8ysMHR","type":"tool_result","content":"The file /Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"37469a34-ea7a-42c0-94e6-5bbdd8fba5c9","tool_use_result":{"filePath":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md","oldString":"| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |","newString":"| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [x] | [ ] | — | [ ] |","originalFile":"# scoringutils Issue Triage\n\n> Auto-generated by Ralph triage loop. Do not edit manually during the loop.\n\n## Summary\n\n| Metric | Count |\n|--------|-------|\n| Total open issues | 106 |\n| Triaged | 106 |\n| Remaining | 0 |\n\n## Pipeline\n\n- [ ] **Test design** — Test specs written for automatable issues\n- [ ] **Implement** — Fixes implemented, PRs created\n- [ ] **Review** — All PRs independently reviewed\n- [ ] **Summary** — Human summary generated\n\n## Issues\n\n| # | Title | Labels | Opened | Category | Priority | Complexity | Automatable | Status Note | Dependencies | Action Summary | Has Tests | Implemented | PR | Reviewed |\n|---|-------|--------|--------|----------|----------|------------|-------------|-------------|--------------|----------------|-----------|-------------|-----|----------|\n| 1065 | Release reminder - February 2026 | | 2026-02-02 | meta | medium | medium | partially | Automated reminder. Dev version (2.1.2.9000) has multivariate feature + bug fix accumulated over 161 days. No blocking bugs. Two open PRs (#1060, #1062) are infrastructure changes. | Maintainers should decide whether to merge #1060/#1062 before releasing. | Decide whether to cut a new release (likely v2.2.0 given multivariate feature). If yes, run `usethis::use_release_issue()` and proceed with CRAN submission. If not, close the issue. | N/A | N/A | — | N/A |\n| 1064 | Pre-ranking for multivariate calibration assessment | | 2026-01-30 | feature | medium | large | no | No pre-ranking or multivariate calibration diagnostics exist in the codebase. The `forecast_sample_multivariate` class and energy score are implemented and stable. Design decision needed: integrate into `score()` (Option A) or standalone `get_multivariate_ranks()` function (Option B). MST method may need `igraph` dependency. | None blocking. Builds on existing `forecast_sample_multivariate` infrastructure. | Implement pre-ranking methods (multivariate rank, optionally MST rank) from Gneiting et al. (2008) as calibration diagnostics for multivariate forecasts, after resolving the API design choice with maintainers. | N/A | N/A | — | N/A |\n| 1057 | Revise README to remove news about the package rewrite | documentation | 2026-01-29 | documentation | low | medium | partially | Open, no assignee. The rewrite messaging and Google Drive paper links appear in 4 locations in README.Rmd. Mechanical edits are straightforward but replacement text requires editorial decisions about where to point users for documentation. | Loosely related to #810 (pkgdown for dev docs) and #759 (future of scoringutils.Rmd vignette). | Edit `README.Rmd` to remove/soften the \"major re-write\" paragraph and replace Google Drive paper links with pointers to package vignettes/docs, then re-render README.md. Confirm preferred documentation hierarchy with maintainers first. | N/A | N/A | — | N/A |\n| 1055 | Model confidence sets | feature request | 2026-01-19 | feature | medium | large | no | Design phase — methodology not yet agreed upon. 6 comments with active debate. Naive pairwise p-value approach acknowledged as incomplete. Three alternatives discussed: Hansen et al. MCS, novel extension for incomplete sets, Bayesian approach. No consensus reached. | Relates to #750 (p-value computation refactor), #769 (pairwise comparison arguments), #37 (Diebold-Mariano test), #1022 (two-model pairwise). | Resolve design consensus on which MCS methodology to implement (Hansen et al. on complete sets, novel incomplete-set extension, or Bayesian), then implement `get_model_confidence_set()` building on existing pairwise comparison infrastructure. | N/A | N/A | — | N/A |\n| 1046 | multivariate scoring in scoring rules vignette | documentation | 2025-11-04 | documentation | low | small | partially | Open, agreed upon by maintainers. The scoring-rules vignette has zero mentions of multivariate scoring. A dedicated multivariate vignette already exists. Only a cross-reference and brief section are missing. | None. All underlying code and the dedicated multivariate vignette already exist. | Add a short section to `vignettes/scoring-rules.Rmd` describing the energy score for multivariate forecasts and cross-linking to the existing `scoring-multivariate-forecasts` vignette. No code changes needed. | N/A | N/A | — | N/A |\n| 1044 | Remove the commented out vignette code. | | 2025-09-23 | cleanup | low | small | yes | Still relevant. Two HTML comment blocks remain: a WIP \"Details on the grouping\" section in `scoring-multivariate-forecasts.Rmd` (lines 88-102) and a ~50-line PIT/Calibration section in `scoring-rules.Rmd` (lines 444-493). Originated from PR #998 review comment. | None. | Delete the two HTML-commented-out code blocks from `vignettes/scoring-multivariate-forecasts.Rmd` and `vignettes/scoring-rules.Rmd`. Optionally confirm with maintainers whether the PIT/Calibration text should be preserved elsewhere. | N/A | [ ] | — | [ ] |\n| 1043 | Update print method for multivariate forecasts to show `joint_across` | | 2025-09-21 | enhancement | low | small | yes | Still relevant. No `print.forecast_sample_multivariate` method exists; the generic `print.forecast` handles all types. `joint_across` is not stored as an attribute — `set_grouping()` computes `.mv_group_id` but discards the original `joint_across` value. | Builds on multivariate infrastructure from merged PR #998. | Add a `print.forecast_sample_multivariate()` method that displays `joint_across` columns. Requires either storing `joint_across` as an attribute during object construction or computing it as the set difference between forecast unit and `get_grouping()` output. Update test snapshots. | [x] | [ ] | — | [ ] |\n| 1026 | as_forecast_sample.forecast_quantile | enhancement | 2025-07-13 | enhancement | medium | medium | partially | Still relevant. The reverse conversion (`as_forecast_quantile.forecast_sample`) exists, but `as_forecast_sample.forecast_quantile` does not. No distribution-fitting dependencies in DESCRIPTION. Author plans to borrow from hubverse approach. | Related to #557 (sample_to_quantile.numeric). May introduce new dependency (e.g., `distfromq`). | Implement `as_forecast_sample.forecast_quantile()` S3 method that fits a distribution or uses interpolation to approximate the predictive CDF from quantiles and draws samples. Requires design decision on approximation method and potential new package dependency. | N/A | N/A | — | N/A |\n| 1022 | Let `get_pairwise_comparison()` run with two models? | | 2025-07-03 | enhancement | low | small | yes | Still relevant. The check at line 162 of `R/pairwise-comparisons.R` calls `cli_abort()` when `length(setdiff(comparators, baseline)) < 2`, blocking the 2-models-with-baseline case. Maintainer has expressed agreement to change to a warning. Also has typo \"compairisons\". | None. Self-contained change. | Change the `cli_abort()` to `cli_warn()` at line 162 of `R/pairwise-comparisons.R` so that 2 models with one as baseline emits a warning instead of an error. Update test expectations and fix the \"compairisons\" typo. | [x] | [ ] | — | [ ] |\n| 1002 | LaTeX not rendering in function reference | | 2025-05-20 | documentation | medium | small | yes | Still relevant. pkgdown defaults to `mathml` which doesn't handle the 63 `\\eqn{}`/`\\deqn{}` occurrences in 4 metrics files. Upstream r-lib/pkgdown#2704 is closed (won't fix mathml); recommended fix is to use `mathjax` or `katex`. No `math-rendering` setting exists in `_pkgdown.yml`. | None internally. CRAN release needed for release site fix. | Add `math-rendering: katex` (or `mathjax`) under the `template:` key in `_pkgdown.yml` and rebuild the pkgdown site. One-line config change fixes all 63 LaTeX expressions across 4 documentation files. | [x] | [ ] | — | [ ] |\n| 986 | Test scores are correct | | 2025-02-21 | enhancement | medium | medium | partially | Still relevant. WIS has reference tests (CovidHubUtils), `logs_binary` validates against `Metrics::ll`, `rps_ordinal` against `scoringRules::rps_probs`. But CRPS/DSS/log_score for sample-based forecasts, dispersion, overprediction, underprediction lack absolute-value tests. No snapshot tests pin numerical outputs on example datasets. | None | Add (1) snapshot tests pinning `score()` output on each built-in example dataset, and (2) targeted correctness tests validating key sample-based scoring functions against known analytical solutions or external reference implementations. | N/A | N/A | — | N/A |\n| 983 | Create `.data.frame` methods for `as_forecast<type>` | | 2025-01-14 | refactor | low | small | yes | Still relevant. Prerequisite #981 (making `as_forecast_*` S3 generics) is done. Currently all 7 types only have `.default` methods; no `.data.frame` methods exist. The `.default` methods silently accept any type and rely on `as.data.table()` coercion deep inside. | #981 (done). No blockers. | Rename the 7 existing `.default` methods to `.data.frame` (since they assume data.frame-like input), then create new `.default` methods that error with a helpful message about unsupported types. Update NAMESPACE, docs, and tests. | [x] | [ ] | — | [ ] |\n| 975 | Add link to score definitions in `summarise_score()` | | 2024-11-05 | enhancement | low | small | yes | Still relevant. No `print.scores` method exists anywhere in the codebase. Scores objects fall through to data.table's default print. The scoring rules vignette exists at the expected URL. Maintainers favor option 1 (link to docs) over printing definitions. | Closely related to #667 (create `print.scores` method). Should be aware of #935 (print side-effects on column mutation). | Create a `print.scores()` S3 method in `R/class-scores.R` that calls `NextMethod()` then appends a `cli_text()` link to the scoring rules vignette. Ideally coordinate with #667 to also show the metrics used. | [x] | [ ] | — | [ ] |\n| 944 | Make `get_metrics()` more customisable | enhancement, feature request | 2024-10-08 | enhancement | low | medium | partially | Still relevant. `get_metrics()` is an S3 generic with `select`/`exclude` args (via #832/#903), but the proposed `replace` argument for inline metric customization has not been implemented. The `add_args` idea from the issue body is less well-defined. | #832 (done). Related to #789 (documenting customization workflow). | Add a `replace` argument to `select_metrics()` and propagate through all 7 `get_metrics.forecast_*` methods, accepting a named list of functions to substitute by name. Evaluate whether `add_args` is worth implementing or should be dropped. | N/A | N/A | — | N/A |\n| 942 | Discrimination plots for binary forecasts | enhancement, feature request | 2024-10-07 | feature | low | small | yes | Still relevant. No binary-specific plot functions exist in the codebase. No discrimination plot, reliability diagram, or any binary visualization exists. The `forecast_binary` class and `example_binary` dataset provide exactly the data structures needed. | None. Thematically adjacent to #49 (calibration plotting) and #286 (diagnostics) but no hard dependency. | Implement a new `plot_discrimination()` function that accepts a `forecast_binary` object, groups predicted probabilities by the two levels of observed, and renders overlapping density plots via ggplot2, with optional faceting by model. Add tests and docs. | [x] | [ ] | — | [ ] |\n| 941 | Rethink `score()` and maybe make it not S3 anymore | refactor | 2024-10-06 | refactor | medium | medium | no | Still relevant. All 7 `score.forecast_*` S3 methods share near-identical boilerplate (clean, validate, reshape, apply_metrics, as_scores). Only the reshape step differs per type. No refactoring has been done since the issue was opened. Both opener and reviewer agree on the direction. | Related to #338 (cross-type metrics). Benefits from #982 (done). | Refactor `score()` from 7 S3 methods into a single function by extracting the type-specific data reshaping into a new internal S3 generic (e.g., `prepare_for_scoring()`). Requires design decision on the preparation step's interface. | N/A | N/A | — | N/A |\n| 939 | remove `check_input_<forecast_type>` functions | refactor | 2024-10-03 | refactor | low | small | partially | Still relevant. All 5 `check_input_*` functions exist. 3 (sample, quantile, interval) are unused in production code — only tested. 2 (binary, point) are used in `assert_forecast` methods. Other types (sample, quantile) already skip the check pattern, showing inconsistency. | Supersedes #684 (subset of this issue). | Delete all 5 `check_input_*` functions and their man pages. For the 2 in use (binary, point), refactor call sites to call `assert_input_*` directly or inline `check_try()`, matching the pattern already used by sample/quantile. Close #684 as duplicate. | N/A | N/A | — | N/A |\n| 938 | Rename/refactor? `assert_dims_ok_point` | refactor, low-priority | 2024-10-03 | refactor | low | small | partially | Still relevant. `assert_dims_ok_point` is used by both `assert_input_point` and `assert_input_binary`, making the `_point` suffix misleading. The function is a general-purpose dimension check. Companion `check_dims_ok_point` also exists. ~5 files to update. | None. | Rename `assert_dims_ok_point` (and `check_dims_ok_point`) to a type-agnostic name (e.g., `assert_dims_ok_scalar` or `assert_dims_match`). Update definition, 2 call sites, tests, and docs. Optionally move out of `metrics-point.R` into a shared file. | N/A | N/A | — | N/A |\n| 935 | `forecast` and `scores` objects print output every time a column is changed | high-priority | 2024-09-29 | bug | medium | large | no | Still relevant. Core bug unfixed: `print.forecast` dispatches to `print.data.table` via `NextMethod()`, which breaks data.table's internal `:=` print-suppression (call stack too deep for `shouldPrint()`). PR #956 only worked around nominal forecast validation errors with a `nrow > 30` hack. The `scores` side may no longer be affected (no `print.scores` exists). | Related to #667 (print.scores — would reintroduce problem), #685 (suppress printing in tests), #1043 (multivariate print). | Design decision needed: (a) accept cosmetic annoyance, (b) reimplement `print.forecast` without dispatching to `print.data.table` (e.g., use `format.data.table` + manipulate `.global$print`), or (c) pursue upstream data.table fix per @MichaelChirico's suggestion. | N/A | N/A | — | N/A |\n| 934 | Use illustration of local and global scores | documentation | 2024-09-28 | documentation | low | small | partially | Still relevant. `score-locality.png` already exists in `vignettes/` but is orphaned — not referenced by any vignette. The scoring-rules vignette mentions local/global in text only, with no visual. Code to regenerate is in the issue body. | Sibling issues: #929, #930, #933 (all repurpose manuscript illustrations). Consider batching. | Add the existing `score-locality.png` to `scoring-rules.Rmd` (or a new comparative vignette) with an explanatory paragraph on local vs. global scoring rules. Coordinate with #929/#930/#933 for a unified approach. | N/A | N/A | — | N/A |\n| 933 | Use nice illustration of CRPS/DSS/Log score + the number of samples needed for scores to converge | documentation | 2024-09-28 | documentation | low | medium | partially | Still relevant. `score-convergence-outliers.png` already exists in `vignettes/` but is orphaned (not referenced by any vignette). Issue #758 contains a detailed draft vignette stub (\"Choosing a scoring rule\") that already references this PNG with prose. Should be batched with siblings #929, #930, #934. | Sibling issues #929, #930, #934. Parent issue #758 (scoring rules explanation vignette). Related to #759 (vignette future). | Create a new \"Choosing a scoring rule\" vignette (per #758's stub) or integrate `score-convergence-outliers.png` into `scoring-rules.Rmd` with explanatory text on sample convergence and score properties. Best addressed as a batch with #929/#930/#934 under #758. | N/A | N/A | — | N/A |\n| 930 | Use nice illustration of the effect of increasing the mean on increasing average scores | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. `illustration-effect-scale.png` already exists in `vignettes/` but is orphaned. A deleted stub vignette (`Choosing-a-score.Rmd`) once referenced it. Author expressed uncertainty (\"maybe we don't want it anymore\"). Should be batched with siblings #929, #933, #934. | Sibling issues #929, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future). | Decide whether to integrate `illustration-effect-scale.png` into `scoring-rules.Rmd` or a new \"Choosing a score\" vignette, with text explaining how average scores scale with forecast target magnitude. If unwanted, close and delete orphaned PNG. Address with #929/#933/#934 as batch. | N/A | N/A | — | N/A |\n| 929 | Use nice illustration of Sharpness and calibration | documentation | 2024-09-27 | documentation | low | medium | partially | Still relevant. Unlike siblings (#930, #933, #934), the calibration/sharpness PNG does **not** exist in the repo — it was never generated. Code to create it is in the issue body. The `scoring-rules.Rmd` has a commented-out calibration section (lines ~449-492) where this illustration would naturally fit. | Sibling issues #930, #933, #934. Related to #758 (scoring rules vignette), #759 (vignette future), #785 (vignette updates). | Generate `calibration-sharpness-illustration.png` from the code in the issue body, place in `vignettes/`, and integrate into `scoring-rules.Rmd` (or a new \"Choosing a score\" vignette). Coordinate with #930/#933/#934 batch. | N/A | N/A | — | N/A |\n| 927 | Make all internal columns, in particular `forecast_id`, more robust by prefixing it with \"scoringutils_\" | good first issue, high-priority | 2024-09-26 | refactor | high | medium | partially | Still relevant. Unprefixed internal columns (`forecast_id`, `weight`, `boundary`) risk collision with user data columns. Codebase already mixes two conventions: `.scoringutils_*` (e.g., `.scoringutils_N`) and `scoringutils_Internal*`. ~3 source files, 1 globalVariables file, 1 snapshot to update for `forecast_id` alone. Not a breaking change — all affected columns are internal. | None blocking. Self-contained refactor. | Rename unprefixed internal temp columns (`forecast_id`, `weight`, `boundary`) to `.scoringutils_` prefix, matching existing convention. Update `R/helper-quantile-interval-range.R`, `R/metrics-quantile.R`, `R/z-globalVariables.R`, and test snapshots. Also unify the two naming conventions (`.scoringutils_*` vs `scoringutils_Internal*`). | N/A | N/A | — | N/A |\n| 922 | remove `check_columns_present` | | 2024-09-25 | cleanup | low | small | yes | Still relevant. `check_columns_present` (and `test_columns_present`) are internal functions with 10 call sites across 9 files. All can be replaced by `checkmate::assert_subset`/`check_subset`/`test_subset` (already a dependency). One call site in `pairwise-comparisons.R:143` uses a custom error message and needs slightly different handling. No user-facing API impact. | Related to #839 (remove `test_columns_not_present`) — both modify `R/check-input-helpers.R`, should be batched. | Replace all 10 call sites of `check_columns_present` (and 1 of `test_columns_present`) with equivalent `checkmate` functions, then delete both functions and their tests. Consider batching with #839. | [x] | [ ] | — | [ ] |\n| 909 | Compact version of `get_duplicate_forecasts()` | enhancement, good first issue, help wanted | 2024-09-13 | enhancement | low | small | yes | Already implemented. The `counts` parameter on `get_duplicate_forecasts()` provides exactly the compact output requested. Tests exist. Issue can be closed. | None | Close this issue — the `counts` argument already provides compact/aggregated duplicate output. No further code changes needed. | N/A | N/A | — | N/A |\n| 907 | coverage of function factory | enhancement | 2024-09-12 | enhancement | low | small | partially | Still relevant. No factory helper exists. Users must manually use `purrr::partial()` (documented in `score()` docs). Only `interval_coverage` benefits currently. Hard-coded 50% and 90% variants in `get_metrics.forecast_quantile()`. Discussion stalled after 5 comments with no consensus on approach. | Related to #451 (quantile/interval metric organization), #668 (coverage flexibility). | Add either a generic `expand_metric()` utility or a `coverage_ranges` argument to `get_metrics.forecast_quantile()` to programmatically generate multiple parameterized coverage metric variants. Needs design decision on approach given only one metric currently benefits. | N/A | N/A | — | N/A |\n| 898 | Support for \"Mixture of Parameters\" scoring | feature request | 2024-09-06 | feature | low | large | partially | Still relevant but low urgency. No `forecast_distribution` class exists. Prerequisites #832 (metrics S3 rework) and #846 (ordinal class) are done. Original requester has deprioritized. Would require new class, input format design, dispatch to `scoringRules` parametric functions, and mixture handling. | #888 (S3 rework of `get_duplicate_forecasts()` — minor blocker for clean extensibility). Builds on completed #832, #846. | Implement a new `forecast_distribution` class for scoring forecasts expressed as parametric distributions or mixtures, dispatching to `scoringRules`' closed-form scoring functions. Deferred until active demand — keep on `scoringutils-2.x` milestone. | N/A | N/A | — | N/A |\n| 895 | Check quantile prediction order helper function | enhancement | 2024-08-19 | enhancement | medium | small | yes | Still relevant. Monotonicity check only exists deep in `bias_quantile_single_vector()` (metrics-quantile.R:495) as a hard error. No early warning in `assert_forecast.forecast_quantile()`. No user-facing diagnostic function. Issue #412 is the maintainer-created parent with an agreed plan (steps 1 and 3 not done). | Duplicate of / should be resolved together with #412. | Create a user-facing helper (e.g., `get_non_monotonic_forecasts()`) to identify rows where predictions decrease with increasing quantile level, and add a warning in `assert_forecast.forecast_quantile()`. Resolves both #895 and #412. | [x] | [ ] | — | [ ] |\n| 889 | Make `get_protected_columns()` S3 to avoid hard-coding things | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. `get_protected_columns()` is a plain function with a hard-coded superset of all column names for all forecast types. Not S3. Only 2 call sites (both in `forecast-unit.R`). The `intersect()` filter masks the problem but prevents extensibility for new forecast classes. No progress made. | Coordinate with #888 (same S3 pattern for `get_duplicate_forecasts()`). Unblocks #852 (new forecast class workflow). Largely resolves #740 (`get_forecast_unit` customization). | Convert `get_protected_columns()` into an S3 generic with per-class methods so each forecast type declares its own protected columns. Coordinate with #888 for consistent pattern. | N/A | N/A | — | N/A |\n| 888 | Rework `get_duplicate_forecasts()` to S3 to avoid hard-coding columns and types | high-priority | 2024-08-10 | refactor | high | medium | partially | Still relevant. Function hard-codes `c(\"sample_id\", \"quantile_level\", \"predicted_label\")` in two places instead of dispatching on S3 class. No work done. Codebase has many S3 precedents now. | Coordinate with #889 (same pattern for `get_protected_columns()`). Partially blocks #898, #852. Related to #740. | Convert `get_duplicate_forecasts()` into an S3 generic with per-class methods where each method knows its own type-specific columns. Retain a `.data.frame`/`.default` method with current column-sniffing logic for backward compatibility. | N/A | N/A | — | N/A |\n| 885 | Functions to export or make internal | refactor, high-priority | 2024-08-10 | refactor | medium | medium | no | Partially done. `validate_forecast()` already deleted (PR #921). Remaining: `as_forecast_generic()`, `as_scores()`, `apply_metrics()` still internal; `new_forecast()` ambiguously exported with `@keywords internal`. Design decision needed on which functions to export for custom forecast class authors. | Depends on #746 (closed). Blocks custom forecast class creation. Related to #852 (design workflow for new classes). | Decide final export list for custom forecast class API: export `as_forecast_generic()`, `as_scores()`, `apply_metrics()`, resolve ambiguous `new_forecast()` status, and update NAMESPACE. Needs maintainer decision on naming/prefixing. | N/A | N/A | — | N/A |\n| 880 | Allow users to specify the quantile in `as_forecast_point.forecast_quantile()? | | 2024-07-30 | enhancement | low | small | yes | Still relevant. Function hard-codes `0.5` on two lines (107, 115) in `R/class-forecast-quantile.R`. Design decisions already resolved in PR #876 discussion: parameter name `quantile_level`, default `0.5`, passed via `...`. No work done since issue opened. | None. Self-contained enhancement. | Add a `quantile_level` parameter (default `0.5`) to `as_forecast_point.forecast_quantile()`, replacing the two hard-coded `0.5` references, then add tests and documentation. | [x] | [ ] | — | [ ] |\n| 872 | Add a reference for CRPS decomposition approach. | | 2024-07-25 | documentation | low | small | partially | Still relevant. `crps_sample()` in `R/metrics-sample.R` has only a `scoringRules` package reference, not one for the decomposition approach. `wis()` already properly cites Bracher et al. 2021. Minor decision needed on which paper(s) to cite: Bracher et al. 2021 and/or Arnold et al. 2023. | Related to #870 (CRPS/WIS decomposition refactor). Could be addressed in same PR. | Add `@references` entries to `crps_sample()` roxygen block citing paper(s) formalizing the overprediction/underprediction/dispersion decomposition (likely Bracher et al. 2021 and/or Arnold et al. 2023). | N/A | N/A | — | N/A |\n| 870 | Refactor CRPS and WIS decomposition | refactor | 2024-07-22 | refactor | low | medium | partially | Partially addressed. PR #985 (Feb 2025) simplified `crps_sample()` decomposition internally, but the structural duplication remains: `crps_sample()`, `wis()`, and `interval_score()` each independently implement `separate_results` branching, and 6 wrapper functions (3 sample + 3 quantile) repeat identical extraction patterns. | Related to #872 (CRPS decomposition reference). Filed during PR #854 review. On `scoringutils-2.x` milestone. | Extract the decomposition logic (`separate_results` branching and wrapper function boilerplate) into a shared internal helper or factory pattern so `crps_sample()`, `wis()`, and `interval_score()` delegate to the same mechanism instead of each implementing it independently. | N/A | N/A | — | N/A |\n| 852 | Design workflow for creating new forecast classes | enhancement | 2024-07-10 | enhancement | high | large | no | Still relevant. The building blocks exist (`new_forecast()` exported, `as_forecast_generic()` internal, pattern visible in 7 class files) but no documentation, vignette, or guide for third-party class creation exists. Three prerequisite S3 refactors (#889, #888, #740) remain open and block clean extensibility because `get_protected_columns()` and `get_duplicate_forecasts()` hard-code column names, preventing new classes from working seamlessly. `as_forecast_generic()`, `apply_metrics()`, and `as_scores()` are still unexported (#885). | #889 (S3 `get_protected_columns`), #888 (S3 `get_duplicate_forecasts`), #740 (`get_forecast_unit` customization), #885 (export decision for helper functions). | Complete prerequisite S3 refactors (#889, #888), decide export list for class-creation helpers (#885), then write a vignette or article documenting the step-by-step workflow for creating a custom `forecast_*` class (define `as_forecast_<type>`, `assert_forecast.<type>`, `score.<type>`, `get_metrics.<type>`, `get_protected_columns.<type>`, `get_duplicate_forecasts.<type>`). | N/A | N/A | — | N/A |\n| 840 | Clean up input checks | | 2024-06-07 | refactor | low | medium | partially | Still relevant. Input checks are applied inconsistently: `assert_forecast.forecast_binary` and `assert_forecast.forecast_point` call `check_input_*` wrappers (double-validating with scoring functions), while sample/quantile/ordinal/nominal types skip this. `check-input-helpers.R` has a comment marking `check_try()` and wrappers for future deletion. Author leans toward pushing all checks to the scoring-function level. No work done. | Related to #939 (remove `check_input_*` functions), #839, #922. On `scoringutils-2.x` milestone. | Decide where input validation should live (scoring-function level vs. `assert_forecast` level vs. both-consistently). Then either remove `check_input_binary`/`check_input_point` calls from `assert_forecast` methods and delete wrappers + `check_try()`, or add missing checks to sample/quantile `assert_forecast` methods for consistency. | N/A | N/A | — | N/A |\n| 839 | Remove `test_columns_not_present` | | 2024-06-07 | cleanup | low | small | yes | Still relevant. `test_columns_not_present()` is a trivial 1-line wrapper around `checkmate::test_names(..., disjunct.from = ...)` with exactly 1 production call site (`R/class-forecast-binary.R:68`) and 1 test block. `checkmate::test_names` is already imported. Straightforward removal. | Related to #922 (remove `check_columns_present`) and #840 (clean up input checks). Can be batched but has no blocking dependency. | Replace the single call in `R/class-forecast-binary.R:68` with `test_names(colnames(forecast), disjunct.from = ...)`, delete the function definition in `R/check-input-helpers.R`, delete the test block, and remove the generated man page. Optionally bundle with #922. | [x] | [ ] | — | [ ] |\n| 826 | Update `plot_heatmap()` to be a table instead of a plot | | 2024-05-19 | enhancement | low | medium | partially | Still relevant. Accessibility concern from @Bisaloo is valid: current ggplot2 heatmap renders values as image text, inaccessible to screen readers. Conversation stalled — Bisaloo never replied to follow-up about output format (HTML/LaTeX). `kableExtra` is already in `Suggests`. This is a breaking change: function returns `ggplot` object, used with `+ facet_wrap()` in `inst/manuscript/`. Not used in any current vignette. Design decision needed on migration strategy. | None blocking. Thematically adjacent to #713 (visualization vignette). | Resolve stalled design conversation on output format and migration strategy (deprecate + new function vs. breaking change). Implement colored-table version using `kableExtra` (already in Suggests) or `gt` (new dep), update manuscript, replace test/snapshot, and deprecate or replace `plot_heatmap()`. | N/A | N/A | — | N/A |\n| 825 | Package scaffolding | | 2024-05-19 | refactor | low | small | yes | Still relevant. Neither recommendation acted upon: (1) `Metrics` package still imported for 3 trivial functions (`ae`, `se`, `ape`) used only in `R/class-forecast-point.R` — these are one-line base-R replacements. `Metrics` did receive a 2025 CRAN update, reducing urgency. (2) `matrixStats` not adopted; 3 `apply()` calls in `R/metrics-sample.R` could benefit. Suggest splitting into two sub-tasks, prioritizing `Metrics` removal as a quick win. | None blocking. Removing `Metrics` requires updating vignettes (`scoring-rules.Rmd`) and tests (`test-metrics-binary.R`) that reference `Metrics::` functions. | (1) Replace `Metrics::ae/se/ape` with internal one-liners in `R/class-forecast-point.R`, remove from DESCRIPTION/NAMESPACE, update vignettes and tests. (2) Optionally evaluate adding `matrixStats` for 3 `apply()` calls — lower value, separate decision. | [x] | [ ] | — | [ ] |\n| 823 | Reduce number of `try()`, `suppressMessages()`, `suppressWarnings()` used in the package | | 2024-05-19 | refactor | medium | medium | no | Still relevant. 8 direct `try()` calls + 6 indirect via `check_try()` + 1 `suppressWarnings(suppressMessages(...))` in R/ code. Usage has slightly increased since filing due to new `[.forecast` subsetting operators (PR #884). Each `try()` exists for a reason; removal requires architectural rethinking of validation flow, not simple find-and-replace. | Deeply linked to #935 (print on column change), #840 (input check cleanup), #939 (remove `check_input_*`), #885 (export decisions), #811 (batch warnings). | Address incrementally: (1) Replace blanket `try()` in subsetting operators with targeted `tryCatch()`, (2) add `verbose` params to internal validation paths to eliminate `suppress*()`, (3) replace `check_try()` with proper `check_*()` functions as part of #840. | N/A | N/A | — | N/A |\n| 811 | Should `score()`/`apply_metrics()` return warning about failed metrics in a batch? | enhancement | 2024-05-07 | enhancement | low | small | yes | Still relevant. `run_safely()` in `R/score.R:210` uses `try()` + immediate `cli_warn()` per failed metric. No batching/deferring mechanism exists. Failed metrics silently dropped from `scores` object via `as_scores()` filtering. Blog post on deferred errors referenced in issue. Only 1 comment from maintainer (\"I like this idea\"). | None blocking. Tangentially related to #823 (reduce `try()`) and #382 (metric/column name clash warnings). | Modify `apply_metrics()`/`run_safely()` to collect error messages in a list during the `lapply` loop, then emit a single batched `cli_warn()` summarizing all failed metrics at the end. Update test expectations in `test-score.R`. | [x] | [ ] | — | [ ] |\n| 810 | Clean up readme by using `pkgdown` to render dev version docs | | 2024-05-05 | documentation | low | small | yes | CLOSED (completed 2026-02-09). PR #1060 merged today, replacing R-based `packageVersion()` detection with pkgdown selective HTML (`.pkgdown-devel`/`.pkgdown-release` fenced divs). `_pkgdown.yml` already had `development: mode: auto`. Dev docs deployed at `/dev/` on gh-pages. | None. Fully resolved. | No action needed — issue closed via merged PR #1060. | N/A | N/A | — | N/A |\n| 808 | Run lintr everywhere | | 2024-05-05 | cleanup | low | medium | partially | Active work in progress. PR #1062 (\"enable lintr for tests, inst, and vignettes\") is open but not yet merged. `.lintr` excludes all `tests/`, `inst/`, and `vignettes/*.R` files. CI only lints changed files on PRs. Main scope is `tests/` (~5,400 lines across 35 files). `inst/` has only 2 R files. `vignettes/*.R` not tracked in git (auto-generated tangles). ~90 `nolint` annotations already exist in `R/` source. | #807 (cli nolint cleanup) should be done first to establish pattern. #513 (vignette .R scripts) related to vignette exclusion. PR #1062 is in flight. | Merge or rebase PR #1062 once reviews pass. May need to fix remaining lint violations or add targeted `# nolint` annotations. Address `tests/` directory-wide lint cleanup separately from `inst/` and `vignettes/`. | N/A | N/A | — | N/A |\n| 807 | Clean up linter statements around `cli` conditions | good first issue, implementation-ready | 2024-05-05 | cleanup | low | medium | yes | Still relevant. ~43 `#nolint start: keyword_quote_linter` blocks across R/ wrap `cli_abort()`/`cli_warn()` calls that use `\"!\" =`, `\"i\" =` named vector syntax. Only 12 instances use Hugo's backtick fix (`\\`!\\` =`). The fix is mechanical: replace `\"!\" =` with `` `!` = `` inside cli condition calls, then remove the `nolint` annotations. Additional `object_usage_linter` suppressions (14 blocks) exist for `.data[...]` patterns in data.table code — these need separate handling. No work done on this issue since filing. | Prerequisite for #808 (run lintr everywhere). Related to PR #583 (which introduced the cli pattern). | Replace all `\"!\" =`, `\"i\" =`, `\"x\" =`, `\"v\" =` with backtick-quoted equivalents (`` `!` = ``, etc.) in `cli_abort()`/`cli_warn()` calls across ~20 R/ files, then delete the corresponding `#nolint start`/`#nolint end` blocks. Handle `object_usage_linter` suppressions separately. | [x] | [ ] | — | [ ] |\n| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |\n| 789 | Add documentation about how to customise scores | documentation | 2024-04-13 | documentation | medium | medium | partially | Partially addressed. The `score()` roxygen docs now have a \"Customising metrics\" section with `purrr::partial()` examples (PR #874). But the core ask — a vignette walkthrough — remains undone. No vignette covers `get_metrics()` → `select_metrics()` → `purrr::partial()` → `score()` workflow. On `scoringutils-2.x` milestone. | Related to #546 (vignette restructuring — decides where customization docs go), #666 (manuscript update). | Create a vignette section (or standalone vignette) walking users through the full metric customization workflow: `get_metrics()`, `select_metrics()`, `purrr::partial()`, custom metric functions, and passing to `score()`. Coordinate with vignette restructuring in #546. | N/A | N/A | — | N/A |\n| 785 | Small updates to the scoring rules Vignette | documentation | 2024-04-10 | documentation | low | small | yes | Still relevant. None of the 7 suggestions from @seabbs's review of PR #762 have been implemented: author field still present, Google Drive link still used, no citations for proper scoring rules or transformed scores paper, `get_metrics` wording not improved for website readers, no introductory paragraph on different probabilistic forecast types. Nearly 2 years open with no progress on these items. | Loosely related to #666 (manuscript update re: Google Drive link), #758 (scoring rules vignette parent issue), #1046 (multivariate scoring in same vignette). | Implement the 7 small documentation edits in `vignettes/scoring-rules.Rmd`: remove author field, replace Google Drive link with proper reference, add citations for proper scoring rules and transformed scores, improve `get_metrics` wording, clean whitespace, and add intro paragraph on probabilistic forecast types. | [ ] | [ ] | — | [ ] |\n| 780 | Add a `verbose` argument to `as_forecast()` | | 2024-04-05 | enhancement | low | small | yes | Still relevant. `verbose` already exists on `assert_forecast()` and `assert_forecast_generic()` (PR #778) but has not been threaded through to any `as_forecast_<type>()` constructor. ~11 test lines and 1 internal R source line use `suppressMessages`/`suppressWarnings` wrappers around `as_forecast_*` calls, confirming ongoing need. Author acknowledged low urgency but wants it for test cleanup. | None. PR #778 (verbose on `assert_forecast`) already merged; plumbing is in place. | Add `verbose = TRUE` parameter to each `as_forecast_<type>.default()` method, pass it to their `assert_forecast()` calls, guard direct `cli_warn()`/`cli_inform()` calls behind the flag, and replace `suppressMessages`/`suppressWarnings` wrappers in tests and internal code with `verbose = FALSE`. | [ ] | [ ] | — | [ ] |\n| 769 | Rethink the way arguments are passed in `get_pairwise_comparisons()` | package improvement | 2024-04-03 | refactor | low | small | yes | Still relevant. `test_type`, `one_sided`, and `n_permutations` are still passed via `...` through 3 levels (`get_pairwise_comparisons` → `pairwise_comparison_one_group` → `compare_forecasts`). Users must read internal `compare_forecasts` docs to discover options. PR #994 added `test_type = NULL` but didn't address the `...` pattern. #750 (split out p-values) was deferred. | Loosely related to #750 (if p-values split out, this becomes moot — but #750 deferred indefinitely). No hard blockers. | Promote `test_type`, `one_sided`, and `n_permutations` from `...` to explicit named arguments in `get_pairwise_comparisons()` and `add_relative_skill()`, improving API discoverability. Update roxygen `@param` tags accordingly. | [ ] | [ ] | — | [ ] |\n| 763 | We should check for consistency when scoring binary forecasts | feature request, high-priority | 2024-03-30 | enhancement | medium | small | yes | Still relevant. No code warns when 0/1 factor levels are in counterintuitive order (e.g., `levels = c(1, 0)` making `0` the reference level). `assert_input_binary()` only validates factor with 2 levels and predicted in [0,1]. No helper for safe factor conversion exists. @seabbs questioned whether this is must-have for 2.0 or nice-to-have. | Loosely related to #840 (input check cleanup) and #939 (remove `check_input_*` functions). | Add a check in `assert_input_binary()` that warns when observed values are \"0\"/\"1\" and level order is `c(1, 0)`. Optionally create `as_binary_observed()` helper with a `reference_level` argument for safe factor conversion. | [ ] | [ ] | — | [ ] |\n| 759 | Future of the current `scoringutils.Rmd` vignette | documentation, question | 2024-03-27 | documentation | medium | medium | partially | Partially addressed. The outdated `scoringutils.Rmd` was removed in PR #836 (May 2024). However, the promised replacement \"Get started\" vignette was never written — @seabbs volunteered June 2024 but no PR materialized. Package has no introductory vignette. README also has dead links to deleted vignettes (`metric-details`, `scoring-forecasts-directly`). | Related to #546 (simplify getting started). Completing this would likely close #546. Dead README links should be fixed regardless. | Write a new \"Get started\" / quick-start vignette to replace the deleted `scoringutils.Rmd`. Fix dead vignette links in README.Rmd. Consider merging #546 into this issue. | N/A | N/A | — | N/A |\n| 758 | Create a vignette that explains scoring rules | documentation | 2024-03-27 | documentation | medium | large | partially | Partially addressed. Part 1 (explain each scoring rule) is covered by the existing `scoring-rules.Rmd` vignette. Part 2 (practical guidance on choosing a scoring rule — convergence, overconfidence, locality, scale sensitivity) remains unaddressed. The issue body contains a detailed vignette stub. Three illustration PNGs exist in `vignettes/` but are orphaned (not referenced by any vignette). | Parent issue for #929, #930, #933, #934 (illustration issues). Related to #785 (scoring rules vignette updates), #1046 (multivariate content). | Narrow scope to creating a \"Choosing a scoring rule\" vignette covering comparative guidance (convergence, overconfidence, locality, scale sensitivity). Coordinate with #929/#930/#933/#934 to incorporate the orphaned illustrations. | N/A | N/A | — | N/A |\n| 752 | Split up `plot_pit()` into a method for vectors and one for data.frames | | 2024-03-27 | refactor | low | small | yes | Fully resolved. `plot_pit()` was removed entirely in PRs #940 and #949. Replaced by `get_pit_histogram()` (S3 generic with methods for `forecast_sample` and `forecast_quantile`) and `pit_histogram_sample()` for low-level computation. Plotting is now via standard ggplot2 calls. The dual-purpose if/else concern no longer exists. | None. | Close as completed. The issue's concern was superseded by a complete removal of `plot_pit()` in favor of `get_pit_histogram()` with proper S3 dispatch. | N/A | N/A | — | N/A |\n| 750 | Move computation of p-values out of `get_pairwise_comparisons()`? | question | 2024-03-26 | discussion | low | medium | no | Partially addressed. PR #994 added `test_type = NULL` to skip p-value computation, resolving the main pain point (spurious warnings from `add_relative_skill()`). The broader architectural question of separating p-value from score ratio computation remains open but contributor consensus was option 1 (do nothing). | #769 (explicit test_type argument) should be considered together. #1022 (two-model case) tangentially related. | Consider closing as won't-fix or converting to long-term design discussion. The practical problem was solved by PR #994. If kept open, the most impactful remaining change would be defaulting `add_relative_skill()` to `test_type = NULL` since it discards p-values anyway. | N/A | N/A | — | N/A |\n| 740 | Make `get_forecast_unit()` and friends customisable such that they can work with new forecast classes | enhancement | 2024-03-24 | refactor | medium | medium | partially | Still relevant. No implementation work done. `get_protected_columns()` remains a plain function with hard-coded column lists (not S3). `get_duplicate_forecasts()` still hard-codes type-specific columns. Related S3 conversions (e.g., `get_forecast_type`, `get_pit`, `as_forecast`) establish the pattern. On `scoringutils-2.x` milestone. | Near-duplicate of #889 (S3 `get_protected_columns`) and #888 (S3 `get_duplicate_forecasts`). Blocks #852 (custom forecast class workflow). | Convert `get_protected_columns()` into an S3 generic with per-class methods (addressing #889), similarly make `get_duplicate_forecasts()` S3 (#888), so each forecast class declares its own columns. Follow established pattern from completed S3 conversions. | N/A | N/A | — | N/A |\n| 731 | Should `wis()` warn about missing values? | question | 2024-03-23 | discussion | low | small | no | Still relevant. Current behavior is correct — `as_forecast()` emits a vague NA message, `clean_forecast()` strips NA rows before `wis()` sees them. Discussion converged on improving the `as_forecast()` message (#537) as the primary fix, with `wis()`-specific warning being secondary. No consensus reached on implementation. | Related to #537 (high-priority: improve NA-removal message). Related to #542 (debug `score()`). Resolving #537 first would clarify what remains here. | Resolve #537 first (improve NA-removal message in `as_forecast()` to report affected row count). Then decide whether `wis()` needs its own warning for direct (non-`score()` pipeline) usage. May be closeable once #537 is done. | N/A | N/A | — | N/A |\n| 718 | Testing fails locally when done repeatedly | enhancement | 2024-03-20 | bug | low | small | yes | Still relevant and unfixed. Root cause: `cli_warn()` with `.frequency = \"once\"` and `.frequency_id = \"small_interval_range\"` suppresses warnings after first test run in same R session. 4 instances of `.frequency = \"once\"` in codebase. Tests pass on CI (fresh process) and on first local run. | No blocking dependencies. Tangentially related to #935 (surprising output behavior). | Add `rlang::reset_message_verbosity(\"small_interval_range\")` before the `expect_warning()` call in `test-metrics-interval-range.R`. Audit the other 3 `.frequency = \"once\"` sites to ensure their tests are similarly resilient. | [ ] | [ ] | — | [ ] |\n| 713 | Create vignette that showcases different ways to visualise forecasts and scores | documentation | 2024-03-11 | documentation | medium | medium | no | Still relevant. Package has 7 exported plot functions (`plot_wis`, `plot_heatmap`, `plot_interval_coverage`, `plot_quantile_coverage`, `plot_pairwise_comparisons`, `plot_forecast_counts`, `plot_correlations`) plus `theme_scoringutils()` but no dedicated visualization vignette. Only a deprecated-visualisations vignette exists. Issue requests updated `plot_score_table()` and mention of `hubVis`. | Related to #826 (plot_heatmap accessibility), #49 (calibration plotting), #942 (discrimination plots), #356 (interactions vignette). Does not block other issues. | Create a new `vignettes/visualising-scores.Rmd` with worked examples for all exported plot functions using example data. Include mention of `hubVis` as alternative for forecast visualization (per closed #812), and an updated `plot_score_table()` equivalent. | N/A | N/A | — | N/A |\n| 702 | Update docs to conform to tidyverse styleguide | good first issue | 2024-03-08 | documentation | low | small | partially | Still relevant. ~85% of `@param` tags already conform to sentence case. ~21 clearly non-conforming (lowercase start) and ~21 special-character-starting descriptions across ~15 R files. Blocker PR #705 (file reorg) was merged March 2024. Assigned to @jamesmbaazam but no PR submitted. | No blocking dependencies. Standalone cleanup task. PR #705 dependency resolved. | Fix ~21 `@param` descriptions across ~15 R files to start with capital letter and end with full stop per tidyverse style guide. Also audit ~21 special-character-starting descriptions and all `@return`/`@returns` tags for same conformance. | N/A | N/A | — | N/A |\n| 686 | Improve code coverage | | 2024-03-06 | meta | low | small | partially | Largely resolved. Coverage is at 98%. The specific sub-issue (#703, misnamed test file) was fixed in PR #704. Only `theme_scoringutils()` (18 lines) lacks any test coverage. The remaining 2% is edge-case branches. Could be closed as-is. | Sub-issue #703 resolved. No blockers. | Optionally add a test for `theme_scoringutils()` and a `.codecov.yml` with a coverage target to prevent regressions, then close this issue given the excellent 98% coverage level. | N/A | N/A | — | N/A |\n| 685 | Suppress printing in tests | enhancement, implementation-ready | 2024-03-06 | cleanup | medium | medium | partially | Still relevant. 29 `suppressMessages()` and 16 `suppressWarnings()` remain across 13 test files, silently swallowing conditions instead of asserting them. Partially addressed: 80+ `expect_no_condition()` calls already exist. Root causes include `as_forecast_*()` verbose messaging and the #935 print bug. | Partially depends on #935 (unwanted printing on `:=`). Overlaps significantly with #823 (reduce `suppress*()` in package). | Audit all 29 `suppressMessages()` and 16 `suppressWarnings()` in tests: replace with `expect_message()`/`expect_warning()` for intentional conditions, pass `verbose = FALSE` where available, or use `expect_no_condition()` after fixing the source. Also review `setup.R` score calls. | N/A | N/A | — | N/A |\n| 684 | Delete functions `check_input_sample()`, `check_input_quantile()`, `check_input_interval()` | | 2024-03-06 | cleanup | low | small | yes | Still relevant but fully superseded by #939, which covers all 5 `check_input_*` functions. These 3 functions are dead code: never called in production, not exported, only tested. A comment in `check-input-helpers.R` explicitly marks them for future deletion. Should be closed as duplicate of #939. | Superseded by #939. Related to #840 (input check cleanup) and #823 (reduce `try()`). | Close as duplicate of #939. If handled independently, delete the 3 function definitions, their man pages, roxygen cross-references, and corresponding test blocks. | [ ] | [ ] | — | [ ] |\n| 668 | Add argument to control what kind of coverage is computed by `get_coverage()` | feature request | 2024-02-29 | enhancement | low | small | yes | Still relevant and unimplemented. `get_coverage()` always computes all 4 coverage metrics with no user control. The issue body contains a near-complete code proposal (with a minor bug to fix). The function structure already cleanly separates interval and quantile computation paths. On `scoringutils-2.x` milestone. | No blocking dependencies. Standalone enhancement. | Add a `type = c(\"quantile\", \"interval\")` argument to `get_coverage()` that conditionally computes interval coverage, quantile coverage, or both. Update downstream column handling, summarisation, and tests. | [ ] | [ ] | — | [ ] |\n| 667 | Create print method for `scores()` objects | feature request | 2024-02-29 | feature | low | small | partially | Still relevant but effectively blocked by #935. No `print.scores` method exists; scores objects fall through to `print.data.table`. Adding a custom print method would exacerbate the unwanted-printing-on-`:=` bug documented in #935. Both maintainers expressed lukewarm interest, deferring to post-release. | Blocked by #935 (print on column change bug). Related to #975 (link to score definitions in print). | Implement `print.scores()` S3 method displaying computed metric names (from `metrics` attribute) before delegating to `NextMethod()`, following the `print.forecast` pattern. Wait until #935 is resolved first to avoid spurious printing on `:=` operations. | N/A | N/A | — | N/A |\n| 666 | Update the scoringutils paper that accompanies the package | question | 2024-02-29 | documentation | medium | large | no | Still relevant but partially stale. Only 2 of ~15 checklist items done. Manuscript in `inst/manuscript/` still references `magrittr`, CITATION still points to 2022 arXiv preprint. README links to Google Drive PDF. Some checklist items reference functions no longer exported. Should be broken into smaller actionable issues. | Related to #759, #789, #546, #758, #1057. | Audit the to-do list against current API to remove stale items, break remaining unchecked items into individual issues, and decide whether to prioritize the \"make a vignette out of the paper\" item before the next CRAN release. Requires human authorship decisions. | N/A | N/A | — | N/A |\n| 646 | Stop converting errors to warnings in `score()`? | help wanted, question, Breaking change | 2024-02-23 | refactor | medium | medium | partially | Still relevant. `run_safely()` in `R/score.R` still converts all metric errors to warnings via `try()` + `cli_warn()` and returns `NULL`, silently dropping failed metrics. Deferred to `scoringutils-2.x` milestone. No consensus on approach: let errors propagate (breaking), add `on_error` parameter (compatible), or batch warnings (#811). | Related to #811 (batch warnings), #941 (`score()` redesign), #823 (reduce `try()`). | Design decision needed: (a) let errors propagate as errors, (b) add `on_error = c(\"warn\", \"error\")` param to `score()`, or (c) combine with #811's batch-warning approach. Implementation touches `run_safely()` in `R/score.R` and test expectations. | N/A | N/A | — | N/A |\n| 625 | Implement a `get_unique_values()` function | implementation-ready | 2024-02-10 | enhancement | low | small | yes | Still relevant. No implementation work done. Function does not exist. Would compute `length(unique(values))` per forecast-unit column (via `get_forecast_unit()`), optionally grouped by model. Similar diagnostic purpose to `get_forecast_counts()` but different output. | Loosely related to #581 (NA in print), #935 (print bug), #621 (closed, prettier print). No hard blockers for standalone function. | Implement a new exported `get_unique_values()` function that takes a forecast object, calls `get_forecast_unit()` to identify relevant columns, and returns a summary table of unique value counts per column. Optionally integrate into `print.forecast()`. | [ ] | [ ] | — | [ ] |\n| 608 | Define input format for categorical forecasts | implementation-ready | 2024-01-17 | discussion | low | small | no | Largely resolved. Input format fully defined and implemented in `forecast_nominal` (PR #837) and `forecast_ordinal` (PR #977). Column named `predicted_label`. Strict completeness enforced. Only unimplemented item is a helper function to auto-expand incomplete forecasts with zero-probability rows, which has no dedicated tracking issue. Can be closed. | #604 (parent, closed), #607 (naming, closed). No blockers. | Close this issue as completed. Optionally open a new targeted issue for the helper function that auto-expands incomplete forecasts with zero-probability rows if still desired. | N/A | N/A | — | N/A |\n| 581 | Add the number of `NA` values to the planned print method for `forecast_*` objects, rather than throw a message? | feature request | 2024-01-05 | enhancement | medium | medium | partially | Still relevant. None of the three requested features implemented: `print.forecast()` shows no NA info, NA message in `assert_forecast_generic()` is still vague (no row count), no `get_NA()` helper exists. Issue #537 is a near-duplicate and both should be addressed together. | Near-duplicate of #537 (should be resolved together). Tangentially related to #731, #542, #935 (print bug). | Enhance `print.forecast()` to display NA row count, improve the message in `assert_forecast_generic()` to report exact number of NA rows, and consider adding a `get_na_summary()` helper. Consolidate with #537. | N/A | N/A | — | N/A |\n| 557 | sample_to_quantile.numeric method | low-priority | 2024-01-05 | enhancement | low | small | yes | Effectively resolved. `sample_to_quantile()` was replaced by `as_forecast_quantile.forecast_sample()` in PR #876. The motivating code (`interval_coverage_sample()`) was deleted entirely. No current code needs a `.numeric` method. Can be closed. | Tangentially related to #1026 (reverse conversion). No blockers. | Close this issue as resolved. The refactoring in PR #876 and deletion of `interval_coverage_sample()` eliminated the code pattern that motivated this request. | N/A | N/A | — | N/A |\n| 546 | Simplify \"Getting Started\" \\| Split into smaller chunks | documentation | 2024-01-05 | documentation | medium | medium | no | Still relevant. The old `scoringutils.Rmd` was deleted (PR #836) but the promised replacement \"Get started\" vignette was never written. Package currently has no introductory vignette at all. README has a \"Quick start\" section but no pkgdown \"Get started\" page. @seabbs volunteered in #759 but no PR materialized. | Tightly coupled with #759 (future of scoringutils.Rmd) — should be resolved together. Related to #789 (metric customization docs). | Write a new introductory \"Getting Started\" vignette (as `vignettes/scoringutils.Rmd` for pkgdown) providing a concise end-to-end walkthrough. Can close both #546 and #759 simultaneously. Requires editorial decisions on scope and content. | N/A | N/A | — | N/A |\n| 542 | Improve ways to debug `score()` | question | 2024-01-04 | enhancement | medium | medium | partially | Still relevant. Neither action item is done: (1) no vignette documents `debugonce()` for scoring rule debugging, (2) `run_safely()` still only reports the metric name in warnings, not which forecast unit/row caused the failure. The `{cli}` migration (PR #583) improved formatting but not informativeness. | Closely related to #646 (stop converting errors to warnings — open, breaking change). Related to closed #391, #418, #543, #583. | Two tasks remain: (1) add documentation showing `debugonce()` usage for debugging scoring failures, and (2) enhance `run_safely()`/`apply_metrics()` to include forecast-unit context in warning messages. Coordinate error-vs-warning design with #646. | N/A | N/A | — | N/A |\n| 537 | Inform users about the number of rows that have NA values | good first issue, question, implementation-ready, high-priority | 2024-01-03 | enhancement | medium | medium | partially | Still relevant. The message in `assert_forecast_generic()` (line 150 of `R/class-forecast.R`) still says the generic \"Some rows containing NA values may be removed\" without a row count. No NA info in `print.forecast`, no `get_na()` helper. The `anyNA()` check and `na.omit()` call are already in place, so computing the count is trivial. | Near-duplicate of #581 (NA count in print method) — should be resolved together. Related to #731 (wis NA warnings). | Minimal fix: add NA row count to the existing `cli_inform` message in `assert_forecast_generic()`. For a more complete resolution, combine with #581 to also add NA summary to `print.forecast` and potentially create a `get_na()` diagnostic helper. | N/A | N/A | — | N/A |\n| 522 | Create a way to test user-provided scoring functions | feature request | 2023-12-06 | feature | medium | medium | partially | Still relevant. No progress made. `validate_metrics()` only checks that items are functions (via `checkmate::check_function`), not signature compatibility, output shape, or runtime behavior. Custom metric errors are silently converted to warnings by `run_safely()`, making debugging hard. Each of the 6+ forecast types passes different arguments to metrics. | Loosely related to #362 (non-standard metric I/O), #823 (reduce `try()`). | Implement an exported `test_metrics()` function that runs each metric on a small representative subset of a forecast object and reports informative diagnostics: signature compatibility, runtime errors, and output shape validation. Needs design decision on API. | N/A | N/A | — | N/A |\n| 520 | Create documentation/vignette for the naming scheme of our functions | help wanted, question | 2023-11-30 | documentation | low | medium | partially | Still relevant. The issue body already describes the naming scheme in detail but no vignette or formal documentation exists. CONTRIBUTING.md only references tidyverse style guide. Issue #948 (closed) debated `get_` prefix but decided to keep it. 65 exported functions follow conventions consistently. ~2 years old with no implementation. | Related to closed #948, #610, #476, #357. No blockers. | Create a developer-facing vignette or CONTRIBUTING.md section formalizing the naming conventions (scoring rules: `<name>_<type>`, `get_*`, `as_forecast_*`, `is_forecast_*`, `plot_*`, `add_*`, `assert_`/`check_`/`test_`). Update to reflect current classes including `forecast_nominal`, `forecast_ordinal`, `forecast_sample_multivariate`. | N/A | N/A | — | N/A |\n| 513 | Investigate R scripts that get generated based on our vignettes | | 2023-11-28 | cleanup | low | small | yes | Already resolved. The `.R` and `.html` vignette artifacts (generated by `knitr` tangle) are gitignored via `vignettes/.gitignore`, excluded from linting via `.lintr`, and not tracked in git. All three mitigations from the discussion are in place. Issue can be closed. | None. | Close this issue — all requested investigation and mitigations (gitignore, buildignore, lint-ignore for vignette-generated `.R` files) are already implemented. No code changes needed. | N/A | N/A | — | N/A |\n| 492 | Expose `get_range_from_quantile()` to the user | question | 2023-11-22 | enhancement | low | small | yes | Still relevant. Function exists at `R/helper-quantile-interval-range.R:185` as `@keywords internal`, not exported. Maintainer consensus reached: rename to `get_interval_range()` and create `add_interval_range()` wrapper. Neither implemented. Original motivating function `plot_ranges()` was deleted, reducing urgency. 3 internal call sites. | Parent meta-issue #484. Tangentially related to #885 (export decisions). | Rename `get_range_from_quantile()` to `get_interval_range()`, export it, and create a new exported `add_interval_range()` that adds an `interval_range` column to a quantile-format data.table. Update 3 internal call sites, NAMESPACE, docs, and tests. | [ ] | [ ] | — | [ ] |\n| 484 | Discussion: Functions to expose to users | | 2023-11-19 | meta | low | small | partially | Partially done. 1 of 3 tracked items complete (`get_metrics()` is already exported). Remaining: `get_protected_columns()` still internal (`@keywords internal` in `R/get-protected-columns.R`), `get_range_from_quantile()` still internal (blocked on naming decision in #492). ~2 years old. | #492 (naming decision blocks `get_range_from_quantile` export). No blockers for `get_protected_columns`. | Update checkboxes: tick `get_metrics()` as done. Export `get_protected_columns()` (add `@export`, remove `@keywords internal`). Resolve #492 naming decision before exporting `get_range_from_quantile`. Consider closing in favor of tracking remaining items individually. | N/A | N/A | — | N/A |\n| 459 | Meta-issue: Code refactoring | refactor | 2023-11-17 | meta | low | medium | partially | 2 of 5 tracked sub-issues done (#446, #469). Of remaining 3: #411 is stale (function `interval_coverage_sample` removed), #454 needs updating (named function gone but duplication between `get_coverage()` and `interval_coverage()` persists), #445 still actionable (64 `::` occurrences across 18 R files). Untracked dimension-checking item partially addressed by existing `assert_input_*` pattern. 2+ years old. | #938 (rename `assert_dims_ok_point`) related to untracked item. #870 (CRPS/WIS refactor) is related open refactoring work not tracked here. | Update the issue body: close #411 as stale, update #454's description to reference current duplication, and decide whether to close this meta-issue in favor of tracking remaining refactoring (#445, #870, #938) as standalone issues. | N/A | N/A | — | N/A |\n| 455 | Discussion: Should scoring rules always return a vector? | Breaking change | 2023-11-15 | discussion | low | large | no | Stale discussion from Nov 2023 with only 2 comments and no concrete proposal. The current design (separate functions per metric component, e.g., `overprediction_quantile()`) already addresses the motivating example. All metrics consistently return numeric vectors; `apply_metrics()` requires this. API is settled. | None | Close as \"won't fix\". The vector-return contract is consistent across all metrics and well-integrated with `apply_metrics()`. The separate-function-per-component pattern already solves the motivating WIS use case. | N/A | N/A | — | N/A |\n| 454 | Code refactoring: Deduplicate code in `get_coverage()` and `interval_coverage_deviation_quantile()` | refactor, implementation-ready | 2023-11-15 | refactor | low | small | yes | Original function `interval_coverage_deviation_quantile()` was removed. Issue title is outdated. Remaining duplication is between `get_coverage()` (data.table-level) and `interval_coverage()` (numeric scoring metric) — both call `quantile_to_interval()` + bounds check independently. Duplication is small (~5 lines of core logic). | Tracked in meta-issue #459. Related to #668 (coverage type argument). | Update issue title to reference `interval_coverage()`. Refactor `get_coverage()` to delegate interval coverage computation to `interval_coverage()` or a shared internal helper, eliminating duplicated `quantile_to_interval()` + bounds-check pattern. | [ ] | [ ] | — | [ ] |\n| 453 | Create function `quantile_coverage_deviation()` | feature request, implementation-ready | 2023-11-15 | feature | low | small | no | Superseded. The requested functionality is already provided by `get_coverage()` (line 88 of `R/get-coverage.R` computes `quantile_coverage_deviation`). The analogous standalone function (`interval_coverage_dev_quantile()`) was removed rather than duplicated. Can be closed. | Related to #454 (also likely closeable) and meta-issue #459. | Close as superseded. Quantile coverage deviation is already computed in `get_coverage()`. The design decision was to consolidate coverage metrics there rather than create standalone functions. | N/A | N/A | — | N/A |\n| 451 | Deal with one-to-one functions related to quantile and interval metrics | question | 2023-11-15 | discussion | low | medium | no | Still relevant. The issue concerns the one-to-one correspondence between quantile-format and interval-format metric functions. Currently: `interval_score()` is internal (not exported), called by `wis()` after `quantile_to_interval()` conversion. Exported quantile metrics: `wis()`, `quantile_score()`, `interval_coverage()`, `ae_median_quantile()`, `bias_quantile()`, `dispersion_quantile()`, `overprediction_quantile()`, `underprediction_quantile()`. No `forecast_interval` class exists — interval format is internal only. The comment from the maintainer (\"not expose functions to users for now and rethink later\") is the current policy. Coverage code in `get_coverage()` still has its own inline computation rather than reusing `interval_coverage()`. | Related to #668 (coverage type argument), #492 (expose `get_range_from_quantile`), #870 (CRPS/WIS decomposition refactor), #907 (coverage function factory), #454 (deduplicate coverage code), #484 (functions to expose). | Keep open as a design discussion for future releases. The immediate question (whether to expose interval-format functions) was deferred. The broader question of code reuse between `get_coverage()` and `interval_coverage()` overlaps with #454 and #668. Revisit when planning the next API refactor cycle. | N/A | N/A | — | N/A |\n| 445 | Cleanup: delete calls that use `::` or `:::` and add to imports instead | refactor, implementation-ready | 2023-11-15 | cleanup | low | small | yes | Still relevant. 25 redundant `pkg::fn()` calls across 9 R files where functions are already imported in NAMESPACE (13 data.table, 5 scoringRules, 3 Metrics, 2 cli, 1 purrr, 1 utils). The oft-cited \"64 occurrences\" overstates scope — 37 are roxygen/comment references that should stay. Purely cosmetic cleanup. | None. Standalone cleanup. Tracked in meta-issue #459. | Remove the `pkg::` prefix from 25 redundant function calls across 9 R files. Leave roxygen documentation cross-references and cli-formatting self-references unchanged. | [ ] | [ ] | — | [ ] |\n| 434 | Discussion: composing score data.frames | help wanted, question | 2023-11-14 | discussion | low | medium | partially | Still relevant. No `c.scores()` or score composition method exists. Scores objects are data.tables with a `metrics` attribute. A `c.scores()` method would need `rbindlist(..., fill = TRUE)` and union of `metrics` attributes. No comments on the issue; design not discussed beyond the example in the issue body. ~2.5 years old with no progress. | Sub-issue of #433. Depends on #432 (as_point) being resolved first to enable the full workflow. | Design and implement a `c.scores()` (or `merge_scores()`) method that combines multiple scores objects via `rbindlist(fill = TRUE)`, merges `metrics` attributes, and validates that forecast unit columns are compatible. Needs maintainer input on API design. | N/A | N/A | — | N/A |\n| 433 | Meta-issue - Feature: scoring probabilistic and point forecasts together / composing scores | help wanted | 2023-11-14 | meta | low | medium | no | Neither sub-issue resolved. PR #790 (implementing `as_point`/`as_quantile`) was closed without merging in May 2024. Only `as_forecast_point.forecast_quantile()` exists (hard-coded to median). No `as_forecast_point.forecast_sample()` method. No score composition mechanism. ~2.5 years old with stalled progress. | Tracks #432 (as_point) and #434 (composing scores). Related to #880 (customizable quantile in as_forecast_point). | Complete both sub-issues: (1) implement `as_forecast_point.forecast_sample()` and optionally a user-friendly `as_point()` wrapper, (2) implement score composition via `c.scores()` or similar. Needs fresh design decision given closed PR #790. | N/A | N/A | — | N/A |\n| 432 | Create function `as_point()` that converts sample- or quantile-based forecasts into point forecasts | help wanted | 2023-11-14 | feature | medium | medium | partially | Partially addressed. `as_forecast_point.forecast_quantile()` exists (hard-coded to median, lines 105-120 of `R/class-forecast-quantile.R`). `as_forecast_point.forecast_sample()` does NOT exist. PR #790 attempted full `as_point()`/`as_quantile()` implementation but was closed without merging (May 2024). @seabbs deprioritized as \"nice to have\". | Sub-issue of #433. Related to #880 (customizable quantile_level in as_forecast_point). | Implement `as_forecast_point.forecast_sample()` (summarize samples via median/mean/custom function). Optionally create a convenience `as_point()` generic wrapping `as_forecast_point()`. Revisit closed PR #790 for design reference. | N/A | N/A | — | N/A |\n| 412 | Add check to `validate_forecast()` that predictions must not decrease with quantile | implementation-ready | 2023-11-10 | enhancement | medium | small | yes | Still relevant. Monotonicity check exists only as a hard error deep in `bias_quantile_single_vector()` (R/metrics-quantile.R:495). `assert_forecast.forecast_quantile()` does NOT check monotonicity — it only validates column presence, quantile range [0,1], and type. `validate_forecast()` was deleted and replaced by `assert_forecast()`. Agreed plan: helper function + warning in `assert_forecast`. No user-facing diagnostic function exists. | Near-duplicate of #895 (user-facing `get_non_monotonic_forecasts()` helper). Related to #840 (input check cleanup). | Add monotonicity warning to `assert_forecast.forecast_quantile()` checking that predictions don't decrease with increasing quantile_level. Create a user-facing `get_non_monotonic_forecasts()` helper to identify affected rows (resolving both #412 and #895). | [ ] | [ ] | — | [ ] |\n| 411 | Rework `interval_coverage_sample()` | refactor | 2023-11-10 | refactor | low | small | yes | Fully resolved. `interval_coverage_sample()` was deleted in commit cc41a0e5 (Jan 5, 2024) as part of the v2.0.0 redesign. NEWS.md documents: \"Removed `interval_coverage_sample()` as users are now expected to convert to a quantile format first before scoring.\" Coverage is now handled by `interval_coverage()` (quantile-based) and `get_coverage()`. Issue can be closed. | None. | Close this issue — `interval_coverage_sample()` was intentionally removed in v2.0.0. The underlying concerns (code simplification, reuse of `interval_coverage_quantile`) were resolved by deleting the function and unifying the API around quantile-format coverage computation. | N/A | N/A | — | N/A |\n| 406 | Maybe expose `get_type()`. | | 2023-11-10 | enhancement | low | small | yes | Still relevant. `get_type()` (vector type detection: classification/integer/continuous) and `get_forecast_type()` (forecast class type) both exist in `R/get-forecast-type.R` but are internal (`@keywords internal`), not exported. The proposed renames (`get_vector_type`, `get_observed_type`, `get_predicted_type`) were never implemented. No comments, no progress. | Related to #484 (functions to expose) and #885 (export decisions). No blockers. | Rename `get_type()` to `get_vector_type()`, export it, and create `get_observed_type()` / `get_predicted_type()` wrappers that extract the relevant column from a forecast and call `get_vector_type()`. Decide whether to also export `get_forecast_type()` (tracked in #484/#885). | [ ] | [ ] | — | [ ] |\n| 385 | Feature: Add data transformation functions to work with other packages | help wanted | 2023-11-03 | feature | low | large | no | Still relevant but aspirational. No conversion functions for external packages (Stan, Odin, yardstick, hubverse) exist. The `as_forecast_*` S3 generic system provides extension points for external packages to write their own methods. Hubverse integration was explicitly moved to external `hubEvals` package (#605 closed). Maintainer consensus: package-specific conversions are too varied and dependency-heavy for scoringutils. Yardstick conversion code in comments never formalized. 2+ years old with no progress. | Related to #356 (interoperability vignette), #363 (external function interface), #852 (custom forecast class workflow), #983 (`.data.frame` methods), #1026 (`as_forecast_sample.forecast_quantile`). | Consider narrowing scope or closing in favor of more specific issues. The broad goal is better served by: (1) completing S3 extensibility infrastructure (#852, #983, #889, #888), (2) writing an interoperability vignette (#356), and (3) possibly adding 1-2 zero-dependency convenience converters if demand warrants. Too broad to be directly actionable as stated. | N/A | N/A | — | N/A |\n| 382 | Feature: Input check to notify about clashes with metrics and column names | good first issue, package improvement, implementation-ready | 2023-11-02 | enhancement | medium | small | yes | Still relevant and unresolved. A pre-v2.0 implementation existed in `check_clean_data()` but was removed during the v2.0 rewrite. A commented-out test skeleton exists in `test-score.R` (lines 51-62). `apply_metrics()` silently overwrites any existing column whose name matches a metric name via `forecast[, (metric_name) := result]`. No pre-scoring clash detection exists. | Tangentially related to #927 (prefix internal columns). Could coordinate with #811 (batch warnings). No blockers. | Add a check after `validate_metrics(metrics)` in each `score.forecast_*` method comparing `names(metrics)` against `colnames(forecast)` and emitting `cli_warn()` on overlap. Uncomment and update the existing test skeleton in `test-score.R`. | [ ] | [ ] | — | [ ] |\n| 363 | Discussion: design interface for external functions with different input/output formats | help wanted, question | 2023-10-26 | enhancement | low | small | yes | Still relevant. No wrapper/adapter functions exist. Users must manually wrap external metrics with non-standard signatures (e.g., reversed arg order, numeric 0/1 instead of factor observed). Two small wrapper proposals in the issue body (`wrap_binary_numeric`, `wrap_switch_order`) were never implemented. The `purrr::partial()` mechanism alone cannot solve argument reordering or type conversion. Zero comments, no design consensus. 2+ years old. | Related to #362 (non-standard I/O formats), #522 (test user-provided scoring functions), #385 (data transformation), #789 (customization docs). No blockers. | Implement 2-3 small exported adapter functions (e.g., `metric_adapt_binary_numeric()` to convert factor to 0/1, `metric_adapt_swap_args()` to reverse observed/predicted order). Document usage in `score()`'s \"Customising metrics\" section. Resolve naming convention with maintainers first. | [ ] | [ ] | — | [ ] |\n| 362 | Discussion: How to handle scores with input / output formats not currently covered | question | 2023-10-26 | discussion | low | large | no | Still relevant. `apply_metrics()` requires each metric to return a numeric vector of length n (one per forecast unit). Metrics with non-standard I/O (many-to-one like AUC, many-to-many like PIT) cannot fit into `score()`. The PIT case is solved outside `score()` via `get_pit_histogram()`. Zero comments, no design consensus. The multivariate sample class introduced a partial precedent (multiple rows collapse into groups) but by restructuring data before `apply_metrics()`, not by changing it. 2+ years old. | Related to #455 (data frame returns — recommended for closure), #363 (wrapper functions), #338 (cross-type metrics), #941 (rethink `score()` S3), #852 (custom class workflow). | Long-term design question with no clear path forward. The pragmatic pattern (non-standard metrics live outside `score()` as standalone functions) is established. Consider closing as won't-fix or consolidating with #455, #363, #338 into a single milestone-level tracking issue. Any solution requires fundamental changes to `apply_metrics()`. | N/A | N/A | — | N/A |\n| 360 | Create a wrapper around log score to warn about its use for integer-valued forecasts | implementation-ready | 2023-10-26 | enhancement | medium | small | yes | Still relevant and unaddressed. `logs_sample()` is a thin wrapper with no integer detection or warning. `get_type()` already exists and is used by `bias_sample()` and `pit_histogram_sample()` for the same purpose. Consensus reached on MVP: add a warning when `get_type(predicted) == \"integer\"`. Discussion also suggested possibly removing `log_score` from default metrics for sample forecasts. | None. All building blocks exist (`get_type()`, `cli_warn()`, pattern established in `bias_sample()`). | Add `get_type(predicted)` check to `logs_sample()` that emits `cli_warn()` when predictions are integer-valued. Optionally move `log_score` out of the default metric list in `get_metrics.forecast_sample()`. Add targeted tests. | [ ] | [ ] | — | [ ] |\n| 356 | Documentation: Create a vignette for interactions with other packages | documentation | 2023-10-26 | documentation | low | medium | partially | Still relevant. No interoperability vignette exists. Deprecated-visualisations vignette mentions hubVis. Hubverse integration moved to external `hubEvals` package (#605, closed). No conversion functions for external packages exist in scoringutils. `as_forecast_*` S3 generics provide extension points for external packages. ~2.5 years old with no progress. | Related to #385 (data transformation for other packages), #852 (custom forecast class workflow), #983 (`.data.frame` methods). | Create a vignette documenting how to use scoringutils with common external packages (hubverse via hubEvals, Stan output, yardstick). Focus on showing the `as_forecast_*()` S3 extension mechanism and practical conversion patterns. Requires editorial decisions on scope and which packages to feature. | N/A | N/A | — | N/A |\n| 353 | Documentation: Create a vignette that details the different inputs and internal workings of scoringutils | documentation | 2023-10-26 | documentation | medium | large | partially | Still relevant but heavily overlapping with #546, #759, #852. The deleted `scoringutils.Rmd` vignette (PR #836) covered 3 of 4 bullet points; replacement was never written. README \"Quick start\" section partially addresses input formats and workflow. The \"create your own class\" bullet is blocked by prerequisite S3 refactors (#889, #888, #885). Package currently has no introductory or architecture vignette. | Tightly coupled with #546 (simplify getting started) and #759 (replace deleted vignette). \"Create your own class\" aspect depends on #852, blocked by #889, #888, #885. | Consider consolidating with #546 and #759 into a single effort to write a new introductory vignette covering input formats, the `as_forecast_*()` / `score()` workflow, and forecast object anatomy. Defer \"create your own class\" section until S3 extensibility refactors are complete. | N/A | N/A | — | N/A |\n| 338 | Discussion: Define implementation for metrics which work for different forecast types | help wanted, question, Breaking change | 2023-10-22 | discussion | low | medium | no | Partially addressed by #832 (`get_metrics()` now S3). The remaining question is whether individual metric functions (e.g., `bias_sample`/`bias_quantile`) should also become S3 generics for standalone use. Practical need is low since `score()` already dispatches correctly via `get_metrics.<class>`. 6 conceptual metrics span 2+ forecast types with type-suffixed names. | #832 (done). Related to #455 (vector returns), #941 (rethink `score()` S3). No blockers. | Consider downgrading from \"Breaking change\" since S3 wrappers could be additive. If pursued, create `bias()`, `overprediction()`, `underprediction()`, `dispersion()`, `ae_median()`, `logs()` as S3 generics dispatching on forecast class, keeping suffixed functions as implementations. Defer to future major release. | N/A | N/A | — | N/A |\n| 329 | Add additional documentation for `crps_sample()`, `logs_sample()` and `dss_sample()` | package improvement | 2023-09-15 | documentation | low | small | partially | Still relevant. Formulas exist in the vignette (`scoring-rules.Rmd`) but have not been ported to the roxygen docs for these three functions. Other functions in the same file (e.g., `bias_sample`, `pit_histogram_sample`) already have formula-rich roxygen documentation via `\\deqn{}`, providing a clear template. `dss_sample()` is worst — almost no description beyond \"wrapper.\" | None. Standalone documentation task. | Add `\\deqn{}` mathematical formulas and expanded descriptions to roxygen docs of `crps_sample()`, `logs_sample()`, and `dss_sample()` in `R/metrics-sample.R`. Adapt formulas from the existing vignette content. `dss_sample()` needs the most work. | N/A | N/A | — | N/A |\n| 289 | Add support for comparing two distributions | | 2023-07-12 | feature | low | large | no | Still relevant. Zero implementation exists. The entire package architecture assumes scoring against scalar observations. No distribution comparison functions in codebase or in `scoringRules` dependency. Requires fundamental design decisions: new forecast class, new metric functions, and integration approach. 2.5+ years old with zero comments. Filed as an aspirational idea. | Related to #852 (custom forecast class workflow), #889/#888 (S3 extensibility). No issues depend on this. | Design and implement a new forecast class for distribution-to-distribution comparison with associated metrics (energy distance, KL divergence, Wasserstein distance). Should be deferred until S3 extensibility infrastructure (#852, #889, #888) is complete. | N/A | N/A | — | N/A |\n| 286 | Extension covering idees in \"Model Diagnostics and Forecast Evaluation for Quantiles\" | enhancement, feature request | 2023-05-03 | feature | medium | large | no | Still relevant. None of the three proposed features (consistency-banded coverage plots, Murphy diagrams, CORP reliability diagrams) are implemented. Basic coverage plots and PIT histograms exist but lack the statistical rigor proposed. Paper's code could serve as starting point. ~3 years old with no progress. Design decisions needed on scope, API, and potential new dependencies (e.g., `reliabilitydiag` R package). | Thematically related to #49 (calibration plotting improvement). No hard blockers. @jbracher is already a scoringutils contributor. | Implement three new diagnostic tools from Bracher et al.: (1) add consistency bands and confidence intervals to existing coverage plots, (2) create `murphy_diagram()` function and plot, (3) create CORP reliability diagram function. Consider addressing #49 simultaneously. | N/A | N/A | — | N/A |\n| 267 | How to score literature/other resources | documentation, help wanted | 2023-02-13 | documentation | low | small | no | Still relevant. Function-level `@references` tags exist across 8 R files, and the scoring-rules vignette has a .bib with 7 papers. However, the agreed-upon deliverable — a standalone, discoverable vignette summarizing scoring methodology and linking to key literature — has not been created. Two vignettes referenced in the README (\"metric-details\", \"scoring-forecasts-directly\") do not exist on disk. ~3 years old. | None blocking. Related to #758 (scoring rules vignette), #789 (customization docs), #666 (update paper). | Create a short standalone vignette summarizing scoring methodology and consolidating all referenced literature into one discoverable place. Link to the full paper and relevant external resources. Also fix the broken vignette links in the README. Requires editorial decisions on content. | N/A | N/A | — | N/A |\n| 193 | Add more metrics to assess sharpness of forecasts in a sample format | feature request, implementation-ready | 2022-02-16 | feature | low | small | yes | Still relevant. `mad_sample()` is the only dedicated sharpness metric. SD and IQR (specifically requested) are not implemented. Both are trivial to add following the `mad_sample()` pattern (data-independent, apply function row-wise over predicted matrix). `dispersion_sample()` (CRPS component) also measures spread but is observation-dependent. `scoringRules` provides no additional sharpness measures. | None. Self-contained addition following existing `mad_sample()` pattern. | Implement `sd_sample()` and `iqr_sample()` in `R/metrics-sample.R` following the `mad_sample()` pattern. Add both to the default metric list in `get_metrics.forecast_sample()`. Add tests, documentation, and NAMESPACE exports. | [ ] | [ ] | — | [ ] |\n| 49 | Improve calibration plotting | enhancement, feature request | 2020-07-25 | feature | low | medium | no | Partially addressed. PIT histograms exist via `get_pit_histogram()` (covering item 1 approximately). Items 2 (ACF of PIT values) and 3 (marginal calibration plot) are completely unimplemented. True Talagrand/verification rank histogram also not implemented as a distinct tool. Maintainer said \"no active plan, but nice to have.\" 5+ years old. | Thematically overlaps with #286 (advanced calibration diagnostics). No hard blockers. | Three remaining items: (1) implement verification rank histogram for ensemble/sample forecasts, (2) implement ACF computation/plot for PIT values, (3) implement marginal calibration plot. Consider consolidating with #286 into a single calibration diagnostics tracking issue. | N/A | N/A | — | N/A |\n| 37 | Add Diebold Mariano test | enhancement, good first issue, help wanted, feature request | 2020-06-20 | feature | low | small | partially | Still relevant. No DM test implementation exists. `compare_forecasts()` in `R/pairwise-comparisons.R` already has a clean `test_type` dispatch pattern (Wilcoxon and permutation). The DM test's main value-add is proper handling of autocorrelated score differences common in time-series forecasting. Open since 2020 with maintainer agreement but explicitly deferred. | Dependency of #1055 (model confidence sets). Related to #750 (p-value refactor), #769 (pairwise comparison arguments), #1022 (two-model case). | Add `\"dm\"` as a new `test_type` option in `compare_forecasts()`. Self-implement the DM test statistic (preferred over adding `forecast` dependency) with Newey-West HAC variance estimator. Add tests and documentation. Coordinate naming and autocorrelation lag handling with maintainers. | N/A | N/A | — | N/A |\n\nTRIAGE_COMPLETE","structuredPatch":[{"oldStart":66,"oldLines":7,"newStart":66,"newLines":7,"lines":[" | 810 | Clean up readme by using `pkgdown` to render dev version docs | | 2024-05-05 | documentation | low | small | yes | CLOSED (completed 2026-02-09). PR #1060 merged today, replacing R-based `packageVersion()` detection with pkgdown selective HTML (`.pkgdown-devel`/`.pkgdown-release` fenced divs). `_pkgdown.yml` already had `development: mode: auto`. Dev docs deployed at `/dev/` on gh-pages. | None. Fully resolved. | No action needed — issue closed via merged PR #1060. | N/A | N/A | — | N/A |"," | 808 | Run lintr everywhere | | 2024-05-05 | cleanup | low | medium | partially | Active work in progress. PR #1062 (\"enable lintr for tests, inst, and vignettes\") is open but not yet merged. `.lintr` excludes all `tests/`, `inst/`, and `vignettes/*.R` files. CI only lints changed files on PRs. Main scope is `tests/` (~5,400 lines across 35 files). `inst/` has only 2 R files. `vignettes/*.R` not tracked in git (auto-generated tangles). ~90 `nolint` annotations already exist in `R/` source. | #807 (cli nolint cleanup) should be done first to establish pattern. #513 (vignette .R scripts) related to vignette exclusion. PR #1062 is in flight. | Merge or rebase PR #1062 once reviews pass. May need to fix remaining lint violations or add targeted `# nolint` annotations. Address `tests/` directory-wide lint cleanup separately from `inst/` and `vignettes/`. | N/A | N/A | — | N/A |"," | 807 | Clean up linter statements around `cli` conditions | good first issue, implementation-ready | 2024-05-05 | cleanup | low | medium | yes | Still relevant. ~43 `#nolint start: keyword_quote_linter` blocks across R/ wrap `cli_abort()`/`cli_warn()` calls that use `\"!\" =`, `\"i\" =` named vector syntax. Only 12 instances use Hugo's backtick fix (`\\`!\\` =`). The fix is mechanical: replace `\"!\" =` with `` `!` = `` inside cli condition calls, then remove the `nolint` annotations. Additional `object_usage_linter` suppressions (14 blocks) exist for `.data[...]` patterns in data.table code — these need separate handling. No work done on this issue since filing. | Prerequisite for #808 (run lintr everywhere). Related to PR #583 (which introduced the cli pattern). | Replace all `\"!\" =`, `\"i\" =`, `\"x\" =`, `\"v\" =` with backtick-quoted equivalents (`` `!` = ``, etc.) in `cli_abort()`/`cli_warn()` calls across ~20 R/ files, then delete the corresponding `#nolint start`/`#nolint end` blocks. Handle `object_usage_linter` suppressions separately. | [x] | [ ] | — | [ ] |","-| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [ ] | [ ] | — | [ ] |","+| 793 | How should we document methods that have different arguments than the default method? | | 2024-04-19 | documentation | low | small | yes | Still relevant. Consensus reached (separate pages per @seabbs), but not implemented. Three generics currently lump methods with differing arguments onto one `@rdname` page: `as_forecast_quantile` (`.forecast_sample` has different args), `as_forecast_point` (`.forecast_quantile`), and `get_pit_histogram` (`.forecast_sample` has extra args). Renders a confusing flat argument list. | None. | Remove shared `@rdname` tags for S3 methods whose arguments differ from the generic (`as_forecast_quantile.forecast_sample`, `as_forecast_point.forecast_quantile`, `get_pit_histogram.forecast_sample`) and give each its own documentation page with proper title and description. | [x] | [ ] | — | [ ] |"," | 789 | Add documentation about how to customise scores | documentation | 2024-04-13 | documentation | medium | medium | partially | Partially addressed. The `score()` roxygen docs now have a \"Customising metrics\" section with `purrr::partial()` examples (PR #874). But the core ask — a vignette walkthrough — remains undone. No vignette covers `get_metrics()` → `select_metrics()` → `purrr::partial()` → `score()` workflow. On `scoringutils-2.x` milestone. | Related to #546 (vignette restructuring — decides where customization docs go), #666 (manuscript update). | Create a vignette section (or standalone vignette) walking users through the full metric customization workflow: `get_metrics()`, `select_metrics()`, `purrr::partial()`, custom metric functions, and passing to `score()`. Coordinate with vignette restructuring in #546. | N/A | N/A | — | N/A |"," | 785 | Small updates to the scoring rules Vignette | documentation | 2024-04-10 | documentation | low | small | yes | Still relevant. None of the 7 suggestions from @seabbs's review of PR #762 have been implemented: author field still present, Google Drive link still used, no citations for proper scoring rules or transformed scores paper, `get_metrics` wording not improved for website readers, no introductory paragraph on different probabilistic forecast types. Nearly 2 years open with no progress on these items. | Loosely related to #666 (manuscript update re: Google Drive link), #758 (scoring rules vignette parent issue), #1046 (multivariate scoring in same vignette). | Implement the 7 small documentation edits in `vignettes/scoring-rules.Rmd`: remove author field, replace Google Drive link with proper reference, add citations for proper scoring rules and transformed scores, improve `get_metrics` wording, clean whitespace, and add intro paragraph on probabilistic forecast types. | [ ] | [ ] | — | [ ] |"," | 780 | Add a `verbose` argument to `as_forecast()` | | 2024-04-05 | enhancement | low | small | yes | Still relevant. `verbose` already exists on `assert_forecast()` and `assert_forecast_generic()` (PR #778) but has not been threaded through to any `as_forecast_<type>()` constructor. ~11 test lines and 1 internal R source line use `suppressMessages`/`suppressWarnings` wrappers around `as_forecast_*` calls, confirming ongoing need. Author acknowledged low urgency but wants it for test cleanup. | None. PR #778 (verbose on `assert_forecast`) already merged; plumbing is in place. | Add `verbose = TRUE` parameter to each `as_forecast_<type>.default()` method, pass it to their `assert_forecast()` calls, guard direct `cli_warn()`/`cli_inform()` calls behind the flag, and replace `suppressMessages`/`suppressWarnings` wrappers in tests and internal code with `verbose = FALSE`. | [ ] | [ ] | — | [ ] |"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CJyr2Qu5EunWQqFUKsUVwX","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me check if all automatable issues with Has Tests not `N/A` are now `[x]`. Let me scan the remaining issues."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":620,"cache_read_input_tokens":65802,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":620},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"64adc473-d9ff-49db-b953-274d57cfbb0c"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CJyr2Qu5EunWQqFUKsUVwX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014vxtwEXMV11zYQvpAqDV7A","name":"Grep","input":{"pattern":"\\| yes \\|.*\\| \\[ \\] \\|.*\\| \\[ \\] \\|","path":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md","output_mode":"content"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":620,"cache_read_input_tokens":65802,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":620},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"1447f5a9-1a7b-48ec-abf2-f69e054897dd"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014vxtwEXMV11zYQvpAqDV7A","type":"tool_result","content":"29:[Omitted long matching line]\n30:[Omitted long matching line]\n32:[Omitted long matching line]\n33:[Omitted long matching line]\n35:[Omitted long matching line]\n36:[Omitted long matching line]\n38:[Omitted long matching line]\n48:[Omitted long matching line]\n52:[Omitted long matching line]\n56:[Omitted long matching line]\n61:[Omitted long matching line]\n63:[Omitted long matching line]\n65:[Omitted long matching line]\n68:[Omitted long matching line]\n69:[Omitted long matching line]\n71:[Omitted long matching line]\n72:[Omitted long matching line]\n73:[Omitted long matching line]\n74:[Omitted long matching line]\n81:[Omitted long matching line]\n86:[Omitted long matching line]\n87:[Omitted long matching line]\n91:[Omitted long matching line]\n101:[Omitted long matching line]\n105:[Omitted long matching line]\n108:[Omitted long matching line]\n112:[Omitted long matching line]\n114:[Omitted long matching line]\n116:[Omitted long matching line]\n117:[Omitted long matching line]\n119:[Omitted long matching line]\n127:[Omitted long matching line]"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"9587a856-f839-46cd-823a-f79043579321","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"29:[Omitted long matching line]\n30:[Omitted long matching line]\n32:[Omitted long matching line]\n33:[Omitted long matching line]\n35:[Omitted long matching line]\n36:[Omitted long matching line]\n38:[Omitted long matching line]\n48:[Omitted long matching line]\n52:[Omitted long matching line]\n56:[Omitted long matching line]\n61:[Omitted long matching line]\n63:[Omitted long matching line]\n65:[Omitted long matching line]\n68:[Omitted long matching line]\n69:[Omitted long matching line]\n71:[Omitted long matching line]\n72:[Omitted long matching line]\n73:[Omitted long matching line]\n74:[Omitted long matching line]\n81:[Omitted long matching line]\n86:[Omitted long matching line]\n87:[Omitted long matching line]\n91:[Omitted long matching line]\n101:[Omitted long matching line]\n105:[Omitted long matching line]\n108:[Omitted long matching line]\n112:[Omitted long matching line]\n114:[Omitted long matching line]\n116:[Omitted long matching line]\n117:[Omitted long matching line]\n119:[Omitted long matching line]\n127:[Omitted long matching line]","numLines":32}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019qEHPGsNevxCodc63SUdZX","type":"message","role":"assistant","content":[{"type":"text","text":"There are many more automatable issues with `[ ]` for Has Tests, so the pipeline checkpoint should NOT be set yet. Let me verify more precisely — I need issues that are `automatable: yes` AND `Has Tests: [ ]`."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":500,"cache_read_input_tokens":66422,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":500},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"e6bd42e9-a5bc-4211-bc7b-095a8fb326b1"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019qEHPGsNevxCodc63SUdZX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01J7jSmaWpmgmcneNXL1P5bZ","name":"Grep","input":{"pattern":"\\| yes \\|[^|]*\\|[^|]*\\|[^|]*\\| \\[ \\] \\| \\[ \\] \\|","path":"/Users/nikos/github-synced/scoringutils-pipeline/.ralph/ISSUE_TRIAGE.md","output_mode":"content","-n":true}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":500,"cache_read_input_tokens":66422,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":500},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"128cb5b4-eefc-4502-af88-a007c2ada60a"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01J7jSmaWpmgmcneNXL1P5bZ","type":"tool_result","content":"71:[Omitted long matching line]\n72:[Omitted long matching line]\n73:[Omitted long matching line]\n74:[Omitted long matching line]\n81:[Omitted long matching line]\n86:[Omitted long matching line]\n87:[Omitted long matching line]\n91:[Omitted long matching line]\n101:[Omitted long matching line]\n105:[Omitted long matching line]\n108:[Omitted long matching line]\n112:[Omitted long matching line]\n114:[Omitted long matching line]\n116:[Omitted long matching line]\n117:[Omitted long matching line]\n119:[Omitted long matching line]\n127:[Omitted long matching line]"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"bcde9aa9-9f65-4904-ac71-5ec30987ac5a","tool_use_result":{"mode":"content","numFiles":0,"filenames":[],"content":"71:[Omitted long matching line]\n72:[Omitted long matching line]\n73:[Omitted long matching line]\n74:[Omitted long matching line]\n81:[Omitted long matching line]\n86:[Omitted long matching line]\n87:[Omitted long matching line]\n91:[Omitted long matching line]\n101:[Omitted long matching line]\n105:[Omitted long matching line]\n108:[Omitted long matching line]\n112:[Omitted long matching line]\n114:[Omitted long matching line]\n116:[Omitted long matching line]\n117:[Omitted long matching line]\n119:[Omitted long matching line]\n127:[Omitted long matching line]","numLines":17}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019FAV69rMp6UzMNuGgik7ft","type":"message","role":"assistant","content":[{"type":"text","text":"There are still many automatable issues with `Has Tests: [ ]`, so the pipeline checkpoint should NOT be set to `[x]`. "}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":66922,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":399},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"2c8a77d1-8e2f-46e3-84c3-84bd7640ca49"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_019FAV69rMp6UzMNuGgik7ft","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01ASDPHFHUKVR2iBEAMDwhcA","name":"TodoWrite","input":{"todos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"completed","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"completed","activeForm":"Updating triage table"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":66922,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":399},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"04a39734-81c4-4007-9b3f-b3d47ab141a6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01ASDPHFHUKVR2iBEAMDwhcA","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"dffffb15-80d1-4b8d-bcb4-3c5c6dd03086","tool_use_result":{"oldTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"completed","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"in_progress","activeForm":"Updating triage table"}],"newTodos":[{"content":"Read full GitHub issue #793 with comments","status":"completed","activeForm":"Reading full GitHub issue #793 with comments"},{"content":"Understand test landscape for related code","status":"completed","activeForm":"Understanding test landscape for related code"},{"content":"Design test cases for issue #793","status":"completed","activeForm":"Designing test cases for issue #793"},{"content":"Write test specs to issue file","status":"completed","activeForm":"Writing test specs to issue file"},{"content":"Update triage table","status":"completed","activeForm":"Updating triage table"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01V5LnbpWiq6JmCZVzuadmnt","type":"message","role":"assistant","content":[{"type":"text","text":"Done. Here's a summary of what was accomplished:\n\n**Issue processed**: #793 — \"How should we document methods that have different arguments than the default method?\"\n\n**Nature of the issue**: Documentation-only change — remove shared `@rdname` tags for three S3 methods that have different parameter signatures from their generics/defaults, so each gets its own help page.\n\n**Test specs written**: `.ralph/issues/793-document-methods-different-args.md` with 6 test cases:\n1. **Regression test**: `as_forecast_quantile.forecast_sample()` accepts `probs` and `type` args\n2. **Regression test**: `as_forecast_point.forecast_quantile()` extracts median without extra args\n3. **Regression test**: `get_pit_histogram.forecast_sample()` accepts `integers` and `n_replicates` args\n4. **Validation test**: `get_pit_histogram.forecast_quantile()` does not have `integers` as a formal parameter\n5. **Documentation structure test**: Separate `.Rd` files exist after the fix (with note that this may not fit project conventions)\n6. **Formals validation test**: Programmatically confirms the `.default` and `.forecast_sample` methods have different formal arguments\n\n**Triage table updated**: Has Tests set to `[x]` for issue #793. Pipeline checkpoint remains `[ ]` as many automatable issues still need test design."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":282,"cache_read_input_tokens":67321,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":282},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","uuid":"7eb4de53-a4cc-4f77-870b-cc39e71427f8"}
{"type":"result","subtype":"success","is_error":false,"duration_ms":270160,"duration_api_ms":285669,"num_turns":34,"result":"Done. Here's a summary of what was accomplished:\n\n**Issue processed**: #793 — \"How should we document methods that have different arguments than the default method?\"\n\n**Nature of the issue**: Documentation-only change — remove shared `@rdname` tags for three S3 methods that have different parameter signatures from their generics/defaults, so each gets its own help page.\n\n**Test specs written**: `.ralph/issues/793-document-methods-different-args.md` with 6 test cases:\n1. **Regression test**: `as_forecast_quantile.forecast_sample()` accepts `probs` and `type` args\n2. **Regression test**: `as_forecast_point.forecast_quantile()` extracts median without extra args\n3. **Regression test**: `get_pit_histogram.forecast_sample()` accepts `integers` and `n_replicates` args\n4. **Validation test**: `get_pit_histogram.forecast_quantile()` does not have `integers` as a formal parameter\n5. **Documentation structure test**: Separate `.Rd` files exist after the fix (with note that this may not fit project conventions)\n6. **Formals validation test**: Programmatically confirms the `.default` and `.forecast_sample` methods have different formal arguments\n\n**Triage table updated**: Has Tests set to `[x]` for issue #793. Pipeline checkpoint remains `[ ]` as many automatable issues still need test design.","stop_reason":null,"session_id":"c911bcbe-fd63-4b04-947b-21bb95a8a4d6","total_cost_usd":1.32864645,"usage":{"input_tokens":58,"cache_creation_input_tokens":49599,"cache_read_input_tokens":1279527,"output_tokens":8792,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":49599,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[]},"modelUsage":{"claude-opus-4-6":{"inputTokens":58,"outputTokens":8792,"cacheReadInputTokens":1279527,"cacheCreationInputTokens":49599,"webSearchRequests":0,"costUSD":1.16984725,"contextWindow":200000,"maxOutputTokens":32000},"claude-haiku-4-5-20251001":{"inputTokens":18970,"outputTokens":6419,"cacheReadInputTokens":640967,"cacheCreationInputTokens":34910,"webSearchRequests":0,"costUSD":0.15879919999999997,"contextWindow":200000,"maxOutputTokens":64000}},"permission_denials":[],"uuid":"015d77c9-337b-4ade-862d-91185aa4f44d"}

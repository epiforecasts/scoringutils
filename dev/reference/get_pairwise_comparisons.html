<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Obtain pairwise comparisons between models — get_pairwise_comparisons • scoringutils</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Obtain pairwise comparisons between models — get_pairwise_comparisons"><meta name="description" content="Compare scores obtained by different models in a pairwise tournament. All
combinations of two models are compared against each other based on the
overlapping set of available forecasts common to both models.
The input should be a scores object as produced by score(). Note that
adding additional unrelated columns can unpredictably change results, as
all present columns are taken into account when determining the set of
overlapping forecasts between two models.
The output of the pairwise comparisons is a set of mean score ratios,
relative skill scores and p-values.
The following illustrates the pairwise comparison process:



Mean score ratios
For every pair of two models, a mean score ratio is computed. This is simply
the mean score of the first model divided by the mean score of the second.
Mean score ratios are computed based on the set of overlapping forecasts
between the two models. That means that only scores for those targets are
taken into account for which both models have submitted a forecast.
(Scaled) Relative skill scores
The relative score of a model is the geometric mean of all mean score
ratios which involve that model.
If a baseline is provided, scaled relative skill scores will be calculated
as well. Scaled relative skill scores are simply the relative skill score of
a model divided by the relative skill score of the baseline model.
p-values
In addition, the function computes p-values for the comparison between two
models (again based on the set of overlapping forecasts). P-values can be
computed in two ways: based on a nonparametric Wilcoxon signed-rank test
(internally using wilcox.test() with paired = TRUE) or based on a
permutation test. The permutation test is based on the difference in mean
scores between two models. The default null hypothesis is that the mean score
difference is zero (see permutation_test()).
Adjusted p-values are computed by calling p.adjust() on the raw p-values.
The code for the pairwise comparisons is inspired by an implementation by
Johannes Bracher.
The implementation of the permutation test follows the function
permutationTest from the surveillance package by Michael Höhle,
Andrea Riebler and Michaela Paul."><meta property="og:description" content="Compare scores obtained by different models in a pairwise tournament. All
combinations of two models are compared against each other based on the
overlapping set of available forecasts common to both models.
The input should be a scores object as produced by score(). Note that
adding additional unrelated columns can unpredictably change results, as
all present columns are taken into account when determining the set of
overlapping forecasts between two models.
The output of the pairwise comparisons is a set of mean score ratios,
relative skill scores and p-values.
The following illustrates the pairwise comparison process:



Mean score ratios
For every pair of two models, a mean score ratio is computed. This is simply
the mean score of the first model divided by the mean score of the second.
Mean score ratios are computed based on the set of overlapping forecasts
between the two models. That means that only scores for those targets are
taken into account for which both models have submitted a forecast.
(Scaled) Relative skill scores
The relative score of a model is the geometric mean of all mean score
ratios which involve that model.
If a baseline is provided, scaled relative skill scores will be calculated
as well. Scaled relative skill scores are simply the relative skill score of
a model divided by the relative skill score of the baseline model.
p-values
In addition, the function computes p-values for the comparison between two
models (again based on the set of overlapping forecasts). P-values can be
computed in two ways: based on a nonparametric Wilcoxon signed-rank test
(internally using wilcox.test() with paired = TRUE) or based on a
permutation test. The permutation test is based on the difference in mean
scores between two models. The default null hypothesis is that the mean score
difference is zero (see permutation_test()).
Adjusted p-values are computed by calling p.adjust() on the raw p-values.
The code for the pairwise comparisons is inspired by an implementation by
Johannes Bracher.
The implementation of the permutation test follows the function
permutationTest from the surveillance package by Michael Höhle,
Andrea Riebler and Michaela Paul."><meta name="robots" content="noindex"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">scoringutils</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.2.2.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://raw.githubusercontent.com/epiforecasts/scoringutils/main/inst/manuscript/manuscript.pdf">scoringutils paper</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/Deprecated-functions.html">Deprecated functions</a></li>
    <li><a class="dropdown-item" href="../articles/Deprecated-visualisations.html">Deprecated Visualisations</a></li>
    <li><a class="dropdown-item" href="../articles/scoring-rules.html">Scoring rules in `scoringutils`</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/epiforecasts/scoringutils/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Obtain pairwise comparisons between models</h1>
      <small class="dont-index">Source: <a href="https://github.com/epiforecasts/scoringutils/blob/main/R/pairwise-comparisons.R" class="external-link"><code>R/pairwise-comparisons.R</code></a></small>
      <div class="d-none name"><code>get_pairwise_comparisons.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Compare scores obtained by different models in a pairwise tournament. All
combinations of two models are compared against each other based on the
overlapping set of available forecasts common to both models.</p>
<p>The input should be a <code>scores</code> object as produced by <code><a href="score.html">score()</a></code>. Note that
adding additional unrelated columns can unpredictably change results, as
all present columns are taken into account when determining the set of
overlapping forecasts between two models.</p>
<p>The output of the pairwise comparisons is a set of mean score ratios,
relative skill scores and p-values.</p>
<p>The following illustrates the pairwise comparison process:</p>
<p></p><div style="text-align: left">
  <img src="figures/pairwise-illustration.png" style="width:750px;max-width:100%;"></div>
<p><em>Mean score ratios</em></p>
<p>For every pair of two models, a mean score ratio is computed. This is simply
the mean score of the first model divided by the mean score of the second.
Mean score ratios are computed based on the set of overlapping forecasts
between the two models. That means that only scores for those targets are
taken into account for which both models have submitted a forecast.</p>
<p><em>(Scaled) Relative skill scores</em></p>
<p>The relative score of a model is the geometric mean of all mean score
ratios which involve that model.
If a baseline is provided, scaled relative skill scores will be calculated
as well. Scaled relative skill scores are simply the relative skill score of
a model divided by the relative skill score of the baseline model.</p>
<p><em>p-values</em></p>
<p>In addition, the function computes p-values for the comparison between two
models (again based on the set of overlapping forecasts). P-values can be
computed in two ways: based on a nonparametric Wilcoxon signed-rank test
(internally using <code><a href="https://rdrr.io/r/stats/wilcox.test.html" class="external-link">wilcox.test()</a></code> with <code>paired = TRUE</code>) or based on a
permutation test. The permutation test is based on the difference in mean
scores between two models. The default null hypothesis is that the mean score
difference is zero (see <code><a href="permutation_test.html">permutation_test()</a></code>).
Adjusted p-values are computed by calling <code><a href="https://rdrr.io/r/stats/p.adjust.html" class="external-link">p.adjust()</a></code> on the raw p-values.</p>
<p>The code for the pairwise comparisons is inspired by an implementation by
Johannes Bracher.
The implementation of the permutation test follows the function
<code>permutationTest</code> from the <code>surveillance</code> package by Michael Höhle,
Andrea Riebler and Michaela Paul.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">get_pairwise_comparisons</span><span class="op">(</span></span>
<span>  <span class="va">scores</span>,</span>
<span>  by <span class="op">=</span> <span class="st">"model"</span>,</span>
<span>  metric <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sets.html" class="external-link">intersect</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"wis"</span>, <span class="st">"crps"</span>, <span class="st">"brier_score"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">scores</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  baseline <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-scores">scores<a class="anchor" aria-label="anchor" href="#arg-scores"></a></dt>
<dd><p>An object of class <code>scores</code> (a data.table with
scores and an additional attribute <code>metrics</code> as produced by <code><a href="score.html">score()</a></code>).</p></dd>


<dt id="arg-by">by<a class="anchor" aria-label="anchor" href="#arg-by"></a></dt>
<dd><p>Character vector with column names that define the grouping level
for the pairwise comparisons. By default (<code>model</code>), there will be one
relative skill score per model. If, for example,
<code>by = c("model", "location")</code>. Then you will get a
separate relative skill score for every model in every location. Internally,
the data.table with scores will be split according <code>by</code> (removing "model"
before splitting) and the pairwise comparisons will be computed separately
for the split data.tables.</p></dd>


<dt id="arg-metric">metric<a class="anchor" aria-label="anchor" href="#arg-metric"></a></dt>
<dd><p>A string with the name of the metric for which
a relative skill shall be computed. By default this is either "crps",
"wis" or "brier_score" if any of these are available.</p></dd>


<dt id="arg-baseline">baseline<a class="anchor" aria-label="anchor" href="#arg-baseline"></a></dt>
<dd><p>A string with the name of a model. If a baseline is
given, then a scaled relative skill with respect to the baseline will be
returned. By default (<code>NULL</code>), relative skill will not be scaled with
respect to a baseline model.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Additional arguments for the comparison between two models. See
<code><a href="compare_two_models.html">compare_two_models()</a></code> for more information.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A data.table with the results of pairwise comparisons
containing the mean score ratios (<code>mean_scores_ratio</code>),
unadjusted (<code>pval</code>) and adjusted (<code>adj_pval</code>) p-values, and relative skill
values of each model (<code>..._relative_skill</code>). If a baseline model is given
then the scaled relative skill is reported as well
(<code>..._scaled_relative_skill</code>).</p>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Nikos Bosse <a href="mailto:nikosbosse@gmail.com">nikosbosse@gmail.com</a></p>
<p>Johannes Bracher, <a href="mailto:johannes.bracher@kit.edu">johannes.bracher@kit.edu</a></p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">scores</span> <span class="op">&lt;-</span> <span class="fu"><a href="score.html">score</a></span><span class="op">(</span><span class="fu"><a href="as_forecast.html">as_forecast_quantile</a></span><span class="op">(</span><span class="va">example_quantile</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> <span style="color: #00BBBB;">ℹ</span> Some rows containing NA values may be removed. This is fine if not</span>
<span class="r-msg co"><span class="r-pr">#&gt;</span>   unexpected.</span>
<span class="r-in"><span><span class="va">pairwise</span> <span class="op">&lt;-</span> <span class="fu">get_pairwise_comparisons</span><span class="op">(</span><span class="va">scores</span>, by <span class="op">=</span> <span class="st">"target_type"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">pairwise2</span> <span class="op">&lt;-</span> <span class="fu">get_pairwise_comparisons</span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="va">scores</span>, by <span class="op">=</span> <span class="st">"target_type"</span>, baseline <span class="op">=</span> <span class="st">"EuroCOVIDhub-baseline"</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="plot_pairwise_comparisons.html">plot_pairwise_comparisons</a></span><span class="op">(</span><span class="va">pairwise</span>, type <span class="op">=</span> <span class="st">"mean_scores_ratio"</span><span class="op">)</span> <span class="op">+</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html" class="external-link">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">target_type</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="get_pairwise_comparisons-1.png" alt="" width="700" height="433"></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://followtheargument.org/" class="external-link">Nikos Bosse</a>, <a href="https://www.samabbott.co.uk/" class="external-link">Sam Abbott</a>, Hugo Gruson, Sebastian Funk.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.9000.</p>
</div>

    </footer></div>





  </body></html>


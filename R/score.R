#' @title Evaluate forecasts
#'
#' @description The function `score` allows automatic scoring of forecasts and
#' wraps the lower level functions in the \pkg{scoringutils} package.
#'
#' It can be used to score forecasts in a quantile-based, sample-based, or
#' binary format. To obtain an overview of what input is expected, have a look
#' at the [example_quantile], [example_continuous], [example_integer], and
#' [example_binary] data sets.
#'
#' You can (and should) check your input using the function [check_forecasts()]
#' before scoring.
#'
#' To obtain a quick overview of the evaluation metrics used, have a look at the
#' [metrics_summary] data included in the package.
#'
#' @param data A data.frame or data.table with the predictions and observations.
#' The following columns need to be present:
#' \itemize{
#'   \item `true_value` - the true observed values
#'   \item `prediction` - predictions or predictive samples for one
#'   true value. (You only don't need to provide a prediction column if
#'   you want to score quantile forecasts in a wide range format.)}
#' For integer and continuous forecasts a `sample` column is needed:
#' \itemize{
#'   \item `sample` - an index to identify the predictive samples in the
#'   prediction column generated by one model for one true value. Only
#'   necessary for continuous and integer forecasts, not for
#'   binary predictions.}
#' For a quantile-format forecast you should provide a column called `quantile`:
#'   - `quantile`: quantile to which the prediction corresponds
#' @param metrics the metrics you want to have in the output. If `NULL` (the
#' default), all available metrics will be computed. For a list of available
#' metrics see [available_metrics()]
#' @param ... additional parameters passed down to lower-level functions.
#' For example, the following arguments can change how weighted interval
#' scores are computed:
#' - `count_median_twice` that controls how the interval scores for different
#' intervals are summed up. This should be a logical (default is `FALSE`) that
#' indicates whether or not to count the median twice when summarising.
#' This would conceptually treat the
#' median as a 0% prediction interval, where the median is the lower as well as
#' the upper bound. The alternative is to treat the median as a single quantile
#' forecast instead of an interval. The interval score would then
#' be better understood as an average of quantile scores.)
#'
#' @return A data.table with unsummarised scores. There will be one score per
#' quantile or sample, which is usually not desired, so you should always run
#' [summarise_scores()] on the unsummarised scores.
#'
#' @importFrom data.table ':=' as.data.table
#'
#' @examples
#' library(magrittr) # pipe operator
#'
#' example_quantile %>%
#'   check_forecasts %>%
#'   score() %>%
#'   add_coverage(by = c("model", "target_type")) %>%
#'   summarise_scores(by = c("model", "target_type")) %>%
#'   summarise_scores(fun = signif, digits = 2)
#'
#' # forecast formats with different metrics
#' score(example_binary)
#' score(example_quantile)
#' score(example_integer)
#' score(example_continuous)
#' @author Nikos Bosse \email{nikosbosse@@gmail.com}
#' @references Funk S, Camacho A, Kucharski AJ, Lowe R, Eggo RM, Edmunds WJ
#' (2019) Assessing the performance of real-time epidemic forecasts: A
#' case study of Ebola in the Western Area region of Sierra Leone, 2014-15.
#' PLoS Comput Biol 15(2): e1006785. <doi:10.1371/journal.pcbi.1006785>
#' @export

score <- function(data,
                  metrics = NULL,
                  ...) {

  # preparations ---------------------------------------------------------------
  # check relevant columns and remove NA values in true_values and prediction
  data <- check_clean_data(data, verbose = FALSE)

  # check metrics are available or set to all metrics --------------------------
  metrics <- check_metrics(metrics)

  # obtain a value for the unit of a single observation ------------------------
  forecast_unit <- get_unit_of_forecast(data)

  # check prediction and target type -------------------------------------------
  prediction_type <- get_prediction_type(data)
  target_type <- get_target_type(data)

  # Score binary predictions ---------------------------------------------------
  if (target_type == "binary") {
    scores <- score_binary(
      data = data,
      forecast_unit = forecast_unit,
      metrics = metrics
    )
  }

  # Score quantile predictions -------------------------------------------------
  if (prediction_type == "quantile") {
    scores <- score_quantile(
      data = data,
      forecast_unit = forecast_unit,
      metrics = metrics,
      ...
    )
  }

  # Score integer or continuous predictions ------------------------------------
  if (prediction_type %in% c("integer", "continuous") && (target_type != "binary")) {
    scores <- score_sample(
      data = data,
      forecast_unit = forecast_unit,
      metrics = metrics,
      prediction_type = prediction_type
    )
  }

  return(scores[])
}
